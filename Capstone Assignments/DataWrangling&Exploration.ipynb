{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYfV_TEsk400",
        "outputId": "b15358a9-dfa0-4a9c-dde9-b65ce80045b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\n            Seniority level\\n          ']\n",
            "['\\n            Not Applicable\\n          ']\n",
            "['\\n            Employment type\\n          ']\n",
            "['\\n            Full-time\\n          ']\n",
            "['\\n              Job function\\n            ']\n",
            "['\\n              Engineering\\n            ']\n",
            "['\\n              Industries\\n            ']\n",
            "['\\n            Construction and Machinery Manufacturing\\n            ']\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import requests\n",
        "\n",
        "# request web page\n",
        "resp = requests.get(\"https://www.linkedin.com/jobs/view/3837175965/?alternateChannel=search&refId=gEpk5%2BQwe78lnqcwlOXxOA%3D%3D&trackingId=3Z6zBAIEXLuPRfFPctXz5A%3D%3D\")\n",
        "\n",
        "# get the response text. in this case it is HTML\n",
        "html = resp.text\n",
        "\n",
        "# parse the HTML\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "spans = soup.find_all('span', {'class': \"description__job-criteria-text description__job-criteria-text--criteria\"})\n",
        "for span in spans:\n",
        "  #for key in span.__dict__.keys():\n",
        "  #print(f\"key {key}\")\n",
        "  #print(f\"value {span.__dict__[key]}\")\n",
        "  parent_tags = span.parent.find_all(\"h3\", {'class': \"description__job-criteria-subheader\"})\n",
        "  for tag in parent_tags:\n",
        "    print(tag.contents)\n",
        "  #print(span.parent.find_all(\"h3\", {'class': \"description__job-criteria-subheader\"}))\n",
        "  print(span.contents)\n",
        "\n",
        "\n",
        "#items = soup.select('option[value]')\n",
        "#print(items)\n",
        "'''links = soup.find_all(\"a\") # Find all elements with the tag <a>\n",
        "for link in links:\n",
        "  print(\"Link:\", link.get(\"href\"), \"Text:\", link.string)'''\n",
        "\n",
        "\n",
        "# print the HTML as text\n",
        "x = soup.get_text().split('\\n')\n",
        "\n",
        "characters_per_line = []\n",
        "\n",
        "# Extract text content from the HTML\n",
        "text_content = soup.get_text()\n",
        "\n",
        "# Split the text into lines\n",
        "lines = text_content.splitlines()\n",
        "\n",
        "# Calculate the number of characters in each line\n",
        "for line in lines:\n",
        "  characters_per_line.append(len(line))\n",
        "\n",
        "'''for i in set(characters_per_line):\n",
        "  if i>50:\n",
        "    list_index = characters_per_line.index(i)\n",
        "    print(characters_per_line[list_index])\n",
        "    print(lines[list_index])'''\n",
        "\n",
        "body_len = max(characters_per_line)\n",
        "body_idx = characters_per_line.index(body_len)\n",
        "body_text = lines[body_idx]\n",
        "#print(body_text)\n",
        "\n",
        "\n",
        "# Remove elements with only whitespace\n",
        "filtered_list = [string for string in x if string.strip()]\n",
        "\n",
        "#print(filtered_list)\n",
        "\n",
        "for i in filtered_list:\n",
        "  if i.find('Join now') != -1 and filtered_list[filtered_list.index(i) + 1].find('Sign in') != -1:\n",
        "    position = filtered_list[filtered_list.index(i) + 2]\n",
        "    company = filtered_list[filtered_list.index(i) + 3]\n",
        "    location = filtered_list[filtered_list.index(i) + 4]\n",
        "    break\n",
        "\n",
        "for i in filtered_list:\n",
        "  if i.find('Base pay range') != -1:\n",
        "    salary_index = filtered_list.index(i) + 1\n",
        "    salary = filtered_list[salary_index]\n",
        "    salary = salary.lstrip()\n",
        "    salary = \"N/A\" if (salary.find(\"$\") == salary.find(\"€\") == salary.find(\"£\") == -1) else salary\n",
        "    break\n",
        "  else:\n",
        "    salary = \"N/A\"\n",
        "\n",
        "\n",
        "#print(f\"position is {position}\")\n",
        "#print(f\"company is {company}\")\n",
        "#print(f\"location is {location}\")\n",
        "#print(f\"salary is {salary}\")\n",
        "\n",
        "\n",
        "#print(soup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGqNfJxy7hNG",
        "outputId": "bc3ac090-e265-409f-aa05-150e786c7c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "position is Embedded Cybersecurity Software Engineer\n",
            "company is Caterpillar Inc.\n",
            "location is Chillicothe, IL\n",
            "salary is N/A\n"
          ]
        }
      ],
      "source": [
        "# get position, company, location, pay\n",
        "\n",
        "x = soup.get_text().split('\\n')\n",
        "\n",
        "# Remove elements with only whitespace\n",
        "filtered_list = [string for string in x if string.strip()]\n",
        "\n",
        "for i in filtered_list:\n",
        "  if i.find('Join now') != -1 and filtered_list[filtered_list.index(i) + 1].find('Sign in') != -1:\n",
        "    position = filtered_list[filtered_list.index(i) + 2]\n",
        "    company = filtered_list[filtered_list.index(i) + 3]\n",
        "    location = filtered_list[filtered_list.index(i) + 4]\n",
        "    break\n",
        "\n",
        "for i in filtered_list:\n",
        "  if i.find('Base pay range') != -1:\n",
        "    salary_index = filtered_list.index(i) + 1\n",
        "    salary = filtered_list[salary_index]\n",
        "    salary = salary.lstrip()\n",
        "    salary = \"N/A\" if (salary.find(\"$\") == salary.find(\"€\") == salary.find(\"£\") == -1) else salary\n",
        "    break\n",
        "  else:\n",
        "    salary = \"N/A\"\n",
        "\n",
        "\n",
        "print(f\"position is {position}\")\n",
        "print(f\"company is {company}\")\n",
        "print(f\"location is {location}\")\n",
        "print(f\"salary is {salary}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZV726Fj8DpJ",
        "outputId": "d6161a1f-db04-4998-b6eb-f1c5691b58d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Career Area: Engineering Job Description:  Your Work Shapes the World at Caterpillar Inc. When you join Caterpillar, you're joining a global team who cares not just about the work we do – but also about each other. We are the makers, problem solvers, and future world builders who are creating stronger, more sustainable communities. We don't just talk about progress and innovation here – we make it happen, with our customers, where we work and live. Together, we are building a better world, so we can all enjoy living in it. Your Work Shapes the World Whether it be groundbreaking products, best in class solutions or creating a lifelong career, you can do the work that matters at Caterpillar. With a 95-year legacy of quality and innovation and 150 locations in countries around the world, your impact spans the globe.When you join Caterpillar, you are joining a team of makers, innovators, and doers. We are the people who roll up our sleeves and do the work to build a better world. We don’t just talk about progress and innovation. We make it happen. And we are proud of that, because it helps our customers build and power the world we live in – the roads, hospitals, homes, and infrastructure. Without a dedicated workforce Caterpillar could not effectively meet our customer’s needs. Join us. Description Come work on the Embedded Product Cybersecurity team for Caterpillar machines & engines. Our team is developing embedded cybersecurity solutions & software for Caterpillar Display, Telematics, Machine, Engine, & Autonomy product lines that will be used for years to come.The ideal candidate will be passionate about developing cybersecurity software solutions for Caterpillar’s embedded product line. They must also be willing to learn new areas of expertise in cybersecurity while working with multiple systems, software, component, and product teams to produce world class cybersecurity solutions for Caterpillar.You will help design, develop, configure, and test our security-enabling software that targets a wide range of scopes, including full-stack ECU component software, system-wide onboard security software, offboard internal development tools, and ECU supplier manufacturing tools. You will participate in iterative development and fast delivery of features utilizing up-to-date technologies and practices like Linux, Python, C/C++, Agile, and emergent design. Join us and be a part of this exciting team! Job Duties This role will be responsible for developing, designing, implementing, and testing software of embedded devices and systems; as well as monitoring and enhancing the efficiency and stability of the systems. Specific Duties And Responsibilities:  Gathering and analyzing user/client requirements to create the software requirements specification (SRS) document.  Writing and implementing source codes of embedded systems and enhancing code samples of existing systems.  Testing and debugging embedded system software using different tools/methods available to improve code quality and optimize system performance.  Collaborating with other teams to provide post-production support.  Design & Document Cybersecurity features  Develop Embedded Cybersecurity software solutions that will be implemented into production software  Validate Embedded Cybersecurity software features used across Caterpillar’s product line  Knowledge and capability to identify Cybersecurity software risks  Skill Descriptors  Effective Communications:  Understanding of effective communication concepts, tools and techniques; ability to effectively transmit, receive, and accurately interpret ideas, information, and needs through the application of appropriate communication behaviors. Level Working Knowledge:  Delivers helpful feedback that focuses on behaviors without offending the recipient. Listens to feedback without defensiveness and uses it for own communication effectiveness. Makes oral presentations and writes reports needed for own work. Avoids technical jargon when inappropriate. Looks for and considers non-verbal cues from individuals and groups. Teamwork:  Knowledge of the necessity and value of teamwork; experience with; ability to work cooperatively towards shared goals and being supportive of others at all levels. Level Working Knowledge:  Explains own role and responsibility within team. Actively participates in team meetings. Shares information, knowledge, and experiences openly and proactively. Describes team mission and objectives in the context of results to be achieved. Demonstrates open, friendly, accepting, and supportive behaviors with team members. Software Development:  Knowledge of software development tools and activities; ability to produce software products or systems in line with product requirements. Level Working Knowledge:  Describes common tools for component-based, object-oriented development. Describes the objectives, activities and results of unit testing. Has developed programs in a specific language and for a specific platform. Interprets functional and technical blueprints; participates in structuring technical components. Participates in technical and code reviews. System Testing:  Knowledge of system and software testing; ability to design, plan and execute system testing strategies and tactics to ensure the quality of software at all stages of the system life cycle. Level Working Knowledge:  Supports the project leader in developing and executing system test plans. Evaluates system documentation and user manuals for usability, accuracy and completeness. Executes test cases, analyzes test results and reports on findings regularly. Tests system components for compliance with functional requirements. Participates in the testing of a system's ability to recover from hardware or software failures. Technical Troubleshooting:  Knowledge of technical troubleshooting approaches, tools and techniques; ability to anticipate, recognize, and resolve technical issues on hardware, software, application or operation. Level Working Knowledge:  Discovers, analyzes, and resolves hardware, software or application problems. Works with vendor-specific diagnostic guides, tools and utilities. Handles calls related to product features, applications, and compatibility standards. Analyzes code, logs, and current systems as part of advanced troubleshooting. Records and reports specific technical problems, solving processes and tools that have been used. Basic Qualifications  BSEE, BSCE, or BSCS  2+ years of development experience using C++, C, and/or Java programming languages  2+ years of experience with scripting using Python  1 year experience working in the Linux environment  1 year experience with Ethernet, TCP/IP, Wi-Fi, and analysis tools such as Wireshark  Prior experience with embedded software development, design, and architecture  Top Candidates will also have  Desire to work in a fast-paced Agile team environment  Experience in Cybersecurity  Experience with GIT configuration management tool  Ability to read electrical schematics  Experience with Linux kernel & Linux device drivers  Experience with RTOS development (i.e. Free RTOS)  Experience with CAN, J1939, and other data link protocols  Experience using Design Patterns and Object Oriented programming  Experience with developing Unit Tests and Test Driven Development  Experience using debugging tools for embedded systems (e.g. Lauterbach, GDB)  Additional Information The location for this position is Mossville, ILDomestic relocation assistance is available for this position.This position will require less than 10% travel Employee benefit details Our goal at Caterpillar is for you to have a rewarding career. Our teams are critical to the success of our customers who build a better world.Here you earn more than just a salary because we value your performance. We offer a total rewards package that provides benefits on day one (medical, dental, vision, RX, and 401K) along with the potential of an annual bonus.Additional benefits include paid vacation days and paid holidays (prorated based upon hire date). Final details Please frequently check the email associated with your application, including the junk/spam folder, as this is the primary correspondence method. If you wish to know the status of your application – please use the candidate log-in on our career website as it will reflect any updates to your status. This employer is not currently hiring foreign national applicants that require or will require sponsorship tied to a specific employer, such as H, L, TN, F, J, E, O. As a global company, Caterpillar offers many job opportunities outside of the U.S. which can be found through our employment website at   www.Caterpillar.com/Careers   . For more information, visit caterpillar.com. To connect with us on social media, visit caterpillar.com/social-media Posting Dates: February 21, 2024 - March 6, 2024Any offer of employment is conditioned upon the successful completion of a drug screen.EEO/AA Employer. All qualified individuals - Including minorities, females, veterans and individuals with disabilities - are encouraged to apply.Not ready to apply? Join our Talent Community .\n"
          ]
        }
      ],
      "source": [
        "# get main body text\n",
        "\n",
        "characters_per_line = []\n",
        "\n",
        "# Extract text content from the HTML\n",
        "text_content = soup.get_text()\n",
        "\n",
        "# Split the text into lines\n",
        "lines = text_content.splitlines()\n",
        "\n",
        "# Calculate the number of characters in each line\n",
        "for line in lines:\n",
        "  characters_per_line.append(len(line))\n",
        "\n",
        "'''for i in set(characters_per_line):\n",
        "  if i>50:\n",
        "    list_index = characters_per_line.index(i)\n",
        "    print(characters_per_line[list_index])\n",
        "    print(lines[list_index])'''\n",
        "\n",
        "body_len = max(characters_per_line)\n",
        "body_idx = characters_per_line.index(body_len)\n",
        "body_text = lines[body_idx]\n",
        "print(body_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rGfdU9b8VYy",
        "outputId": "6169f27a-6bf4-42a5-9a2c-8a3e1c1c2699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\n            Seniority level\\n          ']\n",
            "['\\n            Not Applicable\\n          ']\n",
            "['\\n            Employment type\\n          ']\n",
            "['\\n            Full-time\\n          ']\n",
            "['\\n              Job function\\n            ']\n",
            "['\\n              Information Technology\\n            ']\n",
            "['\\n              Industries\\n            ']\n",
            "['\\n            Technology, Information and Internet\\n            ']\n"
          ]
        }
      ],
      "source": [
        "#get seniority level, employment type, job function, and industries\n",
        "\n",
        "spans = soup.find_all('span', {'class': \"description__job-criteria-text description__job-criteria-text--criteria\"})\n",
        "for span in spans:\n",
        "  #for key in span.__dict__.keys():\n",
        "  #print(f\"key {key}\")\n",
        "  #print(f\"value {span.__dict__[key]}\")\n",
        "  parent_tags = span.parent.find_all(\"h3\", {'class': \"description__job-criteria-subheader\"})\n",
        "  for tag in parent_tags:\n",
        "    print(tag.contents)\n",
        "  #print(span.parent.find_all(\"h3\", {'class': \"description__job-criteria-subheader\"}))\n",
        "  print(span.contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4aKWukh8ssv"
      },
      "source": [
        "I've tried and tried and tried to extract the work location (remote, hybrid, or on-site) but did not succeed. I wanted to since it definitely affects job desirability, particularly for locales that I'm not crazy about (I wouldn't mind working for a company in Nebraska if I can do the job from California). Since this info is probably not one of the more important features though (or at least I don't see how it would have a strong relationship with job function or duties) I am going to move on to scraping other data. It will also be possible to infer this info for some of the job postings and add it to the dataframe (features matrix) later on with the LLM summarizing the body text, so I don't think it's a big deal that I cannot extract this right now.\n",
        "\n",
        "So what else are we still missing? Number of employees and company's industry is still missing, but that's not super useful information for our purposes. We'll at least attempt to extract that info but if we can't no biggie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dJ-1NxAGKFo"
      },
      "source": [
        "The info mentioned above has the same story as the work location; I cannot figure out how to extract it. We should focus on extracting the skills list given in the top section of the job posting on LinkedIn. Hopefully we can do this, but if not we may have to keep trying with beautiful soup or parsing the html some other way, or we might consider leveraging the LinkedIn API repo on GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6_dN_ZLG4Mi"
      },
      "source": [
        "It turns out that the information I am trying to extract programmatically with the requests library is only visible while logged into LinkedIn. Just looking at the job posting from a browser where I haven't logged into LinkedIn, that information is not present and this is why I am not able to extract using the method I have relied on so far (simple requests and parsing html). The information I want that I see while logged into LinkedIn is not merely buried within the html source and requires more work; it is simply not there. So I don't think Selenium makes getting the info I have been failing to collect any more straightforward (although there is probably a way to log into LI with requests or with Selenium and then iterate over the job postings to extract the desired stuff). It is probably easier to log into LinkedIn using some LinkedIn API library, though there may not be any other useful info from the job post the API will allow us to get that we haven't already gotten while not logged in (via basic request.get of url). If we don't go the extra mile to extract these extra fields, I think it will be fine, though our model probably won't be as strong. I think there is a lot of good info in the body that we can use OpenAI or something equivalent to summarize and do further feature extraction.\n",
        "\n",
        "I also think we could go on and on and on enhancing and growing our methods just in the data collection phase to the point of delaying project completion by weeks or even months; we haven't even worked with the LLM yet to do text summarization. I think it would be wiser to move onto that next step because it would achieve a lot more of the feature extraction for us; this will allow us to get a working protoype running sooner, even if the data isn't even close to being optimized. That way we could get version 1 of the project done sooner and enjoy our work more. Then I can always come back to it after the first version of this project is up and running and improve the data collection phase, then retrain models, and modify the whole pipeline as needed. I think Semih would agree. Focus on prototyping now even if the data isn't great."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKrKT19UXR3Z"
      },
      "source": [
        "So the next step will be to generate a pandas dataframe with the following fields as features:\n",
        "\n",
        "position, company, location, salary range, seniority level, employment type, job function, industries, description.\n",
        "\n",
        "From there, the LLM we use will summarize the description field to generate new fields (make more features) and we should think carefully about what additional info we want the LLM to extract from the description and populate additional columns with; let us do this by analyzing what information is in the test job posting (Robotics Engineer - Surgical Robotics , Barrington James). It would be prudent to look at several example postings so that we have good coverage of the possibilities. After we figure out and decide exactly what the LLM should look for in each body text, we will need to be clever and very explicit about the prompt we send it, as well as careful about how we process the response in order to further extract features; once we've brainstormed and prototyped this step we should come back to the previous step involving web scraping and test our methods out on other job postings to make sure they are robust. But for now we will brainstorm the goal of the prompt we send to the LLM. Fun!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYJfeMp93CY5"
      },
      "source": [
        "So after brainstorming and trying to encompass all information that could possibly be conveyed in the job posting, I am thinking that the final dataframe after feature extraction should have 20 columns, 1 of them being the target variable (job desirability) which is the manual label for each job posting. The fields should look something like:\n",
        "\n",
        "\n",
        "```\n",
        "FEATURE,example entry\n",
        "Seniority level,Mid-Senior level\n",
        "Employment type,Full-time\n",
        "Job function,Engineering and Information Technology\n",
        "Industries,Services for Renewable Energy\n",
        "position name,Robotics Engineer – Surgical Robotics\n",
        "company,Barrington James\n",
        "location,\"New York, United States\"\n",
        "salary/compensation range,\"$130,000.00/yr - $200,000.00/yr\"\n",
        "Company description,\n",
        "Responsibilities,\n",
        "Goals/objectives,\n",
        "Description of team/who you will be working with,\n",
        "Required qualifications,\n",
        "Preferred qualifications,\n",
        "Benefits,\n",
        "Work schedule/hours,\n",
        "Travel part of job?,\n",
        "\"Work arrangement (hybrid, on-site, remote?)\",\n",
        "Other/misc info,\n",
        "Desirability rating (1-3) (manually labelled target),3\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPt15PVy0zEi"
      },
      "source": [
        "See these screenshots I've uploaded to Drive showing my first attempt at getting ChatGPT to summarize and organize the info relevant to these fields in a table, from the body text concatenated with the other info I was able to scrape using requests and beautifulsoup. : https://drive.google.com/drive/folders/1XUGI23L5b4LnqQ9gTBb7vPrAgC6iBNCs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPI1pbUVH2s4"
      },
      "source": [
        "After some trial-and-error experimentation with asking ChatGPT to extract and organize the info, I have gotten the best output with the following prompt:\n",
        "\n",
        "\"Take the following text from a job posting and extract all info related to the following fields: Employment type, Job function, Industries, position name, company, location, salary/compensation range, most notable Responsibilities, key Goals/objectives, name of department or team, Most notable qualifications, most notable Benefits, Work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put \"N/A\". Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Here is the text from the job posting:  \n",
        "\"job posting text\" \"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAnEhd6qNYZ7"
      },
      "source": [
        "Which yielded the output shown here: https://drive.google.com/drive/folders/1-SwA1jNScYyt3v7dAOjYovhAf3nAb8L7 where \"job posting text\" was the following:\n",
        "\n",
        "\"Seniority level: Not Applicable\n",
        "Employment type: Full-time\n",
        "Job function: Information Technology, Consulting, and Engineering\n",
        "Industries: Software Development, IT Services and IT Consulting, and Technology, Information and Internet\n",
        "\n",
        "posting name: SDE - Amazon Robotics, Robotic\n",
        "company: Amazon\n",
        "location: North Reading, MA\n",
        "salary: N/A\n",
        "\n",
        "DescriptionDo you want to have a worldwide impact in Robotics? The Vulcan Stow team at Amazon Robotics builds high-performance, real-time robotic systems that can perceive, learn, and act intelligently alongside humans—at Amazon scale. We invent and scale AI systems for robotics in fulfillment.We are seeking software engineers to help with our initial robotic deployments. This includes building computer vision systems, ML and AI models, robotic control and motion planning, and process management. It also includes end-to-end ownership of decision explanation, fault detection, monitoring, A/B testing, large scale model training, simulation, hardware integration, and more. This work spans prototypes in the lab as well as wide-deployment systems. As a software engineer, you will help plan the roadmap, design ML systems, implement, test, and monitor services in our robotic fleet.We are open to hiring candidates to work out of one of the following locations:North Reading, MA, USABasic Qualifications 3+ years of non-internship professional software development experience 2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience Experience programming with at least one software programming language Experience programming with at least one modern language such as Java, C++, or C# including object-oriented design 1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.Preferred Qualifications 3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience Bachelor's degree in computer science or equivalent Robotics experience along with experience with one of the following: * Production-level machine learning * Computer vision (e.g. a variety of neural network architectures using TensorFlow or MxNet, fusion with other sensors) * Hardware integration (e.g. hardware release cycles, heterogeneous hardware fleets) * Building and testing real-time or safety-critical systemsAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Company - Amazon.com Services LLCJob ID: A2423847\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU3Ysg_TPVRz"
      },
      "source": [
        "Now I'm going to look at the original job posting and see what valuable information may have been lost in this process, and there is a fair amount. The information that was lost includes:\n",
        "\n",
        "-description of good or service you will work on\n",
        "-some details of the job (objectives)\n",
        "-broader role name (e.g. SW Engineer)\n",
        "-some responsibilities\n",
        "-some qualifications, and preferred qualifications and requiried/basic get mixed together.\n",
        "\n",
        "In light of this, we will revise our prompt so that it doesn't lose these valuable details and so that it will include new fields for the following:\n",
        "\n",
        "-Description of product/service\n",
        "-broader role name\n",
        "-split most notable qualifications into required and preferred qualifications\n",
        "\n",
        "We will try the following revised prompt:\n",
        "\n",
        "\"Take the following text from a job posting and extract all info related to the following fields: Employment type, Job function, description of product/service, Industries, position name, broader role name, company, location, salary/compensation range, Responsibilities, Goals/objectives, name of department or team, required qualifications, preferred qualifications, Benefits, Work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put \"N/A\". Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Here is the text from the job posting:\n",
        "\"job posting text\" \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEOoKH_JUtnV"
      },
      "source": [
        "In my opinion, this seemed to produce better output. Follow this link for a screenshot of that output: https://drive.google.com/drive/folders/1vt4jhysrwpscVEipweApasw8K1z5tyoA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBY0IPwvXvlU"
      },
      "source": [
        "There is no doubt still some information loss and there are mistakes in the categorizations, but I don't think we can make the output much better. We will test out this revised prompt with another sample of scraped text. Here is the scraped text:\n",
        "\n",
        "\"Seniority level: Entry level\n",
        "Employment type: Full-time\n",
        "Job function: Engineering and Information Technology\n",
        "Industries: Business Consulting and Services\n",
        "\n",
        "posting name: Python Software Engineer (Robotics/Mechatronics)\n",
        "company: Fresh Consulting\n",
        "location: Redmond, WA\n",
        "salary: $30.00/hr - $45.00/hr\n",
        "\n",
        "Fresh Consulting is a design-led, software development and hardware engineering company, offering end-to-end digital services to help companies innovate. We bring together amazing UX designers, sophisticated developers, digital strategists, and top-notch engineers to help companies create fresh experiences that connect humans, systems, and machines. We’ve been growing fast and need someone to help us continue to manage the delivery of high-quality work in a fast-paced environment. See more at freshconsulting.comVisit freshconsulting.com/portfolio to see our project work across several industries.Title: Python Software Engineer (Robotics/Mechatronics)Duration: Project Based Long-Term Vendor ContractLocation: Redmond, WABenefits: Employee benefits at 100% including Medical, PTO, Holiday Pay, 401K Plan and much more!Hours: Minimum 40 Hours/WeekRole Work with the hardware and software teams to integrate various software/hardware components and develop UI front-end for test stations. Integrate motion, lighting, and imaging controllers into test suites. Use technical expertise to investigate, troubleshoot, and verify defects. Be an active team player, while working independently. Proactively reach out to partners and ask relevant questions when blocked. Learn new systems and tools. Document and improve code quality. Working on python and computer vision applications.The Position - Focus on development and execution of test station applications for System validation for AR/VR devices. The Ideal Person will be a software developer with either robotics and/or mechatronics background that have built test stations for manufacturing specifically optical products.Skills 0-1+ years experience. Clear communication, common sense, smart and outside the box thinking. Very strong Python skills. Strong programming and problem solving skills are a must. Understanding of HW, Embedded Systems, Mechatronics, Robotics and related. Understanding of hardware/software interoperability. Understanding of software engineering principles, code version control, and Python. Strong troubleshooting skills to root cause issues. Self-starter, and someone who when they get stuck is willing to ask for help and not just flail around trying to solve it themselves. Good communication skills, both written and oral. Works well with other people and a willingness to learn ones.Education: BSCSE, MSCSE preferred.FRESH-- Work on engineering and research assignments with F500 companies and startups. The relationships that we have created with our clients are one of a kind. We help solve problems in many technologies focusing on R&D, product development, and manufacturing. We work at the most cutting-edge and latest technologies from AR/VR to Autonomous technologies. Closely working with our clients, we believe that long term investments are extremely important to maintain the culture we together have created.We’re a handpicked team of Engineers, digital strategist, designers, and developers united together in creating a fresh experience. Whether we are strategizing, designing, developing, or analyzing, our integrated team works as an extension of yours to improve your impact, your usability, and your customer conversion. In the process, we collaborate with you to get to know your business, understand your industry, and incorporate your big ideas into memorable experiences that keep your customers coming back for more.Fresh Consulting is a participating E-Verify company.freshconsulting.comCompensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Range $30/hr - $45/hr+\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KCwF2X2ZsJ2"
      },
      "source": [
        "We got decent output but some of the statements/sentences exceeded 5 words. See the screenshot linked here: https://drive.google.com/drive/folders/1GC2M-c90B4JE69dNOlakyuGbXcvdatW4. We need to be more explicit about this constraint in our prompt.\n",
        "\n",
        "We tried revising this specific instruction in the prompt in various ways but we weren't able to force Chat to output pieces of information that are always 5 words or less. We might have to just tolerate this and throw away pieces of information that exceed 5 words when processing our data into something we can feed a decision tree. This is unfortunate but hopefully won't harm model performance too much. We shouldn't labor over generating our text data too much because we will probably need to devote a lot time devising a strategy/mechanism for encoding sets of words up to 5 and we need order not matter. Maybe we can just use bag of words in some way? But maybe using TFIDF or something similar would be better. How we are going to mathematically represent textual data for each column is still extremely murky. One thing is clear: we are going to have a LOT of columns if we do this. Luckily, the plan is not to have too many rows or job postings in the dataset. I'm thinking something on the order of a few hundred, but that expectation could very well change. Maybe we will decide to do something simpler and not use ChatGPT at all for feature extraction, but instead do something more basic with count vectorization of words (like BOW or TFIDF) on the entire body text of the job posting so that instead of having potentially 10 to 20 x N columns where N is the size of the vocab space, we only need N columns plus a few more for the designated pieces of information we ARE able to scrape like position name, company, locale, salary. Again, this would take ChatGPT or other LLM-based summarization task out of the data processing step and would substantially shrink the complexity of the dataset/feature space. I'm just afraid that going too simple will result in a crap model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri8481wJngl6"
      },
      "source": [
        "This got me thinking about how to represent sets of up to 5 numbers (positive integers to be specific) as unique numbers, or what 1-1 function I can use to map such a set of words (ignoring their order so that we can assume that different permutations of the same set of 1-5 words convey the same info, which will help limit the size of the feature space) to a number space. So I asked ChatGPT for the answer, and it came up with an application of Cantor's rule, which I thought was really cool! Here is a screenshot of the conversation: https://drive.google.com/drive/folders/1TUHwzsnF2vTZboaJk-W2dCd6m54EIWOy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgbxITBpSw8"
      },
      "source": [
        "We now need to start seriously collecting and processing data. Since our methods of extracting the desired text from the html only works on a handful of job postings in our original list, we need to manually test each one and find a respectable number of them that pass the test so we can automatically prepare a text file for each posting using the scraping logic contained herein, and then we can read each text file into its corresponding prompt string. Then we will still have a lot of work to do as far as taking ChatGPTs response in the form of json or loading it into a data structure some other way and adding that data as a row into our final dataframe. I will make a new spreadsheet to keep track of these postings, which will contain only LinkedIn Jobs links and a rating for each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnPGfqTOayBv"
      },
      "source": [
        "I will just be rerunning the scraping code from the beginning of the notebook with different links in requests.get() to see which of those links get successfully scraped. I will keep track of the ones that work and make sure each has a rating in the new spreadsheet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgEo--5MtLI-"
      },
      "source": [
        "To give an idea of how quickly I can rate and test job posting links, I have gotten about 35 done in about 3 hours. So if I spend another 8 hours on it I should have over 100. I think 100 might be enough to start experimenting with. I am making sure to have examples in all four classes: (0, no interest - 1, a little interest - 2, some interest - 3, a lot of interest)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfL4n3xtKZ7l"
      },
      "source": [
        "Update: I've done about 25 more jobs since my last update which was about 2 hrs ago. I also got sidetracked with some other small tasks so I was probably only working on collecting links for half the time. So a rough estimate is that I am able to get through about 20 postings in an hour. So it shouldn't take me TOO much time to get 100-200 links."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymPATiGnLDpv"
      },
      "source": [
        "Another update: I have gathered 107 links with labels. I am now going to start writing the code to scrape from all of these links using the csv file, and save to text file, and add the text file path to a third column in the csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MJwlw4-S2Zx"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "\n",
        "def scrape_job_postings(csv_file):\n",
        "    # Open the CSV file\n",
        "    with open(csv_file, 'r', newline='') as file:\n",
        "        reader = csv.reader(file)\n",
        "        #csv_writer = csv.writer(file)\n",
        "        row_num = 1\n",
        "\n",
        "        for row in reader:\n",
        "          text_file_path = f\"text_files3/row{row_num}.txt\"\n",
        "          with open(text_file_path, 'w') as file:\n",
        "            job_link = row[0] # Assuming the job links are in the first column\n",
        "            print(job_link)\n",
        "            # Send a GET request to the job link\n",
        "            # request web page\n",
        "            resp = requests.get(fr\"{job_link}\")\n",
        "\n",
        "            if resp.status_code == 200:\n",
        "              # get the response text. in this case it is HTML\n",
        "              html = resp.text\n",
        "              # Parse the HTML content\n",
        "              soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "            else:\n",
        "              time.sleep(1)\n",
        "              # request again\n",
        "              resp = requests.get(job_link)\n",
        "              if resp.status_code == 200:\n",
        "                # get the response text. in this case it is HTML\n",
        "                html = resp.text\n",
        "                # Parse the HTML content\n",
        "                soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "              else:\n",
        "                print(\"Failed to retrieve job posting from\", job_link)\n",
        "                row_num += 1\n",
        "                continue\n",
        "\n",
        "            # get position, company, location, pay\n",
        "            x = soup.get_text().split('\\n')\n",
        "            # Remove elements with only whitespace\n",
        "            filtered_list = [string for string in x if string.strip()]\n",
        "\n",
        "            for i in filtered_list:\n",
        "              if i.find('Join now') != -1 and filtered_list[filtered_list.index(i) + 1].find('Sign in') != -1:\n",
        "                position = filtered_list[filtered_list.index(i) + 2]\n",
        "                company = filtered_list[filtered_list.index(i) + 3]\n",
        "                location = filtered_list[filtered_list.index(i) + 4]\n",
        "                break\n",
        "\n",
        "            for i in filtered_list:\n",
        "              if i.find('Base pay range') != -1:\n",
        "                salary_index = filtered_list.index(i) + 1\n",
        "                salary = filtered_list[salary_index]\n",
        "                salary = salary.lstrip()\n",
        "                salary = \"N/A\" if (salary.find(\"$\") == salary.find(\"€\") == salary.find(\"£\") == -1) else salary\n",
        "                break\n",
        "              else:\n",
        "                salary = \"N/A\"\n",
        "\n",
        "            file.write(f\"position is {position}\\n\")\n",
        "            file.write(f\"company is {company}\\n\")\n",
        "            file.write(f\"location is {location}\\n\")\n",
        "            file.write(f\"salary is {salary}\\n\\n\")\n",
        "\n",
        "            #get seniority level, employment type, job function, and industries\n",
        "            spans = soup.find_all('span', {'class': \"description__job-criteria-text description__job-criteria-text--criteria\"})\n",
        "            for span in spans:\n",
        "              parent_tags = span.parent.find_all(\"h3\", {'class': \"description__job-criteria-subheader\"})\n",
        "              for tag in parent_tags:\n",
        "                field = tag.contents[0].strip()\n",
        "                #print(span.parent.find_all(\"h3\", {'class': \"description__job-criteria-subheader\"}))\n",
        "              value = span.contents[0].strip()\n",
        "              file.write(f\"{field} is {value}\\n\")\n",
        "            file.write(\"\\n\")\n",
        "\n",
        "            # get main body text\n",
        "            characters_per_line = []\n",
        "\n",
        "            # Extract text content from the HTML\n",
        "            text_content = soup.get_text()\n",
        "\n",
        "            # Split the text into lines\n",
        "            lines = text_content.splitlines()\n",
        "\n",
        "            # Calculate the number of characters in each line\n",
        "            for line in lines:\n",
        "              characters_per_line.append(len(line))\n",
        "\n",
        "            body_len = max(characters_per_line)\n",
        "            body_idx = characters_per_line.index(body_len)\n",
        "            body_text = lines[body_idx]\n",
        "            file.write(body_text)\n",
        "          row_num += 1\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "#csv_file_path = \"job_links.csv\"\n",
        "#scrape_job_postings(csv_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcCHirdhWds3",
        "outputId": "207764bc-f4a5-471f-9f5b-bd30cfd7e631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "LJj1E5QgbcUg",
        "outputId": "d404206f-a963-41b6-d8f1-aee149c52d1a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'scrape_job_postings' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-63593f05891b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcsv_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"successfulLinks.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscrape_job_postings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'scrape_job_postings' is not defined"
          ]
        }
      ],
      "source": [
        "csv_file_path = \"successfulLinks.csv\"\n",
        "scrape_job_postings(csv_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmqG6XCPtKvc"
      },
      "source": [
        "Excellent! So the text files were saved in Google Drive and they look good! They are here: https://drive.google.com/drive/folders/1xJxoBnqQKhKg45K_k_4fijBcYnRPjqX9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqHaD88mFm2X"
      },
      "source": [
        "Update: as far as the prompt we send to ChatGPT, here is what I've found to be the best prompt: (note that I have engineered it to have ChatGPT return a json object that contains the extracted feature data for the given job posting)\n",
        "\n",
        "\"Take the following text from a job posting and extract all info related to the following fields: Employment type, Job function, description of product/service, Industries, position name, broader role name, company, location, salary/compensation range, Responsibilities, Goals/objectives, name of department or team, required qualifications, preferred qualifications, Benefits, Work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put \"N/A\". Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Return the table as a json data structure that is loadable in python. Store the dictionary values as python lists. Here is the text from the job posting:\"\n",
        "\n",
        "And the output actually looks pretty good! https://drive.google.com/drive/folders/1IYOZtvYNB9D9ZxDBlU9ux-qrqeEZ3Mc1\n",
        "\n",
        "We should discuss what post-processing steps and further feature engineering we will need to perform on this json data. However, we should first test that we can get json data that will be straightforward to work with using OpenAI API calls. We will go to the other notebook where we test OpenAI API calls: https://colab.research.google.com/drive/1egzUeDTVPsBLbkhcrF1Il1OR_JwyyApu\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PLIr0uwORT1"
      },
      "source": [
        "I may as well copy the code from api-test (which I used to prove that the process of creating a dictionary object from the message returned by ChatGPT using a JSON representation is straightforward) here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwfbaBZTOQ8L",
        "outputId": "44994e89-c59e-4d73-9d77-80a194253f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TIO2YjsPV3A"
      },
      "outputs": [],
      "source": [
        "# getting started with OpenAI API!\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=\"someKey\",\n",
        ")\n",
        "\n",
        "prompt = \"Take the following text from a job posting and extract all info related to the following fields: Employment type, Job function, description of product/service, Industries, position name, broader role name, company, location, salary/compensation range, Responsibilities, Goals/objectives, name of department or team, required qualifications, preferred qualifications, Benefits, Work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put 'N/A'. Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Return the table as a json data structure that is loadable in python. Store the dictionary values as python lists. Here is the text from the job posting: \"\n",
        "\n",
        "with open('row106.txt', 'r') as file:\n",
        "  # Read the contents of the file into a string\n",
        "  file_contents = file.read()\n",
        "\n",
        "prompt = prompt + \"/n\" + file_contents\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXhPZIbaPXYI",
        "outputId": "24fcf2b2-4303-4512-f229-f9d180d11ef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Take the following text from a job posting and extract all info related to the following fields: Employment type, Job function, description of product/service, Industries, position name, broader role name, company, location, salary/compensation range, Responsibilities, Goals/objectives, name of department or team, required qualifications, preferred qualifications, Benefits, Work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put 'N/A'. Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Return the table as a json data structure that is loadable in python. Store the dictionary values as python lists. Here is the text from the job posting: \n",
            "position is Algorithm Developer\n",
            "company is Nurp\n",
            "location is United States\n",
            "salary is $100,000.00/yr - $130,000.00/yr\n",
            "\n",
            "Seniority level is Mid-Senior level\n",
            "Employment type is Full-time\n",
            "Job function is Engineering, Finance, and Information Technology\n",
            "Industries is Financial Services, Investment Banking, and Software Development\n",
            "\n",
            "Algorithmic Trading DeveloperPOSITION SUMMARYAre you passionate about the fusion of finance and technology? Nurp is actively seeking an Algorithmic Trading Developer to join our team. As a key member, you will play a pivotal role in constructing and implementing cutting-edge trading algorithms, contributing to the development and coding of sophisticated trading strategies. If you have a passion for algorithmic trading, a knack for innovation, and an experienced software developer in the trading space, we want to hear from you.ABOUT OUR COMPANYNurp pioneers the convergence of modern and future investing through emerging technologies. Our advanced algorithmic trading programs and comprehensive forex trading systems challenge traditional investment models, propelling algorithmic investing for unparalleled success.PERFORMANCE OBJECTIVESThe primary responsibility of the Algorithmic Developer will be to translate trading strategies provided by strategists and other stakeholders into functional algorithms. Design, code build and test the algorithmic strategies provided into functioning programs for MT 4 and MT 5 platforms.Write clean, concise and efficient code.Troubleshoot and debug program.Analyze complex problems and develop innovative solutions to optimize the algorithms code and address potential issues.Work closely, meeting with and collaborating with traders, quantitative strategists, involved contractors and other team members to accomplish.Analyze user feedback and make adjustments as needed or directed.Recommending and executing program improvements.KEY COMPETENCIESFinancial Acumen: Understanding of financial markets, including equities, derivatives, and forex, would be a plus. Algorithmic Trading Expertise: Strong understanding of algorithmic trading concepts and experience in developing trading algorithms.Programming Skills: Proficiency in programming languages such as Python, C++, or Java, and familiarity with trading platforms and APIs, including MetaTrader 4 and 5.Technical Proficiency: Proficiency in trading platforms, APIs, and data analysis tools, with experience in platforms like MT 4 and 5.Adaptability: Ability to quickly learn new technologies and methodologies to stay ahead of market trends and adapt to changing market conditions.Team Collaboration: Strong interpersonal skills and ability to collaborate effectively with cross-functional teams.Problem Solving: Strong analytical, Initiative, and problem-solving skills.EDUCATION AND EXPERIENCEBachelor's or Master's degree in Computer Science, Finance, Mathematics, or a related field. (Preferred) 3 years of experience developing and coding trading algorithms in the financial industry.(Required)Proficiency in programming languages such as Python and C++.Experience with MT 4 and 5.(Required)Familiarity with trading platforms, APIs, and quantitative analysis tools. (Required)BENEFITS100% Remote work.Health insurance.Dental insurance.Vision Insurance.Voluntary Life Insurance.Paid Time Off.Opportunities for professional development and training.COMMITMENT TO DIVERSITYAs an equal opportunity employer committed to meeting the needs of a multigenerational and multicultural workforce, Nurp LLC recognizes that a diverse staff, reflective of our community, is an integral and welcome part of a successful and ethical business. We hire talent at all levels regardless of race, color, religion, age, national origin, gender, gender identity, sexual orientation, or disability and actively foster inclusion in all forms both within our company and across interactions with clients, candidates, and partners.\n",
            "/n\n",
            "```json\n",
            "{\n",
            "    \"Employment Type\": [\"Full-time\"],\n",
            "    \"Job Function\": [\"Engineering\", \"Finance\", \"Information Technology\"],\n",
            "    \"Description of Product/Service\": [\"Algorithmic trading programs and forex trading systems\", \"Cutting-edge trading algorithms\"],\n",
            "    \"Industries\": [\"Financial Services\", \"Investment Banking\", \"Software Development\"],\n",
            "    \"Position Name\": [\"Algorithm Developer\"],\n",
            "    \"Broader Role Name\": [\"N/A\"],\n",
            "    \"Company\": [\"Nurp\"],\n",
            "    \"Location\": [\"United States\"],\n",
            "    \"Salary/Compensation Range\": [\"$100,000.00/yr - $130,000.00/yr\"],\n",
            "    \"Responsibilities\": [\"Translate trading strategies into functional algorithms\", \"Design, code, test algorithmic strategies\", \"Analyze problems and develop solutions\", \"Collaborate with team and stakeholders\"],\n",
            "    \"Goals/Objectives\": [\"Develop and optimize trading algorithms\", \"Maintain clean and efficient code\"],\n",
            "    \"Name of Department or Team\": [\"N/A\"],\n",
            "    \"Required Qualifications\": [\"Bachelor's or Master's degree in CS, Finance, Math\", \"3 years of experience developing trading algorithms\", \"Proficiency in Python, C++\", \"Experience with MT 4 and 5\", \"Familiarity with trading platforms and APIs\"],\n",
            "    \"Preferred Qualifications\": [\"N/A\"],\n",
            "    \"Benefits\": [\"Remote work\", \"Health/Dental/Vision Insurance\", \"Life Insurance\", \"Paid Time Off\", \"Professional Development Opportunities\"],\n",
            "    \"Work Arrangement\": [\"Remote\"]\n",
            "}\n",
            "```\n",
            "```json\n",
            "{\n",
            "    \"Employment Type\": [\"Full-time\"],\n",
            "    \"Job Function\": [\"Engineering\", \"Finance\", \"Information Technology\"],\n",
            "    \"Description of Product/Service\": [\"Algorithmic trading programs and forex trading systems\", \"Cutting-edge trading algorithms\"],\n",
            "    \"Industries\": [\"Financial Services\", \"Investment Banking\", \"Software Development\"],\n",
            "    \"Position Name\": [\"Algorithm Developer\"],\n",
            "    \"Broader Role Name\": [\"N/A\"],\n",
            "    \"Company\": [\"Nurp\"],\n",
            "    \"Location\": [\"United States\"],\n",
            "    \"Salary/Compensation Range\": [\"$100,000.00/yr - $130,000.00/yr\"],\n",
            "    \"Responsibilities\": [\"Translate trading strategies into functional algorithms\", \"Design, code, test algorithmic strategies\", \"Analyze problems and develop solutions\", \"Collaborate with team and stakeholders\"],\n",
            "    \"Goals/Objectives\": [\"Develop and optimize trading algorithms\", \"Maintain clean and efficient code\"],\n",
            "    \"Name of Department or Team\": [\"N/A\"],\n",
            "    \"Required Qualifications\": [\"Bachelor's or Master's degree in CS, Finance, Math\", \"3 years of experience developing trading algorithms\", \"Proficiency in Python, C++\", \"Experience with MT 4 and 5\", \"Familiarity with trading platforms and APIs\"],\n",
            "    \"Preferred Qualifications\": [\"N/A\"],\n",
            "    \"Benefits\": [\"Remote work\", \"Health/Dental/Vision Insurance\", \"Life Insurance\", \"Paid Time Off\", \"Professional Development Opportunities\"],\n",
            "    \"Work Arrangement\": [\"Remote\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(prompt)\n",
        "print(\"/n\")\n",
        "print(chat_completion.choices[0].message.content)\n",
        "print(chat_completion.choices[0].message.content.strip('json\\n'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU-5PjoQPbbQ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "data = json.loads(chat_completion.choices[0].message.content)\n",
        "\n",
        "# Now, 'data' contains the dictionary representation of the JSON data\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5eX2BqaRqH7"
      },
      "source": [
        "{'Employment type': ['Full-time'], 'Job function': ['Engineering and Information Technology'], 'Description of product/service': ['Kernel development for Boeing products'], 'Industries': ['Airlines and Aviation', 'Aviation and Aerospace Component Manufacturing', 'Defense and Space Manufacturing'], 'Position name': ['Associate Software Engineer - Kernel Developer'], 'Broader role name': ['Software Engineer'], 'Company': ['Boeing'], 'Location': ['Mesa, AZ'], 'Salary/compensation range': ['$79,050.00 - $123,050.00'], 'Responsibilities': ['Develop, document, maintain architectures, algorithms', 'Subject matter expert for kernel internals', 'Create and organize project initiatives', 'Participate in daily scrums'], 'Goals/objectives': ['Contribute to safety-critical kernel development'], 'Name of department or team': ['Kernel development team'], 'Required qualifications': ['Bachelor, Master, or Doctorate in relevant field', '1+ years of Linux OS experience', '1+ years of C++, C, C#, or Python experience'], 'Preferred qualifications': ['2+ years of C++, C, or C# experience', 'Passion for open source projects', 'Real-time software development experience', 'Experience with modern processor architectures'], 'Benefits': ['Competitive base pay', 'Variable compensation opportunities', 'Health insurance, retirement plans, life/disability insurance'], 'Work arrangement': ['Virtual'], 'N/A': ['Seniority level', 'Position description', 'Travel requirements', 'Relocation assistance', 'Drug policy', 'Shift schedule', 'Application deadline', 'Export control details', 'Equal Opportunity Policy']}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTGI5aVMRspO"
      },
      "source": [
        "Let's examine the output and explicitly spell out the further post-processing and feature engineering steps we will need to take. Modifying the prompt is another option that can help reduce the feature engineering work needed downstream. For example, we might want to have ChatGPT extract the name of the state for the locale if applicable instead of us having to extract the state programatically. But that has not been decided. I don't think it would be too challenging for us to do without ChatGPT.\n",
        "\n",
        "So without further ado, let's discuss what processing steps if any are needed to get our data into a more desirable format. We are not concerning ourselves yet with finding encodings or numerical values for our various features. At this stage we look at feature engineering work that will involve specialty logic to parse strings in certain fields, such as the 'Location' field as mentioned above.  \n",
        "\n",
        "Honestly, there isn't that much of that to do though. Some ideas include:\n",
        "\n",
        "- make columns for minimum and maximum of pay range and remove 'salary/compensation range' column from final dataset\n",
        "- extract state and possibly country into a new column of the dataset\n",
        "- we may try to get clever with our prompt engineering to handle this, but the following may actually be straightforward enough to do programmatically:\n",
        "  - extract specific experience qualifications into other lists that go into columns designated '1+ years required, 1+ years desired, 2+ years required, 2+ years desired, 3+ years required, 3+ years desired that will list\n",
        "- we might need logic to handle data that would correspond to new columns, or to fill out columns using data from other columns, like for those fields in the list for 'N/A', we'd need some code that runs that fills out the columns corresponding to those field names with 'N/A'. We'll probably just have a list of supported column names, which should be named as closely as possible to the field name in the JSON ChatGPT spits out. What we end up doing though depends largely on the repeatability of ChatGPT's response structure, format, and overall performance with adhering to the prompt guidelines.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F69hk4icnXcv"
      },
      "source": [
        "We're going to see what response we get with a different prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yroa2J8inWSB"
      },
      "outputs": [],
      "source": [
        "# getting started with OpenAI API!\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=\"someKey\",\n",
        ")\n",
        "\n",
        "prompt = \"Take the following text from a job posting and extract all info related to the following fields: Employment type, Job function, description of product/service, Industries, position name, broader role name, company, location, salary/compensation range, Responsibilities, Goals/objectives, name of department or team, required qualifications, preferred qualifications, Benefits, Work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put 'N/A'. Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Return the table as a json data structure that is loadable in python. Store the dictionary values as python lists. Here is the text from the job posting: \\n\"\n",
        "\n",
        "with open('row105.txt', 'r') as file:\n",
        "  # Read the contents of the file into a string\n",
        "  file_contents = file.read()\n",
        "\n",
        "prompt = prompt  + file_contents\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbx4EEwpn-3R",
        "outputId": "223ccc4a-e11b-4ce6-abe1-afbc1b4deb24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "\"Employment type\": [\"Full-time\"],\n",
            "\"Job function\": [\"Engineering\", \"Finance\", \"Information Technology\"],\n",
            "\"description of product/service\": [\"Algorithmic Trading Developer\", \"Forex trading systems\"],\n",
            "\"Industries\": [\"Financial Services\", \"Investment Banking\", \"Software Development\"],\n",
            "\"Position name\": [\"Algorithm Developer\"],\n",
            "\"Broader role name\": [\"N/A\"],\n",
            "\"Company\": [\"Nurp\"],\n",
            "\"Location\": [\"United States\"],\n",
            "\"Salary/compensation range\": [\"$100,000.00/yr - $130,000.00/yr\"],\n",
            "\"Responsibilities\": [\"Translate trading strategies into algorithms\", \"Design, code, build, and test algorithms\", \"Troubleshoot and debug programs\", \"Collaborate with team members\"],\n",
            "\"Goals/objectives\": [\"Develop efficient trading algorithms\", \"Address potential issues\", \"Make program improvements\"],\n",
            "\"Name of department or team\": [\"N/A\"],\n",
            "\"Required qualifications\": [\"Bachelor's or Master's degree in relevant field\", \"3 years of experience in financial industry\", \"Proficiency in Python and C++\", \"Experience with MT 4 and 5 platforms\", \"Familiarity with trading platforms and APIs\"],\n",
            "\"Preferred qualifications\": [\"N/A\"],\n",
            "\"Benefits\": [\"100% Remote work\", \"Health, dental, vision insurance\", \"Paid Time Off\", \"Professional development opportunities\"],\n",
            "\"Work arrangement\": [\"Remote\"],\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#print(prompt)\n",
        "#print(\"\\n\")\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "D_Fm9QuQoEHq",
        "outputId": "b7e06268-1715-4073-aa1e-c6ea4dcc2c8d"
      },
      "outputs": [
        {
          "ename": "JSONDecodeError",
          "evalue": "Expecting property name enclosed in double quotes: line 18 column 1 (char 1259)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-6b2700755697>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{chat_completion.choices[0].message.content}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Now, 'data' contains the dictionary representation of the JSON data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 18 column 1 (char 1259)"
          ]
        }
      ],
      "source": [
        "import json\n",
        "data = json.loads(f\"{chat_completion.choices[0].message.content}\")\n",
        "\n",
        "# Now, 'data' contains the dictionary representation of the JSON data\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJiyadLPoO26"
      },
      "source": [
        "Clearly not the result we wanted; we definitely need to be explicit in our prompt about how we want only the JSON and nothing else."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UifbVLvcoP6W"
      },
      "outputs": [],
      "source": [
        "# getting started with OpenAI API!\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=\"someKey\",\n",
        ")\n",
        "\n",
        "prompt = \"Take the following text from a job posting and extract all info related to the following fields: Employment type, Job function, description of product/service, Industries, position name, broader role name, company, location, salary/compensation range, Responsibilities, Goals/objectives, name of department or team, required qualifications, preferred qualifications, Benefits, Work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put 'N/A'. Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Return the table as a json data structure that is loadable in python. Store the dictionary values as python lists. Return only the JSON and no title. Here is the text from the job posting: \"\n",
        "\n",
        "with open('row105.txt', 'r') as file:\n",
        "  # Read the contents of the file into a string\n",
        "  file_contents = file.read()\n",
        "\n",
        "prompt = prompt + \"/n\" + file_contents\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "4n1EL3A6pRlF",
        "outputId": "138e9885-871b-4697-a056-b3ce3bb50472"
      },
      "outputs": [
        {
          "ename": "JSONDecodeError",
          "evalue": "Expecting property name enclosed in double quotes: line 18 column 1 (char 1259)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-a138472f696d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_completion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Now, 'data' contains the dictionary representation of the JSON data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 18 column 1 (char 1259)"
          ]
        }
      ],
      "source": [
        "import json\n",
        "data = json.loads(chat_completion.choices[0].message.content)\n",
        "\n",
        "# Now, 'data' contains the dictionary representation of the JSON data\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcFw7OKWrqHX"
      },
      "source": [
        "Well, this isn't exactly going as hoped on test #2. Let's see if it works with a different .txt file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPqlddjHpWub"
      },
      "outputs": [],
      "source": [
        "# getting started with OpenAI API!\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=\"someKey\",\n",
        ")\n",
        "\n",
        "prompt = \"Take the following text from a job posting and extract all info related to the following fields: Employment type, Job function, description of product/service, Industries, position name, broader role name, company, location, salary/compensation range, Responsibilities, Goals/objectives, name of department or team, required qualifications, preferred qualifications, Benefits, Work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put 'N/A'. Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Return the table as a json data structure that is loadable in python. Store the dictionary values as python lists. Return only the JSON and no title. Here is the text from the job posting: \"\n",
        "\n",
        "with open('row99.txt', 'r') as file:\n",
        "  # Read the contents of the file into a string\n",
        "  file_contents = file.read()\n",
        "\n",
        "prompt = prompt + \"/n\" + file_contents\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gITzRNL_r9hO",
        "outputId": "e7e870b6-2117-43b6-dd7e-a77467fd0c03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"Employment type\": [\"Internship\"],\n",
            "  \"Job function\": [\"Research\", \"Analyst\", \"Information Technology\"],\n",
            "  \"Description of product/service\": [\"Quantum computing system\", \"Quantum services\"],\n",
            "  \"Industries\": [\"Software Development\"],\n",
            "  \"Position name\": [\"Research Intern - Quantum Information and Computation\"],\n",
            "  \"Broader role name\": [\"Research Intern\"],\n",
            "  \"Company\": [\"Microsoft\"],\n",
            "  \"Location\": [\"Redmond, WA\"],\n",
            "  \"Salary/compensation range\": [\"$10,120.00/yr - $12,170.00/yr\"],\n",
            "  \"Responsibilities\": [\"Problem identification\", \"Formulation\", \"Publishing results\", \"Collaboration\"],\n",
            "  \"Goals/objectives\": [\"Contribute to research strides\"],\n",
            "  \"Name of department or team\": [\"N/A\"],\n",
            "  \"Required qualifications\": [\"PhD\",\"Physics\", \"Mathematics\", \"Computer Science\", \"Electrical and Computer Engineering\"],\n",
            "  \"Preferred qualifications\": [\"Quantum algorithms\", \"Machine learning\", \"Physics device modeling\", \"Effective communication\", \"Problem-solving skills\"],\n",
            "  \"Benefits\": [\"N/A\"],\n",
            "  \"Work arrangement\": [\"On-site\"],\n",
            "  \"Hybrid, on-site, remote?\": [\"Hybrid\"],\n",
            "  \"N/A\": [\"N/A\"]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#print(prompt)\n",
        "#print(\"\\n\")\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4th0YUGsAbw",
        "outputId": "ea247697-90a1-4279-c48e-9f80096e74ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Employment type': ['Internship'], 'Job function': ['Research', 'Analyst', 'Information Technology'], 'Description of product/service': ['Quantum computing system', 'Quantum services'], 'Industries': ['Software Development'], 'Position name': ['Research Intern - Quantum Information and Computation'], 'Broader role name': ['Research Intern'], 'Company': ['Microsoft'], 'Location': ['Redmond, WA'], 'Salary/compensation range': ['$10,120.00/yr - $12,170.00/yr'], 'Responsibilities': ['Problem identification', 'Formulation', 'Publishing results', 'Collaboration'], 'Goals/objectives': ['Contribute to research strides'], 'Name of department or team': ['N/A'], 'Required qualifications': ['PhD', 'Physics', 'Mathematics', 'Computer Science', 'Electrical and Computer Engineering'], 'Preferred qualifications': ['Quantum algorithms', 'Machine learning', 'Physics device modeling', 'Effective communication', 'Problem-solving skills'], 'Benefits': ['N/A'], 'Work arrangement': ['On-site'], 'Hybrid, on-site, remote?': ['Hybrid'], 'N/A': ['N/A']}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "data = json.loads(chat_completion.choices[0].message.content)\n",
        "\n",
        "# Now, 'data' contains the dictionary representation of the JSON data\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f3g0F8bsEFm"
      },
      "source": [
        "So the good news is this worked on test text files 1 and 3, but not #2. Let's try more of them to estimate what our failure rate would be and see if it's worth living with/working around."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igQeErdXsDWX"
      },
      "outputs": [],
      "source": [
        "# getting started with OpenAI API!\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=\"someKey\",\n",
        ")\n",
        "\n",
        "prompt = \"Take the following text from a job posting and extract all info related to the following fields: Employment type, Job function, description of product/service, Industries, position name, broader role name, company, location, salary/compensation range, Responsibilities, Goals/objectives, name of department or team, required qualifications, preferred qualifications, Benefits, Work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put 'N/A'. Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Return the table as a json data structure that is loadable in python. Store the dictionary values as python lists. Return only the JSON and no title. Here is the text from the job posting: \"\n",
        "\n",
        "with open('row95.txt', 'r') as file:\n",
        "  # Read the contents of the file into a string\n",
        "  file_contents = file.read()\n",
        "\n",
        "prompt = prompt + \"/n\" + file_contents\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW1FRp7xso9s",
        "outputId": "4265a2bf-053c-4710-e8cf-26266661706b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"Employment Type\": [\"Full-time\"],\n",
            "  \"Job Function\": [\"Engineering\", \"Finance\", \"Information Technology\"],\n",
            "  \"Product/Service Description\": [\"Algorithmic Trading Developer\"],\n",
            "  \"Industries\": [\"Financial Services\", \"Investment Banking\", \"Software Development\"],\n",
            "  \"Position Name\": [\"Algorithm Developer\"],\n",
            "  \"Broader Role Name\": [\"N/A\"],\n",
            "  \"Company\": [\"Nurp\"],\n",
            "  \"Location\": [\"United States\"],\n",
            "  \"Salary/Compensation Range\": [\"$100,000.00/yr\", \"$130,000.00/yr\"],\n",
            "  \"Responsibilities\": [\"Translate trading strategies into algorithms\", \"Design, code, build, and test algorithms\", \"Troubleshoot and debug programs\", \"Analyze problems and develop innovative solutions\", \"Meet and collaborate with team members\", \"Analyze user feedback and make adjustments\", \"Recommend and execute program improvements\"],\n",
            "  \"Goals/Objectives\": [\"Implement trading algorithms\", \"Optimize algorithms code\", \"Address potential issues\", \"Stay ahead of market trends\"],\n",
            "  \"Department/Team Name\": [\"N/A\"],\n",
            "  \"Required Qualifications\": [\"Bachelor's or Master's degree in relevant field\", \"3 years of experience in coding trading algorithms\", \"Proficiency in Python and C++\", \"Experience with MT 4 and 5\", \"Familiarity with trading platforms and APIs\"],\n",
            "  \"Preferred Qualifications\": [\"N/A\"],\n",
            "  \"Benefits\": [\"100% Remote work\", \"Health, dental, and vision insurance\", \"Life insurance\", \"Paid Time Off\", \"Professional development opportunities\"],\n",
            "  \"Work Arrangement\": [\"Remote\"]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#print(prompt)\n",
        "#print(\"\\n\")\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4ioaaozstt5",
        "outputId": "f2b36b06-7b30-4bfc-d6d0-2d013361595d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Employment Type': ['Full-time'], 'Job Function': ['Engineering', 'Finance', 'Information Technology'], 'Product/Service Description': ['Algorithmic Trading Developer'], 'Industries': ['Financial Services', 'Investment Banking', 'Software Development'], 'Position Name': ['Algorithm Developer'], 'Broader Role Name': ['N/A'], 'Company': ['Nurp'], 'Location': ['United States'], 'Salary/Compensation Range': ['$100,000.00/yr', '$130,000.00/yr'], 'Responsibilities': ['Translate trading strategies into algorithms', 'Design, code, build, and test algorithms', 'Troubleshoot and debug programs', 'Analyze problems and develop innovative solutions', 'Meet and collaborate with team members', 'Analyze user feedback and make adjustments', 'Recommend and execute program improvements'], 'Goals/Objectives': ['Implement trading algorithms', 'Optimize algorithms code', 'Address potential issues', 'Stay ahead of market trends'], 'Department/Team Name': ['N/A'], 'Required Qualifications': [\"Bachelor's or Master's degree in relevant field\", '3 years of experience in coding trading algorithms', 'Proficiency in Python and C++', 'Experience with MT 4 and 5', 'Familiarity with trading platforms and APIs'], 'Preferred Qualifications': ['N/A'], 'Benefits': ['100% Remote work', 'Health, dental, and vision insurance', 'Life insurance', 'Paid Time Off', 'Professional development opportunities'], 'Work Arrangement': ['Remote']}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "data = json.loads(chat_completion.choices[0].message.content.strip())\n",
        "\n",
        "# Now, 'data' contains the dictionary representation of the JSON data\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-SR74VaRZ6e",
        "outputId": "1f976458-12c6-454c-e3dc-691c271009d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 16)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_columns = [\"emploment type\", \"job function\", \"description of product/service\", \"industries\",\n",
        "              \"position name\", \"broader role name\", \"company\", \"location\", \"salary/compensation range\",\n",
        "              \"responsibilities\", \"goals/objectives\", \"name of department/team\", \"required qualifications\",\n",
        "              \"preferred qualifications\", \"benefits\", \"work arrangement\"]\n",
        "df = pd.DataFrame.from_dict([data])\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDRiIM_es2m8"
      },
      "source": [
        "Excellent, we're at 3/4. Let's try maybe 10. Instead of making new cells we will just rerun the last 3 and report back on our results.\n",
        "\n",
        "Try 5 - fail\n",
        "\n",
        "Try 6 - pass\n",
        "\n",
        "Try 7 - pass\n",
        "\n",
        "Try 8 - pass\n",
        "\n",
        "Try 9 - pass\n",
        "\n",
        "Try 10 - pass\n",
        "\n",
        "So we have 2 failures out of 10. We guess that the success rate of what we're doing is 80%. But with the two failures, we see the same root cause: the response returned by ChatGPT has the word 'json' in the text. So maybe it is straightforward to remove this label and just get the json in code so we can convert those two failures to passes. We'll go back to one of the failing situations and see if we can process the string correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSIFRgqqujuI"
      },
      "outputs": [],
      "source": [
        "# getting started with OpenAI API!\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=\"someKey\",\n",
        ")\n",
        "\n",
        "prompt = \"Take the following text from a job posting and extract all info related to the following fields: Employment type, Job function, description of product/service, Industries, position name, broader role name, company, location, salary/compensation range, Responsibilities, Goals/objectives, name of department or team, required qualifications, preferred qualifications, Benefits, Work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put 'N/A'. Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Return the table as a json data structure that is loadable in python. Store the dictionary values as python lists. Return only the JSON and no title. Here is the text from the job posting: \"\n",
        "\n",
        "with open('row66.txt', 'r') as file:\n",
        "  # Read the contents of the file into a string\n",
        "  file_contents = file.read()\n",
        "\n",
        "prompt = prompt + \"/n\" + file_contents\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bamc1M_buzzD"
      },
      "source": [
        "Well, after trying this again with one of the failing text files ChatGPT's behavior no longer deviates from what we want. Let's try out the other failing text file again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TOHCfNHvIuo"
      },
      "outputs": [],
      "source": [
        "# getting started with OpenAI API!\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=\"someKey\",\n",
        ")\n",
        "\n",
        "prompt = \"Take the following text from a job posting and extract all info related to the following fields: emploment type, job function, description of product/service, industries, position name, broader role name, company, location, salary/compensation range, responsibilities, goals/objectives, name of department/team, required qualifications, preferred qualifications, benefits, work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put 'N/A'. Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Return the table as a json data structure that is loadable in python. Store the dictionary values as python lists. Return only the JSON and no title. Here is the text from the job posting: \"\n",
        "with open('row101.txt', 'r') as file:\n",
        "  # Read the contents of the file into a string\n",
        "  file_contents = file.read()\n",
        "\n",
        "prompt = prompt + \"/n\" + file_contents\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrXViAVRvgla"
      },
      "source": [
        "The other failing one, 'row105.txt', still fails after trying again. So we can say with some level of confidence that our failure rate is around 20%. Maybe white space is the issue for the still failing case? The answer is no, .strip() method didn't fix the issue. We might have to just live with this sub-optimal performance to continue moving forward preparing our baseline dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KZl5DbkSmro"
      },
      "source": [
        "We will modify our prompt so we can try to get Chat to make the field names all be lower-cased.\n",
        "\n",
        "\"Take the following text from a job posting and extract all info related to the following fields: emploment type, job function, description of product/service, industries, position name, broader role name, company, location, salary/compensation range, responsibilities, goals/objectives, name of department/team, required qualifications, preferred qualifications, benefits, work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put 'N/A'. Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Return the table as a json data structure that is loadable in python. Store the dictionary values as python lists. Return only the JSON and no title. Here is the text from the job posting: \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qcmzPsFTmLD"
      },
      "source": [
        "This didn't influence Chat's behavior or if it did it made it output upper-case field names! Thus we will need to post process the JSON dictionary keys and make sure they match with our dataframe column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwKp-rx-UjjV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_columns = [\"emploment type\", \"job function\", \"description of product/service\", \"industries\",\n",
        "              \"position name\", \"broader role name\", \"company\", \"location\", \"salary/compensation range\",\n",
        "              \"responsibilities\", \"goals/objectives\", \"name of department/team\", \"required qualifications\",\n",
        "              \"preferred qualifications\", \"benefits\", \"work arrangement\"]\n",
        "# Initialize DataFrame with column names\n",
        "df = pd.DataFrame(columns=df_columns)\n",
        "\n",
        "df.head()\n",
        "\n",
        "try:\n",
        "  row_num = df.iloc[-1]\n",
        "except IndexError:\n",
        "  row_num = 0\n",
        "\n",
        "# Iterate over each key-value pair in the JSON dictionary\n",
        "for key, value in data.items():\n",
        "    # Check if the key exists as a column name (ignoring case)\n",
        "    column_name = key.lower()\n",
        "    if column_name in df.columns:\n",
        "        # Add the value to the corresponding column and row\n",
        "        df.at[row_num, column_name] = value\n",
        "\n",
        "\n",
        "#df = pd.DataFrame.from_dict([data])\n",
        "#print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNhzDntkVZu0",
        "outputId": "f6777c43-e852-4cea-c41a-40c841b1f361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 16)\n"
          ]
        }
      ],
      "source": [
        "df.head()\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NobklA54VgTU"
      },
      "outputs": [],
      "source": [
        "# getting started with OpenAI API!\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=\"someKey\",\n",
        ")\n",
        "\n",
        "prompt = \"Take the following text from a job posting and extract all info related to the following fields: emploment type, job function, description of product/service, industries, position name, broader role name, company, location, salary/compensation range, responsibilities, goals/objectives, name of department/team, required qualifications, preferred qualifications, benefits, work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put 'N/A'. Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Return the table as a json data structure that is loadable in python. Store the dictionary values as python lists. Return only the JSON and no title. Here is the text from the job posting: \"\n",
        "with open('row101.txt', 'r') as file:\n",
        "  # Read the contents of the file into a string\n",
        "  file_contents = file.read()\n",
        "\n",
        "prompt = prompt + \"/n\" + file_contents\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0GW9cUDVoNi",
        "outputId": "06f85bf1-a3a5-4bfa-bbdb-7a898c558610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"employment_type\": [\"Full-time\"],\n",
            "  \"job_function\": [\"Design\", \"Consulting\", \"Engineering\"],\n",
            "  \"description_of_product/service\": [\"Optical Design Software\"],\n",
            "  \"industries\": [\"Semiconductor Manufacturing\", \"Software Development\", \"Computer Hardware Manufacturing\"],\n",
            "  \"position_name\": [\"Software Architect - C++\"],\n",
            "  \"broader_role_name\": [\"Software Architect\"],\n",
            "  \"company\": [\"Synopsys Inc\"],\n",
            "  \"location\": [\"Irvine, CA\"],\n",
            "  \"salary_compensation_range\": [\"N/A\"],\n",
            "  \"responsibilities\": [\"Guide development process\", \"Assess legacy systems\", \"Design scalable components\", \"Lead modernization initiatives\", \"Collaborate with teams\", \"Provide technical guidance\", \"Oversee application of best practices\", \"Create architecture documentation\", \"Stay updated with industry trends\", \"Drive performance tuning\", \"Develop algorithms for parallel computation\"],\n",
            "  \"goals_objectives\": [\"Deliver cutting-edge optical design solutions\"],\n",
            "  \"name_of_department_team\": [\"OSG\"],\n",
            "  \"required_qualifications\": [\"Bachelor's degree in CS or related field\", \"6+ years experience as Software Architect\", \"C++ development background\", \"Understanding of software design patterns\", \"Excellent problem-solving skills\", \"Excellent communication skills\"],\n",
            "  \"preferred_qualifications\": [\"Experience in Physics, Optics, Mathematics\", \"Hands-on experience with parallel computation\", \"Experience in CAD/CAM and ray tracing\", \"Knowledge of 3D Geometry and Optimization Algorithms\"],\n",
            "  \"benefits\": [\"Competitive salary\", \"Bonus package\", \"Stock purchase plan\", \"401k plan\", \"Insurance packages\", \"Professional development support\"],\n",
            "  \"work_arrangement\": [\"Hybrid\", \"Remote\"],\n",
            "  \"N/A\": [\"position is Software Architect - C++ - 46456BR\", \"Seniority level is Mid-Senior level\"]\n",
            "}\n",
            "{'employment_type': ['Full-time'], 'job_function': ['Design', 'Consulting', 'Engineering'], 'description_of_product/service': ['Optical Design Software'], 'industries': ['Semiconductor Manufacturing', 'Software Development', 'Computer Hardware Manufacturing'], 'position_name': ['Software Architect - C++'], 'broader_role_name': ['Software Architect'], 'company': ['Synopsys Inc'], 'location': ['Irvine, CA'], 'salary_compensation_range': ['N/A'], 'responsibilities': ['Guide development process', 'Assess legacy systems', 'Design scalable components', 'Lead modernization initiatives', 'Collaborate with teams', 'Provide technical guidance', 'Oversee application of best practices', 'Create architecture documentation', 'Stay updated with industry trends', 'Drive performance tuning', 'Develop algorithms for parallel computation'], 'goals_objectives': ['Deliver cutting-edge optical design solutions'], 'name_of_department_team': ['OSG'], 'required_qualifications': [\"Bachelor's degree in CS or related field\", '6+ years experience as Software Architect', 'C++ development background', 'Understanding of software design patterns', 'Excellent problem-solving skills', 'Excellent communication skills'], 'preferred_qualifications': ['Experience in Physics, Optics, Mathematics', 'Hands-on experience with parallel computation', 'Experience in CAD/CAM and ray tracing', 'Knowledge of 3D Geometry and Optimization Algorithms'], 'benefits': ['Competitive salary', 'Bonus package', 'Stock purchase plan', '401k plan', 'Insurance packages', 'Professional development support'], 'work_arrangement': ['Hybrid', 'Remote'], 'N/A': ['position is Software Architect - C++ - 46456BR', 'Seniority level is Mid-Senior level']}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "print(chat_completion.choices[0].message.content.strip(\"`\").strip('json').strip())\n",
        "data = json.loads(chat_completion.choices[0].message.content.strip(\"`\").strip('json').strip())\n",
        "\n",
        "# Now, 'data' contains the dictionary representation of the JSON data\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX9vBra8ZgfW"
      },
      "source": [
        "Since we have the seen ChatGPT putting '_' between words we will need to tweak our json item iterator code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTBsVjFwdncQ"
      },
      "outputs": [],
      "source": [
        "row_iter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScrkguQCZdoX",
        "outputId": "45a12795-1c57-4ecf-c7bf-8267b45ce54a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 16)\n",
            "  employment_type                       job_function  \\\n",
            "0     [Full-time]  [Design, Consulting, Engineering]   \n",
            "2             NaN                                NaN   \n",
            "\n",
            "  description_of_product/service  \\\n",
            "0      [Optical Design Software]   \n",
            "2                            NaN   \n",
            "\n",
            "                                          industries  \\\n",
            "0  [Semiconductor Manufacturing, Software Develop...   \n",
            "2  [Semiconductor Manufacturing, Software Develop...   \n",
            "\n",
            "                position_name     broader_role_name         company  \\\n",
            "0  [Software Architect - C++]  [Software Architect]  [Synopsys Inc]   \n",
            "2                         NaN                   NaN  [Synopsys Inc]   \n",
            "\n",
            "       location salary_compensation_range  \\\n",
            "0  [Irvine, CA]                     [N/A]   \n",
            "2  [Irvine, CA]                       NaN   \n",
            "\n",
            "                                    responsibilities  \\\n",
            "0  [Guide development process, Analyze existing l...   \n",
            "2  [Guide development process, Assess legacy syst...   \n",
            "\n",
            "                                    goals_objectives name_of_department/team  \\\n",
            "0  [Deliver cutting-edge optical design solutions...          [Synopsys OSG]   \n",
            "2                                                NaN                     NaN   \n",
            "\n",
            "                             required_qualifications  \\\n",
            "0  [Bachelor's degree in CS or related field, 6+ ...   \n",
            "2                                                NaN   \n",
            "\n",
            "                            preferred_qualifications  \\\n",
            "0  [Experience in Physics, Optics, Mathematics, H...   \n",
            "2                                                NaN   \n",
            "\n",
            "                                            benefits work_arrangement  \n",
            "0  [Ability to work remotely/from multiple locati...         [Hybrid]  \n",
            "2  [Competitive salary, Bonus package, Stock purc...              NaN  \n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  row_num = df.iloc[-1]\n",
        "  row_num = df.shape[0] + 1\n",
        "except IndexError:\n",
        "  row_num = 0\n",
        "\n",
        "# Iterate over each key-value pair in the JSON dictionary\n",
        "for key, value in data.items():\n",
        "    # Check if the key exists as a column name (ignoring case)\n",
        "    column_name = key.replace(\"_\", \" \").lower()\n",
        "    if column_name in df.columns:\n",
        "        # Add the value to the corresponding column and row\n",
        "        df.at[row_num, column_name] = value\n",
        "\n",
        "\n",
        "#df = pd.DataFrame.from_dict([data])\n",
        "print(df.shape)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZILEISL7bujt",
        "outputId": "e657a4bf-f8e1-47c6-b472-f56361743137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    [Harnham]\n",
            "1    [Harnham]\n",
            "Name: company, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df['company'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCMByhU3eUu9"
      },
      "outputs": [],
      "source": [
        "global row_iter\n",
        "row_iter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB4GnR3recVF",
        "outputId": "6a173642-3335-4866-fe2d-6f2be2ae8e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_columns = [\"emploment type\", \"job function\", \"description of product/service\", \"industries\",\n",
        "              \"position name\", \"broader role name\", \"company\", \"location\", \"salary/compensation range\",\n",
        "              \"responsibilities\", \"goals/objectives\", \"name of department/team\", \"required qualifications\",\n",
        "              \"preferred qualifications\", \"benefits\", \"work arrangement\"]\n",
        "# Initialize DataFrame with column names\n",
        "df = pd.DataFrame(columns=df_columns)\n",
        "\n",
        "print(df.last_valid_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ7CHeLGdzBW"
      },
      "outputs": [],
      "source": [
        "# getting started with OpenAI API!\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "def generate_json_summary(text_file_path):\n",
        "  with open(text_file_path, 'r') as file:\n",
        "    # Read the contents of the file into a string\n",
        "    file_contents = file.read()\n",
        "\n",
        "  prompt = \"Take the following text from a job posting and extract all info related to the following fields: emploment type, job function, description of product/service, industries, position name, broader role name, company, location, salary/compensation range, responsibilities, goals/objectives, name of department/team, required qualifications, preferred qualifications, benefits, work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put 'N/A'. Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Return the table as a json data structure that is loadable in python. Store the dictionary values as python lists. Return only the JSON and no title. Here is the text from the job posting: \"\n",
        "\n",
        "  prompt = prompt + \"/n\" + file_contents\n",
        "\n",
        "  client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=\"someKey\",\n",
        "  )\n",
        "\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt,\n",
        "          }\n",
        "      ],\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "  )\n",
        "  json_data = data = json.loads(chat_completion.choices[0].message.content.strip(\"`\").strip('json').strip())\n",
        "  return json_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oloyy8Ff0Oj"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=\"someKey\",\n",
        ")\n",
        "\n",
        "prompt = \"Take the following text from a job posting and extract all info related to the following fields: emploment type, job function, description of product/service, industries, position name, broader role name, company, location, salary/compensation range, responsibilities, goals/objectives, name of department/team, required qualifications, preferred qualifications, benefits, work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put 'N/A'. Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Return the table as a json data structure that is loadable in python. Store the dictionary values as python lists. Return only the JSON and no title. Here is the text from the job posting: \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z-s-LgieQpM"
      },
      "outputs": [],
      "source": [
        "def add_row_to_df(json_data):\n",
        "  # Iterate over each key-value pair in the JSON dictionary\n",
        "  row_num = df.last_valid_index()\n",
        "  if row_num == None:\n",
        "    row_num = 0\n",
        "  else:\n",
        "    row_num = row_num + 1\n",
        "  for key, value in json_data.items():\n",
        "      # Check if the key exists as a column name (ignoring case)\n",
        "      column_name = key.replace(\"_\", \" \").lower()\n",
        "      if column_name in df.columns:\n",
        "          # Add the value to the corresponding column and row\n",
        "          df.at[row_num, column_name] = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuVjv1vKgPtY",
        "outputId": "4d240019-8965-470a-85ba-a50190e720b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [emploment type, job function, description of product/service, industries, position name, broader role name, company, location, salary/compensation range, responsibilities, goals/objectives, name of department/team, required qualifications, preferred qualifications, benefits, work arrangement]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plLFN5JDe5WD",
        "outputId": "c8adbabb-89c0-414b-edde-fb3df7098072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  emploment type                                    job function  \\\n",
            "0            NaN                                         [Other]   \n",
            "1            NaN  [Engineering, Finance, Information Technology]   \n",
            "2            NaN           [Engineering, Information Technology]   \n",
            "3            NaN                        [Education and Training]   \n",
            "4            NaN           [Engineering, Information Technology]   \n",
            "\n",
            "        description of product/service  \\\n",
            "0                                [N/A]   \n",
            "1      [Algorithmic Trading Developer]   \n",
            "2      [Quantum Engineering Solutions]   \n",
            "3     [Quantum computing applications]   \n",
            "4  [Quantitative software development]   \n",
            "\n",
            "                                          industries  \\\n",
            "0                             [Software Development]   \n",
            "1  [Financial Services, Investment Banking, Softw...   \n",
            "2  [Appliances, Electrical, Electronics Manufactu...   \n",
            "3                                [Research Services]   \n",
            "4                       [IT Services, IT Consulting]   \n",
            "\n",
            "                           position name broader role name  \\\n",
            "0          [Machine Learning Consultant]             [N/A]   \n",
            "1                  [Algorithm Developer]             [N/A]   \n",
            "2            [Quantum Solution Engineer]             [N/A]   \n",
            "3  [Summer Internship - Quantum Systems]          [Intern]   \n",
            "4       [Quantitative Software Engineer]             [N/A]   \n",
            "\n",
            "                   company           location  \\\n",
            "0                   [Dice]    [United States]   \n",
            "1                   [Nurp]    [United States]   \n",
            "2  [Keysight Technologies]   [Santa Rosa, CA]   \n",
            "3   [QuEra Computing Inc.]       [Boston, MA]   \n",
            "4                   [Raft]  [San Antonio, TX]   \n",
            "\n",
            "         salary/compensation range  \\\n",
            "0                            [N/A]   \n",
            "1                              NaN   \n",
            "2                            [N/A]   \n",
            "3                              NaN   \n",
            "4  [$90,000.00/yr, $170,000.00/yr]   \n",
            "\n",
            "                                    responsibilities  \\\n",
            "0  [Requirement gathering and documentation, Ente...   \n",
            "1  [Translate trading strategies to algorithms, D...   \n",
            "2  [Customer success, Engage with customers, Defi...   \n",
            "3  [Holography/Laser Beam Optimization, Algorithm...   \n",
            "4  [Develop software for quantitative methods, Dr...   \n",
            "\n",
            "                                    goals/objectives  \\\n",
            "0                                              [N/A]   \n",
            "1                                                NaN   \n",
            "2  [Create world-leading quantum solutions, Innov...   \n",
            "3                                                NaN   \n",
            "4                                              [N/A]   \n",
            "\n",
            "           name of department/team  \\\n",
            "0                            [N/A]   \n",
            "1                            [N/A]   \n",
            "2  [Quantum Engineering Solutions]   \n",
            "3                              NaN   \n",
            "4                            [N/A]   \n",
            "\n",
            "                             required qualifications  \\\n",
            "0  [Strong understanding of SDLC, Proficiency in ...   \n",
            "1  [Bachelor's or Master's degree in relevant fie...   \n",
            "2  [MS or PhD in physics or engineering, 5+ years...   \n",
            "3  [Degree in CS/Physics/Math or related, Python ...   \n",
            "4  [3+ years software development, Python/Java/C+...   \n",
            "\n",
            "                            preferred qualifications  \\\n",
            "0                                              [N/A]   \n",
            "1                                              [N/A]   \n",
            "2  [Experimental background in quantum physics, O...   \n",
            "3                                [Optics experience]   \n",
            "4  [Big data processing experience, Machine learn...   \n",
            "\n",
            "                                            benefits work arrangement  \n",
            "0                                              [N/A]         [Remote]  \n",
            "1  [100% Remote work, Health, Dental, Vision Insu...         [Remote]  \n",
            "2  [Medical, dental, vision, 401(k) Plan, Paid Ho...        [On-site]  \n",
            "3                         [Diverse work environment]        [On-site]  \n",
            "4  [Competitive salary, Healthcare/dental/vision ...   [Local remote]  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "files_list = os.listdir()\n",
        "\n",
        "for i in files_list:\n",
        "  if 'row' in i:\n",
        "    json_data = generate_json_summary(i)\n",
        "    add_row_to_df(json_data)\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuMjXBx30dph"
      },
      "source": [
        "Great! We have code that effectively creates a crude form of the dataframe we want. There is still data and feature engineering to do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr96kNhz0sdz"
      },
      "source": [
        "Once this dataframe is created from all of the text files, we"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "q4tkrhED1kHM",
        "outputId": "45bebd2c-4a11-4285-aced-14ce058de654"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "'str' object has no attribute 'empty'",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ab759d13-3c99-4dfc-9860-76cfb2aaf4a5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emploment type</th>\n",
              "      <th>job function</th>\n",
              "      <th>description of product/service</th>\n",
              "      <th>industries</th>\n",
              "      <th>position name</th>\n",
              "      <th>broader role name</th>\n",
              "      <th>company</th>\n",
              "      <th>location</th>\n",
              "      <th>salary/compensation range</th>\n",
              "      <th>responsibilities</th>\n",
              "      <th>goals/objectives</th>\n",
              "      <th>name of department/team</th>\n",
              "      <th>required qualifications</th>\n",
              "      <th>preferred qualifications</th>\n",
              "      <th>benefits</th>\n",
              "      <th>work arrangement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[Other]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Software Development]</td>\n",
              "      <td>[Machine Learning Consultant]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Dice]</td>\n",
              "      <td>[United States]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Requirement gathering and documentation, Ente...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Strong understanding of SDLC, Proficiency in ...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Remote]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[Engineering, Finance, Information Technology]</td>\n",
              "      <td>[Algorithmic Trading Developer]</td>\n",
              "      <td>[Financial Services, Investment Banking, Softw...</td>\n",
              "      <td>[Algorithm Developer]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Nurp]</td>\n",
              "      <td>[United States]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Translate trading strategies to algorithms, D...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Bachelor's or Master's degree in relevant fie...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[100% Remote work, Health, Dental, Vision Insu...</td>\n",
              "      <td>[Remote]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[Quantum Engineering Solutions]</td>\n",
              "      <td>[Appliances, Electrical, Electronics Manufactu...</td>\n",
              "      <td>[Quantum Solution Engineer]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Keysight Technologies]</td>\n",
              "      <td>[Santa Rosa, CA]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Customer success, Engage with customers, Defi...</td>\n",
              "      <td>[Create world-leading quantum solutions, Innov...</td>\n",
              "      <td>[Quantum Engineering Solutions]</td>\n",
              "      <td>[MS or PhD in physics or engineering, 5+ years...</td>\n",
              "      <td>[Experimental background in quantum physics, O...</td>\n",
              "      <td>[Medical, dental, vision, 401(k) Plan, Paid Ho...</td>\n",
              "      <td>[On-site]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[Education and Training]</td>\n",
              "      <td>[Quantum computing applications]</td>\n",
              "      <td>[Research Services]</td>\n",
              "      <td>[Summer Internship - Quantum Systems]</td>\n",
              "      <td>[Intern]</td>\n",
              "      <td>[QuEra Computing Inc.]</td>\n",
              "      <td>[Boston, MA]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Holography/Laser Beam Optimization, Algorithm...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Degree in CS/Physics/Math or related, Python ...</td>\n",
              "      <td>[Optics experience]</td>\n",
              "      <td>[Diverse work environment]</td>\n",
              "      <td>[On-site]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[Quantitative software development]</td>\n",
              "      <td>[IT Services, IT Consulting]</td>\n",
              "      <td>[Quantitative Software Engineer]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Raft]</td>\n",
              "      <td>[San Antonio, TX]</td>\n",
              "      <td>[$90,000.00/yr, $170,000.00/yr]</td>\n",
              "      <td>[Develop software for quantitative methods, Dr...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[3+ years software development, Python/Java/C+...</td>\n",
              "      <td>[Big data processing experience, Machine learn...</td>\n",
              "      <td>[Competitive salary, Healthcare/dental/vision ...</td>\n",
              "      <td>[Local remote]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[Engineering and IT]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[IT Services, IT Consulting]</td>\n",
              "      <td>[AI Software Engineer]</td>\n",
              "      <td>[Software Engineer]</td>\n",
              "      <td>[Zoom]</td>\n",
              "      <td>[California, USA]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Collaborate multidisciplinary teams, Implemen...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Advanced education in CS, AI, Deep understand...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Diverse perks, health support, work-life bala...</td>\n",
              "      <td>[Hybrid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[Kernel development for safety-critical systems]</td>\n",
              "      <td>[Airlines and Aviation, Aerospace Component Ma...</td>\n",
              "      <td>[Associate Software Engineer - Kernel Developer]</td>\n",
              "      <td>[Software Engineer]</td>\n",
              "      <td>[Boeing]</td>\n",
              "      <td>[Mesa, AZ]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Develops reusable architectures, Serves as su...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Bachelor/Master/Doctorate in related field, 1...</td>\n",
              "      <td>[2+ years C++, C, or C# experience, Real-time ...</td>\n",
              "      <td>[Health insurance, Retirement savings plans, P...</td>\n",
              "      <td>[Virtual]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[Design, Consulting, Engineering]</td>\n",
              "      <td>[Optical Design Software]</td>\n",
              "      <td>[Semiconductor Manufacturing, Software Develop...</td>\n",
              "      <td>[Software Architect - C++]</td>\n",
              "      <td>[Software Architect]</td>\n",
              "      <td>[Synopsys Inc]</td>\n",
              "      <td>[Irvine, CA]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Guide development process, Assess legacy syst...</td>\n",
              "      <td>[Deliver cutting-edge optical solutions, Integ...</td>\n",
              "      <td>[Synopsys OSG]</td>\n",
              "      <td>[Bachelor's degree in CS or related field, 6+ ...</td>\n",
              "      <td>[Background in Physics, Optics, Mathematics, E...</td>\n",
              "      <td>[Cutting-edge technology projects, Dynamic wor...</td>\n",
              "      <td>[Hybrid, Remote]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab759d13-3c99-4dfc-9860-76cfb2aaf4a5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab759d13-3c99-4dfc-9860-76cfb2aaf4a5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab759d13-3c99-4dfc-9860-76cfb2aaf4a5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b36e375a-46e0-4ec2-87db-56494bd811c6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b36e375a-46e0-4ec2-87db-56494bd811c6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b36e375a-46e0-4ec2-87db-56494bd811c6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4e9433c5-ccbf-4775-aacb-980e39b4159a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4e9433c5-ccbf-4775-aacb-980e39b4159a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  emploment type                                    job function  \\\n",
              "0            NaN                                         [Other]   \n",
              "1            NaN  [Engineering, Finance, Information Technology]   \n",
              "2            NaN           [Engineering, Information Technology]   \n",
              "3            NaN                        [Education and Training]   \n",
              "4            NaN           [Engineering, Information Technology]   \n",
              "5            NaN                            [Engineering and IT]   \n",
              "6            NaN           [Engineering, Information Technology]   \n",
              "7            NaN               [Design, Consulting, Engineering]   \n",
              "\n",
              "                     description of product/service  \\\n",
              "0                                             [N/A]   \n",
              "1                   [Algorithmic Trading Developer]   \n",
              "2                   [Quantum Engineering Solutions]   \n",
              "3                  [Quantum computing applications]   \n",
              "4               [Quantitative software development]   \n",
              "5                                               NaN   \n",
              "6  [Kernel development for safety-critical systems]   \n",
              "7                         [Optical Design Software]   \n",
              "\n",
              "                                          industries  \\\n",
              "0                             [Software Development]   \n",
              "1  [Financial Services, Investment Banking, Softw...   \n",
              "2  [Appliances, Electrical, Electronics Manufactu...   \n",
              "3                                [Research Services]   \n",
              "4                       [IT Services, IT Consulting]   \n",
              "5                       [IT Services, IT Consulting]   \n",
              "6  [Airlines and Aviation, Aerospace Component Ma...   \n",
              "7  [Semiconductor Manufacturing, Software Develop...   \n",
              "\n",
              "                                      position name     broader role name  \\\n",
              "0                     [Machine Learning Consultant]                 [N/A]   \n",
              "1                             [Algorithm Developer]                 [N/A]   \n",
              "2                       [Quantum Solution Engineer]                 [N/A]   \n",
              "3             [Summer Internship - Quantum Systems]              [Intern]   \n",
              "4                  [Quantitative Software Engineer]                 [N/A]   \n",
              "5                            [AI Software Engineer]   [Software Engineer]   \n",
              "6  [Associate Software Engineer - Kernel Developer]   [Software Engineer]   \n",
              "7                        [Software Architect - C++]  [Software Architect]   \n",
              "\n",
              "                   company           location  \\\n",
              "0                   [Dice]    [United States]   \n",
              "1                   [Nurp]    [United States]   \n",
              "2  [Keysight Technologies]   [Santa Rosa, CA]   \n",
              "3   [QuEra Computing Inc.]       [Boston, MA]   \n",
              "4                   [Raft]  [San Antonio, TX]   \n",
              "5                   [Zoom]  [California, USA]   \n",
              "6                 [Boeing]         [Mesa, AZ]   \n",
              "7           [Synopsys Inc]       [Irvine, CA]   \n",
              "\n",
              "         salary/compensation range  \\\n",
              "0                            [N/A]   \n",
              "1                              NaN   \n",
              "2                            [N/A]   \n",
              "3                              NaN   \n",
              "4  [$90,000.00/yr, $170,000.00/yr]   \n",
              "5                              NaN   \n",
              "6                              NaN   \n",
              "7                            [N/A]   \n",
              "\n",
              "                                    responsibilities  \\\n",
              "0  [Requirement gathering and documentation, Ente...   \n",
              "1  [Translate trading strategies to algorithms, D...   \n",
              "2  [Customer success, Engage with customers, Defi...   \n",
              "3  [Holography/Laser Beam Optimization, Algorithm...   \n",
              "4  [Develop software for quantitative methods, Dr...   \n",
              "5  [Collaborate multidisciplinary teams, Implemen...   \n",
              "6  [Develops reusable architectures, Serves as su...   \n",
              "7  [Guide development process, Assess legacy syst...   \n",
              "\n",
              "                                    goals/objectives  \\\n",
              "0                                              [N/A]   \n",
              "1                                                NaN   \n",
              "2  [Create world-leading quantum solutions, Innov...   \n",
              "3                                                NaN   \n",
              "4                                              [N/A]   \n",
              "5                                                NaN   \n",
              "6                                                NaN   \n",
              "7  [Deliver cutting-edge optical solutions, Integ...   \n",
              "\n",
              "           name of department/team  \\\n",
              "0                            [N/A]   \n",
              "1                            [N/A]   \n",
              "2  [Quantum Engineering Solutions]   \n",
              "3                              NaN   \n",
              "4                            [N/A]   \n",
              "5                              NaN   \n",
              "6                              NaN   \n",
              "7                   [Synopsys OSG]   \n",
              "\n",
              "                             required qualifications  \\\n",
              "0  [Strong understanding of SDLC, Proficiency in ...   \n",
              "1  [Bachelor's or Master's degree in relevant fie...   \n",
              "2  [MS or PhD in physics or engineering, 5+ years...   \n",
              "3  [Degree in CS/Physics/Math or related, Python ...   \n",
              "4  [3+ years software development, Python/Java/C+...   \n",
              "5  [Advanced education in CS, AI, Deep understand...   \n",
              "6  [Bachelor/Master/Doctorate in related field, 1...   \n",
              "7  [Bachelor's degree in CS or related field, 6+ ...   \n",
              "\n",
              "                            preferred qualifications  \\\n",
              "0                                              [N/A]   \n",
              "1                                              [N/A]   \n",
              "2  [Experimental background in quantum physics, O...   \n",
              "3                                [Optics experience]   \n",
              "4  [Big data processing experience, Machine learn...   \n",
              "5                                              [N/A]   \n",
              "6  [2+ years C++, C, or C# experience, Real-time ...   \n",
              "7  [Background in Physics, Optics, Mathematics, E...   \n",
              "\n",
              "                                            benefits  work arrangement  \n",
              "0                                              [N/A]          [Remote]  \n",
              "1  [100% Remote work, Health, Dental, Vision Insu...          [Remote]  \n",
              "2  [Medical, dental, vision, 401(k) Plan, Paid Ho...         [On-site]  \n",
              "3                         [Diverse work environment]         [On-site]  \n",
              "4  [Competitive salary, Healthcare/dental/vision ...    [Local remote]  \n",
              "5  [Diverse perks, health support, work-life bala...          [Hybrid]  \n",
              "6  [Health insurance, Retirement savings plans, P...         [Virtual]  \n",
              "7  [Cutting-edge technology projects, Dynamic wor...  [Hybrid, Remote]  "
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brs1-B4x2YH5"
      },
      "source": [
        "Our first thought might be to fill all missing values (or fields with value NaN) to 0. When we tokenize words and then phrases in the vocabulary, we will make sure nothing is assigned value 0. Or, we will make one-hot encodings of phrase occurence for each column, but that is not ideal. Hopefully the algorithm we use can learn well enough from label encodings rather than having to use one-hot encodings which would make the dataframe have many many columns. We know that this can negatively impact performance but the difference might be small enough to justify abandoning the one-hot approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkxfjJd838Nm",
        "outputId": "70b29250-8d7b-4aa2-8460-61a18583f08c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   emploment type                                    job function  \\\n",
            "0               0                                         [Other]   \n",
            "1               0  [Engineering, Finance, Information Technology]   \n",
            "2               0           [Engineering, Information Technology]   \n",
            "3               0                        [Education and Training]   \n",
            "4               0           [Engineering, Information Technology]   \n",
            "5               0                            [Engineering and IT]   \n",
            "6               0           [Engineering, Information Technology]   \n",
            "7               0               [Design, Consulting, Engineering]   \n",
            "\n",
            "                     description of product/service  \\\n",
            "0                                             [N/A]   \n",
            "1                   [Algorithmic Trading Developer]   \n",
            "2                   [Quantum Engineering Solutions]   \n",
            "3                  [Quantum computing applications]   \n",
            "4               [Quantitative software development]   \n",
            "5                                                 0   \n",
            "6  [Kernel development for safety-critical systems]   \n",
            "7                         [Optical Design Software]   \n",
            "\n",
            "                                          industries  \\\n",
            "0                             [Software Development]   \n",
            "1  [Financial Services, Investment Banking, Softw...   \n",
            "2  [Appliances, Electrical, Electronics Manufactu...   \n",
            "3                                [Research Services]   \n",
            "4                       [IT Services, IT Consulting]   \n",
            "5                       [IT Services, IT Consulting]   \n",
            "6  [Airlines and Aviation, Aerospace Component Ma...   \n",
            "7  [Semiconductor Manufacturing, Software Develop...   \n",
            "\n",
            "                                      position name     broader role name  \\\n",
            "0                     [Machine Learning Consultant]                 [N/A]   \n",
            "1                             [Algorithm Developer]                 [N/A]   \n",
            "2                       [Quantum Solution Engineer]                 [N/A]   \n",
            "3             [Summer Internship - Quantum Systems]              [Intern]   \n",
            "4                  [Quantitative Software Engineer]                 [N/A]   \n",
            "5                            [AI Software Engineer]   [Software Engineer]   \n",
            "6  [Associate Software Engineer - Kernel Developer]   [Software Engineer]   \n",
            "7                        [Software Architect - C++]  [Software Architect]   \n",
            "\n",
            "                   company           location  \\\n",
            "0                   [Dice]    [United States]   \n",
            "1                   [Nurp]    [United States]   \n",
            "2  [Keysight Technologies]   [Santa Rosa, CA]   \n",
            "3   [QuEra Computing Inc.]       [Boston, MA]   \n",
            "4                   [Raft]  [San Antonio, TX]   \n",
            "5                   [Zoom]  [California, USA]   \n",
            "6                 [Boeing]         [Mesa, AZ]   \n",
            "7           [Synopsys Inc]       [Irvine, CA]   \n",
            "\n",
            "         salary/compensation range  \\\n",
            "0                            [N/A]   \n",
            "1                                0   \n",
            "2                            [N/A]   \n",
            "3                                0   \n",
            "4  [$90,000.00/yr, $170,000.00/yr]   \n",
            "5                                0   \n",
            "6                                0   \n",
            "7                            [N/A]   \n",
            "\n",
            "                                    responsibilities  \\\n",
            "0  [Requirement gathering and documentation, Ente...   \n",
            "1  [Translate trading strategies to algorithms, D...   \n",
            "2  [Customer success, Engage with customers, Defi...   \n",
            "3  [Holography/Laser Beam Optimization, Algorithm...   \n",
            "4  [Develop software for quantitative methods, Dr...   \n",
            "5  [Collaborate multidisciplinary teams, Implemen...   \n",
            "6  [Develops reusable architectures, Serves as su...   \n",
            "7  [Guide development process, Assess legacy syst...   \n",
            "\n",
            "                                    goals/objectives  \\\n",
            "0                                              [N/A]   \n",
            "1                                                  0   \n",
            "2  [Create world-leading quantum solutions, Innov...   \n",
            "3                                                  0   \n",
            "4                                              [N/A]   \n",
            "5                                                  0   \n",
            "6                                                  0   \n",
            "7  [Deliver cutting-edge optical solutions, Integ...   \n",
            "\n",
            "           name of department/team  \\\n",
            "0                            [N/A]   \n",
            "1                            [N/A]   \n",
            "2  [Quantum Engineering Solutions]   \n",
            "3                                0   \n",
            "4                            [N/A]   \n",
            "5                                0   \n",
            "6                                0   \n",
            "7                   [Synopsys OSG]   \n",
            "\n",
            "                             required qualifications  \\\n",
            "0  [Strong understanding of SDLC, Proficiency in ...   \n",
            "1  [Bachelor's or Master's degree in relevant fie...   \n",
            "2  [MS or PhD in physics or engineering, 5+ years...   \n",
            "3  [Degree in CS/Physics/Math or related, Python ...   \n",
            "4  [3+ years software development, Python/Java/C+...   \n",
            "5  [Advanced education in CS, AI, Deep understand...   \n",
            "6  [Bachelor/Master/Doctorate in related field, 1...   \n",
            "7  [Bachelor's degree in CS or related field, 6+ ...   \n",
            "\n",
            "                            preferred qualifications  \\\n",
            "0                                              [N/A]   \n",
            "1                                              [N/A]   \n",
            "2  [Experimental background in quantum physics, O...   \n",
            "3                                [Optics experience]   \n",
            "4  [Big data processing experience, Machine learn...   \n",
            "5                                              [N/A]   \n",
            "6  [2+ years C++, C, or C# experience, Real-time ...   \n",
            "7  [Background in Physics, Optics, Mathematics, E...   \n",
            "\n",
            "                                            benefits  work arrangement  \n",
            "0                                              [N/A]          [Remote]  \n",
            "1  [100% Remote work, Health, Dental, Vision Insu...          [Remote]  \n",
            "2  [Medical, dental, vision, 401(k) Plan, Paid Ho...         [On-site]  \n",
            "3                         [Diverse work environment]         [On-site]  \n",
            "4  [Competitive salary, Healthcare/dental/vision ...    [Local remote]  \n",
            "5  [Diverse perks, health support, work-life bala...          [Hybrid]  \n",
            "6  [Health insurance, Retirement savings plans, P...         [Virtual]  \n",
            "7  [Cutting-edge technology projects, Dynamic wor...  [Hybrid, Remote]  \n"
          ]
        }
      ],
      "source": [
        "df_filled = df.fillna(0)\n",
        "\n",
        "print(df_filled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w1HAiLj6wXt"
      },
      "source": [
        "The next step will be to accumulate all the words in the vocabulary. We need to first make a list of all the words that appear in our columns, except for the 'location' and 'salary' column which we will handle differently.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "wNJcQxy88H4A",
        "outputId": "0446b5ca-2de4-4249-cf9d-52c50fb47818"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "unhashable type: 'list'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-66ce1d9514fa>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Get the set of all unique values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0munique_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns_to_check\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2240\u001b[0m         \u001b[0mCategories\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'b'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m         \"\"\"\n\u001b[0;32m-> 2242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    999\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \"\"\"\n\u001b[0;32m--> 409\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0munique_with_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique_with_mask\u001b[0;34m(values, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.unique\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        }
      ],
      "source": [
        "# the following does not contain 'location' or 'salary/compensation range'\n",
        "columns_to_check = [\"emploment type\", \"job function\", \"description of product/service\", \"industries\",\n",
        "              \"position name\", \"broader role name\", \"company\", \"responsibilities\", \"goals/objectives\",\n",
        "              \"name of department/team\", \"required qualifications\", \"preferred qualifications\",\n",
        "              \"benefits\", \"work arrangement\"]\n",
        "\n",
        "# Get the set of all unique values\n",
        "unique_values = set(df[columns_to_check].stack().unique())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6acLuZa8x1B"
      },
      "source": [
        "Here exposes a major problem: most of our values are lists which this df.stack().unique() call cannot unhash. We may have to evaluate the vocabulary distribution a different way which is not ideal. We will have to generate all of our .json files and save them off. Then, we will need special logic that goes through our chosen fields in each JSON file that we have chosen for our training set (80% of files) and adds every word that occurs to a registry which is a big list or dictionary. Then after doing this each word in the vocab registry will have an associated integer. We will make 'N/A' be 0 as the NaN's will also be filled with 0. By having a lookup registry for each word in the vocab set we can represent each unique phrase as a unique number based on applying Cantor's rule to the set of words in the phrase. When we set up the registry we will not include standard stopping words (e.g. a, the, and, etc) and thus we will lose track of any stopping words but assign numbers to those that are not. This list of phrases separated by commas should then become a list of lists of numbers. For each list of numbers, we will use the Cantor function to calculate its numerical representation. Thus a phrase of 'N/A' will get a value of 1 since 2^0 = 1. Then every field of the dataframe will have numbers, or a list.\n",
        "\n",
        "From talking about my plans though, I am starting to get quite worried that a label encoding will be bad. Maybe we should at least do a one-hot encoding for phrase occurences in each column. There will probably be at least several hundred different phrases but maybe more. My first instinct is to see how well we will do if we then encode our groups of phrases into unique numbers for each group by again applying Cantor's rule."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSaGTiZkB6jr"
      },
      "source": [
        "So now, we backtrack to generating AND saving the JSON files. Then we will shuffle our rows, and pick an 80% training subset on which to tokenize our words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEbVJGIUC0MD"
      },
      "source": [
        "First, we modify the generate_json_data function to be a generate_json_file function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utu79EtCB5zl"
      },
      "outputs": [],
      "source": [
        "# getting started with OpenAI API!\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "def generate_json_file(text_file_path):\n",
        "  with open(text_file_path, 'r') as file:\n",
        "    # Read the contents of the file into a string\n",
        "    file_contents = file.read()\n",
        "\n",
        "  prompt = \"Take the following text from a job posting and extract all info related to the following fields which will end up being the keys in the JSON data you will return: emploment type, job function, description of product/service, industries, position name, broader role name, company, location, salary/compensation range, responsibilities, goals/objectives, name of department/team, required qualifications, preferred qualifications, benefits, work arrangement (hybrid, on-site, remote?), organizing this info into a table where the first column contains the fields and the second column contains the info relevant to these fields. Try to extract as much of the info as possible while being as succinct as possible. Remove redundancy wherever possible. If there is no info related to a particular field, put 'N/A'. Standardize entries in the info column by separating individual considerations with a hyphen. Do not exceed 5 words for any individual consideration in the info column. Use acronyms and abbreviations where necessary to do so. Return the table as a json data structure that is loadable in python, and make sure the keys are the fields listed earlier, not 'fields' and 'info'. Store the dictionary values as python lists. Return only the JSON and no title. Here is the text from the job posting: \"\n",
        "\n",
        "  prompt = prompt + \"/n\" + file_contents\n",
        "\n",
        "  client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=\"someKey\",\n",
        "  )\n",
        "\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt,\n",
        "          }\n",
        "      ],\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "  )\n",
        "  json_files_dir = r\"drive/MyDrive/LI-Jobs-JSON/\"\n",
        "  json_data = json.loads(chat_completion.choices[0].message.content.strip(\"`\").strip('json').strip())\n",
        "  json_file_path = json_files_dir + text_file_path.strip(r\"drive/MyDrive/text_files2/\").strip('.txt') + '.json'\n",
        "  # Write JSON data to the file\n",
        "  with open(json_file_path, \"w\") as json_file:\n",
        "    json.dump(json_data, json_file)\n",
        "\n",
        "  return json_file_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n612Df8rpaIY",
        "outputId": "60748205-968c-4ed0-e8d8-aa6a7c180188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftoTLWt0DCBm"
      },
      "source": [
        "Since we should have our files generated we need not worry about making the dataframe at this stage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK50G5_MDRdO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dir_name = \"drive/MyDrive/text_files2/\"\n",
        "\n",
        "files_list = os.listdir(dir_name)\n",
        "\n",
        "for i in files_list:\n",
        "  if 'row' in i:\n",
        "    file_path = dir_name + i\n",
        "    generate_json_file(file_path)\n",
        "    # ignore adding row to dataframe for now\n",
        "    #add_row_to_df(json_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsh54MTgnnq9"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OqiaBSzDvv4"
      },
      "source": [
        "Excellent, so it took 57 seconds for the above code to generate 12 .json files. So the stage of preparing the json files for 100 text files would take around 10 mins, which is not bad. Also, all my OpenAI API calls so far have cost me 5 cents. I estimate that I've made up to 50 or so. So if I need to make 500 API calls, it will cost me about 50 cents! I can live with that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJrDW67iKqKn",
        "outputId": "cc6a1a42-0a21-46ec-e718-a043535e7e60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jW9OdnV3YPp"
      },
      "source": [
        "The plan is to now attempt to generate a json file for every one of the 107 text files we have saved in Drive. We will save the JSON files to this folder in Drive: https://drive.google.com/drive/u/0/folders/1XZV0nbGcIuT0Kim3IoNP0sdrKuvi1uza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwsAP5u_4F4w",
        "outputId": "7c05636d-047c-4ad4-d187-ce91d260f588"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['How to get started with Drive.pdf',\n",
              " 'Stewart Calculus Early Transcendentals 7th.pdf',\n",
              " 'Stewart Calculus 7 Edition [Solutions Manual Chapters 1-11].pdf',\n",
              " 'writ2 article 21st century atlantis.pdf',\n",
              " 'Sublease AgreementLiam.doc',\n",
              " 'Untitled document.gdoc',\n",
              " 'Liam resume.pages',\n",
              " 'Liam resume.pdf',\n",
              " 'Liam resume.doc',\n",
              " 'Psych Final.docx',\n",
              " 'Psych Midterm.docx',\n",
              " 'Psych Practice Questions.zip',\n",
              " '1d stats reports peak measurements ss.pages',\n",
              " '2016_09_13_19_12_55.pdf',\n",
              " '2016_09_13_19_19_55.pdf',\n",
              " '2016_12_05_14_03_42.pdf',\n",
              " 'Griffiths (1).pdf',\n",
              " 'Hartle,Gravity.pdf',\n",
              " 'Sublease AgreementLiam.doc.gdoc',\n",
              " 'Quantum-Mechanics-griffiths-2ed-Solutions.pdf',\n",
              " 'Liam resume.TLdoc.gdoc',\n",
              " 'Hartle Gravity Solutions.pdf',\n",
              " '[griffiths_d.]_introduction_to_elementary_particle.pdf',\n",
              " 'Liamresume.TLdoc 2.docx',\n",
              " 'Liamresume.TLdoc 2.docx.gdoc',\n",
              " 'Liam Resume Current.docx',\n",
              " 'Resume  05-04-17.docx',\n",
              " 'The BEST Resume.pdf',\n",
              " 'FT Supp.gdoc',\n",
              " 'Fitness Transform CL.gdoc',\n",
              " 'Productive Robotics CovL.gdoc',\n",
              " 'taylor classical mechanics.pdf',\n",
              " 'classical mechanics taylor.pdf',\n",
              " 'Complex Analysis Bak & Newman.pdf',\n",
              " 'Microwave Optics.gslides',\n",
              " 'The BEST Resume.pdf.gdoc',\n",
              " 'Resume Current (1).docx',\n",
              " 'Resume Current.pdf',\n",
              " 'Interferometry.gslides',\n",
              " 'Laser Properties.gslides',\n",
              " 'Abstract algebra chapter 1 solutions.pdf',\n",
              " 'Principles of Mathematical Analysis Rudin.pdf',\n",
              " 'history-of-modern-latin-america-a-meade-teresa-a.pdf',\n",
              " 'Griffiths-Electrodynamics-4ed.pdf',\n",
              " 'Ross-Elementary-Analysis.pdf',\n",
              " 'Brown-Churchill-Complex Variables and Application 8th edition.pdf',\n",
              " 'Abstract algebra dummit.pdf',\n",
              " 'aimless-for you_ 7.mp3',\n",
              " 'a lowfi christmas mix_ 17.mp3',\n",
              " 'close your eyes_ 6.mp3',\n",
              " 'axiom-skadderbrain_ 4.mp3',\n",
              " 'backwhen cherry_ 6.mp3',\n",
              " 'atcafe_ 6.mp3',\n",
              " 'dozing off_ 19.mp3',\n",
              " 'young vibes_ 9.mp3',\n",
              " 'dozing off_ 5.mp3',\n",
              " 'atcafe_ 4.mp3',\n",
              " 'a lowfi christmas mix_ 3 1.mp3',\n",
              " 'axiom-skadderbrain_ 8.mp3',\n",
              " 'atcafe_ 15.mp3',\n",
              " 'dozing off_ 13.mp3',\n",
              " 'dozing off_ 16.mp3',\n",
              " 'delusion_ 3.mp3',\n",
              " 'CALM_ 2.mp3',\n",
              " 'dozing off_ 17.mp3',\n",
              " 'sunday beats_ 2.mp3',\n",
              " 'backwhen cherry_ 9.mp3',\n",
              " 'dozing off_ 10.mp3',\n",
              " 'dozing off_ 14.mp3',\n",
              " 'selcouth_ 5.mp3',\n",
              " 'CALM_ 4.mp3',\n",
              " 'nightlife inst_ 2.mp3',\n",
              " 'nightlife inst_ 9.mp3',\n",
              " 'dozing off_ 1.mp3',\n",
              " 'a lowfi chirstmas mix_ 4 1.mp3',\n",
              " 'sunday beats_ 1.mp3',\n",
              " 'a lowfi christmas mix_ 19.mp3',\n",
              " 'nightlife inst_ 11.mp3',\n",
              " 'childhood_ 3.mp3',\n",
              " 'close your eyes_ 17.mp3',\n",
              " 'boom bap_ 8.mp3',\n",
              " 'backwhen cherry_ 7.mp3',\n",
              " 'close your eyes_ 16.mp3',\n",
              " 'childhood_ 4.mp3',\n",
              " 'nightlife inst_ 19.mp3',\n",
              " 'axiom- skadderbrain_ 2.mp3',\n",
              " 'dozing off_ 11.mp3',\n",
              " 'nightlife inst_ 6.mp3',\n",
              " 'boom bap_ 4.mp3',\n",
              " 'CALM_ 5.mp3',\n",
              " 'selcouth_ 4.mp3',\n",
              " 'delusion_ 1.mp3',\n",
              " 'zimmer 26_ 9.mp3',\n",
              " 'dreamin_ 5.mp3',\n",
              " 'sunday beats_ 4.mp3',\n",
              " 'backwhen cherry_ 1.mp3',\n",
              " 'CALM_ 1.mp3',\n",
              " 'a lowfi christmas mix_ 14.mp3',\n",
              " 'a lowfi christmas mix_ 2.mp3',\n",
              " 'axiom-skadderbrain_ 12.mp3',\n",
              " 'atcafe_ 8.mp3',\n",
              " 'nightlife inst_ 1.mp3',\n",
              " 'delusion_ 2.mp3',\n",
              " 'young vibes_ 6.mp3',\n",
              " 'delusion_ 5.mp3',\n",
              " 'close your eyes_ 10.mp3',\n",
              " 'close your eyes_ 31.mp3',\n",
              " 'close your eyes_ 22.mp3',\n",
              " 'dozing off_ 6.mp3',\n",
              " 'axiom-skadderbrain_ 9.mp3',\n",
              " 'childhood_ 1.mp3',\n",
              " 'sunday beats_ 5.mp3',\n",
              " 'selcouth_ 3.mp3',\n",
              " 'a lowfi christmas mix_ 11.mp3',\n",
              " 'dozing off_ 2.mp3',\n",
              " 'close your eyes_ 3.mp3',\n",
              " 'boom bap_ 1.mp3',\n",
              " 'close your eyes_ 20.mp3',\n",
              " 'close your eyes_ 13.mp3',\n",
              " 'atcafe_ 10.mp3',\n",
              " 'zimmer 26_ 2.mp3',\n",
              " 'close your eyes_ 33.mp3',\n",
              " 'close your eyes_ 4.mp3',\n",
              " 'a lowfi christmas mix_ 5.mp3',\n",
              " 'a lowfi christmas mix_ 1 1.mp3',\n",
              " 'close your eyes_ 19.mp3',\n",
              " 'selcouth_ 7.mp3',\n",
              " 'nightlife inst_ 7.mp3',\n",
              " 'close your eyes_ 29.mp3',\n",
              " 'close your eyes_ 5.mp3',\n",
              " 'atcafe_ 14.mp3',\n",
              " 'a lowfi christmas mix_ 6.mp3',\n",
              " 'axiom-skadderbrain_ 5.mp3',\n",
              " 'dreamin_ 3.mp3',\n",
              " 'young vibes_ 14.mp3',\n",
              " 'atcafe_ 5.mp3',\n",
              " 'boom bap_ 11.mp3',\n",
              " 'nightlife inst_ 13.mp3',\n",
              " 'dreamin_ 6.mp3',\n",
              " 'delusion_ 7.mp3',\n",
              " 'backwhen cherry_ 3.mp3',\n",
              " 'close your eyes_ 15.mp3',\n",
              " 'axiom-skadderbrain_ 10.mp3',\n",
              " 'atcafe_ 7.mp3',\n",
              " 'dozing off_ 25.mp3',\n",
              " 'young vibes_ 13.mp3',\n",
              " 'atcafe_ 1.mp3',\n",
              " 'dreamin_ 4.mp3',\n",
              " 'zimmer 26_ 10.mp3',\n",
              " 'CALM_ 6.mp3',\n",
              " 'dozing off_ 22.mp3',\n",
              " 'a lowfi christmas mix_ 10.mp3',\n",
              " 'aimless-for you_ 4.mp3',\n",
              " 'nightlife inst_ 8.mp3',\n",
              " 'boom bap_ 13.mp3',\n",
              " 'axiom-skadderbrain_ 11.mp3',\n",
              " 'close your eyes_ 8.mp3',\n",
              " 'axiom-skadderbrain_ 6.mp3',\n",
              " 'a lowfi christmas mix_ 9.mp3',\n",
              " 'backwhen cherry_ 10.mp3',\n",
              " 'close your eyes_ 26.mp3',\n",
              " 'CALM_ 3.mp3',\n",
              " 'atcafe_ 9.mp3',\n",
              " 'young vibes_ 12.mp3',\n",
              " 'zimmer 26_ 6.mp3',\n",
              " 'close your eyes_ 28.mp3',\n",
              " 'delusion_ 4.mp3',\n",
              " 'aimless-for you_ 8.mp3',\n",
              " 'atcafe_ 13.mp3',\n",
              " 'delusion_ 6.mp3',\n",
              " 'atcafe_ 12.mp3',\n",
              " 'nightlife inst_ 4.mp3',\n",
              " 'young vibes_ 5.mp3',\n",
              " 'nightlife inst_ 16.mp3',\n",
              " 'backwhen cherry_ 8.mp3',\n",
              " 'backwhen cherry_ 2.mp3',\n",
              " 'close your eyes_ 2.mp3',\n",
              " 'sunday beats_ 3.mp3',\n",
              " 'young vibes_ 11.mp3',\n",
              " 'zimmer 26_ 4.mp3',\n",
              " 'dozing off_ 21.mp3',\n",
              " 'close your eyes_ 27.mp3',\n",
              " 'selcouth_ 1.mp3',\n",
              " 'close your eyes_ 30.mp3',\n",
              " 'nightlife inst_ 10.mp3',\n",
              " 'atcafe_ 2.mp3',\n",
              " 'selcouth_ 6.mp3',\n",
              " 'boom bap_ 5.mp3',\n",
              " 'zimmer 26_ 7.mp3',\n",
              " 'young vibes_ 4.mp3',\n",
              " 'childhood_ 5.mp3',\n",
              " 'backwhen cherry_ 4.mp3',\n",
              " 'young vibes_ 2.mp3',\n",
              " 'a lowfi christmas mix_ 18.mp3',\n",
              " 'axiom- skadderbrain_ 3.mp3',\n",
              " 'boom bap_ 10.mp3',\n",
              " 'dozing off_ 23.mp3',\n",
              " 'a lowfi christmas mix_ 2 1.mp3',\n",
              " 'young vibes_ 10.mp3',\n",
              " 'young vibes_ 7.mp3',\n",
              " 'dozing off_ 24.mp3',\n",
              " 'a lowfi christmas mix_ 12.mp3',\n",
              " 'a lowfi christmas mix_ 7.mp3',\n",
              " 'nightlife inst_ 17.mp3',\n",
              " 'dreamin_ 1.mp3',\n",
              " 'dozing off_ 26.mp3',\n",
              " 'dozing off_ 12.mp3',\n",
              " 'atcafe_ 3.mp3',\n",
              " 'axiom- skadderbrain_ 1.mp3',\n",
              " 'boom bap_ 6.mp3',\n",
              " 'zimmer 26_ 3.mp3',\n",
              " 'atcafe_ 11.mp3',\n",
              " 'close your eyes_ 32.mp3',\n",
              " 'a lowfi christmas mix_ 3.mp3',\n",
              " 'zimmer 26_ 1.mp3',\n",
              " 'aimless-for you_ 1.mp3',\n",
              " 'boom bap_ 7.mp3',\n",
              " 'young vibes_ 3.mp3',\n",
              " 'dozing off_ 7.mp3',\n",
              " 'close your eyes_ 24.mp3',\n",
              " 'close your eyes_ 18.mp3',\n",
              " 'a lowfi christmas mix_ 1.mp3',\n",
              " 'a lowfi christmas mix_ 13.mp3',\n",
              " 'aimless-for you_ 6.mp3',\n",
              " 'selcouth_ 2.mp3',\n",
              " 'nightlife inst_ 12.mp3',\n",
              " 'close your eyes_ 7.mp3',\n",
              " 'atcafe_ 17.mp3',\n",
              " 'close your eyes_ 23.mp3',\n",
              " 'backwhen cherry_ 5.mp3',\n",
              " 'dozing off_ 3.mp3',\n",
              " 'young vibes_ 8.mp3',\n",
              " 'CALM_ 7.mp3',\n",
              " 'sunday beats_ 6.mp3',\n",
              " 'boom bap_ 9.mp3',\n",
              " 'nightlife inst_ 3.mp3',\n",
              " 'a lowfi christmas mix_ 15.mp3',\n",
              " 'close your eyes_ 21.mp3',\n",
              " 'young vibes_ 1.mp3',\n",
              " 'atcafe_ 16.mp3',\n",
              " 'boom bap_ 2.mp3',\n",
              " 'childhood_ 6.mp3',\n",
              " 'dozing off_ 20.mp3',\n",
              " 'aimless-for you_ 5.mp3',\n",
              " 'childhood_ 2.mp3',\n",
              " 'nightlife inst_ 5.mp3',\n",
              " 'dozing off_ 9.mp3',\n",
              " 'zimmer 26_ 11.mp3',\n",
              " 'close your eyes_ 25.mp3',\n",
              " 'aimless-for you_ 2.mp3',\n",
              " 'zimmer 26_ 5.mp3',\n",
              " 'boom bap_ 12.mp3',\n",
              " 'zimmer 26_ 8.mp3',\n",
              " 'boom bap_ 14.mp3',\n",
              " 'a lowfi chirstmas mix_ 4.mp3',\n",
              " 'nightlife inst_ 15.mp3',\n",
              " 'boom bap_ 3.mp3',\n",
              " 'young vibes_ 15.mp3',\n",
              " 'axiom-skadderbrain_ 7.mp3',\n",
              " 'nightlife inst_ 14.mp3',\n",
              " 'dozing off_ 15.mp3',\n",
              " 'a lowfi christmas mix_ 16.mp3',\n",
              " 'dozing off_ 8.mp3',\n",
              " 'nightlife inst_ 18.mp3',\n",
              " 'close your eyes_ 1.mp3',\n",
              " 'close your eyes_ 14.mp3',\n",
              " 'atcafe_ 19.mp3',\n",
              " 'aimless-for you_ 3.mp3',\n",
              " 'close your eyes_ 34.mp3',\n",
              " 'close your eyes_ 11.mp3',\n",
              " 'close your eyes_ 9.mp3',\n",
              " 'dreamin_ 2.mp3',\n",
              " 'close your eyes_ 12.mp3',\n",
              " 'atcafe_ 18.mp3',\n",
              " 'dozing off_ 4.mp3',\n",
              " 'dozing off_ 18.mp3',\n",
              " 'AS Background Consent Form - Rev 3.19.13 [Fillable Form] (1).pdf',\n",
              " 'FLIR ITAR form.pdf',\n",
              " 'FLIR ITAR form.gdoc',\n",
              " 'winmail.dat',\n",
              " 'Untitled folder',\n",
              " 'Resume Current.docx',\n",
              " 'Resume 7-11-21.gdoc',\n",
              " 'RESUME 7-21-2021.gdoc',\n",
              " 'Resume 09_20_21.gdoc',\n",
              " 'Griffiths.pdf',\n",
              " 'Genentech CV.gdoc',\n",
              " 'job apps snippets.gdoc',\n",
              " 'Places bucket list.gsheet',\n",
              " 'RF Wireless Design Validation Test (DVT) Engineering Apple Cover Letter.gdoc',\n",
              " 'resume.gdoc',\n",
              " 'LinkedIn Project Ingredients.gdoc',\n",
              " 'Colab Notebooks',\n",
              " 'Career Strategy Plan - MEC - Liam Abrams.gdoc',\n",
              " 'AI in College Admissions Decisions - A Discussion of Ethical Implications.gdoc',\n",
              " 'Notes for First Meeting with Semih.gdoc',\n",
              " 'Questions for Peter.gdoc',\n",
              " 'Kauai Trip Outline.gdoc',\n",
              " 'Liam Abrams Resume CWC.gdoc',\n",
              " 'Daily improvement grade.gsheet',\n",
              " 'API.gdoc',\n",
              " 'new office roi.docx',\n",
              " 'Desired jobs.gsheet',\n",
              " 'Questions for next meeting (2 14 24).gdoc',\n",
              " 'LI-jobs-features-list.gsheet',\n",
              " 'LI-jobs-ChatGPT-screenshots',\n",
              " 'Liam Abrams Resume CWC - for valet job.gdoc',\n",
              " 'Liam Abrams Resume CWC - dental office.gdoc',\n",
              " 'successfulLinks.gsheet',\n",
              " 'text_files2',\n",
              " 'LI-Jobs-JSON']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.listdir(\"drive/MyDrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr8vjhfK4-s6"
      },
      "source": [
        "We will modify our generate_json_files function to save each JSON file to the correct folder in drive. We will also need to modify our for loop so that the files_list has the correct paths to the text files saved in Drive. Then we will rerun both code blocks: the generate_json_files function definition, as well as the for loop code that calls the function. We'll report back on how long it took and what the damage is cost-wise from the OpenAI API calls.\n",
        "\n",
        "It took us about a minute to do 23 before we encountered an issue on row24.\n",
        "\n",
        "We will rerun this against rows 24-107. We made a folder for the already done ones which is a subfolder of text_files2.\n",
        "\n",
        "It turns out we need to unmount and remount drive after moving data files around because the directory structure in this workspace doesn't get updated when I make changes directly to Drive. It took the for loop around 6 mins to do 64, including repeating the first 23. Since we have already generated JSON files for the first 64, we will move the original text files for those 64 over to alreadyDone and rerun the for loop. We have to unmount and remount drive as well after making the changes to text_files2. We got done with another 8 before the for loop ran into the usual error with generating the JSON file. For this scenario, it would probably be wise to do some exception handling to ask ChatGPT again to return the JSON and hopefully on the 2nd try it is valid. For now though we will continue to generate JSON files the rough and dirty way, moving text files that have already been successfully summarized in JSON to alreadyDone, and rerunning everything.\n",
        "\n",
        "We finally finished up the last 35 JSON files in about 3 mins. So we generated JSON files for all 107 original text files. In total, we have made no more than 200 OpenAI API calls, which have incurred a total of 14 cents worth of costs. Not bad! So to process a fairly large dataset of maybe 1000 jobs would cost no more than a dollar!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC7xBvoIERLh"
      },
      "source": [
        "We note that all of the JSON file names are missing 'r' and came at as 'ow54.json', probably because we tried concatenating the file name with the directory rather than using os.path.join. We will fix this in the future. We will quickly fix the file names that were generated with a for loop. We will also move all text files that we've processed to \"alreadyDone\", so that when the time comes to add more data to the dataset, it will be clear which ones will require JSON summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWCRFtsOEph6",
        "outputId": "874e2c8b-be83-4833-812d-88cba8106c6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All files have been renamed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Specify the directory path\n",
        "directory_path = \"drive/MyDrive/LI-Jobs-JSON/\"\n",
        "\n",
        "# Get a list of all files in the directory\n",
        "files = os.listdir(directory_path)\n",
        "\n",
        "# Iterate over each file and rename it\n",
        "for old_name in files:\n",
        "    if old_name[0] == 'o':\n",
        "      # Construct the new name however you like\n",
        "      new_name = \"r\" + old_name  # Example: Add a prefix to the old name\n",
        "\n",
        "      # Join the directory path with the old file name\n",
        "      old_path = os.path.join(directory_path, old_name)\n",
        "\n",
        "      # Join the directory path with the new file name\n",
        "      new_path = os.path.join(directory_path, new_name)\n",
        "\n",
        "      # Rename the file\n",
        "      os.rename(old_path, new_path)\n",
        "\n",
        "      #print(f\"Renamed '{old_name}' to '{new_name}'\")\n",
        "\n",
        "print(\"All files have been renamed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8ejj_gjUgtQ"
      },
      "source": [
        "I am thinking that if we do use Cantor's function to make a 1-1 mapping from possible phrase space to number space, we might consider using CatBoostAlgorithm rather than a regular decision tree-based algorithm to make sure those numbers are treated as categorical rather than ordinal. Another thing to think about is would it be straightforward or easy enough to leverage a word-embedding model like Word2Vec to generate effective encodings for us that may actually be treated as ordinal or that are vectors that don't require too many columns to express in our dataframe, which we could then train a regular decision-tree based model on?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6Rs2HX-HmXi"
      },
      "source": [
        "I believe we have enough raw data now to use to play around with different ML algorithms. We need to create a dataframe that contains the field-value pairings of each job posting which will be a row in the dataframe. The final dataframe we pass to the algorithm will depend on the algorithm we choose to use. Thus we have some more important decisions to make as well as a fair amount of processing that we still will need to do on the data side. The first thing to note is I have observed two variants of the JSON files we generated. One is the one we anticipated/desired where ChatGPT properly organizes the information into dictionary key-value pairs where the keys are the different fields we specified in our prompt, such as 'employment_type', 'work_arrangement', 'benefits', etc. The other is a dictionary with only two keys: 'fields' and 'info' whose values are lists, and the value for a given index of the 'info' list will be the info value corresponding to the field value for that same index in the 'field' list. So just loading our data from our JSON files into a crude version of our desired final dataframe will require some custom logic since the JSON files aren't all in the same format, unfortunately. In addition, the convention for the field names (whether they are capitalized or not and whether they are snake-cased) varies across JSON files. So we will need to be quite diligent with how we load our data at this point into the dataframe. Not to mention that all the work that will be required to encode our text under each column prior to feeding our data into the ML algorithm will be significant, but we need to focus on one thing at a time so that our objective isn't too daunting. So we will focus on generating a crude version of our final dataframe, where all of the dataframe elements will contain text. In addition, we will need to cross-reference the original successfulLinks spreadsheet in order to correctly add the rating value into our target variable column which we will aptly name 'rating'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJGcDBmuOeRj"
      },
      "source": [
        "We will now embark on our next step, generating a dataframe from the 107 JSON files and the ratings column in the successfulLinks.csv file. In our code we will start by declaring the needed file paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCmkPKlBPBou",
        "outputId": "df993b12-a873-4e93-a719-0818cfeb3ffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXOwNn_bO6hI"
      },
      "outputs": [],
      "source": [
        "json_files_path = \"drive/MyDrive/LI-Jobs-JSON/\"\n",
        "links_csv_path = \"drive/MyDrive/successfulLinksGDRIVE.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZy8PYmnSJ3Z"
      },
      "source": [
        "I think the plan should be to make the dataframe row-by-row, including the rating field. This may be subject to change. I think it will be helpful to read the successfulLinks csv file into a dataframe so that the indexing will automatically match up between it and the dataframe we are generating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6BdYRHgQuoC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "links_dataframe = pd.read_csv(links_csv_path, header=None, names=['url', 'rating'])\n",
        "#links_dataframe.head()\n",
        "#print(links_dataframe.loc[0, 'rating'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFnzG1NKVi1r"
      },
      "source": [
        "Excellent, so now we can hopefully create our dataframe row by row, remembering that we will need some special logic to deal with the different cases of JSON files. We have some code we wrote earlier where we instantiated an empty dataframe with specified column names and made a function to add a row to that dataframe with a JSON dictionary. Let us revisit and modify that code to accomplish what we need to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQ71rzHPMySp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# let's snakecase our column names to avoid having spaces in them\n",
        "# also we add a rating column at the end of the list to store the target variable\n",
        "df_columns = [\"emploment_type\", \"job_function\", \"description_of_product/service\", \"industries\",\n",
        "              \"position_name\", \"broader_role_name\", \"company\", \"location\", \"salary/compensation_range\",\n",
        "              \"responsibilities\", \"goals/objectives\", \"name_of_department/team\", \"required_qualifications\",\n",
        "              \"preferred_qualifications\", \"benefits\", \"work_arrangement\", \"rating\"]\n",
        "# Initialize DataFrame with column names\n",
        "df = pd.DataFrame(columns=df_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqM39z9XNy6_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "locale_json_files_path = \"drive/MyDrive/jobLocations/\"\n",
        "salary_json_files_path = \"drive/MyDrive/jobSalaries/\"\n",
        "\n",
        "for i in range(1, 108):\n",
        "  row_num = df.last_valid_index()\n",
        "  if row_num == None:\n",
        "    row_num = 0\n",
        "  else:\n",
        "    row_num = row_num + 1\n",
        "  assert i == row_num + 1\n",
        "  json_file_path = os.path.join(json_files_path, f'row{i}.json')\n",
        "  # Read JSON file\n",
        "  with open(json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  if 'fields' in json_data.keys():\n",
        "    #print(json_data)\n",
        "    field_names = json_data['fields']\n",
        "    for index, value in enumerate(field_names):\n",
        "      info = json_data['info'][index]\n",
        "      # Check if the value exists as a column name (ignoring case)\n",
        "      column_name = value.replace(\" \", \"_\").lower()\n",
        "      if column_name in df.columns:\n",
        "        # Add the info to the corresponding column and row\n",
        "        df.at[row_num, column_name] = info\n",
        "  else:\n",
        "    for key, value in json_data.items():\n",
        "      # Check if the key exists as a column name (ignoring case)\n",
        "      column_name = key.replace(\" \", \"_\").lower()\n",
        "      if column_name == 'emploment_type':\n",
        "        column_name = 'employment_type'\n",
        "      if column_name in df.columns:\n",
        "        # Add the value to the corresponding column and row\n",
        "        df.at[row_num, column_name] = value\n",
        "\n",
        "  locale_json_file_path = os.path.join(locale_json_files_path, f'row{i}.json')\n",
        "  salary_json_file_path = os.path.join(salary_json_files_path, f'row{i}.json')\n",
        "  # Read locale JSON file\n",
        "  with open(locale_json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  city = json_data['city']\n",
        "  state = json_data['state']\n",
        "  country = json_data['country']\n",
        "  df.at[row_num, 'city'] = city\n",
        "  df.at[row_num, 'state'] = state\n",
        "  df.at[row_num, 'country'] = country\n",
        "  # Read salary JSON file\n",
        "  with open(salary_json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  min_salary = json_data['min_salary']\n",
        "  max_salary = json_data['min_salary']\n",
        "  df.at[row_num, 'min_salary'] = min_salary\n",
        "  df.at[row_num, 'max_salary'] = max_salary\n",
        "  rating = links_dataframe.loc[row_num, 'rating']\n",
        "  df.at[row_num, 'rating'] = rating\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOpMU1zreWYR"
      },
      "source": [
        "We need to work around the case where the summary is broken down into JSON with 'fields' and 'info' keys. From the looks of it, the associations between the items in 'info' and those in 'fields' aren't always to be correct, as the attempt on the third one of that kind ran into an error. I think we will make the decision to print JSON dictionaries that have 'fields' as a key, and not actually individual fields as keys, and pass on making the JSON dictionary for now until we require CHATGPT to redo the ones we have identified in the more desirable and supported format. It may be prudent to write some code to automatically delete the JSON files with the undesired formats before we generate the new ones in the desired format. In addition we will make a list of those indices so we will know the names of which files to delete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clldmJvFgNNX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "need_fix_indices_list = []\n",
        "for i in range(1, 108):\n",
        "  #row_num = df.last_valid_index()\n",
        "  #if row_num == None:\n",
        "    #row_num = 0\n",
        "  #else:\n",
        "    #row_num = row_num + 1\n",
        "  #assert i == row_num + 1\n",
        "  json_file_path = os.path.join(json_files_path, f'row{i}.json')\n",
        "  # Read JSON file\n",
        "  with open(json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  if 'fields' in json_data.keys():\n",
        "    need_fix_indices_list.append(i)\n",
        "\n",
        "\n",
        "    '''field_names = json_data['fields']\n",
        "    for index, value in enumerate(field_names):\n",
        "      info = json_data['info'][index]\n",
        "      # Check if the value exists as a column name (ignoring case)\n",
        "      column_name = value.replace(\" \", \"_\").lower()\n",
        "      if column_name in df.columns:\n",
        "        # Add the info to the corresponding column and row\n",
        "        df.at[row_num, column_name] = info'''\n",
        "  else:\n",
        "    '''for key, value in json_data.items():\n",
        "      # Check if the key exists as a column name (ignoring case)\n",
        "      column_name = key.replace(\" \", \"_\").lower()\n",
        "      if column_name in df.columns:\n",
        "        # Add the value to the corresponding column and row\n",
        "        df.at[row_num, column_name] = value'''\n",
        "\n",
        "  #rating = links_dataframe.loc[row_num, 'rating']\n",
        "  #df.at[row_num, 'rating'] = rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u71L7nkl6Xv",
        "outputId": "b27de4ff-88fc-45de-a3e8-f1dcd8d1a08b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 3, 15, 19, 20, 23, 24, 25, 26, 32, 33, 34, 38, 40, 41, 44, 55, 60, 61, 65, 68, 74, 79, 80, 81, 82, 83, 85, 89, 94, 96, 99, 102]\n",
            "33\n"
          ]
        }
      ],
      "source": [
        "print(need_fix_indices_list)\n",
        "print(len(need_fix_indices_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwY5zwgAnGjP"
      },
      "source": [
        "We need to get 33 redone responses from ChtGPT. We should probably reengineer our prompt to be as explicit as possible about the JSON file structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZ0qYeKjnyUv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Source directory\n",
        "source_dir = \"drive/MyDrive/text_files2/alreadyDone\"\n",
        "\n",
        "# Destination directory (parent directory)\n",
        "destination_dir = \"drive/MyDrive/text_files2\"\n",
        "text_files_dir_name = destination_dir\n",
        "# List all files in the source directory\n",
        "files = os.listdir(source_dir)\n",
        "\n",
        "# Move each file to the destination directory\n",
        "'''for file in files:\n",
        "    # Get the full path of the source file\n",
        "    source_file = os.path.join(source_dir, file)\n",
        "    # Move the file to the destination directory\n",
        "    shutil.move(source_file, destination_dir)'''\n",
        "\n",
        "#files_list = os.listdir(dir_name)\n",
        "\n",
        "'''for ind in need_fix_indices_list:\n",
        "  json_files_dir = \"drive/MyDrive/LI-Jobs-JSON\"\n",
        "  json_file_name = f'row{ind}.json'\n",
        "  json_file_path = os.path.join(json_files_dir, json_file_name)\n",
        "  os.remove(json_file_path)'''\n",
        "\n",
        "\n",
        "for ind in need_fix_indices_list:\n",
        "  if ind > 83:\n",
        "    file_path = f'row{ind}.txt'\n",
        "    file_path = os.path.join(text_files_dir_name, file_path)\n",
        "    generate_json_file(file_path)\n",
        "    # ignore adding row to dataframe for now\n",
        "    #add_row_to_df(json_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt98_LhNqQWU"
      },
      "outputs": [],
      "source": [
        "def tokenize_document(document_path):\n",
        "    \"\"\"Tokenize a document into words.\"\"\"\n",
        "    with open(document_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "        words = text.split()\n",
        "        return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHMSUsNFrCVr",
        "outputId": "842e43ba-ecc6-4d39-bf64-f9cebe13b41a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['{\"employment',\n",
              " 'type\":',\n",
              " '[\"Full-time\"],',\n",
              " '\"job',\n",
              " 'function\":',\n",
              " '[\"Engineering\",',\n",
              " '\"Information',\n",
              " 'Technology\"],',\n",
              " '\"description',\n",
              " 'of',\n",
              " 'product/service\":',\n",
              " '[\"design-led',\n",
              " 'software',\n",
              " 'development\",',\n",
              " '\"end-to-end',\n",
              " 'digital',\n",
              " 'services\"],',\n",
              " '\"industries\":',\n",
              " '[\"Business',\n",
              " 'Consulting\",',\n",
              " '\"Services\"],',\n",
              " '\"position',\n",
              " 'name\":',\n",
              " '[\"Python',\n",
              " 'Software',\n",
              " 'Engineer',\n",
              " '(Robotics/Mechatronics)\"],',\n",
              " '\"broader',\n",
              " 'role',\n",
              " 'name\":',\n",
              " '[\"N/A\"],',\n",
              " '\"company\":',\n",
              " '[\"Fresh',\n",
              " 'Consulting\"],',\n",
              " '\"location\":',\n",
              " '[\"Redmond,',\n",
              " 'WA\"],',\n",
              " '\"salary/compensation',\n",
              " 'range\":',\n",
              " '[\"$30.00/hr',\n",
              " '-',\n",
              " '$45.00/hr\"],',\n",
              " '\"responsibilities\":',\n",
              " '[\"integrate',\n",
              " 'software/hardware',\n",
              " 'components\",',\n",
              " '\"develop',\n",
              " 'UI',\n",
              " 'front-end\",',\n",
              " '\"investigate',\n",
              " 'defects\",',\n",
              " '\"be',\n",
              " 'active',\n",
              " 'team',\n",
              " 'player\",',\n",
              " '\"learn',\n",
              " 'new',\n",
              " 'systems/tools\",',\n",
              " '\"document',\n",
              " 'code',\n",
              " 'quality\",',\n",
              " '\"work',\n",
              " 'on',\n",
              " 'python',\n",
              " 'applications\"],',\n",
              " '\"goals/objectives\":',\n",
              " '[\"manage',\n",
              " 'delivery',\n",
              " 'of',\n",
              " 'high-quality',\n",
              " 'work\"],',\n",
              " '\"name',\n",
              " 'of',\n",
              " 'department/team\":',\n",
              " '[\"N/A\"],',\n",
              " '\"required',\n",
              " 'qualifications\":',\n",
              " '[\"0-1+',\n",
              " 'years',\n",
              " 'experience\",',\n",
              " '\"Python',\n",
              " 'skills\",',\n",
              " '\"programming',\n",
              " 'skills\",',\n",
              " '\"problem',\n",
              " 'solving',\n",
              " 'skills\",',\n",
              " '\"understanding',\n",
              " 'of',\n",
              " 'HW/Embedded',\n",
              " 'Systems/Mechatronics/Robotics\",',\n",
              " '\"troubleshooting',\n",
              " 'skills\",',\n",
              " '\"BSCSE/MSCSE',\n",
              " 'preferred\"],',\n",
              " '\"preferred',\n",
              " 'qualifications\":',\n",
              " '[\"clear',\n",
              " 'communication\",',\n",
              " '\"outside',\n",
              " 'the',\n",
              " 'box',\n",
              " 'thinking\",',\n",
              " '\"work',\n",
              " 'well',\n",
              " 'with',\n",
              " 'others\"],',\n",
              " '\"benefits\":',\n",
              " '[\"100%',\n",
              " 'Medical\",',\n",
              " '\"PTO\",',\n",
              " '\"Holiday',\n",
              " 'Pay\",',\n",
              " '\"401K',\n",
              " 'Plan\"],',\n",
              " '\"work',\n",
              " 'arrangement\":',\n",
              " '[\"N/A\"]}']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenize_document(\"drive/MyDrive/LI-Jobs-JSON/row1.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8TBsWcOrcwI"
      },
      "source": [
        "So tokenizing our JSON files works pretty well but not perfectly. Moreover, we only want to tokenize the values, not the keys, of the JSON dictionary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xFrHUcncrUF"
      },
      "source": [
        "One idea I have is to start with a pre-trained Word2Vec model and represent each word in the dataframe as its embedding in that model. One problem however is that there is no guarantee that a given word in our dataset was present in the original training data for that model and we will not be able to get an embedding for that word unless we fit a Word2Vec model to our specific corpus which contains that word. Another issue is that we will need to be very diligent about post-processing our text so that words stuck together with a hyphen (-) or slash (/) are treated as separate words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxX5TBUgd4XE"
      },
      "source": [
        "Using a pre-trained vocabulary model through transfer learning can save us a lot of work on the feature engineering side including having to concatenate all of our text together and tokenize each unique word in it, and it might be able to save us from having to include TF-IDF features or worse still write custom code to encode the units of our corpus (in this case words). And instead of encoding unique bags or groupings of words that make the phrases, we might choose to use a clustering algorithm on this embedding model to shrink down the words feature space in order to then bin the possible phrases into a much smaller set of classes, or we could use some logic involving cosine similarity. There is a lot of thinking as well as implementation work we still need to do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3Oc4q4Khk97"
      },
      "source": [
        "Right now we will do some EDA on each column to see what special work we will have to do for that particular column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "iNM6W5WaDVeQ",
        "outputId": "cbe4f541-581f-4d00-b32b-472721ee4c42"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 107,\n  \"fields\": [\n    {\n      \"column\": \"emploment_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job_function\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description_of_product/service\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"industries\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"position_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"broader_role_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"company\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"salary/compensation_range\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"responsibilities\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"goals/objectives\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name_of_department/team\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"required_qualifications\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preferred_qualifications\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"benefits\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"work_arrangement\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"0\",\n        \"max\": \"3\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2\",\n          \"0\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1c0afded-9b4e-4da5-8e76-70d4b1104997\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emploment_type</th>\n",
              "      <th>job_function</th>\n",
              "      <th>description_of_product/service</th>\n",
              "      <th>industries</th>\n",
              "      <th>position_name</th>\n",
              "      <th>broader_role_name</th>\n",
              "      <th>company</th>\n",
              "      <th>location</th>\n",
              "      <th>salary/compensation_range</th>\n",
              "      <th>responsibilities</th>\n",
              "      <th>goals/objectives</th>\n",
              "      <th>name_of_department/team</th>\n",
              "      <th>required_qualifications</th>\n",
              "      <th>preferred_qualifications</th>\n",
              "      <th>benefits</th>\n",
              "      <th>work_arrangement</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[design-led software development, end-to-end d...</td>\n",
              "      <td>[Business Consulting, Services]</td>\n",
              "      <td>[Python Software Engineer (Robotics/Mechatroni...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Fresh Consulting]</td>\n",
              "      <td>[Redmond, WA]</td>\n",
              "      <td>[$30.00/hr - $45.00/hr]</td>\n",
              "      <td>[integrate software/hardware components, devel...</td>\n",
              "      <td>[manage delivery of high-quality work]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[0-1+ years experience, Python skills, program...</td>\n",
              "      <td>[clear communication, outside the box thinking...</td>\n",
              "      <td>[100% Medical, PTO, Holiday Pay, 401K Plan]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[Design, Art/Creative, Information Technology]</td>\n",
              "      <td>[Surgical Robotics Systems]</td>\n",
              "      <td>[Biotechnology Research, Pharmaceutical Manufa...</td>\n",
              "      <td>[Robotics Engineer]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Barrington James]</td>\n",
              "      <td>[New York, United States]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Contribute to cutting-edge robotic systems, C...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Bachelor's, Master's, or Ph.D. in Robotics, M...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[Information Technology, Consulting, Engineering]</td>\n",
              "      <td>[Amazon Robotics builds high-performance, real...</td>\n",
              "      <td>[Software Development, IT Services, IT Consult...</td>\n",
              "      <td>[SDE - Amazon Robotics]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Amazon]</td>\n",
              "      <td>[North Reading, MA]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Help with initial robotic deployments, Plan r...</td>\n",
              "      <td>[Build high-performance robotic systems, Inven...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[3+ years professional software development ex...</td>\n",
              "      <td>[3+ years full software development life cycle...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[Credit scoring models]</td>\n",
              "      <td>[Financial Services, Capital Markets, IT Servi...</td>\n",
              "      <td>[Senior Software Engineer]</td>\n",
              "      <td>[Software Engineer]</td>\n",
              "      <td>[VantageScore®]</td>\n",
              "      <td>[San Francisco Bay Area]</td>\n",
              "      <td>[$150K - $200K]</td>\n",
              "      <td>[Application Development, Collaboration, Mento...</td>\n",
              "      <td>[Building public APIs]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Bachelor's degree, Master's degree, Computer ...</td>\n",
              "      <td>[Quantitative applications, Fintech experience...</td>\n",
              "      <td>[401(K) match, Flexible Time Off, 12 Paid Holi...</td>\n",
              "      <td>[Hybrid]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[Engineering, Quality Assurance, Information T...</td>\n",
              "      <td>[Large-scale distributed software applications...</td>\n",
              "      <td>[IT Services, IT Consulting]</td>\n",
              "      <td>[Software Engineer in Test]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Optomi]</td>\n",
              "      <td>[Dallas-Fort Worth Metroplex]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Build and maintain automated test infrastruct...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[5+ years of test automation experience, Profi...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c0afded-9b4e-4da5-8e76-70d4b1104997')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c0afded-9b4e-4da5-8e76-70d4b1104997 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c0afded-9b4e-4da5-8e76-70d4b1104997');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2fa9b3b1-5972-4686-a6d1-1c2cdfc781d1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2fa9b3b1-5972-4686-a6d1-1c2cdfc781d1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2fa9b3b1-5972-4686-a6d1-1c2cdfc781d1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  emploment_type                                       job_function  \\\n",
              "0            NaN              [Engineering, Information Technology]   \n",
              "1            NaN     [Design, Art/Creative, Information Technology]   \n",
              "2            NaN  [Information Technology, Consulting, Engineering]   \n",
              "3            NaN              [Engineering, Information Technology]   \n",
              "4            NaN  [Engineering, Quality Assurance, Information T...   \n",
              "\n",
              "                      description_of_product/service  \\\n",
              "0  [design-led software development, end-to-end d...   \n",
              "1                        [Surgical Robotics Systems]   \n",
              "2  [Amazon Robotics builds high-performance, real...   \n",
              "3                            [Credit scoring models]   \n",
              "4  [Large-scale distributed software applications...   \n",
              "\n",
              "                                          industries  \\\n",
              "0                    [Business Consulting, Services]   \n",
              "1  [Biotechnology Research, Pharmaceutical Manufa...   \n",
              "2  [Software Development, IT Services, IT Consult...   \n",
              "3  [Financial Services, Capital Markets, IT Servi...   \n",
              "4                       [IT Services, IT Consulting]   \n",
              "\n",
              "                                       position_name    broader_role_name  \\\n",
              "0  [Python Software Engineer (Robotics/Mechatroni...                [N/A]   \n",
              "1                                [Robotics Engineer]                [N/A]   \n",
              "2                            [SDE - Amazon Robotics]                [N/A]   \n",
              "3                         [Senior Software Engineer]  [Software Engineer]   \n",
              "4                        [Software Engineer in Test]                [N/A]   \n",
              "\n",
              "              company                       location  \\\n",
              "0  [Fresh Consulting]                  [Redmond, WA]   \n",
              "1  [Barrington James]      [New York, United States]   \n",
              "2            [Amazon]            [North Reading, MA]   \n",
              "3     [VantageScore®]       [San Francisco Bay Area]   \n",
              "4            [Optomi]  [Dallas-Fort Worth Metroplex]   \n",
              "\n",
              "  salary/compensation_range  \\\n",
              "0   [$30.00/hr - $45.00/hr]   \n",
              "1                       NaN   \n",
              "2                     [N/A]   \n",
              "3           [$150K - $200K]   \n",
              "4                     [N/A]   \n",
              "\n",
              "                                    responsibilities  \\\n",
              "0  [integrate software/hardware components, devel...   \n",
              "1  [Contribute to cutting-edge robotic systems, C...   \n",
              "2  [Help with initial robotic deployments, Plan r...   \n",
              "3  [Application Development, Collaboration, Mento...   \n",
              "4  [Build and maintain automated test infrastruct...   \n",
              "\n",
              "                                    goals/objectives name_of_department/team  \\\n",
              "0             [manage delivery of high-quality work]                   [N/A]   \n",
              "1                                                NaN                     NaN   \n",
              "2  [Build high-performance robotic systems, Inven...                   [N/A]   \n",
              "3                             [Building public APIs]                   [N/A]   \n",
              "4                                              [N/A]                   [N/A]   \n",
              "\n",
              "                             required_qualifications  \\\n",
              "0  [0-1+ years experience, Python skills, program...   \n",
              "1  [Bachelor's, Master's, or Ph.D. in Robotics, M...   \n",
              "2  [3+ years professional software development ex...   \n",
              "3  [Bachelor's degree, Master's degree, Computer ...   \n",
              "4  [5+ years of test automation experience, Profi...   \n",
              "\n",
              "                            preferred_qualifications  \\\n",
              "0  [clear communication, outside the box thinking...   \n",
              "1                                              [N/A]   \n",
              "2  [3+ years full software development life cycle...   \n",
              "3  [Quantitative applications, Fintech experience...   \n",
              "4                                              [N/A]   \n",
              "\n",
              "                                            benefits work_arrangement rating  \n",
              "0        [100% Medical, PTO, Holiday Pay, 401K Plan]            [N/A]      1  \n",
              "1                                              [N/A]            [N/A]      2  \n",
              "2                                              [N/A]        [On-site]      2  \n",
              "3  [401(K) match, Flexible Time Off, 12 Paid Holi...         [Hybrid]      3  \n",
              "4                                              [N/A]        [On-site]      1  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf836B3Wg_lF",
        "outputId": "5967715e-c385-498c-bf0d-87ed9f6efc9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "['Full-time']\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "['Full-time']\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "['Full-time']\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n"
          ]
        }
      ],
      "source": [
        "for i in df['emploment_type']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL9iEnifhskt"
      },
      "source": [
        "We note that first off, we are missing a 'y' 'emploment_type'. Also, there are only three rows that are Full-time and the rest are nans. So our first option is to just drop this column entirely, as it is just taking up space and yet barely providing any useful information at all.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hY0KvQZiW4B",
        "outputId": "38d4c353-230b-4911-cc15-712b66335e8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Engineering', 'Information Technology']\n",
            "['Design', 'Art/Creative', 'Information Technology']\n",
            "['Information Technology', 'Consulting', 'Engineering']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Quality Assurance', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology', 'Research']\n",
            "['Information Technology']\n",
            "['Finance', 'Sales']\n",
            "['Engineering']\n",
            "['Information Technology']\n",
            "['Design', 'Art/Creative', 'Information Technology']\n",
            "['Information Technology - Other - Consulting']\n",
            "['Analyst']\n",
            "['Engineering', 'Finance', 'Information Technology']\n",
            "['Engineering']\n",
            "['Accounting/Auditing', 'Finance']\n",
            "['Finance', 'Information Technology']\n",
            "['Engineering']\n",
            "['Research and Education']\n",
            "['Accounting/Auditing', 'Finance']\n",
            "['Engineering', 'Information Technology']\n",
            "['Other']\n",
            "['Administrative', 'Sales', 'Customer Service']\n",
            "['Sales and Business Development']\n",
            "['Accounting/Auditing', 'Finance']\n",
            "['Other']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Manufacturing']\n",
            "['Information Technology']\n",
            "['Education']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering']\n",
            "['Information Technology']\n",
            "['Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Sales', 'General Business', 'Customer Service']\n",
            "['Health Care Provider']\n",
            "['Engineering', 'Information Technology']\n",
            "['Information Technology', 'Consulting', 'Engineering']\n",
            "['Engineering', 'Information Technology']\n",
            "['Other', 'Engineering']\n",
            "['Information Technology']\n",
            "['Engineering and Information Technology']\n",
            "['Information Technology', 'Business Development', 'Engineering']\n",
            "['Engineering']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering']\n",
            "['Training']\n",
            "['Information Technology', 'Business Development']\n",
            "['Marketing', 'Sales']\n",
            "['Assistant Manager']\n",
            "['Research', 'Analyst', 'Information Technology']\n",
            "['Sales and Business Development']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Sales']\n",
            "['Engineering', 'Design', 'Information Technology']\n",
            "['Other']\n",
            "['Research', 'Analyst', 'Information Technology']\n",
            "['Information Technology', 'Engineering']\n",
            "['Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering']\n",
            "['Engineering', 'Information Technology']\n",
            "['Marketing', 'Sales']\n",
            "['Sales and Business Development']\n",
            "['Sales and Business Development']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology', 'Analyst']\n",
            "['Engineering']\n",
            "['Consulting']\n",
            "['Information Technology', 'Engineering']\n",
            "['Engineering']\n",
            "['Engineering and Information Technology']\n",
            "['Management', 'Manufacturing']\n",
            "['Research', 'Analyst', 'Information Technology']\n",
            "['Engineering']\n",
            "['Engineering']\n",
            "['Engineering and Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering']\n",
            "['Engineering and Information Technology']\n",
            "['AI Applications Engineer']\n",
            "['Engineering', 'Information Technology', 'Research']\n",
            "['Engineering', 'Information Technology']\n",
            "['Quality Assurance']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering and Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Education and Training']\n",
            "['Research', 'Analyst', 'Information Technology']\n",
            "['Science']\n",
            "['Design', 'Consulting', 'Engineering']\n",
            "['Information Technology']\n",
            "['Engineering and Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Finance', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Information Technology']\n"
          ]
        }
      ],
      "source": [
        "for i in df['job_function']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGdoQi7jiecc"
      },
      "source": [
        "The job_function column we should definitely keep, at least for now. We see there are some words grouped together with '/' like Art/Creative. So the first thing we should probably do is .replace('/', ' '), and we PROBABLY want to do this for the whole dataframe but we will only do it for this column right now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAiakA7ai7SF"
      },
      "outputs": [],
      "source": [
        "# Replace '/' with ' ' in each list\n",
        "df['job_function'] = df['job_function'].apply(lambda x: [category.replace('/', ' ') for category in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_Ha9Qc8jlMh",
        "outputId": "1ed13bd4-a434-488a-a99f-dcdf1286697d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Engineering', 'Information Technology']\n",
            "['Design', 'Art Creative', 'Information Technology']\n",
            "['Information Technology', 'Consulting', 'Engineering']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Quality Assurance', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology', 'Research']\n",
            "['Information Technology']\n",
            "['Finance', 'Sales']\n",
            "['Engineering']\n",
            "['Information Technology']\n",
            "['Design', 'Art Creative', 'Information Technology']\n",
            "['Information Technology - Other - Consulting']\n",
            "['Analyst']\n",
            "['Engineering', 'Finance', 'Information Technology']\n",
            "['Engineering']\n",
            "['Accounting Auditing', 'Finance']\n",
            "['Finance', 'Information Technology']\n",
            "['Engineering']\n",
            "['Research and Education']\n",
            "['Accounting Auditing', 'Finance']\n",
            "['Engineering', 'Information Technology']\n",
            "['Other']\n",
            "['Administrative', 'Sales', 'Customer Service']\n",
            "['Sales and Business Development']\n",
            "['Accounting Auditing', 'Finance']\n",
            "['Other']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Manufacturing']\n",
            "['Information Technology']\n",
            "['Education']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering']\n",
            "['Information Technology']\n",
            "['Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Sales', 'General Business', 'Customer Service']\n",
            "['Health Care Provider']\n",
            "['Engineering', 'Information Technology']\n",
            "['Information Technology', 'Consulting', 'Engineering']\n",
            "['Engineering', 'Information Technology']\n",
            "['Other', 'Engineering']\n",
            "['Information Technology']\n",
            "['Engineering and Information Technology']\n",
            "['Information Technology', 'Business Development', 'Engineering']\n",
            "['Engineering']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering']\n",
            "['Training']\n",
            "['Information Technology', 'Business Development']\n",
            "['Marketing', 'Sales']\n",
            "['Assistant Manager']\n",
            "['Research', 'Analyst', 'Information Technology']\n",
            "['Sales and Business Development']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Sales']\n",
            "['Engineering', 'Design', 'Information Technology']\n",
            "['Other']\n",
            "['Research', 'Analyst', 'Information Technology']\n",
            "['Information Technology', 'Engineering']\n",
            "['Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering']\n",
            "['Engineering', 'Information Technology']\n",
            "['Marketing', 'Sales']\n",
            "['Sales and Business Development']\n",
            "['Sales and Business Development']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Information Technology', 'Analyst']\n",
            "['Engineering']\n",
            "['Consulting']\n",
            "['Information Technology', 'Engineering']\n",
            "['Engineering']\n",
            "['Engineering and Information Technology']\n",
            "['Management', 'Manufacturing']\n",
            "['Research', 'Analyst', 'Information Technology']\n",
            "['Engineering']\n",
            "['Engineering']\n",
            "['Engineering and Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering']\n",
            "['Engineering and Information Technology']\n",
            "['AI Applications Engineer']\n",
            "['Engineering', 'Information Technology', 'Research']\n",
            "['Engineering', 'Information Technology']\n",
            "['Quality Assurance']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering and Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Education and Training']\n",
            "['Research', 'Analyst', 'Information Technology']\n",
            "['Science']\n",
            "['Design', 'Consulting', 'Engineering']\n",
            "['Information Technology']\n",
            "['Engineering and Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Engineering', 'Finance', 'Information Technology']\n",
            "['Engineering', 'Information Technology']\n",
            "['Information Technology']\n"
          ]
        }
      ],
      "source": [
        "for i in df['job_function']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGCBooF5jxHh"
      },
      "source": [
        "Now we will attempt to find some pre-trained vocabulary model like a pre-trained Word2Vec model and see if we can get word embeddings for each word in each item of each list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4bumDkDmqR9"
      },
      "source": [
        "So we are downloading a 500 dimensional pre-trained Word2Vec model from 2018 from Github and it is over 17 GB. Hopefully I will be able to store it on disk space and then instantiate the embedding model within Colab using the gensim API. While we are waiting for that to get downloaded we will do more EDA on the other columns.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQuWCtmmnkTO",
        "outputId": "009665bd-b65f-418f-d3a3-c305ef340e41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['design-led software development', 'end-to-end digital services']\n",
            "['Surgical Robotics Systems']\n",
            "['Amazon Robotics builds high-performance, real-time robotic systems', 'Invent and scale AI systems for robotics in fulfillment', 'Building computer vision systems, ML and AI models, robotic control and motion planning, process management', 'End-to-end ownership of decision explanation, fault detection, monitoring, A/B testing, large scale model training, simulation, hardware integration']\n",
            "['Credit scoring models']\n",
            "['Large-scale distributed software applications, systems, services']\n",
            "['AI-driven education platform']\n",
            "['Financial Services']\n",
            "['Financial Services']\n",
            "['Quantitative trading team', 'ML based data pipelines', 'Analytics for research', 'Systematic trading strategies']\n",
            "nan\n",
            "['Global markets proprietary trading firm']\n",
            "['Remotely-operated endovascular surgical robot']\n",
            "['Bioinformatics pipelines using Nextflow', 'Python/R scripts for data processing', 'Reporting system for clinic-ready reports', 'Documentation for pipeline management', 'Web-based user interfaces']\n",
            "['Financial Planning solutions']\n",
            "['Generative AI and NLP']\n",
            "['ETL Automation', 'Front-End Dashboarding', 'Documentation']\n",
            "['Low Latency Trading Systems']\n",
            "['Advanced medical device']\n",
            "['Augmented Reality Systems Platform']\n",
            "['SAP Analytics Cloud (SAC)', 'Financial Planning processes']\n",
            "['CPUs', 'System on Chips', 'machine learning', 'data centers', 'high-performance computing applications']\n",
            "['Interdisciplinary Artificial Intelligence Research']\n",
            "['N/A']\n",
            "['Security risk assessment']\n",
            "['Qualcomm Neural Processing SDK']\n",
            "['Appliances', 'Electrical', 'Electronics Manufacturing']\n",
            "['Material handling equipment and systems']\n",
            "['N/A']\n",
            "['Machine Learning', 'X-ray Imaging']\n",
            "['Firmware development for hardware media pipeline', 'Digital Rights Management', 'Trusted Execution Environment', 'Audio/Video formats and containers']\n",
            "['Financial Services']\n",
            "['N/A']\n",
            "['Advancing understanding of radio spectrum and wireless signals']\n",
            "['Automation test frameworks - Selenium, Appium, Playwright', 'iOS XCTest, XCUITest', 'Android Espresso, UI Automator', 'Java, JavaScript']\n",
            "['Teaching students to read and comprehend']\n",
            "['CAD/EDA Tools Software Engineer for Test Chip Design']\n",
            "['Embedded software for Bobcat equipment']\n",
            "['Quantitative Developer for systematic corporate bond and credit derivatives strategies']\n",
            "['Machine Learning ASICs for Data Center servers']\n",
            "['N/A']\n",
            "['Google Cloud Platform', 'cutting-edge technology', 'cleanest cloud in the industry']\n",
            "nan\n",
            "['Marine Engineering Networking', 'C/Networking Software']\n",
            "['consumer electronics']\n",
            "['Financial Services']\n",
            "['Mission capability integrator']\n",
            "['AI Video Platform']\n",
            "['User-owned talent network', 'Connects professionals with enterprises', 'Eliminates middlemen and markups', 'Efficient and quality matching']\n",
            "['Triage Software Engineer - Initial defect analysis - Dashboard creation - Problem-solving - Communication skills - Automotive Infotainment - Embedded software - JIRA/Confluence - Agile/Scrum - Requirement Analysis']\n",
            "['Small satellite industry solutions']\n",
            "nan\n",
            "['Scientific Software Engineer - Space', 'Join a company at the heart of space research and operations', 'Create solutions for complex problems', 'Ensure data and products are of highest quality for aerospace community']\n",
            "['Cybersecurity']\n",
            "['AI/Client models']\n",
            "['Academic support through tutoring']\n",
            "nan\n",
            "['K9 gear']\n",
            "['Boston Public Market']\n",
            "['AI Research']\n",
            "['Artificial Intelligence']\n",
            "['AI research']\n",
            "['AI solutions for educational experience enhancement']\n",
            "['Training devices for military aircraft']\n",
            "['Data & AI solutions']\n",
            "['seismic-acoustic signal processing']\n",
            "['N/A']\n",
            "['Jury consulting services']\n",
            "['Cyber Security services', 'cutting-edge technologies']\n",
            "['Data Engineering for Wholesale Building Materials']\n",
            "['Software Development']\n",
            "['AR/VR development']\n",
            "['AI Microsoft Chatbot Developer']\n",
            "['Creative studio', 'Lifestyle consultancy', 'Branding', 'Marketing', 'Design', 'Web & app development', 'Business leadership', 'Revenue & scale strategies']\n",
            "['Transformer products and solutions']\n",
            "['Cybersecurity Data Services']\n",
            "['Data Science Platform empowers data scientists to build machine learning systems']\n",
            "['Machine Learning Platform']\n",
            "['High-performance data analytics platform handling petabytes of data']\n",
            "['Real Time ML Service', 'RTML Model Serving Framework', 'RTML Framework', 'AI Center', 'AI-driven solutions']\n",
            "['Pre-owned vehicles', 'Financing', 'Warranties', 'Vehicle appraisals']\n",
            "['Autonomous driving software']\n",
            "['Quantitative Software Engineer']\n",
            "['Transportation services']\n",
            "['Clinical Trial Research']\n",
            "['AI for Autonomy Lab researches applying AI-related technologies for autonomy systems']\n",
            "['Embedded Cybersecurity solutions for Caterpillar machines & engines']\n",
            "['AI research and deployment']\n",
            "['Microservices development']\n",
            "['Electric vehicles']\n",
            "['AI platform at Together AI', 'Research-driven artificial intelligence company', 'Contribute to leading open-source research, models, and datasets']\n",
            "['Building open source digital systems and solutions to battle environmental threats', 'Developing open innovative technology to increase planetary resilience', 'Creating software to track progress towards Paris Agreement goals', 'Improving data infrastructure for climate analysis using AI', 'Maximizing impact through Open Source projects']\n",
            "['Software development for finance industry']\n",
            "['Support workflow development for NOAA SFS', 'NWP modeling system', 'Forecast guidance', 'Earth system models']\n",
            "['Software solutions for critical infrastructure']\n",
            "['AI algorithms', 'software applications']\n",
            "['enterprise B2B SaaS solutions']\n",
            "['Quantum control solution (QCS)', 'Quantum computing', 'Quantum communications', 'Quantum sensing']\n",
            "['Quantum Systems']\n",
            "['Quantum computing system', 'Azure Quantum', 'Revolutionize computing']\n",
            "['Quantum Computing and Devices']\n",
            "['Cutting-edge optical design solutions']\n",
            "['Introduction of automation to construction sector']\n",
            "['Software engineering opportunity at JPMorgan Chase']\n",
            "['Ads Creative Management']\n",
            "['Algorithmic trading programs', 'Forex trading systems']\n",
            "[\"Kernel software development for Boeing's product portfolio\"]\n",
            "nan\n"
          ]
        }
      ],
      "source": [
        "for i in df['description_of_product/service']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKeoBwRMoE8J"
      },
      "source": [
        "We are reminded by the above that we should NOT apply the Lamba function to replace '/' with ' ' to the whole dataframe just yet, as there nan's as well as 'N/A's within lists under at least some of the columns. First we should fill the free nan's with 0's."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBZQRhphopDp",
        "outputId": "9157f3a2-fcae-4a23-b150-5e4edc59429d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['design-led software development', 'end-to-end digital services']\n",
            "['Surgical Robotics Systems']\n",
            "['Amazon Robotics builds high-performance, real-time robotic systems', 'Invent and scale AI systems for robotics in fulfillment', 'Building computer vision systems, ML and AI models, robotic control and motion planning, process management', 'End-to-end ownership of decision explanation, fault detection, monitoring, A/B testing, large scale model training, simulation, hardware integration']\n",
            "['Credit scoring models']\n",
            "['Large-scale distributed software applications, systems, services']\n",
            "['AI-driven education platform']\n",
            "['Financial Services']\n",
            "['Financial Services']\n",
            "['Quantitative trading team', 'ML based data pipelines', 'Analytics for research', 'Systematic trading strategies']\n",
            "0\n",
            "['Global markets proprietary trading firm']\n",
            "['Remotely-operated endovascular surgical robot']\n",
            "['Bioinformatics pipelines using Nextflow', 'Python/R scripts for data processing', 'Reporting system for clinic-ready reports', 'Documentation for pipeline management', 'Web-based user interfaces']\n",
            "['Financial Planning solutions']\n",
            "['Generative AI and NLP']\n",
            "['ETL Automation', 'Front-End Dashboarding', 'Documentation']\n",
            "['Low Latency Trading Systems']\n",
            "['Advanced medical device']\n",
            "['Augmented Reality Systems Platform']\n",
            "['SAP Analytics Cloud (SAC)', 'Financial Planning processes']\n",
            "['CPUs', 'System on Chips', 'machine learning', 'data centers', 'high-performance computing applications']\n",
            "['Interdisciplinary Artificial Intelligence Research']\n",
            "['N/A']\n",
            "['Security risk assessment']\n",
            "['Qualcomm Neural Processing SDK']\n",
            "['Appliances', 'Electrical', 'Electronics Manufacturing']\n",
            "['Material handling equipment and systems']\n",
            "['N/A']\n",
            "['Machine Learning', 'X-ray Imaging']\n",
            "['Firmware development for hardware media pipeline', 'Digital Rights Management', 'Trusted Execution Environment', 'Audio/Video formats and containers']\n",
            "['Financial Services']\n",
            "['N/A']\n",
            "['Advancing understanding of radio spectrum and wireless signals']\n",
            "['Automation test frameworks - Selenium, Appium, Playwright', 'iOS XCTest, XCUITest', 'Android Espresso, UI Automator', 'Java, JavaScript']\n",
            "['Teaching students to read and comprehend']\n",
            "['CAD/EDA Tools Software Engineer for Test Chip Design']\n",
            "['Embedded software for Bobcat equipment']\n",
            "['Quantitative Developer for systematic corporate bond and credit derivatives strategies']\n",
            "['Machine Learning ASICs for Data Center servers']\n",
            "['N/A']\n",
            "['Google Cloud Platform', 'cutting-edge technology', 'cleanest cloud in the industry']\n",
            "0\n",
            "['Marine Engineering Networking', 'C/Networking Software']\n",
            "['consumer electronics']\n",
            "['Financial Services']\n",
            "['Mission capability integrator']\n",
            "['AI Video Platform']\n",
            "['User-owned talent network', 'Connects professionals with enterprises', 'Eliminates middlemen and markups', 'Efficient and quality matching']\n",
            "['Triage Software Engineer - Initial defect analysis - Dashboard creation - Problem-solving - Communication skills - Automotive Infotainment - Embedded software - JIRA/Confluence - Agile/Scrum - Requirement Analysis']\n",
            "['Small satellite industry solutions']\n",
            "0\n",
            "['Scientific Software Engineer - Space', 'Join a company at the heart of space research and operations', 'Create solutions for complex problems', 'Ensure data and products are of highest quality for aerospace community']\n",
            "['Cybersecurity']\n",
            "['AI/Client models']\n",
            "['Academic support through tutoring']\n",
            "0\n",
            "['K9 gear']\n",
            "['Boston Public Market']\n",
            "['AI Research']\n",
            "['Artificial Intelligence']\n",
            "['AI research']\n",
            "['AI solutions for educational experience enhancement']\n",
            "['Training devices for military aircraft']\n",
            "['Data & AI solutions']\n",
            "['seismic-acoustic signal processing']\n",
            "['N/A']\n",
            "['Jury consulting services']\n",
            "['Cyber Security services', 'cutting-edge technologies']\n",
            "['Data Engineering for Wholesale Building Materials']\n",
            "['Software Development']\n",
            "['AR/VR development']\n",
            "['AI Microsoft Chatbot Developer']\n",
            "['Creative studio', 'Lifestyle consultancy', 'Branding', 'Marketing', 'Design', 'Web & app development', 'Business leadership', 'Revenue & scale strategies']\n",
            "['Transformer products and solutions']\n",
            "['Cybersecurity Data Services']\n",
            "['Data Science Platform empowers data scientists to build machine learning systems']\n",
            "['Machine Learning Platform']\n",
            "['High-performance data analytics platform handling petabytes of data']\n",
            "['Real Time ML Service', 'RTML Model Serving Framework', 'RTML Framework', 'AI Center', 'AI-driven solutions']\n",
            "['Pre-owned vehicles', 'Financing', 'Warranties', 'Vehicle appraisals']\n",
            "['Autonomous driving software']\n",
            "['Quantitative Software Engineer']\n",
            "['Transportation services']\n",
            "['Clinical Trial Research']\n",
            "['AI for Autonomy Lab researches applying AI-related technologies for autonomy systems']\n",
            "['Embedded Cybersecurity solutions for Caterpillar machines & engines']\n",
            "['AI research and deployment']\n",
            "['Microservices development']\n",
            "['Electric vehicles']\n",
            "['AI platform at Together AI', 'Research-driven artificial intelligence company', 'Contribute to leading open-source research, models, and datasets']\n",
            "['Building open source digital systems and solutions to battle environmental threats', 'Developing open innovative technology to increase planetary resilience', 'Creating software to track progress towards Paris Agreement goals', 'Improving data infrastructure for climate analysis using AI', 'Maximizing impact through Open Source projects']\n",
            "['Software development for finance industry']\n",
            "['Support workflow development for NOAA SFS', 'NWP modeling system', 'Forecast guidance', 'Earth system models']\n",
            "['Software solutions for critical infrastructure']\n",
            "['AI algorithms', 'software applications']\n",
            "['enterprise B2B SaaS solutions']\n",
            "['Quantum control solution (QCS)', 'Quantum computing', 'Quantum communications', 'Quantum sensing']\n",
            "['Quantum Systems']\n",
            "['Quantum computing system', 'Azure Quantum', 'Revolutionize computing']\n",
            "['Quantum Computing and Devices']\n",
            "['Cutting-edge optical design solutions']\n",
            "['Introduction of automation to construction sector']\n",
            "['Software engineering opportunity at JPMorgan Chase']\n",
            "['Ads Creative Management']\n",
            "['Algorithmic trading programs', 'Forex trading systems']\n",
            "[\"Kernel software development for Boeing's product portfolio\"]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "df['description_of_product/service'] = df['description_of_product/service'].fillna(0)\n",
        "\n",
        "for i in df['description_of_product/service']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSfNo5AwpErv"
      },
      "source": [
        "Next, instances of ['N/A'] should also be replaced with 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0fqQwjwpa5Q"
      },
      "outputs": [],
      "source": [
        "# Replace 'N/A' with 0\n",
        "import numpy as np\n",
        "df['description_of_product/service'] = df['description_of_product/service'].apply(lambda x: np.nan if x == ['N/A'] else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubaNRQa0p44l",
        "outputId": "995844f3-aae5-4747-d5d4-b5be978a2012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['design-led software development', 'end-to-end digital services']\n",
            "['Surgical Robotics Systems']\n",
            "['Amazon Robotics builds high-performance, real-time robotic systems', 'Invent and scale AI systems for robotics in fulfillment', 'Building computer vision systems, ML and AI models, robotic control and motion planning, process management', 'End-to-end ownership of decision explanation, fault detection, monitoring, A/B testing, large scale model training, simulation, hardware integration']\n",
            "['Credit scoring models']\n",
            "['Large-scale distributed software applications, systems, services']\n",
            "['AI-driven education platform']\n",
            "['Financial Services']\n",
            "['Financial Services']\n",
            "['Quantitative trading team', 'ML based data pipelines', 'Analytics for research', 'Systematic trading strategies']\n",
            "0\n",
            "['Global markets proprietary trading firm']\n",
            "['Remotely-operated endovascular surgical robot']\n",
            "['Bioinformatics pipelines using Nextflow', 'Python/R scripts for data processing', 'Reporting system for clinic-ready reports', 'Documentation for pipeline management', 'Web-based user interfaces']\n",
            "['Financial Planning solutions']\n",
            "['Generative AI and NLP']\n",
            "['ETL Automation', 'Front-End Dashboarding', 'Documentation']\n",
            "['Low Latency Trading Systems']\n",
            "['Advanced medical device']\n",
            "['Augmented Reality Systems Platform']\n",
            "['SAP Analytics Cloud (SAC)', 'Financial Planning processes']\n",
            "['CPUs', 'System on Chips', 'machine learning', 'data centers', 'high-performance computing applications']\n",
            "['Interdisciplinary Artificial Intelligence Research']\n",
            "0\n",
            "['Security risk assessment']\n",
            "['Qualcomm Neural Processing SDK']\n",
            "['Appliances', 'Electrical', 'Electronics Manufacturing']\n",
            "['Material handling equipment and systems']\n",
            "0\n",
            "['Machine Learning', 'X-ray Imaging']\n",
            "['Firmware development for hardware media pipeline', 'Digital Rights Management', 'Trusted Execution Environment', 'Audio/Video formats and containers']\n",
            "['Financial Services']\n",
            "0\n",
            "['Advancing understanding of radio spectrum and wireless signals']\n",
            "['Automation test frameworks - Selenium, Appium, Playwright', 'iOS XCTest, XCUITest', 'Android Espresso, UI Automator', 'Java, JavaScript']\n",
            "['Teaching students to read and comprehend']\n",
            "['CAD/EDA Tools Software Engineer for Test Chip Design']\n",
            "['Embedded software for Bobcat equipment']\n",
            "['Quantitative Developer for systematic corporate bond and credit derivatives strategies']\n",
            "['Machine Learning ASICs for Data Center servers']\n",
            "0\n",
            "['Google Cloud Platform', 'cutting-edge technology', 'cleanest cloud in the industry']\n",
            "0\n",
            "['Marine Engineering Networking', 'C/Networking Software']\n",
            "['consumer electronics']\n",
            "['Financial Services']\n",
            "['Mission capability integrator']\n",
            "['AI Video Platform']\n",
            "['User-owned talent network', 'Connects professionals with enterprises', 'Eliminates middlemen and markups', 'Efficient and quality matching']\n",
            "['Triage Software Engineer - Initial defect analysis - Dashboard creation - Problem-solving - Communication skills - Automotive Infotainment - Embedded software - JIRA/Confluence - Agile/Scrum - Requirement Analysis']\n",
            "['Small satellite industry solutions']\n",
            "0\n",
            "['Scientific Software Engineer - Space', 'Join a company at the heart of space research and operations', 'Create solutions for complex problems', 'Ensure data and products are of highest quality for aerospace community']\n",
            "['Cybersecurity']\n",
            "['AI/Client models']\n",
            "['Academic support through tutoring']\n",
            "0\n",
            "['K9 gear']\n",
            "['Boston Public Market']\n",
            "['AI Research']\n",
            "['Artificial Intelligence']\n",
            "['AI research']\n",
            "['AI solutions for educational experience enhancement']\n",
            "['Training devices for military aircraft']\n",
            "['Data & AI solutions']\n",
            "['seismic-acoustic signal processing']\n",
            "0\n",
            "['Jury consulting services']\n",
            "['Cyber Security services', 'cutting-edge technologies']\n",
            "['Data Engineering for Wholesale Building Materials']\n",
            "['Software Development']\n",
            "['AR/VR development']\n",
            "['AI Microsoft Chatbot Developer']\n",
            "['Creative studio', 'Lifestyle consultancy', 'Branding', 'Marketing', 'Design', 'Web & app development', 'Business leadership', 'Revenue & scale strategies']\n",
            "['Transformer products and solutions']\n",
            "['Cybersecurity Data Services']\n",
            "['Data Science Platform empowers data scientists to build machine learning systems']\n",
            "['Machine Learning Platform']\n",
            "['High-performance data analytics platform handling petabytes of data']\n",
            "['Real Time ML Service', 'RTML Model Serving Framework', 'RTML Framework', 'AI Center', 'AI-driven solutions']\n",
            "['Pre-owned vehicles', 'Financing', 'Warranties', 'Vehicle appraisals']\n",
            "['Autonomous driving software']\n",
            "['Quantitative Software Engineer']\n",
            "['Transportation services']\n",
            "['Clinical Trial Research']\n",
            "['AI for Autonomy Lab researches applying AI-related technologies for autonomy systems']\n",
            "['Embedded Cybersecurity solutions for Caterpillar machines & engines']\n",
            "['AI research and deployment']\n",
            "['Microservices development']\n",
            "['Electric vehicles']\n",
            "['AI platform at Together AI', 'Research-driven artificial intelligence company', 'Contribute to leading open-source research, models, and datasets']\n",
            "['Building open source digital systems and solutions to battle environmental threats', 'Developing open innovative technology to increase planetary resilience', 'Creating software to track progress towards Paris Agreement goals', 'Improving data infrastructure for climate analysis using AI', 'Maximizing impact through Open Source projects']\n",
            "['Software development for finance industry']\n",
            "['Support workflow development for NOAA SFS', 'NWP modeling system', 'Forecast guidance', 'Earth system models']\n",
            "['Software solutions for critical infrastructure']\n",
            "['AI algorithms', 'software applications']\n",
            "['enterprise B2B SaaS solutions']\n",
            "['Quantum control solution (QCS)', 'Quantum computing', 'Quantum communications', 'Quantum sensing']\n",
            "['Quantum Systems']\n",
            "['Quantum computing system', 'Azure Quantum', 'Revolutionize computing']\n",
            "['Quantum Computing and Devices']\n",
            "['Cutting-edge optical design solutions']\n",
            "['Introduction of automation to construction sector']\n",
            "['Software engineering opportunity at JPMorgan Chase']\n",
            "['Ads Creative Management']\n",
            "['Algorithmic trading programs', 'Forex trading systems']\n",
            "[\"Kernel software development for Boeing's product portfolio\"]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "for i in df['description_of_product/service']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2UDMaibqKhi"
      },
      "source": [
        "We note that for hyphenated word groupings, at least some of them are legitimate individual words, for example, 'X-ray'. Thus we will hold off on applying a lambda function anywhere in the dataframe that replaces '-' with ' ' until we can verify whether or not the hyphenated word grouping is considered a word in our word embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La9gzQO_rAnY",
        "outputId": "e8dab94f-0680-4983-8344-08c7be6ace13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Business Consulting', 'Services']\n",
            "['Biotechnology Research', 'Pharmaceutical Manufacturing']\n",
            "['Software Development', 'IT Services', 'IT Consulting', 'Technology', 'Information', 'Internet']\n",
            "['Financial Services', 'Capital Markets', 'IT Services', 'IT Consulting']\n",
            "['IT Services', 'IT Consulting']\n",
            "['IT Services', 'IT Consulting']\n",
            "['Financial Services']\n",
            "['Financial Services']\n",
            "['Financial Services', 'Technology', 'Information and Internet', 'Software Development']\n",
            "['IT Services', 'IT Consulting']\n",
            "['Staffing', 'Recruiting']\n",
            "['Robotics Engineering', 'Software Development', 'Medical Equipment Manufacturing']\n",
            "['Hospitals and Health Care']\n",
            "['Food and Beverage Services']\n",
            "['Outsourcing and Offshoring Consulting', 'Business Consulting and Services', 'IT Services and IT Consulting']\n",
            "['Advertising Services', 'OEM/Automotive']\n",
            "['Banking', 'Software Development', 'Financial Services']\n",
            "['Software Development']\n",
            "['Technology', 'Information', 'Internet']\n",
            "['Manufacturing', 'Food and Beverage Manufacturing', 'Food and Beverage Services']\n",
            "['Computer Hardware Manufacturing', 'Software Development', 'Computers and Electronics Manufacturing']\n",
            "['Higher Education and Research Services']\n",
            "['Hospitals and Health Care', 'Non-profit Organizations', 'Education Administration Programs']\n",
            "['IT Services', 'IT Consulting']\n",
            "['Telecommunications']\n",
            "['Appliances', 'Electrical', 'Electronics Manufacturing']\n",
            "['Industrial Automation']\n",
            "['Manufacturing']\n",
            "['Research Services', 'Higher Education']\n",
            "['Software Development']\n",
            "['Financial Services']\n",
            "['Software Development']\n",
            "['Broadcast Media Production and Distribution']\n",
            "['Financial Services']\n",
            "['Primary and Secondary Education', 'E-Learning Providers']\n",
            "['Semiconductor Manufacturing']\n",
            "['Machinery Manufacturing', 'Manufacturing', 'Construction']\n",
            "['Investment Management']\n",
            "['Technology', 'Information', 'Internet']\n",
            "['Software Development']\n",
            "['Information Services and Technology', 'Information and Internet']\n",
            "['Hospitals and Health Care']\n",
            "['Consumer Electronics']\n",
            "['Software Development', 'IT Services', 'IT Consulting', 'Technology', 'Information', 'Internet']\n",
            "['Financial Services']\n",
            "['Civil Engineering']\n",
            "['Software Development']\n",
            "['Technology', 'Information', 'Internet']\n",
            "['Technology', 'Information and Media', 'Information Services', 'Software Development']\n",
            "['Defense', 'Space Manufacturing']\n",
            "['Technology', 'Information', 'Internet']\n",
            "['Aviation and Aerospace Component Manufacturing', 'Research Services', 'Defense and Space Manufacturing']\n",
            "['Software Development']\n",
            "['IT Services', 'IT Consulting']\n",
            "['Hospitals and Health Care']\n",
            "['Business Consulting', 'Services', 'Automation Machinery Manufacturing']\n",
            "['Retail']\n",
            "['Non-profit Organizations']\n",
            "['Technology', 'Information', 'Internet']\n",
            "['Semiconductor Manufacturing']\n",
            "['Research Services']\n",
            "['Higher Education']\n",
            "['Airlines and Aviation', 'Aviation and Aerospace Component Manufacturing', 'Defense and Space Manufacturing']\n",
            "['Computer Hardware Manufacturing']\n",
            "['Defense and Space Manufacturing', 'Engineering Services', 'Software Development']\n",
            "['Software Development']\n",
            "['Research Services']\n",
            "['IT Services', 'IT Consulting']\n",
            "['Wholesale Building Materials']\n",
            "['Software Development']\n",
            "['IT Services', 'IT Consulting', 'Technology', 'Information', 'Media']\n",
            "['Software Development']\n",
            "['Marketing Services', 'Media', 'Technology', 'Hospitality', 'Food & beverage', 'Retail', 'Real estate']\n",
            "['Appliances', 'Electrical', 'Electronics Manufacturing']\n",
            "['Computer and Network Security']\n",
            "['Advertising Services']\n",
            "['IT Services', 'IT Consulting', 'Financial Services', 'Banking']\n",
            "['Technology', 'Information and Media']\n",
            "['Telecommunications']\n",
            "['Software Development']\n",
            "['Software Development', 'Motor Vehicle Manufacturing']\n",
            "['IT Services', 'IT Consulting']\n",
            "['Transportation/Trucking/Railroad']\n",
            "['Research']\n",
            "['Defense and Space Manufacturing', 'Higher Education', 'Software Development']\n",
            "['Construction, Machinery Manufacturing']\n",
            "['Research Services']\n",
            "['IT Services', 'IT Consulting']\n",
            "['Motor Vehicle Manufacturing']\n",
            "['Software Development']\n",
            "['Environmental Services']\n",
            "['Technology', 'Information', 'Internet', 'Financial Services', 'Software Development']\n",
            "['Computer Hardware Manufacturing', 'Defense and Space Manufacturing', 'IT Services and IT Consulting']\n",
            "['Computer and Network Security']\n",
            "['IT Services', 'IT Consulting']\n",
            "['Financial Services']\n",
            "['Appliances', 'Electrical', 'Electronics Manufacturing']\n",
            "['Research Services']\n",
            "['Software Development']\n",
            "['Computer Hardware Manufacturing']\n",
            "['Semiconductor Manufacturing', 'Software Development', 'Computer Hardware Manufacturing']\n",
            "['Technology', 'Information and Media']\n",
            "['Financial Services']\n",
            "['Software Development']\n",
            "['Financial Services', 'Investment Banking', 'Software Development']\n",
            "['Airlines and Aviation', 'Aviation and Aerospace Component Manufacturing', 'Defense and Space Manufacturing']\n",
            "['Government Administration']\n"
          ]
        }
      ],
      "source": [
        "for i in df['industries']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBKPGXy0rIeJ",
        "outputId": "497f7f5d-6fe6-41aa-bb39-6b2af0041e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Python Software Engineer (Robotics/Mechatronics)']\n",
            "['Robotics Engineer']\n",
            "['SDE - Amazon Robotics']\n",
            "['Senior Software Engineer']\n",
            "['Software Engineer in Test']\n",
            "['AI Prompt Engineer']\n",
            "['Lead Software Engineer - Python']\n",
            "['Software Engineer III (Python/ML)']\n",
            "['Machine Learning Engineer']\n",
            "['Python Developer']\n",
            "['C++ Quantitative Developer']\n",
            "['Senior Machine Learning Engineer']\n",
            "['Bioinformatics Software Engineer']\n",
            "['Tech Functional Architect, FP&A']\n",
            "['Generative AI Engineer']\n",
            "['Analytics Engineer']\n",
            "['C++ Low Latency Trading Systems Developer']\n",
            "['Embedded Software Engineer']\n",
            "['AR Systems Integration Lead']\n",
            "['Tech Functional Architect, FP&A']\n",
            "['Principal System Software Architect']\n",
            "['Assistant/Associate/Full Professor']\n",
            "['Accountant']\n",
            "['Cyber and RMF Specialist, Mid']\n",
            "['Staff AI Software Build and Release Engineer']\n",
            "['Sales Coordinator']\n",
            "['Sales Application Engineer - Automation']\n",
            "['Staff Accountant']\n",
            "['Research Associate']\n",
            "['Firmware Engineer']\n",
            "['Software Engineering']\n",
            "['Embedded Engineer']\n",
            "['Machine Learning Engineer']\n",
            "['Software Engineer in Test']\n",
            "['Tutor']\n",
            "['Software Engineer']\n",
            "['Embedded Software Engineer']\n",
            "['Quantitative Developer']\n",
            "['Machine Learning SoC Architect']\n",
            "['Generative AI Engineer']\n",
            "['Database Acceleration Specialist']\n",
            "['GCP Data Engineer']\n",
            "['C/Networking Software Engineer']\n",
            "['Software Development Engineer - Test']\n",
            "['Lead Software Engineer']\n",
            "['Senior Level Resiliency Systems Engineer']\n",
            "['Senior Software Engineer']\n",
            "['Go Expert - AI Training']\n",
            "['Triage Software Engineer']\n",
            "['Aerospace Software Engineer']\n",
            "['Machine Learning Engineer']\n",
            "['Scientific Software Engineer - Space']\n",
            "['Rust Engineer', 'C++ Engineer']\n",
            "['AI Engineer']\n",
            "['Peer Tutor']\n",
            "['Innovation Manager (Marketing Technologist) - Cookie Management']\n",
            "['SEO & Content Marketing Specialist']\n",
            "['Assistant Manager']\n",
            "['Postdoctoral Research Scientist, Artificial Intelligence (PhD)']\n",
            "['Technical Sales Specialist']\n",
            "['AI Research Scientist', 'AI Research Engineer']\n",
            "['Software Engineer']\n",
            "['Rotorcraft Vehicle Simulation Software Engineer']\n",
            "['Technology Sales Engineer']\n",
            "['Algorithm Engineer']\n",
            "['Machine Learning Consultant']\n",
            "['Research Assistant']\n",
            "['System Engineer']\n",
            "['Data Engineer']\n",
            "['Gen AI Engineer']\n",
            "['AR/VR Developer']\n",
            "['AI Microsoft Chatbot Developer']\n",
            "['Search Engine Marketing Specialist']\n",
            "['Technical Sales Manager']\n",
            "['Sales Engineer']\n",
            "['Lead ML Ops Engineer']\n",
            "['ML Ops Engineer']\n",
            "['ML/ML Ops Engineer']\n",
            "['RTML Engineer', 'ML Ops Engineer']\n",
            "['Python Developer']\n",
            "['Machine Learning Systems Engineer']\n",
            "['Quantitative Software Engineer']\n",
            "['Driver', 'Bus Driver', 'CDL Driver', 'Non CDL Driver', 'Dispatcher']\n",
            "['Research Assistant']\n",
            "['Machine Learning Engineer']\n",
            "['Embedded Cybersecurity Software Engineer']\n",
            "['Senior Software Engineer, Front End']\n",
            "['Python Developer']\n",
            "['Embedded Software Engineer II']\n",
            "['Systems Research Engineer, Machine Learning Systems']\n",
            "['AI Application Engineer']\n",
            "['Software Engineer']\n",
            "['Scientific Application Programmer']\n",
            "['Product Security Test Engineer']\n",
            "['AI Software Engineer']\n",
            "['Distinguished Engineer']\n",
            "['Quantum Solution Engineer']\n",
            "['Summer Internship - Quantum Systems']\n",
            "['Research Intern - Quantum Information and Computation']\n",
            "['Research Scientist']\n",
            "['Software Architect - C++']\n",
            "['Machine Learning Engineer']\n",
            "['Software Engineer II (Quant/Python)']\n",
            "['Staff Software Engineer']\n",
            "['Algorithm Developer']\n",
            "['Associate Software Engineer - Kernel Developer']\n",
            "['Machine Learning Engineer']\n"
          ]
        }
      ],
      "source": [
        "for i in df['position_name']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZVYJjENrbOn"
      },
      "source": [
        "We see parentheses around 'PhD'. We will most likely want to remove parentheses throughout the whole dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko9cP3Vfrwqi"
      },
      "outputs": [],
      "source": [
        "# Remove '(' and ')' from each item in lists\n",
        "df['position_name'] = df['position_name'].apply(lambda x: [item.replace('(', '').replace(')', '') for item in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQfZdnZjsDN_",
        "outputId": "7ff39710-5d0f-44ed-ae30-9f932d42c8e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Python Software Engineer Robotics/Mechatronics']\n",
            "['Robotics Engineer']\n",
            "['SDE - Amazon Robotics']\n",
            "['Senior Software Engineer']\n",
            "['Software Engineer in Test']\n",
            "['AI Prompt Engineer']\n",
            "['Lead Software Engineer - Python']\n",
            "['Software Engineer III Python/ML']\n",
            "['Machine Learning Engineer']\n",
            "['Python Developer']\n",
            "['C++ Quantitative Developer']\n",
            "['Senior Machine Learning Engineer']\n",
            "['Bioinformatics Software Engineer']\n",
            "['Tech Functional Architect, FP&A']\n",
            "['Generative AI Engineer']\n",
            "['Analytics Engineer']\n",
            "['C++ Low Latency Trading Systems Developer']\n",
            "['Embedded Software Engineer']\n",
            "['AR Systems Integration Lead']\n",
            "['Tech Functional Architect, FP&A']\n",
            "['Principal System Software Architect']\n",
            "['Assistant/Associate/Full Professor']\n",
            "['Accountant']\n",
            "['Cyber and RMF Specialist, Mid']\n",
            "['Staff AI Software Build and Release Engineer']\n",
            "['Sales Coordinator']\n",
            "['Sales Application Engineer - Automation']\n",
            "['Staff Accountant']\n",
            "['Research Associate']\n",
            "['Firmware Engineer']\n",
            "['Software Engineering']\n",
            "['Embedded Engineer']\n",
            "['Machine Learning Engineer']\n",
            "['Software Engineer in Test']\n",
            "['Tutor']\n",
            "['Software Engineer']\n",
            "['Embedded Software Engineer']\n",
            "['Quantitative Developer']\n",
            "['Machine Learning SoC Architect']\n",
            "['Generative AI Engineer']\n",
            "['Database Acceleration Specialist']\n",
            "['GCP Data Engineer']\n",
            "['C/Networking Software Engineer']\n",
            "['Software Development Engineer - Test']\n",
            "['Lead Software Engineer']\n",
            "['Senior Level Resiliency Systems Engineer']\n",
            "['Senior Software Engineer']\n",
            "['Go Expert - AI Training']\n",
            "['Triage Software Engineer']\n",
            "['Aerospace Software Engineer']\n",
            "['Machine Learning Engineer']\n",
            "['Scientific Software Engineer - Space']\n",
            "['Rust Engineer', 'C++ Engineer']\n",
            "['AI Engineer']\n",
            "['Peer Tutor']\n",
            "['Innovation Manager Marketing Technologist - Cookie Management']\n",
            "['SEO & Content Marketing Specialist']\n",
            "['Assistant Manager']\n",
            "['Postdoctoral Research Scientist, Artificial Intelligence PhD']\n",
            "['Technical Sales Specialist']\n",
            "['AI Research Scientist', 'AI Research Engineer']\n",
            "['Software Engineer']\n",
            "['Rotorcraft Vehicle Simulation Software Engineer']\n",
            "['Technology Sales Engineer']\n",
            "['Algorithm Engineer']\n",
            "['Machine Learning Consultant']\n",
            "['Research Assistant']\n",
            "['System Engineer']\n",
            "['Data Engineer']\n",
            "['Gen AI Engineer']\n",
            "['AR/VR Developer']\n",
            "['AI Microsoft Chatbot Developer']\n",
            "['Search Engine Marketing Specialist']\n",
            "['Technical Sales Manager']\n",
            "['Sales Engineer']\n",
            "['Lead ML Ops Engineer']\n",
            "['ML Ops Engineer']\n",
            "['ML/ML Ops Engineer']\n",
            "['RTML Engineer', 'ML Ops Engineer']\n",
            "['Python Developer']\n",
            "['Machine Learning Systems Engineer']\n",
            "['Quantitative Software Engineer']\n",
            "['Driver', 'Bus Driver', 'CDL Driver', 'Non CDL Driver', 'Dispatcher']\n",
            "['Research Assistant']\n",
            "['Machine Learning Engineer']\n",
            "['Embedded Cybersecurity Software Engineer']\n",
            "['Senior Software Engineer, Front End']\n",
            "['Python Developer']\n",
            "['Embedded Software Engineer II']\n",
            "['Systems Research Engineer, Machine Learning Systems']\n",
            "['AI Application Engineer']\n",
            "['Software Engineer']\n",
            "['Scientific Application Programmer']\n",
            "['Product Security Test Engineer']\n",
            "['AI Software Engineer']\n",
            "['Distinguished Engineer']\n",
            "['Quantum Solution Engineer']\n",
            "['Summer Internship - Quantum Systems']\n",
            "['Research Intern - Quantum Information and Computation']\n",
            "['Research Scientist']\n",
            "['Software Architect - C++']\n",
            "['Machine Learning Engineer']\n",
            "['Software Engineer II Quant/Python']\n",
            "['Staff Software Engineer']\n",
            "['Algorithm Developer']\n",
            "['Associate Software Engineer - Kernel Developer']\n",
            "['Machine Learning Engineer']\n"
          ]
        }
      ],
      "source": [
        "for i in df['position_name']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFQusuvpsNpk",
        "outputId": "db5e486a-d030-4ffa-8971-27e632758b54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Software Engineer']\n",
            "['N/A']\n",
            "['AI Engineer']\n",
            "['Software Engineer']\n",
            "['Software Engineer']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Tech Product Manager']\n",
            "['N/A']\n",
            "['Analytics & Quality Engineer']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['FP&A Tech Workstream Lead']\n",
            "['Director']\n",
            "['MizzouForward']\n",
            "['N/A']\n",
            "['Information security risk specialist']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Sales Application Engineer']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Clinician']\n",
            "['CAD/EDA Tools Software Engineer']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Data Scientist', 'AI-ML Engineer']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Software Engineer']\n",
            "['N/A']\n",
            "['Software Engineer']\n",
            "['Systems Engineer']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Software Engineer']\n",
            "['Engineering']\n",
            "['N/A']\n",
            "['Engineering']\n",
            "['Engineer']\n",
            "['Engineer']\n",
            "['N/A']\n",
            "['Innovation Manager']\n",
            "['N/A']\n",
            "['Manager On Duty']\n",
            "['Research Scientist']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['AI Engineer']\n",
            "['Software Engineer']\n",
            "['Brand Technical Specialist']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Operational Support Engineer']\n",
            "['N/A']\n",
            "['Engineer']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Marketing Analyst']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Data Science Platform Team']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Principle Engineer']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Software Engineer']\n",
            "['Engineering']\n",
            "['N/A']\n",
            "['Software Engineer II - Field Support']\n",
            "['Systems Research Engineer']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Engineering Solutions']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Software Architect']\n",
            "['N/A']\n",
            "['Software Engineer']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['Software Engineer']\n",
            "['N/A']\n"
          ]
        }
      ],
      "source": [
        "for i in df['broader_role_name']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V36aurRsWii",
        "outputId": "dc60bad5-7676-4453-ed23-281f0cd65679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Fresh Consulting']\n",
            "['Barrington James']\n",
            "['Amazon']\n",
            "['VantageScore®']\n",
            "['Optomi']\n",
            "['Crossover']\n",
            "['JPMorgan Chase & Co.']\n",
            "['JPMorgan Chase & Co.']\n",
            "['maven']\n",
            "['REI Systems']\n",
            "['Jobot']\n",
            "['Remedy Robotics']\n",
            "['Insight Global']\n",
            "['Ocean Spray Cranberries']\n",
            "['Capgemini']\n",
            "['Harnham']\n",
            "['Huxley']\n",
            "['Oxenham Group']\n",
            "['Meta']\n",
            "['MSH']\n",
            "['NVIDIA']\n",
            "['University of Missouri-Columbia']\n",
            "['Altarum']\n",
            "['Booz Allen Hamilton']\n",
            "['Qualcomm']\n",
            "['Generac Power Systems']\n",
            "['Conveyor Solutions, Inc.']\n",
            "['Bespoke Beauty Brands']\n",
            "['SLAC National Accelerator Laboratory']\n",
            "['Dice']\n",
            "['JPMorgan Chase & Co.']\n",
            "['Dice']\n",
            "['Harnham']\n",
            "['Photon']\n",
            "['Lindamood-Bell Learning Processes']\n",
            "['Intel Corporation']\n",
            "['Bobcat Company']\n",
            "['ASB Resources']\n",
            "['Meta']\n",
            "['Dice']\n",
            "['Google']\n",
            "['Fractal']\n",
            "['Garmin']\n",
            "['Amazon Lab126']\n",
            "['JPMorgan Chase & Co.']\n",
            "['Peraton']\n",
            "['Oho Group Ltd']\n",
            "['Braintrust']\n",
            "['CoreTek Labs']\n",
            "['EVONA']\n",
            "['HireIO, Inc.']\n",
            "['EVONA']\n",
            "['Dice']\n",
            "['Diverse Lynx']\n",
            "['Oregon Health & Science University']\n",
            "['MindSource']\n",
            "['Ray Allen Manufacturing']\n",
            "['Boston Public Market Association']\n",
            "['Meta']\n",
            "['Intel Corporation']\n",
            "['LG AI Research']\n",
            "['Catholic Institute of Technology']\n",
            "['Boeing']\n",
            "['IBM']\n",
            "['Insight Global']\n",
            "['Dice']\n",
            "['Dana Meeks Consulting']\n",
            "['Sealing Technologies, a Parsons Company']\n",
            "['Pella Corporation']\n",
            "['Dice']\n",
            "['The Mice Groups, Inc.']\n",
            "['Dice']\n",
            "['The Madison Melle Agency']\n",
            "['HICO America']\n",
            "['alphaMountain.ai']\n",
            "['Klaviyo']\n",
            "['Apexon']\n",
            "['Grid Dynamics']\n",
            "['InfoVision Inc.']\n",
            "['hackajob']\n",
            "['Ghost Autonomy']\n",
            "['Raft']\n",
            "['MASS TRANSPORTATION SERVICES, INC']\n",
            "['The US Oncology Network']\n",
            "['Software Engineering Institute | Carnegie Mellon University']\n",
            "['Caterpillar Inc.']\n",
            "['OpenAI']\n",
            "['TEKsystems']\n",
            "['Motiv Power Systems']\n",
            "['Together AI']\n",
            "['Open Earth Foundation']\n",
            "['maven']\n",
            "['SAIC']\n",
            "['Verve Industrial, A Rockwell Automation Company']\n",
            "['Zoom']\n",
            "['Capital One']\n",
            "['Keysight Technologies']\n",
            "['QuEra Computing Inc.']\n",
            "['Microsoft']\n",
            "['IBM']\n",
            "['Synopsys Inc']\n",
            "['Harnham']\n",
            "['JPMorgan Chase & Co.']\n",
            "['Reddit, Inc.']\n",
            "['Nurp']\n",
            "['Boeing']\n",
            "['Blu Omega']\n"
          ]
        }
      ],
      "source": [
        "for i in df['company']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0Hx0goRsgGQ",
        "outputId": "0cab396e-22f8-4050-c8a5-4c3e9c6f9ccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Redmond, WA']\n",
            "['New York, United States']\n",
            "['North Reading, MA']\n",
            "['San Francisco Bay Area']\n",
            "['Dallas-Fort Worth Metroplex']\n",
            "['Evansville, IN']\n",
            "['Houston, TX']\n",
            "['Jersey City, NJ']\n",
            "['Greater Chicago Area']\n",
            "['Sterling, VA']\n",
            "['Indianapolis, IN']\n",
            "['San Francisco Bay Area']\n",
            "['Memphis Metropolitan Area']\n",
            "['Lakeville, MA']\n",
            "['San Francisco Bay Area']\n",
            "['United States']\n",
            "['Chicago, IL']\n",
            "['Boston, MA']\n",
            "['Redmond, WA']\n",
            "['Greater Boston']\n",
            "['Boulder, CO']\n",
            "['Columbia, MO']\n",
            "['Ann Arbor, MI']\n",
            "['Lexington Park, MD']\n",
            "['San Diego, CA']\n",
            "['Pewaukee, WI']\n",
            "['Dallas-Fort Worth Metroplex']\n",
            "['Irving, TX']\n",
            "['Menlo Park, CA']\n",
            "['Dallas, TX']\n",
            "['Jersey City, NJ']\n",
            "['Bellevue, WA']\n",
            "['New York, NY']\n",
            "['Alpharetta, GA']\n",
            "['Palm Beach County, FL']\n",
            "['Hillsboro, OR']\n",
            "['Bismarck, ND']\n",
            "['Manhattan, NY']\n",
            "['Austin, TX']\n",
            "['Plano, TX']\n",
            "['Los Angeles, CA']\n",
            "['Bentonville, AR']\n",
            "['Cary, NC']\n",
            "['Sunnyvale, CA']\n",
            "['Brooklyn, NY']\n",
            "['Chantilly, VA']\n",
            "['Sunnyvale, CA']\n",
            "['Texas, United States']\n",
            "['Dallas, TX']\n",
            "['Colorado, United States']\n",
            "['San Francisco, CA']\n",
            "['Colorado, United States']\n",
            "['King of Prussia, PA']\n",
            "['San Jose, CA']\n",
            "['Portland, OR']\n",
            "['California, United States']\n",
            "['Colorado Springs, CO']\n",
            "['Boston, MA']\n",
            "['Pittsburgh, PA']\n",
            "['Hillsboro, OR']\n",
            "['Ann Arbor, MI']\n",
            "['United States']\n",
            "['Hazelwood, MO']\n",
            "['Indianapolis, IN']\n",
            "['United States']\n",
            "['United States']\n",
            "['Oakland, CA']\n",
            "['Columbia, MD']\n",
            "['Pella, IA']\n",
            "['Atlanta, GA']\n",
            "['United States']\n",
            "['United States']\n",
            "['Los Angeles, CA']\n",
            "['Pittsburgh, PA']\n",
            "['Lehi, UT']\n",
            "['Boston, MA']\n",
            "['Berkeley Heights, NJ']\n",
            "['United States']\n",
            "['Irving, TX', 'Dallas, TX', 'NJ']\n",
            "['United States']\n",
            "['Mountain View, CA']\n",
            "['San Antonio, TX']\n",
            "['East Orange, NJ']\n",
            "['Country Club, CA']\n",
            "['Pittsburgh, PA']\n",
            "['Chillicothe, IL']\n",
            "['San Francisco, CA']\n",
            "['Milwaukee, WI']\n",
            "['Foster City, CA']\n",
            "['San Francisco Bay Area (Hybrid)']\n",
            "['United States']\n",
            "['New York, NY']\n",
            "['College Park, MD']\n",
            "['United States']\n",
            "['California, United States']\n",
            "['Cambridge, MA']\n",
            "['Santa Rosa, CA']\n",
            "['Boston, MA']\n",
            "['Redmond, WA']\n",
            "['Yorktown Heights, NY']\n",
            "['Irvine, CA']\n",
            "['Chicago, IL']\n",
            "['New York, United States']\n",
            "['United States']\n",
            "['United States']\n",
            "['Mesa, AZ']\n",
            "['United States']\n"
          ]
        }
      ],
      "source": [
        "for i in df['location']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtdM12E-tIn4"
      },
      "source": [
        "This is an example of something we might want to ask ChatGPT to do for us, at least in future posting summarization; it'd be nice if it could identify the city, state, and country for us so we don't need to write tricky code to do this feature extraction. We could try doing a for loop where we pass each list value to ChatGPT and have it spit out JSON that we can then use to create new columns for city, state, and country in our dataframe and fill them row by row."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aafVJuC_vMxe"
      },
      "source": [
        "To do this first we will design the prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGuUdwiKwfMX"
      },
      "source": [
        "\"Take the following python list and create a JSON dictionary containing 'city', 'state', and 'country' as keys and fill out the values. If the list is ['Colorado Springs, CO'] you would return {\"city\": \"Colorado Springs\", \"state\": \"CO\", \"country\": \"USA\"}. Return only the JSON dictionary. I want you to do it, not to tell me how to code it. I want you to do it for:\n",
        "{list}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpxklLpdybqa",
        "outputId": "bf564f08-2230-493b-dea5-5dc28f6d1671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"city\": \"Redmond\", \"state\": \"WA\", \"country\": \"USA\"}\n",
            "{\"city\": \"New York\", \"state\": \"\", \"country\": \"United States\"}\n",
            "{\"city\": \"North Reading\", \"state\": \"MA\", \"country\": \"USA\"}\n",
            "{\"city\": \"San Francisco\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Dallas-Fort Worth\", \"state\": \"TX\", \"country\": \"USA\"}\n",
            "{\"city\": \"Evansville\", \"state\": \"IN\", \"country\": \"USA\"}\n",
            "{\n",
            "  \"city\": \"Houston\",\n",
            "  \"state\": \"TX\",\n",
            "  \"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"Jersey City\", \"state\": \"NJ\", \"country\": \"USA\"}\n",
            "{\"city\": \"Chicago\", \"state\": \"IL\", \"country\": \"USA\"}\n",
            "{\"city\": \"Sterling\", \"state\": \"VA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Indianapolis\", \"state\": \"IN\", \"country\": \"USA\"}\n",
            "{\"city\": \"San Francisco\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Memphis Metropolitan Area\", \"state\": \"\", \"country\": \"\"}\n",
            "{\"city\": \"Lakeville\", \"state\": \"MA\", \"country\": \"USA\"}\n",
            "{\"city\": \"San Francisco\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\"city\": \"\", \"state\": \"\", \"country\": \"United States\"}\n",
            "{\"city\": \"Chicago\", \"state\": \"IL\", \"country\": \"USA\"}\n",
            "{\"city\": \"Boston\", \"state\": \"MA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Redmond\", \"state\": \"WA\", \"country\": \"USA\"}\n",
            "{\n",
            "  \"city\": \"Greater Boston\",\n",
            "  \"state\": null,\n",
            "  \"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"Boulder\", \"state\": \"CO\", \"country\": \"USA\"}\n",
            "{\"city\": \"Columbia\", \"state\": \"MO\", \"country\": \"USA\"}\n",
            "{\n",
            "  \"city\": \"Ann Arbor\",\n",
            "  \"state\": \"MI\",\n",
            "  \"country\": \"USA\"\n",
            "}\n",
            "{\n",
            "  \"city\": \"Lexington Park\",\n",
            "  \"state\": \"MD\",\n",
            "  \"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"San Diego\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Pewaukee\", \"state\": \"WI\", \"country\": \"USA\"}\n",
            "{\"city\": \"Dallas-Fort Worth\", \"state\": \"TX\", \"country\": \"USA\"}\n",
            "{\n",
            "\"city\": \"Irving\",\n",
            "\"state\": \"TX\",\n",
            "\"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"Menlo Park\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Dallas\", \"state\": \"TX\", \"country\": \"USA\"}\n",
            "{\"city\": \"Jersey City\", \"state\": \"NJ\", \"country\": \"USA\"}\n",
            "{\"city\": \"Bellevue\", \"state\": \"WA\", \"country\": \"USA\"}\n",
            "{\n",
            "  \"city\": \"New York\",\n",
            "  \"state\": \"NY\",\n",
            "  \"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"Alpharetta\", \"state\": \"GA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Palm Beach\", \"state\": \"FL\", \"country\": \"USA\"}\n",
            "{\"city\": \"Hillsboro\", \"state\": \"OR\", \"country\": \"USA\"}\n",
            "{\"city\": \"Bismarck\", \"state\": \"ND\", \"country\": \"USA\"}\n",
            "{\"city\": \"Manhattan\", \"state\": \"NY\", \"country\": \"USA\"}\n",
            "{\"city\": \"Austin\", \"state\": \"TX\", \"country\": \"USA\"}\n",
            "{\"city\": \"Plano\", \"state\": \"TX\", \"country\": \"USA\"}\n",
            "{\"city\": \"Los Angeles\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Bentonville\", \"state\": \"AR\", \"country\": \"USA\"}\n",
            "{\"city\": \"Cary\", \"state\": \"NC\", \"country\": \"USA\"}\n",
            "{\"city\": \"Sunnyvale\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Brooklyn\", \"state\": \"NY\", \"country\": \"USA\"}\n",
            "{\"city\": \"Chantilly\", \"state\": \"VA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Sunnyvale\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Texas\", \"state\": \"TX\", \"country\": \"United States\"}\n",
            "{\"city\": \"Dallas\", \"state\": \"TX\", \"country\": \"USA\"}\n",
            "{\"city\": \"Colorado\", \"state\": \"\", \"country\": \"United States\"}\n",
            "{\"city\": \"San Francisco\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Colorado\", \"state\": \"\", \"country\": \"United States\"}\n",
            "{\n",
            "  \"city\": \"King of Prussia\",\n",
            "  \"state\": \"PA\",\n",
            "  \"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"San Jose\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Portland\", \"state\": \"OR\", \"country\": \"USA\"}\n",
            "{\"city\": \"California\", \"state\": \"\", \"country\": \"United States\"}\n",
            "{\"city\": \"Colorado Springs\", \"state\": \"CO\", \"country\": \"USA\"}\n",
            "{\n",
            "\"city\": \"Boston\",\n",
            "\"state\": \"MA\",\n",
            "\"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"Pittsburgh\", \"state\": \"PA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Hillsboro\", \"state\": \"OR\", \"country\": \"USA\"}\n",
            "{\n",
            "  \"city\": \"Ann Arbor\",\n",
            "  \"state\": \"MI\",\n",
            "  \"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"\", \"state\": \"\", \"country\": \"United States\"}\n",
            "{\"city\": \"Hazelwood\", \"state\": \"MO\", \"country\": \"USA\"}\n",
            "{\"city\": \"Indianapolis\", \"state\": \"IN\", \"country\": \"USA\"}\n",
            "{\"city\": \"\", \"state\": \"\", \"country\": \"United States\"}\n",
            "{\"city\": \"\", \"state\": \"\", \"country\": \"United States\"}\n",
            "{\n",
            "  \"city\": \"Oakland\",\n",
            "  \"state\": \"CA\",\n",
            "  \"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"Columbia\", \"state\": \"MD\", \"country\": \"USA\"}\n",
            "{\"city\": \"Pella\", \"state\": \"IA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Atlanta\", \"state\": \"GA\", \"country\": \"USA\"}\n",
            "{\"city\": \"\", \"state\": \"\", \"country\": \"United States\"}\n",
            "{\"city\": \"\", \"state\": \"\", \"country\": \"USA\"}\n",
            "{\"city\": \"Los Angeles\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Pittsburgh\", \"state\": \"PA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Lehi\", \"state\": \"UT\", \"country\": \"USA\"}\n",
            "{\"city\": \"Boston\", \"state\": \"MA\", \"country\": \"USA\"}\n",
            "{\n",
            "  \"city\": \"Berkeley Heights\",\n",
            "  \"state\": \"NJ\",\n",
            "  \"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"\", \"state\": \"\", \"country\": \"United States\"}\n",
            "{\n",
            "  \"1\": {\n",
            "    \"city\": \"Irving\",\n",
            "    \"state\": \"TX\",\n",
            "    \"country\": \"USA\"\n",
            "  },\n",
            "  \"2\": {\n",
            "    \"city\": \"Dallas\",\n",
            "    \"state\": \"TX\",\n",
            "    \"country\": \"USA\"\n",
            "  },\n",
            "  \"3\": {\n",
            "    \"city\": \"NJ\",\n",
            "    \"state\": \"\",\n",
            "    \"country\": \"USA\"\n",
            "  }\n",
            "}\n",
            "{\"city\": \"N/A\", \"state\": \"N/A\", \"country\": \"United States\"}\n",
            "{\n",
            "    \"city\": \"Mountain View\",\n",
            "    \"state\": \"CA\",\n",
            "    \"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"San Antonio\", \"state\": \"TX\", \"country\": \"USA\"}\n",
            "{\"city\": \"East Orange\", \"state\": \"NJ\", \"country\": \"USA\"}\n",
            "{\n",
            "    \"city\": \"Country Club\",\n",
            "    \"state\": \"CA\",\n",
            "    \"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"Pittsburgh\", \"state\": \"PA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Chillicothe\", \"state\": \"IL\", \"country\": \"USA\"}\n",
            "{\"city\": \"San Francisco\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Milwaukee\", \"state\": \"WI\", \"country\": \"USA\"}\n",
            "{\"city\": \"Foster City\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\n",
            "    \"city\": \"San Francisco\",\n",
            "    \"state\": \"CA\",\n",
            "    \"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"\", \"state\": \"\", \"country\": \"United States\"}\n",
            "{\n",
            "    \"city\": \"New York\",\n",
            "    \"state\": \"NY\",\n",
            "    \"country\": \"USA\"\n",
            "}\n",
            "{\n",
            "  \"city\": \"College Park\",\n",
            "  \"state\": \"MD\",\n",
            "  \"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"\", \"state\": \"\", \"country\": \"United States\"}\n",
            "{\"city\": \"California\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Cambridge\", \"state\": \"MA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Santa Rosa\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Boston\", \"state\": \"MA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Redmond\", \"state\": \"WA\", \"country\": \"USA\"}\n",
            "{\"city\": \"Yorktown Heights\", \"state\": \"NY\", \"country\": \"USA\"}\n",
            "{\"city\": \"Irvine\", \"state\": \"CA\", \"country\": \"USA\"}\n",
            "{\n",
            "   \"city\": \"Chicago\",\n",
            "   \"state\": \"IL\",\n",
            "   \"country\": \"USA\"\n",
            "}\n",
            "{\"city\": \"New York\", \"state\": \"\", \"country\": \"United States\"}\n",
            "{\"city\": \"\", \"state\": \"\", \"country\": \"United States\"}\n",
            "{\n",
            "  \"city\": \"\",\n",
            "  \"state\": \"\",\n",
            "  \"country\": \"United States\"\n",
            "}\n",
            "{\"city\": \"Mesa\", \"state\": \"AZ\", \"country\": \"USA\"}\n",
            "{\n",
            "\"city\": \"\",\n",
            "\"state\": \"\",\n",
            "\"country\": \"United States\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "for index, value in enumerate(df['location']):\n",
        "  generate_location_json_file(index, value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoHTLrTrwn-1"
      },
      "outputs": [],
      "source": [
        "# getting started with OpenAI API!\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "def generate_location_json_file(ind, location_val):\n",
        "\n",
        "  prompt = \"Take the following python list and create a JSON dictionary containing 'city', 'state', and 'country' as keys and fill out the values. If the list is ['Colorado Springs, CO'] you would return {'city': 'Colorado Springs', 'state': 'CO', 'country': 'USA'}. If the list is instead Return only the JSON dictionary, and make sure to use double quotes even though I used single in this prompt. I want you to do it, not to tell me how to code it. I want you to do it for: \"\n",
        "\n",
        "  prompt = prompt + \"/n\" + str(location_val)\n",
        "\n",
        "  client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=\"someKey\",\n",
        "  )\n",
        "\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt,\n",
        "          }\n",
        "      ],\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "  )\n",
        "  json_files_dir = r\"drive/MyDrive/jobLocations/\"\n",
        "  print(chat_completion.choices[0].message.content)\n",
        "  json_data = json.loads(chat_completion.choices[0].message.content.strip(\"`\").strip('json').strip())\n",
        "  json_file_path = json_files_dir + f'row{ind + 1}.json'\n",
        "  # Write JSON data to the file\n",
        "  with open(json_file_path, \"w\") as json_file:\n",
        "    json.dump(json_data, json_file)\n",
        "\n",
        "  return json_file_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSrkJpTUQRL1"
      },
      "source": [
        "Excellent, so we have generated the JSON files for the location column data. This will prove helpful when we make new feature columns for city, state, and country. So far we have two columns which we may choose to treat differently from the rest: the employment_type column which we might drop and the location columns which we will treat as having categorical data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az1ALhuwyRkb",
        "outputId": "05118456-98e5-4b1b-8e24-ffb55c83f160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m204.8/227.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocb7CBhvRfGe",
        "outputId": "8aa7f2b5-88b3-4f29-b14c-0f19f68e1761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['$30.00/hr - $45.00/hr']\n",
            "nan\n",
            "['N/A']\n",
            "['$150K - $200K']\n",
            "['N/A']\n",
            "nan\n",
            "['N/A']\n",
            "['N/A']\n",
            "nan\n",
            "nan\n",
            "['$100,000.00/yr', '$175,000.00/yr']\n",
            "nan\n",
            "['$50.00/hr - $60.00/hr', 'Compensation: $50/hr to $65/hr']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "nan\n",
            "['N/A']\n",
            "['$129,000.00/yr', '$200,000.00/yr']\n",
            "['N/A']\n",
            "['$216,000.00/yr - $414,000.00/yr']\n",
            "nan\n",
            "['N/A']\n",
            "['$58,300.00/yr - $133,000.00/yr']\n",
            "['$126,000.00/yr - $189,000.00/yr']\n",
            "['N/A']\n",
            "['N/A']\n",
            "nan\n",
            "['$70,000.00/yr - $100,000.00/yr']\n",
            "['N/A']\n",
            "nan\n",
            "['N/A']\n",
            "['$170,000.00/yr - $200,000.00/yr']\n",
            "['N/A']\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "['$150,000.00/yr - $200,000.00/yr']\n",
            "nan\n",
            "['N/A']\n",
            "['$154,000.00/yr - $236,000.00/yr']\n",
            "nan\n",
            "nan\n",
            "['$115,000.00/yr - $223,600.00/yr']\n",
            "nan\n",
            "nan\n",
            "['$150,000.00/yr - $220,000.00/yr']\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "nan\n",
            "nan\n",
            "['N/A']\n",
            "['$117,000.00/yr - $173,000.00/yr']\n",
            "['N/A', 'Annual Salary Range: $181,145.00-$289,863.00']\n",
            "['N/A']\n",
            "nan\n",
            "nan\n",
            "['$107,000.00/yr - $162,000.00/yr']\n",
            "['$100,000.00/yr - $140,000.00/yr']\n",
            "['N/A']\n",
            "['N/A']\n",
            "['N/A']\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "['N/A']\n",
            "nan\n",
            "['$192,000.00/yr', '$288,000.00/yr']\n",
            "nan\n",
            "['N/A']\n",
            "['N/A']\n",
            "['$120,000.00/yr - $170,000.00/yr']\n",
            "['$175,000.00/yr - $275,000.00/yr']\n",
            "['$90,000.00/yr - $170,000.00/yr']\n",
            "['N/A']\n",
            "nan\n",
            "['N/A']\n",
            "['N/A']\n",
            "['$245,000.00/yr - $385,000.00/yr']\n",
            "['N/A']\n",
            "['$122,000.00/yr - $132,000.00/yr']\n",
            "nan\n",
            "['$60,000.00/yr - $90,000.00/yr']\n",
            "nan\n",
            "nan\n",
            "['N/A']\n",
            "['$137,500.00/yr', '$220,000.00/yr']\n",
            "['N/A']\n",
            "nan\n",
            "['N/A']\n",
            "['$10,120.00/yr - $12,170.00/yr', 'USD $5,090 - $13,240 per month']\n",
            "['$98,144.00/yr - $216,646.00/yr']\n",
            "nan\n",
            "['$130,000.00/yr - $150,000.00/yr']\n",
            "['N/A']\n",
            "['$198,200.00/yr - $297,300.00/yr']\n",
            "['$100,000.00/yr', '$130,000.00/yr']\n",
            "nan\n",
            "nan\n"
          ]
        }
      ],
      "source": [
        "for i in df['salary/compensation_range']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nplgnsb-Sn_m"
      },
      "source": [
        "We might want to do what we did for the 'location' data and have ChatGPT summarize our data into JSON files with two keys. salary_min and salary_max."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVbnyj15TMyA"
      },
      "outputs": [],
      "source": [
        "# getting started with OpenAI API!\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "def generate_salary_json_file(ind, location_val):\n",
        "\n",
        "  prompt = \"Take the following python data and infer the minimum and maximuim of the salary range, and fill out their values as floating point numbers with three decimal places in units of thousands in a JSON dictionary, with 'salary_min' and 'salary_max' being the keys. If the data given is ['$150,000.00/yr - $220,000.00/yr'] then you should return {'salary_min': 150, 'salary_max': 220}, but make sure to use double quotes to enclose the key names. If you infer that info is in dollars per hour, convert the numbers to annual salary in thousands so output is same regardless of given units. Note that $48/hr is equal to $100,000/yr. Put 'N/A' under a fields if the required information is not given. If only one number is given put it under 'salary_max'. Return only the JSON dictionary. I want you to do it, not to tell me how to code it. I want you to do it for: \"\n",
        "\n",
        "  prompt = prompt + \"/n\" + str(location_val)\n",
        "\n",
        "  client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=\"someKey\",\n",
        "  )\n",
        "\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt,\n",
        "          }\n",
        "      ],\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "  )\n",
        "  json_files_dir = r\"drive/MyDrive/jobSalaries/\"\n",
        "  print(chat_completion.choices[0].message.content)\n",
        "  json_data = json.loads(chat_completion.choices[0].message.content.strip(\"`\").strip('json').strip())\n",
        "  json_file_path = json_files_dir + f'row{ind + 1}.json'\n",
        "  # Write JSON data to the file\n",
        "  with open(json_file_path, \"w\") as json_file:\n",
        "    json.dump(json_data, json_file)\n",
        "\n",
        "  return json_file_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mYJcOB8WoKJ",
        "outputId": "afaf990b-b50b-4689-cd6c-feff32e9c7e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"salary_min\": 62.4,\n",
            "    \"salary_max\": 93.6\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\"salary_min\": 150, \"salary_max\": 200}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 100,\n",
            "    \"salary_max\": 175\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 100,\n",
            "    \"salary_max\": 130\n",
            "}\n",
            "{\n",
            "\"salary_min\": \"N/A\",\n",
            "\"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 129,\n",
            "    \"salary_max\": 200\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 216,\n",
            "    \"salary_max\": 414\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 58.3,\n",
            "    \"salary_max\": 133\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 126,\n",
            "    \"salary_max\": 189\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 70,\n",
            "    \"salary_max\": 100\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 170,\n",
            "    \"salary_max\": 200\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 150,\n",
            "    \"salary_max\": 200\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 154,\n",
            "    \"salary_max\": 236\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 115,\n",
            "    \"salary_max\": 223.6\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 150,\n",
            "    \"salary_max\": 220\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": 117,\n",
            "  \"salary_max\": 173\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 181.145,\n",
            "    \"salary_max\": 289.863\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\"salary_min\": 107, \"salary_max\": 162}\n",
            "{\"salary_min\": 100, \"salary_max\": 140}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\"salary_min\": 192, \"salary_max\": 288}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 120,\n",
            "    \"salary_max\": 170\n",
            "}\n",
            "{\n",
            "  \"salary_min\": 175,\n",
            "  \"salary_max\": 275\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 90,\n",
            "    \"salary_max\": 170\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 245,\n",
            "    \"salary_max\": 385\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "\t\"salary_min\": 122,\n",
            "\t\"salary_max\": 132\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\"salary_min\": 60, \"salary_max\": 90}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 137.5,\n",
            "    \"salary_max\": 220\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": \"N/A\",\n",
            "  \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 101,\n",
            "    \"salary_max\": 122\n",
            "}\n",
            "{\"salary_min\": 98.144, \"salary_max\": 216.646}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": 130,\n",
            "    \"salary_max\": 150\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "  \"salary_min\": 198.2,\n",
            "  \"salary_max\": 297.3\n",
            "}\n",
            "{\"salary_min\": 100, \"salary_max\": 130}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n",
            "{\n",
            "    \"salary_min\": \"N/A\",\n",
            "    \"salary_max\": \"N/A\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "for index, value in enumerate(df['salary/compensation_range']):\n",
        "  generate_salary_json_file(index, value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKyU9qijq9fv",
        "outputId": "a75af583-7b1c-4340-d7fa-138c522c6bc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['emploment_type', 'job_function', 'description_of_product/service',\n",
            "       'industries', 'position_name', 'broader_role_name', 'company',\n",
            "       'location', 'salary/compensation_range', 'responsibilities',\n",
            "       'goals/objectives', 'name_of_department/team',\n",
            "       'required_qualifications', 'preferred_qualifications', 'benefits',\n",
            "       'work_arrangement', 'rating'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojk90KjlYMxg",
        "outputId": "f5bd94aa-5553-4a55-dca1-9417a14bf830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['integrate software/hardware components', 'develop UI front-end', 'investigate defects', 'be active team player', 'learn new systems/tools', 'document code quality', 'work on python applications']\n",
            "['Contribute to cutting-edge robotic systems', 'Collaborate with cross-functional teams', 'Implement advanced control algorithms', 'Optimize system performance', 'Stay current with emerging technologies']\n",
            "['Help with initial robotic deployments', 'Plan roadmap, design ML systems, implement, test, monitor services']\n",
            "['Application Development', 'Collaboration', 'Mentorship', 'Establish Best Practices']\n",
            "['Build and maintain automated test infrastructure', 'Write and execute end-to-end integration scenarios', 'Collaborate with business groups and external teams', 'Partner with developers', 'Collaborate with DevOps', 'Set up test pipelines', 'Test complex data pipelines', 'Test serverless-based architecture on AWS', 'Deploy tests in AWS', 'Use Jira or qTest for tracking']\n",
            "['Design, develop, and refine prompts', 'Build scalable, automated workflows', 'Engage in thought leadership', 'Collaborate with teams to ensure alignment']\n",
            "['Execute creative software solutions', 'Develop secure high-quality code', 'Lead evaluation sessions', 'Drive awareness of new technologies']\n",
            "['Design, Develop, Troubleshoot, Architect, Analyze']\n",
            "['Build data pipelines', 'Research trading strategies', 'Enhance existing strategies', 'Create new strategies']\n",
            "['Write well designed code with automated testing', 'Operations and maintenance of Data.gov websites', 'Triage security and compliance issues', 'Migration to cloud infrastructure', 'Operate within agile scrum framework']\n",
            "['Design and implement network connectivity', 'Enhance existing components for performance', 'Collaborate with strategy teams', 'Develop components for data collection', 'Maintain applications and connections']\n",
            "['Train deep neural networks', 'Understand training data distributions', 'Develop metrics for model performance', 'Deploy trained networks on robotic system']\n",
            "['Build bioinformatics pipelines', 'Write Python/R scripts', 'Ensure pipeline flexibility', 'Implement reporting system', 'Provide documentation', 'Create web-based interfaces']\n",
            "['Workstream planning', 'Design collaboration', 'User story documentation', 'End-to-end process integration', 'Training support', 'Data cleansing direction']\n",
            "['Design, develop, and implement ML models', 'Utilize Python programming language', 'Collaborate with cross-functional teams', 'Evaluate and fine-tune models']\n",
            "['ETL Automation (~60%)', 'Front-End Dashboarding (~20%)', 'Documentation and Miscellaneous (20%)']\n",
            "['Developing low latency trading systems']\n",
            "['Work with Embedded Open-Source tools']\n",
            "['Identify gaps in AR hardware roadmap', 'Drive development of clear requirements', 'Lead prototyping vehicles engineering process', 'Communicate technology, plans effectively']\n",
            "['Functional expert for SAP Analytics Cloud (SAC)', 'Lead product team', 'Perform cost-benefit analyses', 'Collaborate with stakeholders', 'Identify cost savings initiatives', 'Automate processes', 'Drive innovative thinking', 'Lead ERP transformation project team']\n",
            "['Craft next gen SoC, CPUs', 'Provide direction for software design', 'Collaborate with hardware/software engineers', 'Research industry directions']\n",
            "['External research funding', 'Research portfolio accomplishments', 'National awards honors']\n",
            "['Prepares day-to-day and month-end close entries', 'Prepares complex reconciliations', 'Assists with month-end and year-end closing process', 'Assists in preparing working papers for external audit and tax preparation', 'Makes recommendations for improving accounting processes', 'Interacts with internal clients and responds to requests']\n",
            "['Analyze system details', 'Identify security requirements', 'Guide client through a plan of action']\n",
            "['Contribute to DevOps methodology', 'Ensure product quality and best practices', 'Drive packaging and deployment strategies', 'Interact with cross-functional teams', 'Troubleshoot applications and make enhancements']\n",
            "['Run reports to support customer meetings', \"Create PowerPoint presentations for ISR's and Field Sales\", 'Process manual orders for dealers', 'Partner with internal business partners', 'Maintain and monitor customer portals on Generac websites', 'Create and maintain process documents for team', 'Process name changes and business changes for dealers', 'Proactively monitor sales levels for dealers', 'Act as liaison between sales teams and customers', 'Enhance processes by utilizing Continuous Improvement mindset', 'Manage inbound and outbound calls and email correspondence', 'Support non-revenue generated work for sales teams']\n",
            "['Maintain annual sales plan', 'Manage customer relationships', 'Develop new customer relationships', 'Anticipate customer needs', 'Develop project proposals', 'Follow-up on proposals', 'Process orders', 'Provide customer service', 'Utilize CRM tool', 'Prepare estimates', 'Travel to job sites', 'Participate in meetings', 'Develop supplier relationships', 'Perform market research']\n",
            "['Financial Record Keeping', 'Reconciliation', 'Month-end Closing', 'Manage Quickbooks', 'Process credit applications', 'Reconcile chargebacks']\n",
            "['Developing machine learning algorithms', 'Testing algorithms on data system', 'Collaborating with research staff', 'Communicating research results']\n",
            "['Firmware development', 'DRM implementation', 'Audio/Video analysis']\n",
            "['Manage performance testing', 'Identify bottlenecks', 'Automate testing process', 'Assist cloud enablement', 'Create telemetry', 'Determine capacity testing', 'Generate dashboards']\n",
            "['C++ Developer', 'Core Windows development', 'bug fix', 'feature level work', 'debugging in C++', 'feature validations', 'issues triage', 'driving bug fixes', 'code reviews', 'handling end-to-end delivery', 'debug issues with windbg/similar debuggers', 'incident triage', 'investigation and analysis', 'scenario validation', 'building automation', 'drive regular scenario validation', 'building effective documentation', 'reporting feature development status']\n",
            "['Design experimental frameworks', 'Develop and optimize machine learning models for real-time, edge applications', 'Assess effectiveness of models', 'Stay updated on advancements in machine learning and signal processing', 'Translate research findings into actionable insights', 'Integrate machine learning models into products', 'Provide technical guidance and mentorship']\n",
            "['Create automation scripts', 'Analyze Business Requirements', 'Participate in development and testing sessions', 'Prepare test execution plan', 'Coordinate with QA team', 'Debug and fix issues', 'Automate customer scenarios']\n",
            "['One-to-one and small group instruction', 'Implement lesson plans', 'Interact positively with clients and staff', 'Manage client records']\n",
            "['Development of EDA software tools and flows', 'Support test chip layout', 'Collaborate with process technologists', 'Troubleshoot design and verification issues', 'Build Design of Experiments', 'Develop Design Rule Check software']\n",
            "['Testing', 'Software Process', 'Coding', 'Requirements Documentation/Software Project Scope']\n",
            "['Design and develop software systems for research and production processes', 'Manage CI/CD pipeline and troubleshoot issues', 'Assist in building efficient tools for data organization and visualization', 'Automate order generation and integrate compliance checks', 'Build desktop UI tools for portfolio monitoring']\n",
            "['Algorithm analysis', 'Performance analysis', 'Architecture definition', 'Map Data Center workloads', 'Perform detailed calculations', 'Drive architecture definition', 'Identify appropriate workloads', 'Evangelize architectural solutions', 'Collaborate with cross functional teams']\n",
            "['Deep learning engineering', 'NLP/LLM processing', 'PySpark/Databricks programming', 'Model deployment', 'Backend application building', 'Vector databases knowledge', 'Transformers experience', 'Cloud computing']\n",
            "['Consult with customers to identify appropriate Google data management solutions', 'Work with Product Management teams to assist market adoption and solution alignment with enterprise customer requirements', 'Manage Databases workloads within assigned solutions and region', \"Lead field teams and Databases counterparts to drive demand, accelerate execution, and bring real digital transformation through Google's Databases Platform\", 'Scale capability, execution, and experience through Product, Engineering, and Partner teams, and drive customer success through prescriptive activation of internal and external teams']\n",
            "['N/A']\n",
            "['Lead Software Engineer', 'Research fundamental problems', 'Implement algorithm solutions', 'Participate in project leadership', 'Contribute to advanced technical research', 'Provide reliable solutions']\n",
            "['Developing test strategies', 'Creating test harnesses', 'Providing test infrastructure', 'Coordinating with offshore team', 'Developing test plans']\n",
            "['Creative software solutions', 'Technical troubleshooting', 'Production code development', 'Evaluation sessions', 'Maintenance automation']\n",
            "['Guide engineering teams in multi-discipline approach', 'Requirements engineering', 'Solutions engineering', 'Integration', 'Test and evaluation', 'Maintainability analysis']\n",
            "['Develop edge-computing stack', 'Deploy machine learning models', 'Optimize platform performance', 'Build edge applications']\n",
            "['Evaluate AI-generated code', 'Solve coding problems', 'Optimize code efficiency', 'Write robust test cases']\n",
            "['Initial defect analysis - Triage defects - Monitor defect dashboard - Create reports - Work with cross-functional teams - Drive defect triage calls']\n",
            "['Develop software for data processing', 'Contribute to scientific code development', 'Research scientific reference material', 'Document software specifications', 'Support Business Development activities']\n",
            "['Research and apply large-scale models', 'Optimize enterprise applications', 'Implement relevant applications', 'Collaborate with cross-functional teams', 'Research and explore usage scenarios']\n",
            "['Develop software for earth observation data', 'Contribute to scientific processing code', 'Research scientific reference material', 'Document software specifications', 'Refine aerospace/scientific software', 'Collaborate with a dynamic team', 'Support Business Development activities']\n",
            "['Research and Development', 'Taking Initiative on Projects']\n",
            "['Python, Linux, C/C++, Shell Scripting', 'Optimizing and integrating AI model', 'Leading small team']\n",
            "['Provide academic support through tutoring', 'Maintain accurate tutoring records', 'Communicate effectively with faculty']\n",
            "['Maintain marketing and servicing websites', 'Implement customer opt-out choices', 'Collaborate with stakeholders', 'Enforce compliance with regulations']\n",
            "['SEO strategies', 'Content creation', 'Collaboration with teams', 'Keyword research', 'Content calendar management', 'Performance analysis']\n",
            "['Maintain clean, safe space', 'Respond to needs/questions', 'Handle emergencies', 'Work with staff/volunteers/interns', 'Passion for local agriculture']\n",
            "['Write research code', 'Publish research papers', 'Design experiments']\n",
            "['Drive customer engagements', 'Guide account executives', 'Provide feedback on market trends', 'Identify new business opportunities', 'Interact with technical decision makers', 'Facilitate financial analyses']\n",
            "['Lead, collaborate, execute innovative AI research projects', 'Identify new directions, formulate objectives aligned with mission', 'Contribute to development of advanced ML models, algorithms, datasets', 'Collaborate with diverse team, foster open communication, shared learning', 'Engage in interdisciplinary research efforts for high-impact outcomes', 'Publish in top-tier conferences, journals, communicate research findings', 'Create demos/systems to highlight AI innovations, foster collaboration', 'Contribute to mentoring junior team members, foster growth']\n",
            "['Collaborate with cross-functional teams for AI-based product development', 'Design and develop software solutions using AI technologies', 'Implement algorithms, models, and data pipelines for decision-making and automation', 'Optimize and improve existing AI systems and algorithms', 'Conduct testing and debugging of software components', 'Stay up-to-date with advancements in AI technologies', 'Collaborate with stakeholders for feedback on software solutions', 'Document software designs, processes, and technical specifications']\n",
            "['Lead complex software engineering projects', 'Develop and maintain code', 'Integrate software components', 'Create and test procedures', 'Document deployed processes', 'Troubleshoot software issues']\n",
            "['Client strategy design', 'Solution definition', 'Educational support', 'Credibility building']\n",
            "['software design and development on complex, tactical geophysical systems', 'code and unit testing', 'troubleshooting', 'guidance and/or execution on corrective actions', 'recommendations for design enhancement', 'support integration and test actions']\n",
            "['Requirement gathering and documentation', 'Enterprise architecture focus on AI models', 'Model-based development review', 'Data synchronization principles', 'ServiceNow familiarity']\n",
            "['Participant communication', 'Data management', 'Research materials preparation']\n",
            "['Innovate new ways', 'Solve problems', 'Research and solve', 'Provide customer service']\n",
            "['Design data pipelines', 'Develop data quality metrics', 'Communicate project status', 'Collaborate with business', 'Analyzing data integration problems']\n",
            "['Designing and maintaining software services', 'Integration of architectural development', 'Set directions on hardware/software platforms', 'Design and develop GenAI use case model pipeline', 'Interact with industry, standards, suppliers']\n",
            "['Unity development', 'XR application development', 'ARCore', 'ARFoundation', 'OpenXR libraries', 'UX design', 'Programming languages']\n",
            "['Interact web services/APIs', 'Design chatbot structure', 'Implement NLP techniques', 'Train/deploy AI models', 'Analyze chatbot data', 'Comply with data privacy', 'Collaborate with teams', 'Technical writing', 'Initiate proof of concept']\n",
            "['Create and deploy campaigns', 'Analyze campaigns', 'Manage paid search campaigns', 'Communicate with clients and stakeholders', 'Marketing efforts']\n",
            "['Technical Sales management', 'Relationship development', 'Technical proposals development', 'Customer discussions', 'RFQs and RFIs support', 'Forecasting reports generation', 'Product development input', 'Trade shows attendance', 'Interaction with factory management']\n",
            "['Technical Pre-Sales Support', 'Trial Support', 'Post-Sales Technical Support', 'Data Dispute Resolution']\n",
            "['Technical leadership on team building and maintaining services for data science and ML at Klaviyo', 'Develop tools for training, testing, serving, and monitoring models']\n",
            "['Build, install, configure, manage, scale ML platform', 'Implement scalable ML/DL solutions', 'Create & maintain ML/DL pipelines', 'Address performance, scalability, governance of ML models', 'Stay updated on latest ML/DL technologies']\n",
            "['Conduct research on advanced techniques', 'Collaborate with stakeholders', 'Implement strategies for alignment', 'Gather requirements for modeling techniques']\n",
            "['Domain expert in RTML serving technology', 'Define technical strategy and architecture', 'Lead development activities', 'Support internal customers', 'Mentor junior developers', 'Adhere to industry standards']\n",
            "['N/A']\n",
            "['Define architecture and build infrastructure for ML solutions', 'Integrate best practices from ML research into systems', 'Create data preprocessing pipelines', 'Implement CI/CD pipelines for ML model deployment', 'Optimize and scale systems', 'Monitor and analyze system health', 'Identify and solve issues for uninterrupted service']\n",
            "['Develop software for large datasets']\n",
            "['Transportation of passengers', 'Dispatching', 'Scheduling', 'Pre-trip inspections', 'Record maintenance', 'Professional communication']\n",
            "['Trains on specific laboratory aspects', 'Assures lab staff has kits accessible', 'Timely packing and shipping of lab samples', 'Maintains patient data files', 'Collects patient data', 'Assists with scheduling appointments', 'Prepares patient records for audits', 'Maintains supplies for clinical research', 'May assist with direct patient care']\n",
            "['Solution Development - Hands-on Prototyping - Strategy - Collaboration - Mentoring']\n",
            "['Develop, design, test software of embedded devices/systems', 'Monitor, enhance system efficiency/stability', 'Gather/analyze user requirements', 'Implement source codes', 'Test/debug system software', 'Collaborate with other teams', 'Design/Document Cybersecurity features', 'Validate Cybersecurity features', 'Identify Cybersecurity risks']\n",
            "['Partner with research, product, and design', 'Design and build front-end systems', 'Create inclusive culture', 'Plan and deploy infrastructure']\n",
            "['Developing Microservices', 'Utilizing Python, AWS, Gitlab', 'CICD, REST APIs, Kubernetes', 'Docker, Messaging Tools (Kafka, Redis)']\n",
            "['Troubleshooting software-centric electromechanical vehicle systems', 'Software design, coding, testing, debugging', 'Collaborating with Customer Support, Engineering, Manufacturing']\n",
            "['Optimize and fine-tune existing training and inference platform', 'Collaborate with cross-functional teams', 'Develop own ideas to optimize platforms', 'Stay up-to-date with latest advancements in ML systems']\n",
            "['Design, architect, and build AI functionality', 'Use large language model APIs', 'Participate in AI technical process standards', 'Build machine learning models', 'Participate in team building activities', 'Encourage and mentor Open Source contributors', 'Represent OEF at standards discussions']\n",
            "['Developing software for finance industry']\n",
            "['Design, develop, maintain NWP workflow features', 'Follow software best practices', 'Create documentation for software']\n",
            "['Drive security tests', 'Perform vulnerability assessments', 'Assist with security automation', 'Coordinate findings with leadership']\n",
            "['Collaborating multidisciplinary teams', 'Implementing AI solutions', 'Designing, developing AI algorithms', 'Ensuring software reliability', 'Documenting code and processes', 'Expressing AI dedication']\n",
            "['Build awareness-increase knowledge-drive adoption-operate as trusted advisor-lead talent development-collaborate on key innovation initiatives']\n",
            "['Engage with customers', 'Demonstrate proof of concept', 'Define technical specifications', 'Create technical content', 'Represent QES with business development']\n",
            "['Holography and Laser Beam Optimization', 'Algorithm Development', 'Experimental Support and Data Analysis']\n",
            "['Problem identification', 'Formulation', 'Hypotheses', 'Publishing results', 'Collaboration']\n",
            "['Designing qubit devices for error rates, qubit physics modeling, communication with team']\n",
            "['Guide development with C++', 'Analyze legacy systems', 'Design scalable software components', 'Lead modernization initiatives', 'Collaborate with cross-functional teams', 'Provide technical guidance', 'Create architecture documentation', 'Drive system performance tuning', 'Develop algorithms for parallel computation']\n",
            "['Work alongside BE Engineers', 'Build machine learning models', 'Utilize computer vision technology', 'Report directly into the Head of Artificial Intelligence']\n",
            "['Standard software solutions execution', 'Collaboration with Quant Researchers and Business Users', 'Coding in python and React/Java Script', 'Gaining exposure to Pricing, Risk, and Trade Management functions']\n",
            "['Technical Leadership - Backend infrastructure design, development, maintenance', 'Scalability - Architect and implement scalable solutions', 'Integration - Collaborate with teams and services for integration', 'Performance Optimization - Monitor system performance, identify bottlenecks', 'Data Management - Data storage, retrieval, indexing strategies', 'Security - Implement security measures', 'Automation - Develop and maintain automated processes', 'Collaboration - Work with other teams for seamless communication', 'Mentorship - Provide technical guidance and mentorship', 'Problem Solving - Identify challenges, propose solutions']\n",
            "['Translating trading strategies', 'Design, code, build and test algorithms', 'Troubleshooting and debugging programs', 'Collaborating with team members', 'Analyzing user feedback and making adjustments', 'Recommending and executing program improvements']\n",
            "['Develops reusable architectures and designs for kernel software', 'Subject matter expert for kernel internals', 'Organizes backlog for time-phasing', 'Participates in daily scrums']\n",
            "['Develop text processing models', 'Design ML models at scale', 'Collaborate with MLOps team']\n"
          ]
        }
      ],
      "source": [
        "for i in df['responsibilities']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtN4-aKNYZnZ",
        "outputId": "8011943c-aa41-418b-b69e-f10f56ee7880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "2\n",
            "3\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "2\n",
            "2\n",
            "3\n",
            "2\n",
            "1\n",
            "3\n",
            "2\n",
            "3\n",
            "2\n",
            "3\n",
            "1\n",
            "3\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "3\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "3\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "2\n",
            "1\n",
            "2\n",
            "3\n",
            "2\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "3\n",
            "2\n",
            "3\n",
            "2\n",
            "1\n",
            "2\n",
            "3\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "3\n",
            "0\n",
            "2\n",
            "1\n",
            "3\n",
            "2\n",
            "3\n",
            "2\n",
            "2\n",
            "3\n",
            "2\n",
            "0\n",
            "0\n",
            "2\n",
            "2\n",
            "3\n",
            "2\n",
            "2\n",
            "3\n",
            "2\n",
            "2\n",
            "3\n",
            "1\n",
            "3\n",
            "2\n",
            "3\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "2\n",
            "3\n",
            "2\n",
            "2\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "for i in df['rating']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OxV8UEnYqTD"
      },
      "source": [
        "Just thinking about it now and I am fearing that the pre-trained 17GB Word2Vec model I downloaded earlier probably won't work and we may need to fit one to our training data set, which will come from their corresponding text files concatenated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mZMku-EG081"
      },
      "source": [
        "We'll embark on gathering all the code we've written to get our dataframe data in the desired format. We will gather all columns from the original JSON file but then we will create new columns for city, state, country, min_salary and max_salary. After that we will either represent each unique phrase as a unique number or better yet shrink the feature space to categories of similar enough phrases using some kind of clustering or grouping algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP3KbtqFGyIm",
        "outputId": "f08883f7-c722-4fe8-f0f4-2e993f99b4af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n"
          ]
        }
      ],
      "source": [
        "json_files_path = \"drive/MyDrive/LI-Jobs-JSON/\"\n",
        "links_csv_path = \"drive/MyDrive/successfulLinksGDRIVE.csv\"\n",
        "\n",
        "import pandas as pd\n",
        "links_dataframe = pd.read_csv(links_csv_path, header=None, names=['url', 'rating'])\n",
        "#links_dataframe.head()\n",
        "#print(links_dataframe.loc[0, 'rating'])\n",
        "\n",
        "# let's snakecase our column names to avoid having spaces in them\n",
        "# also we add a rating column at the end of the list to store the target variable\n",
        "df_columns = [\"employment_type\", \"job_function\", \"description_of_product/service\", \"industries\",\n",
        "              \"position_name\", \"broader_role_name\", \"company\", #\"location\", \"salary/compensation_range\",\n",
        "              \"responsibilities\", \"goals/objectives\", \"name_of_department/team\", \"required_qualifications\",\n",
        "              \"preferred_qualifications\", \"benefits\", \"work_arrangement\", \"city\", \"state\", \"country\",\n",
        "              \"min_salary\", \"max_salary\", \"rating\"]\n",
        "# Initialize DataFrame with column names\n",
        "df = pd.DataFrame(columns=df_columns)\n",
        "\n",
        "import os\n",
        "import json\n",
        "locale_json_files_path = \"drive/MyDrive/jobLocations/\"\n",
        "salary_json_files_path = \"drive/MyDrive/jobSalaries/\"\n",
        "\n",
        "for i in range(1, 108):\n",
        "  row_num = df.last_valid_index()\n",
        "  print(row_num)\n",
        "  if row_num == None:\n",
        "    row_num = 0\n",
        "  else:\n",
        "    row_num = row_num + 1\n",
        "  assert i == row_num + 1\n",
        "  json_file_path = os.path.join(json_files_path, f'row{i}.json')\n",
        "  # Read JSON file\n",
        "  with open(json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  if 'fields' in json_data.keys():\n",
        "    #print(json_data)\n",
        "    field_names = json_data['fields']\n",
        "    for index, value in enumerate(field_names):\n",
        "      info = json_data['info'][index]\n",
        "      # Check if the value exists as a column name (ignoring case)\n",
        "      column_name = value.replace(\" \", \"_\").lower()\n",
        "      if column_name in df.columns:\n",
        "        # Add the info to the corresponding column and row\n",
        "        df.at[row_num, column_name] = info\n",
        "  else:\n",
        "    for key, value in json_data.items():\n",
        "      # Check if the key exists as a column name (ignoring case)\n",
        "      column_name = key.replace(\" \", \"_\").lower()\n",
        "      if column_name == 'emploment_type':\n",
        "        column_name = 'employment_type'\n",
        "      if column_name in df.columns:\n",
        "        # Add the value to the corresponding column and row\n",
        "        df.at[row_num, column_name] = value\n",
        "\n",
        "  locale_json_file_path = os.path.join(locale_json_files_path, f'row{i}.json')\n",
        "  salary_json_file_path = os.path.join(salary_json_files_path, f'row{i}.json')\n",
        "  # Read locale JSON file\n",
        "  with open(locale_json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  try:\n",
        "    city = json_data[\"city\"]\n",
        "    state = json_data[\"state\"]\n",
        "    country = json_data[\"country\"]\n",
        "    df.at[row_num, 'city'] = city\n",
        "    df.at[row_num, 'state'] = state\n",
        "    df.at[row_num, 'country'] = country\n",
        "  except:\n",
        "    df.at[row_num, 'city'] = \"N/A\"\n",
        "    df.at[row_num, 'state'] = \"N/A\"\n",
        "    df.at[row_num, 'country'] = \"N/A\"\n",
        "  # Read salary JSON file\n",
        "  with open(salary_json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  min_salary = json_data[\"salary_min\"]\n",
        "  max_salary = json_data[\"salary_max\"]\n",
        "  df.at[row_num, 'min_salary'] = min_salary\n",
        "  df.at[row_num, 'max_salary'] = max_salary\n",
        "  rating = links_dataframe.loc[row_num, 'rating']\n",
        "  df.at[row_num, 'rating'] = rating\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "g9Ddk0hQPqR1",
        "outputId": "c7e9093b-37e6-4def-d423-4abf4deb3459"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 107,\n  \"fields\": [\n    {\n      \"column\": \"employment_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job_function\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description_of_product/service\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"industries\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"position_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"broader_role_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"company\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"responsibilities\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"goals/objectives\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name_of_department/team\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"required_qualifications\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preferred_qualifications\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"benefits\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"work_arrangement\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 67,\n        \"samples\": [\n          \"Sunnyvale\",\n          \"Boulder\",\n          \"Dallas-Fort Worth\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"VA\",\n          \"FL\",\n          \"WA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"United States\",\n          \"N/A\",\n          \"USA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_salary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          70,\n          181.145,\n          170\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_salary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          100,\n          288,\n          93.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"0\",\n        \"max\": \"3\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2\",\n          \"0\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d32a5027-942e-4fe7-b016-3f6790dda35f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>employment_type</th>\n",
              "      <th>job_function</th>\n",
              "      <th>description_of_product/service</th>\n",
              "      <th>industries</th>\n",
              "      <th>position_name</th>\n",
              "      <th>broader_role_name</th>\n",
              "      <th>company</th>\n",
              "      <th>responsibilities</th>\n",
              "      <th>goals/objectives</th>\n",
              "      <th>name_of_department/team</th>\n",
              "      <th>required_qualifications</th>\n",
              "      <th>preferred_qualifications</th>\n",
              "      <th>benefits</th>\n",
              "      <th>work_arrangement</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "      <th>min_salary</th>\n",
              "      <th>max_salary</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[design-led software development, end-to-end d...</td>\n",
              "      <td>[Business Consulting, Services]</td>\n",
              "      <td>[Python Software Engineer (Robotics/Mechatroni...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Fresh Consulting]</td>\n",
              "      <td>[integrate software/hardware components, devel...</td>\n",
              "      <td>[manage delivery of high-quality work]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[0-1+ years experience, Python skills, program...</td>\n",
              "      <td>[clear communication, outside the box thinking...</td>\n",
              "      <td>[100% Medical, PTO, Holiday Pay, 401K Plan]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>Redmond</td>\n",
              "      <td>WA</td>\n",
              "      <td>USA</td>\n",
              "      <td>62.4</td>\n",
              "      <td>93.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Design, Art/Creative, Information Technology]</td>\n",
              "      <td>[Surgical Robotics Systems]</td>\n",
              "      <td>[Biotechnology Research, Pharmaceutical Manufa...</td>\n",
              "      <td>[Robotics Engineer]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Barrington James]</td>\n",
              "      <td>[Contribute to cutting-edge robotic systems, C...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Bachelor's, Master's, or Ph.D. in Robotics, M...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>New York</td>\n",
              "      <td></td>\n",
              "      <td>United States</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Information Technology, Consulting, Engineering]</td>\n",
              "      <td>[Amazon Robotics builds high-performance, real...</td>\n",
              "      <td>[Software Development, IT Services, IT Consult...</td>\n",
              "      <td>[SDE - Amazon Robotics]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Amazon]</td>\n",
              "      <td>[Help with initial robotic deployments, Plan r...</td>\n",
              "      <td>[Build high-performance robotic systems, Inven...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[3+ years professional software development ex...</td>\n",
              "      <td>[3+ years full software development life cycle...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>North Reading</td>\n",
              "      <td>MA</td>\n",
              "      <td>USA</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[Credit scoring models]</td>\n",
              "      <td>[Financial Services, Capital Markets, IT Servi...</td>\n",
              "      <td>[Senior Software Engineer]</td>\n",
              "      <td>[Software Engineer]</td>\n",
              "      <td>[VantageScore®]</td>\n",
              "      <td>[Application Development, Collaboration, Mento...</td>\n",
              "      <td>[Building public APIs]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Bachelor's degree, Master's degree, Computer ...</td>\n",
              "      <td>[Quantitative applications, Fintech experience...</td>\n",
              "      <td>[401(K) match, Flexible Time Off, 12 Paid Holi...</td>\n",
              "      <td>[Hybrid]</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>CA</td>\n",
              "      <td>USA</td>\n",
              "      <td>150</td>\n",
              "      <td>200</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Quality Assurance, Information T...</td>\n",
              "      <td>[Large-scale distributed software applications...</td>\n",
              "      <td>[IT Services, IT Consulting]</td>\n",
              "      <td>[Software Engineer in Test]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Optomi]</td>\n",
              "      <td>[Build and maintain automated test infrastruct...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[5+ years of test automation experience, Profi...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>Dallas-Fort Worth</td>\n",
              "      <td>TX</td>\n",
              "      <td>USA</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d32a5027-942e-4fe7-b016-3f6790dda35f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d32a5027-942e-4fe7-b016-3f6790dda35f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d32a5027-942e-4fe7-b016-3f6790dda35f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-85301a32-3ab2-4c5d-8fbd-4ad916f70274\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-85301a32-3ab2-4c5d-8fbd-4ad916f70274')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-85301a32-3ab2-4c5d-8fbd-4ad916f70274 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  employment_type                                       job_function  \\\n",
              "0     [Full-time]              [Engineering, Information Technology]   \n",
              "1     [Full-time]     [Design, Art/Creative, Information Technology]   \n",
              "2     [Full-time]  [Information Technology, Consulting, Engineering]   \n",
              "3     [Full-time]              [Engineering, Information Technology]   \n",
              "4     [Full-time]  [Engineering, Quality Assurance, Information T...   \n",
              "\n",
              "                      description_of_product/service  \\\n",
              "0  [design-led software development, end-to-end d...   \n",
              "1                        [Surgical Robotics Systems]   \n",
              "2  [Amazon Robotics builds high-performance, real...   \n",
              "3                            [Credit scoring models]   \n",
              "4  [Large-scale distributed software applications...   \n",
              "\n",
              "                                          industries  \\\n",
              "0                    [Business Consulting, Services]   \n",
              "1  [Biotechnology Research, Pharmaceutical Manufa...   \n",
              "2  [Software Development, IT Services, IT Consult...   \n",
              "3  [Financial Services, Capital Markets, IT Servi...   \n",
              "4                       [IT Services, IT Consulting]   \n",
              "\n",
              "                                       position_name    broader_role_name  \\\n",
              "0  [Python Software Engineer (Robotics/Mechatroni...                [N/A]   \n",
              "1                                [Robotics Engineer]                [N/A]   \n",
              "2                            [SDE - Amazon Robotics]                [N/A]   \n",
              "3                         [Senior Software Engineer]  [Software Engineer]   \n",
              "4                        [Software Engineer in Test]                [N/A]   \n",
              "\n",
              "              company                                   responsibilities  \\\n",
              "0  [Fresh Consulting]  [integrate software/hardware components, devel...   \n",
              "1  [Barrington James]  [Contribute to cutting-edge robotic systems, C...   \n",
              "2            [Amazon]  [Help with initial robotic deployments, Plan r...   \n",
              "3     [VantageScore®]  [Application Development, Collaboration, Mento...   \n",
              "4            [Optomi]  [Build and maintain automated test infrastruct...   \n",
              "\n",
              "                                    goals/objectives name_of_department/team  \\\n",
              "0             [manage delivery of high-quality work]                   [N/A]   \n",
              "1                                                NaN                     NaN   \n",
              "2  [Build high-performance robotic systems, Inven...                   [N/A]   \n",
              "3                             [Building public APIs]                   [N/A]   \n",
              "4                                              [N/A]                   [N/A]   \n",
              "\n",
              "                             required_qualifications  \\\n",
              "0  [0-1+ years experience, Python skills, program...   \n",
              "1  [Bachelor's, Master's, or Ph.D. in Robotics, M...   \n",
              "2  [3+ years professional software development ex...   \n",
              "3  [Bachelor's degree, Master's degree, Computer ...   \n",
              "4  [5+ years of test automation experience, Profi...   \n",
              "\n",
              "                            preferred_qualifications  \\\n",
              "0  [clear communication, outside the box thinking...   \n",
              "1                                              [N/A]   \n",
              "2  [3+ years full software development life cycle...   \n",
              "3  [Quantitative applications, Fintech experience...   \n",
              "4                                              [N/A]   \n",
              "\n",
              "                                            benefits work_arrangement  \\\n",
              "0        [100% Medical, PTO, Holiday Pay, 401K Plan]            [N/A]   \n",
              "1                                              [N/A]            [N/A]   \n",
              "2                                              [N/A]        [On-site]   \n",
              "3  [401(K) match, Flexible Time Off, 12 Paid Holi...         [Hybrid]   \n",
              "4                                              [N/A]        [On-site]   \n",
              "\n",
              "                city state        country min_salary max_salary rating  \n",
              "0            Redmond    WA            USA       62.4       93.6      1  \n",
              "1           New York        United States        N/A        N/A      2  \n",
              "2      North Reading    MA            USA        N/A        N/A      2  \n",
              "3      San Francisco    CA            USA        150        200      3  \n",
              "4  Dallas-Fort Worth    TX            USA        N/A        N/A      1  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r3ul6MSZtWD"
      },
      "source": [
        "In the non-special columns (not location or salary columns, and possibly not 'employment_type'), we want to iterate over all the elements of the dataframe and split each string in order to get a list of words, and then we will need further logic to fully clean those lists of words so that they do not contain any special characters like ! or ? or / or -. Before we do this we should replace any instances of [\"N/A\"] or \"N/A\" in our dataframe with NaN.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjDauA90yJ9Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Replace 'N/A' with NaN in the whole DataFrame\n",
        "df.replace('N/A', np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "IOD42G4HJ0Rp",
        "outputId": "56fab396-27c3-4a81-b92a-b8c50e00a54b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 107,\n  \"fields\": [\n    {\n      \"column\": \"employment_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job_function\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description_of_product/service\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"industries\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"position_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"broader_role_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"company\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"responsibilities\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"goals/objectives\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name_of_department/team\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"required_qualifications\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preferred_qualifications\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"benefits\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"work_arrangement\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 66,\n        \"samples\": [\n          \"San Antonio\",\n          \"Santa Rosa\",\n          \"Redmond\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"VA\",\n          \"FL\",\n          \"WA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"USA\",\n          \"United States\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.0285584779617,\n        \"min\": 58.3,\n        \"max\": 245.0,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          170.0,\n          175.0,\n          62.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 78.08504978928872,\n        \"min\": 90.0,\n        \"max\": 414.0,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          236.0,\n          170.0,\n          93.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5e598a34-3c13-4026-8f10-b4d9457b63de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>employment_type</th>\n",
              "      <th>job_function</th>\n",
              "      <th>description_of_product/service</th>\n",
              "      <th>industries</th>\n",
              "      <th>position_name</th>\n",
              "      <th>broader_role_name</th>\n",
              "      <th>company</th>\n",
              "      <th>responsibilities</th>\n",
              "      <th>goals/objectives</th>\n",
              "      <th>name_of_department/team</th>\n",
              "      <th>required_qualifications</th>\n",
              "      <th>preferred_qualifications</th>\n",
              "      <th>benefits</th>\n",
              "      <th>work_arrangement</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "      <th>min_salary</th>\n",
              "      <th>max_salary</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[design-led software development, end-to-end d...</td>\n",
              "      <td>[Business Consulting, Services]</td>\n",
              "      <td>[Python Software Engineer (Robotics/Mechatroni...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Fresh Consulting]</td>\n",
              "      <td>[integrate software/hardware components, devel...</td>\n",
              "      <td>[manage delivery of high-quality work]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[0-1+ years experience, Python skills, program...</td>\n",
              "      <td>[clear communication, outside the box thinking...</td>\n",
              "      <td>[100% Medical, PTO, Holiday Pay, 401K Plan]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>Redmond</td>\n",
              "      <td>WA</td>\n",
              "      <td>USA</td>\n",
              "      <td>62.4</td>\n",
              "      <td>93.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Design, Art/Creative, Information Technology]</td>\n",
              "      <td>[Surgical Robotics Systems]</td>\n",
              "      <td>[Biotechnology Research, Pharmaceutical Manufa...</td>\n",
              "      <td>[Robotics Engineer]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Barrington James]</td>\n",
              "      <td>[Contribute to cutting-edge robotic systems, C...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Bachelor's, Master's, or Ph.D. in Robotics, M...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>New York</td>\n",
              "      <td></td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Information Technology, Consulting, Engineering]</td>\n",
              "      <td>[Amazon Robotics builds high-performance, real...</td>\n",
              "      <td>[Software Development, IT Services, IT Consult...</td>\n",
              "      <td>[SDE - Amazon Robotics]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Amazon]</td>\n",
              "      <td>[Help with initial robotic deployments, Plan r...</td>\n",
              "      <td>[Build high-performance robotic systems, Inven...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[3+ years professional software development ex...</td>\n",
              "      <td>[3+ years full software development life cycle...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>North Reading</td>\n",
              "      <td>MA</td>\n",
              "      <td>USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[Credit scoring models]</td>\n",
              "      <td>[Financial Services, Capital Markets, IT Servi...</td>\n",
              "      <td>[Senior Software Engineer]</td>\n",
              "      <td>[Software Engineer]</td>\n",
              "      <td>[VantageScore®]</td>\n",
              "      <td>[Application Development, Collaboration, Mento...</td>\n",
              "      <td>[Building public APIs]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Bachelor's degree, Master's degree, Computer ...</td>\n",
              "      <td>[Quantitative applications, Fintech experience...</td>\n",
              "      <td>[401(K) match, Flexible Time Off, 12 Paid Holi...</td>\n",
              "      <td>[Hybrid]</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>CA</td>\n",
              "      <td>USA</td>\n",
              "      <td>150.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Quality Assurance, Information T...</td>\n",
              "      <td>[Large-scale distributed software applications...</td>\n",
              "      <td>[IT Services, IT Consulting]</td>\n",
              "      <td>[Software Engineer in Test]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Optomi]</td>\n",
              "      <td>[Build and maintain automated test infrastruct...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[5+ years of test automation experience, Profi...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>Dallas-Fort Worth</td>\n",
              "      <td>TX</td>\n",
              "      <td>USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e598a34-3c13-4026-8f10-b4d9457b63de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e598a34-3c13-4026-8f10-b4d9457b63de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e598a34-3c13-4026-8f10-b4d9457b63de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ac440982-73b4-431f-8026-86e1e523dec2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ac440982-73b4-431f-8026-86e1e523dec2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ac440982-73b4-431f-8026-86e1e523dec2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  employment_type                                       job_function  \\\n",
              "0     [Full-time]              [Engineering, Information Technology]   \n",
              "1     [Full-time]     [Design, Art/Creative, Information Technology]   \n",
              "2     [Full-time]  [Information Technology, Consulting, Engineering]   \n",
              "3     [Full-time]              [Engineering, Information Technology]   \n",
              "4     [Full-time]  [Engineering, Quality Assurance, Information T...   \n",
              "\n",
              "                      description_of_product/service  \\\n",
              "0  [design-led software development, end-to-end d...   \n",
              "1                        [Surgical Robotics Systems]   \n",
              "2  [Amazon Robotics builds high-performance, real...   \n",
              "3                            [Credit scoring models]   \n",
              "4  [Large-scale distributed software applications...   \n",
              "\n",
              "                                          industries  \\\n",
              "0                    [Business Consulting, Services]   \n",
              "1  [Biotechnology Research, Pharmaceutical Manufa...   \n",
              "2  [Software Development, IT Services, IT Consult...   \n",
              "3  [Financial Services, Capital Markets, IT Servi...   \n",
              "4                       [IT Services, IT Consulting]   \n",
              "\n",
              "                                       position_name    broader_role_name  \\\n",
              "0  [Python Software Engineer (Robotics/Mechatroni...                [N/A]   \n",
              "1                                [Robotics Engineer]                [N/A]   \n",
              "2                            [SDE - Amazon Robotics]                [N/A]   \n",
              "3                         [Senior Software Engineer]  [Software Engineer]   \n",
              "4                        [Software Engineer in Test]                [N/A]   \n",
              "\n",
              "              company                                   responsibilities  \\\n",
              "0  [Fresh Consulting]  [integrate software/hardware components, devel...   \n",
              "1  [Barrington James]  [Contribute to cutting-edge robotic systems, C...   \n",
              "2            [Amazon]  [Help with initial robotic deployments, Plan r...   \n",
              "3     [VantageScore®]  [Application Development, Collaboration, Mento...   \n",
              "4            [Optomi]  [Build and maintain automated test infrastruct...   \n",
              "\n",
              "                                    goals/objectives name_of_department/team  \\\n",
              "0             [manage delivery of high-quality work]                   [N/A]   \n",
              "1                                                NaN                     NaN   \n",
              "2  [Build high-performance robotic systems, Inven...                   [N/A]   \n",
              "3                             [Building public APIs]                   [N/A]   \n",
              "4                                              [N/A]                   [N/A]   \n",
              "\n",
              "                             required_qualifications  \\\n",
              "0  [0-1+ years experience, Python skills, program...   \n",
              "1  [Bachelor's, Master's, or Ph.D. in Robotics, M...   \n",
              "2  [3+ years professional software development ex...   \n",
              "3  [Bachelor's degree, Master's degree, Computer ...   \n",
              "4  [5+ years of test automation experience, Profi...   \n",
              "\n",
              "                            preferred_qualifications  \\\n",
              "0  [clear communication, outside the box thinking...   \n",
              "1                                              [N/A]   \n",
              "2  [3+ years full software development life cycle...   \n",
              "3  [Quantitative applications, Fintech experience...   \n",
              "4                                              [N/A]   \n",
              "\n",
              "                                            benefits work_arrangement  \\\n",
              "0        [100% Medical, PTO, Holiday Pay, 401K Plan]            [N/A]   \n",
              "1                                              [N/A]            [N/A]   \n",
              "2                                              [N/A]        [On-site]   \n",
              "3  [401(K) match, Flexible Time Off, 12 Paid Holi...         [Hybrid]   \n",
              "4                                              [N/A]        [On-site]   \n",
              "\n",
              "                city state        country  min_salary  max_salary  rating  \n",
              "0            Redmond    WA            USA        62.4        93.6       1  \n",
              "1           New York        United States         NaN         NaN       2  \n",
              "2      North Reading    MA            USA         NaN         NaN       2  \n",
              "3      San Francisco    CA            USA       150.0       200.0       3  \n",
              "4  Dallas-Fort Worth    TX            USA         NaN         NaN       1  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb4Q3EEGKvw_"
      },
      "source": [
        "The time has come for us to write a loop that goes through all dataframe values that are lists and spits out the words for each individual phrase string as a list. Thus we want to convert the lists of phrases to a list of lists of words. We want to do this so we can then run some kind of algorithm that bins like phrases into groups, using logic to ejudicate likeness of phrases by trying to find a corresponding mate for each word in one of the phrases with one from the other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAXA3QLCL49n"
      },
      "outputs": [],
      "source": [
        "value = df.at[0, 'responsibilities']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQAWtAM4MVoi",
        "outputId": "cc37d9e3-b3d5-4856-b7fb-d6750b0809f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['integrate software/hardware components', 'develop UI front-end', 'investigate defects', 'be active team player', 'learn new systems/tools', 'document code quality', 'work on python applications']\n"
          ]
        }
      ],
      "source": [
        "print(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs5menVnMZ8T",
        "outputId": "65df6d18-edcc-4d46-deef-cda7cc26d918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "7\n",
            "[['integrate', 'software/hardware', 'components'], ['develop', 'UI', 'front-end'], ['investigate', 'defects'], ['be', 'active', 'team', 'player'], ['learn', 'new', 'systems/tools'], ['document', 'code', 'quality'], ['work', 'on', 'python', 'applications']]\n"
          ]
        }
      ],
      "source": [
        "print(type(value))\n",
        "print(len(value))\n",
        "value_converted = []\n",
        "for i in value:\n",
        "  value_converted.append(i.split(' '))\n",
        "print(value_converted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr5oNk5vM0MD"
      },
      "source": [
        "Now we need some code that does a lookup of the word in whatever registry we are using to encode or embed our words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPIPbv01NHpN"
      },
      "outputs": [],
      "source": [
        "''' the following is pseudo code, bc we are hoping to be able to use a pre-trained model as a word registry,\n",
        "but if we are not then we are going to need code where we operate on each element in order to generate our registry,\n",
        "which is not ideal'''\n",
        "value_converted_numeric = []\n",
        "for i in value_converted:\n",
        "  phrase_numeric_list = []\n",
        "  for j in i:\n",
        "    if j in registry:\n",
        "      embdg = registry[j]\n",
        "      phrase_numeric_list.append(embdg)\n",
        "    else:\n",
        "      j = j.replace('/', ' ')\n",
        "      j = j.replace('-', ' ')\n",
        "      j = j.replace(',', '')\n",
        "      j_split = j.split(' ')\n",
        "      if len(j_split) > 1:\n",
        "        for i in j_split:\n",
        "          if i in registry:\n",
        "            embdg = registry[i]\n",
        "            phrase_nuberic_list.append(embdg)\n",
        "          else:\n",
        "            pass\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "\n",
        "  value_converted_numeric.append(phrase_numeric_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXcyRRgPDsCa"
      },
      "source": [
        "The following is test code from documentation on an open-source pre-trained sentence transformer model! https://huggingface.co/thenlper/gte-large\n",
        "\n",
        "It in fact runs. So I will see if I can leverage this as my first attempt at representing the phrases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348,
          "referenced_widgets": [
            "d52d2a2f701b486698cdc2eb6bd6c2be",
            "46518caac64c4a2ba98131fcd66326f5",
            "8189b9da85b248bd92b6bf9c5e3d867c",
            "e1187541c7d54ebfae8d864f9251c043",
            "2c86771d6b94401b9648dcb009b4d484",
            "c8fc22bdc3f1401f9e68223d5a37de01",
            "2db4cd5154a346858bd7025fd54bcb09",
            "3da0019237b243b780acef6d0f22f37a",
            "3bcde355f8634868bfc227929e3bb42f",
            "beab1d51be68467ea2576bd34d4d9c24",
            "da8d58d0783b4beeabcd6f6ec5987a90",
            "3ae5834b0f82407fb98d07ea4e52c8ac",
            "fcee6dd17e4840cea7dd90e8eac8112d",
            "f8c66e840ecf49bd86aa0e9ab0a3651a",
            "5ebf77738c3e4cdf8dec22198ad4eb41",
            "cd104025953b4359ac283e969a2b579b",
            "5bb882ae35664d14a8aab0ed77e89608",
            "5484f2b27d3a44db8667246d19fcae52",
            "c092cd76cf2c4e958163ce0a54a75624",
            "f4a7bf080192418993ba6e6f1523a86e",
            "9a316d2cf0034d14bfeb57acf3bb1479",
            "6556f139039c48919b49fe34c22b7e84",
            "c3491bdef5a64858abe4f3b175619e92",
            "ca927467b3d041329d4c486e4aebdea1",
            "5e86a8753c8649a3b80f31b58fc5d2f5",
            "279189017e5a4910aeed8e1cbbd3f09a",
            "5d4c529834ce4ed78e1f2ca767bfbff8",
            "b66be90ca504470ca479c8b1c91f7a20",
            "4f6b84d076b04e36956e5ef1b75284cd",
            "4be6a679bfb44a44b02ac04583fc3a20",
            "6b048daa757e45259595abe80b56849a",
            "9fc74b89464748d79edf3daf0a9ae7a0",
            "7274e9fda8824c308fa3500479d65f58",
            "a645403deb474f289c34b95c5cac8533",
            "a25aa875d53448bcb2fdcfce02fc73e9",
            "981e8d8eb5314445bf25bf6dca552526",
            "f8cfaa7e154e4e0ab533a07d18f50079",
            "5cc0554f42bf43e2aa0bc85da4d6aadb",
            "9722ab19e772488fa29913b39ca77c9d",
            "87eb7c5ddd464ad7b6e0569fad7c2c8f",
            "3598f566a3424d638eabde520018d76f",
            "248989e5950b41359a0a4db2ddae5e0a",
            "f4ff7a27ad8e4f5d8365946912e022f7",
            "6c332a3db4d2420c8146055129172319",
            "8a1d553fbc8943339c946184a5e740d8",
            "d6390d0d4ba24243b79094ef1b43cf59",
            "45a190c36e4a47cea541fd153880385d",
            "585f9b9684b246b69bff4d2625a3f732",
            "8700f1089613406085f728586400a43d",
            "781e682023664d3b80e42c6ee79f0c47",
            "a5a436be21e64472b04566292585772f",
            "f1c9d64614ca4a3397b51f110d9ad2ef",
            "8835e39eaa6d4bc8affe7886742eee78",
            "fde057fbd7904c2ba2f3157555e260b6",
            "a598316d50114db39532309d9c1f6ceb",
            "1e11858eedb74e1d83511f4a8d71a4e8",
            "ebb6876bceca4313a8b02ccf42517dba",
            "250f7bcc862c46808ea3247acf02ec76",
            "c509e26d1ea34267b61bb21e5ad3f0d3",
            "e423b33c22aa4ae681edf96326becbb2",
            "77345e0837034d21afd88761bf99cb52",
            "4d5c5e00063a4903a26e3df8bf18c899",
            "94bf1fc22ecf4742a22b5e4341bdbf47",
            "4cfefdc8982e440381417cea4b08a308",
            "d126b92c8b2b4501af977738030a4a5b",
            "c6ea76a53dc64a9ea52c77e004f9a979"
          ]
        },
        "id": "c4FtqQwaDdsT",
        "outputId": "17e4a511-2710-480c-9fdb-c64475b776cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d52d2a2f701b486698cdc2eb6bd6c2be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ae5834b0f82407fb98d07ea4e52c8ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3491bdef5a64858abe4f3b175619e92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a645403deb474f289c34b95c5cac8533",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a1d553fbc8943339c946184a5e740d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e11858eedb74e1d83511f4a8d71a4e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[65.60009002685547, 87.13587188720703, 67.97511291503906]]\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "def average_pool(last_hidden_states: Tensor,\n",
        "                 attention_mask: Tensor) -> Tensor:\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "input_texts = [\n",
        "    \"what is the capital of China?\",\n",
        "    \"how to implement quick sort in python?\",\n",
        "    \"Beijing\",\n",
        "    \"sorting algorithms\"\n",
        "]\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-large\")\n",
        "model = AutoModel.from_pretrained(\"thenlper/gte-large\")\n",
        "\n",
        "# Tokenize the input texts\n",
        "batch_dict = tokenizer(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "outputs = model(**batch_dict)\n",
        "embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "# (Optionally) normalize embeddings\n",
        "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "scores = (embeddings[:1] @ embeddings[1:].T) * 100\n",
        "print(scores.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_WPfRK3EVo9"
      },
      "source": [
        "Is there code we could use to cluster all of our sentences into a smaller number of categories using the transformer that we train on our phrase set? This link proved insightful if not highly applicable and shows a possibly preferable alternative to gte-large, with SentenceTransformer\n",
        "\n",
        "https://towardsdatascience.com/clustering-sentence-embeddings-to-identify-intents-in-short-text-48d22d3bf02e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFQ8wjNZGrsv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# load intents dataset\n",
        "data_sample = pd.read_csv('../data/processed/data_sample.csv')\n",
        "all_intents = list(data_sample['text'])\n",
        "\n",
        "# define the document embedding models to use for comparison\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "model_use = hub.load(module_url)\n",
        "model_st1 = SentenceTransformer('all-mpnet-base-v2')\n",
        "model_st2 = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "model_st3 = SentenceTransformer('paraphrase-mpnet-base-v2')\n",
        "\n",
        "def embed(model, model_type, sentences):\n",
        "  \"\"\"\n",
        "  wrapper function for generating message embeddings\n",
        "  \"\"\"\n",
        "\n",
        "    if model_type == 'use':\n",
        "        embeddings = model(sentences)\n",
        "    elif model_type == 'sentence transformer':\n",
        "        embeddings = model.encode(sentences)\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "# generate embeddings for each model\n",
        "embeddings_use = embed(model_use, 'use', all_intents)\n",
        "embeddings_st1 = embed(model_st1, 'sentence transformer', all_intents)\n",
        "embeddings_st2 = embed(model_st2, 'sentence transformer', all_intents)\n",
        "embeddings_st3 = embed(model_st3, 'sentence transformer', all_intents)\n",
        "\n",
        "def generate_clusters(message_embeddings,\n",
        "                      n_neighbors,\n",
        "                      n_components,\n",
        "                      min_cluster_size,\n",
        "                      random_state = None):\n",
        "    \"\"\"\n",
        "    Generate HDBSCAN cluster object after reducing embedding dimensionality with UMAP\n",
        "    \"\"\"\n",
        "\n",
        "    umap_embeddings = (umap.UMAP(n_neighbors=n_neighbors,\n",
        "                                n_components=n_components,\n",
        "                                metric='cosine',\n",
        "                                random_state=random_state)\n",
        "                            .fit_transform(message_embeddings))\n",
        "\n",
        "    clusters = hdbscan.HDBSCAN(min_cluster_size = min_cluster_size,\n",
        "                               metric='euclidean',\n",
        "                               cluster_selection_method='eom').fit(umap_embeddings)\n",
        "\n",
        "    return clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-OTQSrCNBXX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "uc8_YWc8M8RK",
        "outputId": "cf00a94c-4498-450e-d951-2fb929591773"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 107,\n  \"fields\": [\n    {\n      \"column\": \"employment_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job_function\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description_of_product/service\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"industries\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"position_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"broader_role_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"company\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"responsibilities\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"goals/objectives\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name_of_department/team\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"required_qualifications\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preferred_qualifications\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"benefits\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"work_arrangement\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 66,\n        \"samples\": [\n          \"San Antonio\",\n          \"Santa Rosa\",\n          \"Redmond\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"VA\",\n          \"FL\",\n          \"WA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"USA\",\n          \"United States\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.0285584779617,\n        \"min\": 58.3,\n        \"max\": 245.0,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          170.0,\n          175.0,\n          62.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 78.08504978928872,\n        \"min\": 90.0,\n        \"max\": 414.0,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          236.0,\n          170.0,\n          93.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7700a650-eb58-4943-916c-c6de2e43a672\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>employment_type</th>\n",
              "      <th>job_function</th>\n",
              "      <th>description_of_product/service</th>\n",
              "      <th>industries</th>\n",
              "      <th>position_name</th>\n",
              "      <th>broader_role_name</th>\n",
              "      <th>company</th>\n",
              "      <th>responsibilities</th>\n",
              "      <th>goals/objectives</th>\n",
              "      <th>name_of_department/team</th>\n",
              "      <th>required_qualifications</th>\n",
              "      <th>preferred_qualifications</th>\n",
              "      <th>benefits</th>\n",
              "      <th>work_arrangement</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "      <th>min_salary</th>\n",
              "      <th>max_salary</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[design-led software development, end-to-end d...</td>\n",
              "      <td>[Business Consulting, Services]</td>\n",
              "      <td>[Python Software Engineer (Robotics/Mechatroni...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Fresh Consulting]</td>\n",
              "      <td>[integrate software/hardware components, devel...</td>\n",
              "      <td>[manage delivery of high-quality work]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[0-1+ years experience, Python skills, program...</td>\n",
              "      <td>[clear communication, outside the box thinking...</td>\n",
              "      <td>[100% Medical, PTO, Holiday Pay, 401K Plan]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>Redmond</td>\n",
              "      <td>WA</td>\n",
              "      <td>USA</td>\n",
              "      <td>62.4</td>\n",
              "      <td>93.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Design, Art/Creative, Information Technology]</td>\n",
              "      <td>[Surgical Robotics Systems]</td>\n",
              "      <td>[Biotechnology Research, Pharmaceutical Manufa...</td>\n",
              "      <td>[Robotics Engineer]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Barrington James]</td>\n",
              "      <td>[Contribute to cutting-edge robotic systems, C...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Bachelor's, Master's, or Ph.D. in Robotics, M...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>New York</td>\n",
              "      <td></td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Information Technology, Consulting, Engineering]</td>\n",
              "      <td>[Amazon Robotics builds high-performance, real...</td>\n",
              "      <td>[Software Development, IT Services, IT Consult...</td>\n",
              "      <td>[SDE - Amazon Robotics]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Amazon]</td>\n",
              "      <td>[Help with initial robotic deployments, Plan r...</td>\n",
              "      <td>[Build high-performance robotic systems, Inven...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[3+ years professional software development ex...</td>\n",
              "      <td>[3+ years full software development life cycle...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>North Reading</td>\n",
              "      <td>MA</td>\n",
              "      <td>USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[Credit scoring models]</td>\n",
              "      <td>[Financial Services, Capital Markets, IT Servi...</td>\n",
              "      <td>[Senior Software Engineer]</td>\n",
              "      <td>[Software Engineer]</td>\n",
              "      <td>[VantageScore®]</td>\n",
              "      <td>[Application Development, Collaboration, Mento...</td>\n",
              "      <td>[Building public APIs]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Bachelor's degree, Master's degree, Computer ...</td>\n",
              "      <td>[Quantitative applications, Fintech experience...</td>\n",
              "      <td>[401(K) match, Flexible Time Off, 12 Paid Holi...</td>\n",
              "      <td>[Hybrid]</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>CA</td>\n",
              "      <td>USA</td>\n",
              "      <td>150.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Quality Assurance, Information T...</td>\n",
              "      <td>[Large-scale distributed software applications...</td>\n",
              "      <td>[IT Services, IT Consulting]</td>\n",
              "      <td>[Software Engineer in Test]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Optomi]</td>\n",
              "      <td>[Build and maintain automated test infrastruct...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[5+ years of test automation experience, Profi...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>Dallas-Fort Worth</td>\n",
              "      <td>TX</td>\n",
              "      <td>USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7700a650-eb58-4943-916c-c6de2e43a672')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7700a650-eb58-4943-916c-c6de2e43a672 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7700a650-eb58-4943-916c-c6de2e43a672');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-30968630-b88c-4af6-82c8-54939e2b9ee0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-30968630-b88c-4af6-82c8-54939e2b9ee0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-30968630-b88c-4af6-82c8-54939e2b9ee0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  employment_type                                       job_function  \\\n",
              "0     [Full-time]              [Engineering, Information Technology]   \n",
              "1     [Full-time]     [Design, Art/Creative, Information Technology]   \n",
              "2     [Full-time]  [Information Technology, Consulting, Engineering]   \n",
              "3     [Full-time]              [Engineering, Information Technology]   \n",
              "4     [Full-time]  [Engineering, Quality Assurance, Information T...   \n",
              "\n",
              "                      description_of_product/service  \\\n",
              "0  [design-led software development, end-to-end d...   \n",
              "1                        [Surgical Robotics Systems]   \n",
              "2  [Amazon Robotics builds high-performance, real...   \n",
              "3                            [Credit scoring models]   \n",
              "4  [Large-scale distributed software applications...   \n",
              "\n",
              "                                          industries  \\\n",
              "0                    [Business Consulting, Services]   \n",
              "1  [Biotechnology Research, Pharmaceutical Manufa...   \n",
              "2  [Software Development, IT Services, IT Consult...   \n",
              "3  [Financial Services, Capital Markets, IT Servi...   \n",
              "4                       [IT Services, IT Consulting]   \n",
              "\n",
              "                                       position_name    broader_role_name  \\\n",
              "0  [Python Software Engineer (Robotics/Mechatroni...                [N/A]   \n",
              "1                                [Robotics Engineer]                [N/A]   \n",
              "2                            [SDE - Amazon Robotics]                [N/A]   \n",
              "3                         [Senior Software Engineer]  [Software Engineer]   \n",
              "4                        [Software Engineer in Test]                [N/A]   \n",
              "\n",
              "              company                                   responsibilities  \\\n",
              "0  [Fresh Consulting]  [integrate software/hardware components, devel...   \n",
              "1  [Barrington James]  [Contribute to cutting-edge robotic systems, C...   \n",
              "2            [Amazon]  [Help with initial robotic deployments, Plan r...   \n",
              "3     [VantageScore®]  [Application Development, Collaboration, Mento...   \n",
              "4            [Optomi]  [Build and maintain automated test infrastruct...   \n",
              "\n",
              "                                    goals/objectives name_of_department/team  \\\n",
              "0             [manage delivery of high-quality work]                   [N/A]   \n",
              "1                                                NaN                     NaN   \n",
              "2  [Build high-performance robotic systems, Inven...                   [N/A]   \n",
              "3                             [Building public APIs]                   [N/A]   \n",
              "4                                              [N/A]                   [N/A]   \n",
              "\n",
              "                             required_qualifications  \\\n",
              "0  [0-1+ years experience, Python skills, program...   \n",
              "1  [Bachelor's, Master's, or Ph.D. in Robotics, M...   \n",
              "2  [3+ years professional software development ex...   \n",
              "3  [Bachelor's degree, Master's degree, Computer ...   \n",
              "4  [5+ years of test automation experience, Profi...   \n",
              "\n",
              "                            preferred_qualifications  \\\n",
              "0  [clear communication, outside the box thinking...   \n",
              "1                                              [N/A]   \n",
              "2  [3+ years full software development life cycle...   \n",
              "3  [Quantitative applications, Fintech experience...   \n",
              "4                                              [N/A]   \n",
              "\n",
              "                                            benefits work_arrangement  \\\n",
              "0        [100% Medical, PTO, Holiday Pay, 401K Plan]            [N/A]   \n",
              "1                                              [N/A]            [N/A]   \n",
              "2                                              [N/A]        [On-site]   \n",
              "3  [401(K) match, Flexible Time Off, 12 Paid Holi...         [Hybrid]   \n",
              "4                                              [N/A]        [On-site]   \n",
              "\n",
              "                city state        country  min_salary  max_salary  rating  \n",
              "0            Redmond    WA            USA        62.4        93.6       1  \n",
              "1           New York        United States         NaN         NaN       2  \n",
              "2      North Reading    MA            USA         NaN         NaN       2  \n",
              "3      San Francisco    CA            USA       150.0       200.0       3  \n",
              "4  Dallas-Fort Worth    TX            USA         NaN         NaN       1  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "3yZWqIDiNN3K",
        "outputId": "06ba83f0-45f2-47eb-babf-a3d051cd3521"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1ed773e5-e530-4d39-8b34-292444a594b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>employment_type</th>\n",
              "      <th>job_function</th>\n",
              "      <th>description_of_product/service</th>\n",
              "      <th>industries</th>\n",
              "      <th>position_name</th>\n",
              "      <th>broader_role_name</th>\n",
              "      <th>company</th>\n",
              "      <th>responsibilities</th>\n",
              "      <th>goals/objectives</th>\n",
              "      <th>name_of_department/team</th>\n",
              "      <th>...</th>\n",
              "      <th>preferred_qualifications</th>\n",
              "      <th>benefits</th>\n",
              "      <th>work_arrangement</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "      <th>min_salary</th>\n",
              "      <th>max_salary</th>\n",
              "      <th>rating</th>\n",
              "      <th>reponsibilities_vectors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[design-led software development, end-to-end d...</td>\n",
              "      <td>[Business Consulting, Services]</td>\n",
              "      <td>[Python Software Engineer (Robotics/Mechatroni...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Fresh Consulting]</td>\n",
              "      <td>[integrate software/hardware components, devel...</td>\n",
              "      <td>[manage delivery of high-quality work]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>...</td>\n",
              "      <td>[clear communication, outside the box thinking...</td>\n",
              "      <td>[100% Medical, PTO, Holiday Pay, 401K Plan]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>Redmond</td>\n",
              "      <td>WA</td>\n",
              "      <td>USA</td>\n",
              "      <td>62.4</td>\n",
              "      <td>93.6</td>\n",
              "      <td>1</td>\n",
              "      <td>[[-0.019170776, 0.0026787028, -0.028830342, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Design, Art/Creative, Information Technology]</td>\n",
              "      <td>[Surgical Robotics Systems]</td>\n",
              "      <td>[Biotechnology Research, Pharmaceutical Manufa...</td>\n",
              "      <td>[Robotics Engineer]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Barrington James]</td>\n",
              "      <td>[Contribute to cutting-edge robotic systems, C...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>New York</td>\n",
              "      <td></td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>[[0.0024300036, 0.014651684, -0.05683916, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Information Technology, Consulting, Engineering]</td>\n",
              "      <td>[Amazon Robotics builds high-performance, real...</td>\n",
              "      <td>[Software Development, IT Services, IT Consult...</td>\n",
              "      <td>[SDE - Amazon Robotics]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Amazon]</td>\n",
              "      <td>[Help with initial robotic deployments, Plan r...</td>\n",
              "      <td>[Build high-performance robotic systems, Inven...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>...</td>\n",
              "      <td>[3+ years full software development life cycle...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>North Reading</td>\n",
              "      <td>MA</td>\n",
              "      <td>USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>[[0.011741058, 0.019328363, -0.030540159, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[Credit scoring models]</td>\n",
              "      <td>[Financial Services, Capital Markets, IT Servi...</td>\n",
              "      <td>[Senior Software Engineer]</td>\n",
              "      <td>[Software Engineer]</td>\n",
              "      <td>[VantageScore®]</td>\n",
              "      <td>[Application Development, Collaboration, Mento...</td>\n",
              "      <td>[Building public APIs]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>...</td>\n",
              "      <td>[Quantitative applications, Fintech experience...</td>\n",
              "      <td>[401(K) match, Flexible Time Off, 12 Paid Holi...</td>\n",
              "      <td>[Hybrid]</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>CA</td>\n",
              "      <td>USA</td>\n",
              "      <td>150.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[[0.00232864, -0.010402084, -0.023544975, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Quality Assurance, Information T...</td>\n",
              "      <td>[Large-scale distributed software applications...</td>\n",
              "      <td>[IT Services, IT Consulting]</td>\n",
              "      <td>[Software Engineer in Test]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Optomi]</td>\n",
              "      <td>[Build and maintain automated test infrastruct...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>Dallas-Fort Worth</td>\n",
              "      <td>TX</td>\n",
              "      <td>USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>[[-0.013181117, 0.0006007539, -0.035469025, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ed773e5-e530-4d39-8b34-292444a594b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ed773e5-e530-4d39-8b34-292444a594b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ed773e5-e530-4d39-8b34-292444a594b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2df7dcab-7bac-46bd-9985-6638139c50f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2df7dcab-7bac-46bd-9985-6638139c50f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2df7dcab-7bac-46bd-9985-6638139c50f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  employment_type                                       job_function  \\\n",
              "0     [Full-time]              [Engineering, Information Technology]   \n",
              "1     [Full-time]     [Design, Art/Creative, Information Technology]   \n",
              "2     [Full-time]  [Information Technology, Consulting, Engineering]   \n",
              "3     [Full-time]              [Engineering, Information Technology]   \n",
              "4     [Full-time]  [Engineering, Quality Assurance, Information T...   \n",
              "\n",
              "                      description_of_product/service  \\\n",
              "0  [design-led software development, end-to-end d...   \n",
              "1                        [Surgical Robotics Systems]   \n",
              "2  [Amazon Robotics builds high-performance, real...   \n",
              "3                            [Credit scoring models]   \n",
              "4  [Large-scale distributed software applications...   \n",
              "\n",
              "                                          industries  \\\n",
              "0                    [Business Consulting, Services]   \n",
              "1  [Biotechnology Research, Pharmaceutical Manufa...   \n",
              "2  [Software Development, IT Services, IT Consult...   \n",
              "3  [Financial Services, Capital Markets, IT Servi...   \n",
              "4                       [IT Services, IT Consulting]   \n",
              "\n",
              "                                       position_name    broader_role_name  \\\n",
              "0  [Python Software Engineer (Robotics/Mechatroni...                [N/A]   \n",
              "1                                [Robotics Engineer]                [N/A]   \n",
              "2                            [SDE - Amazon Robotics]                [N/A]   \n",
              "3                         [Senior Software Engineer]  [Software Engineer]   \n",
              "4                        [Software Engineer in Test]                [N/A]   \n",
              "\n",
              "              company                                   responsibilities  \\\n",
              "0  [Fresh Consulting]  [integrate software/hardware components, devel...   \n",
              "1  [Barrington James]  [Contribute to cutting-edge robotic systems, C...   \n",
              "2            [Amazon]  [Help with initial robotic deployments, Plan r...   \n",
              "3     [VantageScore®]  [Application Development, Collaboration, Mento...   \n",
              "4            [Optomi]  [Build and maintain automated test infrastruct...   \n",
              "\n",
              "                                    goals/objectives name_of_department/team  \\\n",
              "0             [manage delivery of high-quality work]                   [N/A]   \n",
              "1                                                NaN                     NaN   \n",
              "2  [Build high-performance robotic systems, Inven...                   [N/A]   \n",
              "3                             [Building public APIs]                   [N/A]   \n",
              "4                                              [N/A]                   [N/A]   \n",
              "\n",
              "   ...                           preferred_qualifications  \\\n",
              "0  ...  [clear communication, outside the box thinking...   \n",
              "1  ...                                              [N/A]   \n",
              "2  ...  [3+ years full software development life cycle...   \n",
              "3  ...  [Quantitative applications, Fintech experience...   \n",
              "4  ...                                              [N/A]   \n",
              "\n",
              "                                            benefits work_arrangement  \\\n",
              "0        [100% Medical, PTO, Holiday Pay, 401K Plan]            [N/A]   \n",
              "1                                              [N/A]            [N/A]   \n",
              "2                                              [N/A]        [On-site]   \n",
              "3  [401(K) match, Flexible Time Off, 12 Paid Holi...         [Hybrid]   \n",
              "4                                              [N/A]        [On-site]   \n",
              "\n",
              "                city state        country min_salary  max_salary  rating  \\\n",
              "0            Redmond    WA            USA       62.4        93.6       1   \n",
              "1           New York        United States        NaN         NaN       2   \n",
              "2      North Reading    MA            USA        NaN         NaN       2   \n",
              "3      San Francisco    CA            USA      150.0       200.0       3   \n",
              "4  Dallas-Fort Worth    TX            USA        NaN         NaN       1   \n",
              "\n",
              "                             reponsibilities_vectors  \n",
              "0  [[-0.019170776, 0.0026787028, -0.028830342, 0....  \n",
              "1  [[0.0024300036, 0.014651684, -0.05683916, -0.0...  \n",
              "2  [[0.011741058, 0.019328363, -0.030540159, -0.0...  \n",
              "3  [[0.00232864, -0.010402084, -0.023544975, -0.0...  \n",
              "4  [[-0.013181117, 0.0006007539, -0.035469025, 0....  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-large\")\n",
        "model = AutoModel.from_pretrained(\"thenlper/gte-large\")\n",
        "\n",
        "def average_pool(last_hidden_states: Tensor,\n",
        "                 attention_mask: Tensor) -> Tensor:\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "new_col_data = []\n",
        "phrases = []\n",
        "for value in df['responsibilities']:\n",
        "  # Tokenize the input texts\n",
        "  for phrase in value:\n",
        "    phrases.append(phrase)\n",
        "  batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "  outputs = model(**batch_dict)\n",
        "  embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "  # (Optionally) normalize embeddings\n",
        "  embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "  new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "df['reponsibilities_vectors'] = new_col_data\n",
        "\n",
        "\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "OdrgmB0AQHm9",
        "outputId": "d461d895-1e27-45c2-cdbd-15b0539bde79"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7dc4706b-76a2-4dfd-9327-903adacd6970\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>employment_type</th>\n",
              "      <th>job_function</th>\n",
              "      <th>description_of_product/service</th>\n",
              "      <th>industries</th>\n",
              "      <th>position_name</th>\n",
              "      <th>broader_role_name</th>\n",
              "      <th>company</th>\n",
              "      <th>responsibilities</th>\n",
              "      <th>goals/objectives</th>\n",
              "      <th>name_of_department/team</th>\n",
              "      <th>...</th>\n",
              "      <th>preferred_qualifications</th>\n",
              "      <th>benefits</th>\n",
              "      <th>work_arrangement</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "      <th>min_salary</th>\n",
              "      <th>max_salary</th>\n",
              "      <th>rating</th>\n",
              "      <th>reponsibilities_vectors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[design-led software development, end-to-end d...</td>\n",
              "      <td>[Business Consulting, Services]</td>\n",
              "      <td>[Python Software Engineer (Robotics/Mechatroni...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Fresh Consulting]</td>\n",
              "      <td>[integrate software/hardware components, devel...</td>\n",
              "      <td>[manage delivery of high-quality work]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>...</td>\n",
              "      <td>[clear communication, outside the box thinking...</td>\n",
              "      <td>[100% Medical, PTO, Holiday Pay, 401K Plan]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>Redmond</td>\n",
              "      <td>WA</td>\n",
              "      <td>USA</td>\n",
              "      <td>62.4</td>\n",
              "      <td>93.6</td>\n",
              "      <td>1</td>\n",
              "      <td>[[-0.019170776, 0.0026787028, -0.028830342, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Design, Art/Creative, Information Technology]</td>\n",
              "      <td>[Surgical Robotics Systems]</td>\n",
              "      <td>[Biotechnology Research, Pharmaceutical Manufa...</td>\n",
              "      <td>[Robotics Engineer]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Barrington James]</td>\n",
              "      <td>[Contribute to cutting-edge robotic systems, C...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>New York</td>\n",
              "      <td></td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>[[0.0024300036, 0.014651684, -0.05683916, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Information Technology, Consulting, Engineering]</td>\n",
              "      <td>[Amazon Robotics builds high-performance, real...</td>\n",
              "      <td>[Software Development, IT Services, IT Consult...</td>\n",
              "      <td>[SDE - Amazon Robotics]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Amazon]</td>\n",
              "      <td>[Help with initial robotic deployments, Plan r...</td>\n",
              "      <td>[Build high-performance robotic systems, Inven...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>...</td>\n",
              "      <td>[3+ years full software development life cycle...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>North Reading</td>\n",
              "      <td>MA</td>\n",
              "      <td>USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>[[0.011741058, 0.019328363, -0.030540159, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[Credit scoring models]</td>\n",
              "      <td>[Financial Services, Capital Markets, IT Servi...</td>\n",
              "      <td>[Senior Software Engineer]</td>\n",
              "      <td>[Software Engineer]</td>\n",
              "      <td>[VantageScore®]</td>\n",
              "      <td>[Application Development, Collaboration, Mento...</td>\n",
              "      <td>[Building public APIs]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>...</td>\n",
              "      <td>[Quantitative applications, Fintech experience...</td>\n",
              "      <td>[401(K) match, Flexible Time Off, 12 Paid Holi...</td>\n",
              "      <td>[Hybrid]</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>CA</td>\n",
              "      <td>USA</td>\n",
              "      <td>150.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[[0.00232864, -0.010402084, -0.023544975, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Quality Assurance, Information T...</td>\n",
              "      <td>[Large-scale distributed software applications...</td>\n",
              "      <td>[IT Services, IT Consulting]</td>\n",
              "      <td>[Software Engineer in Test]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Optomi]</td>\n",
              "      <td>[Build and maintain automated test infrastruct...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>Dallas-Fort Worth</td>\n",
              "      <td>TX</td>\n",
              "      <td>USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>[[-0.013181117, 0.0006007539, -0.035469025, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7dc4706b-76a2-4dfd-9327-903adacd6970')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7dc4706b-76a2-4dfd-9327-903adacd6970 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7dc4706b-76a2-4dfd-9327-903adacd6970');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a1e63860-7884-477f-a0b9-f212606b8995\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a1e63860-7884-477f-a0b9-f212606b8995')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a1e63860-7884-477f-a0b9-f212606b8995 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  employment_type                                       job_function  \\\n",
              "0     [Full-time]              [Engineering, Information Technology]   \n",
              "1     [Full-time]     [Design, Art/Creative, Information Technology]   \n",
              "2     [Full-time]  [Information Technology, Consulting, Engineering]   \n",
              "3     [Full-time]              [Engineering, Information Technology]   \n",
              "4     [Full-time]  [Engineering, Quality Assurance, Information T...   \n",
              "\n",
              "                      description_of_product/service  \\\n",
              "0  [design-led software development, end-to-end d...   \n",
              "1                        [Surgical Robotics Systems]   \n",
              "2  [Amazon Robotics builds high-performance, real...   \n",
              "3                            [Credit scoring models]   \n",
              "4  [Large-scale distributed software applications...   \n",
              "\n",
              "                                          industries  \\\n",
              "0                    [Business Consulting, Services]   \n",
              "1  [Biotechnology Research, Pharmaceutical Manufa...   \n",
              "2  [Software Development, IT Services, IT Consult...   \n",
              "3  [Financial Services, Capital Markets, IT Servi...   \n",
              "4                       [IT Services, IT Consulting]   \n",
              "\n",
              "                                       position_name    broader_role_name  \\\n",
              "0  [Python Software Engineer (Robotics/Mechatroni...                [N/A]   \n",
              "1                                [Robotics Engineer]                [N/A]   \n",
              "2                            [SDE - Amazon Robotics]                [N/A]   \n",
              "3                         [Senior Software Engineer]  [Software Engineer]   \n",
              "4                        [Software Engineer in Test]                [N/A]   \n",
              "\n",
              "              company                                   responsibilities  \\\n",
              "0  [Fresh Consulting]  [integrate software/hardware components, devel...   \n",
              "1  [Barrington James]  [Contribute to cutting-edge robotic systems, C...   \n",
              "2            [Amazon]  [Help with initial robotic deployments, Plan r...   \n",
              "3     [VantageScore®]  [Application Development, Collaboration, Mento...   \n",
              "4            [Optomi]  [Build and maintain automated test infrastruct...   \n",
              "\n",
              "                                    goals/objectives name_of_department/team  \\\n",
              "0             [manage delivery of high-quality work]                   [N/A]   \n",
              "1                                                NaN                     NaN   \n",
              "2  [Build high-performance robotic systems, Inven...                   [N/A]   \n",
              "3                             [Building public APIs]                   [N/A]   \n",
              "4                                              [N/A]                   [N/A]   \n",
              "\n",
              "   ...                           preferred_qualifications  \\\n",
              "0  ...  [clear communication, outside the box thinking...   \n",
              "1  ...                                              [N/A]   \n",
              "2  ...  [3+ years full software development life cycle...   \n",
              "3  ...  [Quantitative applications, Fintech experience...   \n",
              "4  ...                                              [N/A]   \n",
              "\n",
              "                                            benefits work_arrangement  \\\n",
              "0        [100% Medical, PTO, Holiday Pay, 401K Plan]            [N/A]   \n",
              "1                                              [N/A]            [N/A]   \n",
              "2                                              [N/A]        [On-site]   \n",
              "3  [401(K) match, Flexible Time Off, 12 Paid Holi...         [Hybrid]   \n",
              "4                                              [N/A]        [On-site]   \n",
              "\n",
              "                city state        country min_salary  max_salary  rating  \\\n",
              "0            Redmond    WA            USA       62.4        93.6       1   \n",
              "1           New York        United States        NaN         NaN       2   \n",
              "2      North Reading    MA            USA        NaN         NaN       2   \n",
              "3      San Francisco    CA            USA      150.0       200.0       3   \n",
              "4  Dallas-Fort Worth    TX            USA        NaN         NaN       1   \n",
              "\n",
              "                             reponsibilities_vectors  \n",
              "0  [[-0.019170776, 0.0026787028, -0.028830342, 0....  \n",
              "1  [[0.0024300036, 0.014651684, -0.05683916, -0.0...  \n",
              "2  [[0.011741058, 0.019328363, -0.030540159, -0.0...  \n",
              "3  [[0.00232864, -0.010402084, -0.023544975, -0.0...  \n",
              "4  [[-0.013181117, 0.0006007539, -0.035469025, 0....  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "Xkvx9j24RSWw",
        "outputId": "d360adfb-540c-4ce0-f90f-5b9df863d8bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=100, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=100, random_state=0)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KMeans(n_clusters=100, random_state=0)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "phrase_vecs_list = []\n",
        "for i in df['reponsibilities_vectors']:\n",
        "  for j in i:\n",
        "    phrase_vecs_list.append(j)\n",
        "kmeans = KMeans(n_clusters=100, random_state=0)\n",
        "kmeans.fit(phrase_vecs_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcUrOkHYSi7V",
        "outputId": "a51f5658-dcf6-4d76-8cd3-1bb675195216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[88 78 25 55 20  4 65 20 40 48 13 17 57 47  3 19 59 27  5  2 55 76 76  5\n",
            " 96  5  5 99 38 93 12 10 53  4 35 58 22 96 81 81 58 77 86 28 51  6 83 13\n",
            " 55 75 83 57 57 71 57 96 65 96 32 38 78 93 19 11  2 21 64 47 65 40 71 50\n",
            " 50 38 81 20 87 38 79 16 85 79 63 76  9 99 58 54 20 54 19 73 73 45 45 56\n",
            " 64 56 56 70 44 32 38 44 76 27 53 40 25 26  7 46  6 86 11 46 26 26 27 83\n",
            " 26 56 90 90 52 61 61 46 69 44 52 34 76 90  9 14 64 56 14 46 64 48 48 55\n",
            " 67  3 85 63  5 13 99 51 15  5 50 77  3 25 49 77 49 28 25  4 42  0 28 63\n",
            " 49 82 49 38  3 33  1 71 17 67 47 59 99 38  3 99 10 25 52 92 92 44 14 75\n",
            "  5 19 25 33 77  5 11  4 38 75 43 75 46 50 48 63 66 94 71 66 94 97 40  1\n",
            " 46 75 57  3 29 16 51 52  6 94 94  6 80 54 12 48 54 73 97  5  5  5 10  5\n",
            " 53 25  4 35 82 54 38 97  2 35 82  1 57 13  1 71  4 13 77 28 75 74 18 11\n",
            " 24 71 13  3 40 52 75 74 18 11 74 55 24 79 61 65 41 55 59 14 67 86 52 76\n",
            " 36 29 68 55 18 91 63 36 52 95 55 62 74 67 33 37 26 16 58 16 63 41 10 47\n",
            " 55 73 67 84 59 31 41  8 41 72 17 76 11 54  4 88 30 11 25 44 97 21  9 75\n",
            " 77 25 70 70  2 38 22  3 29 52 44 29 18 58 12 12 69 96 75 44 19  2 83 22\n",
            " 20 43 16  3  3 62 62 39 78  4  2 98 47 57 98 64 55 11 84 68 68 68 44  9\n",
            "  7 90 61 37 21 50 61  9 16  7 21  7 64 55 57 23 23 23 47 17 73 76 10 38\n",
            " 85 66 79 69 59 27 80 47 47 96 43 13 32 12 75 95 95 91 34 14 44 21 60 60\n",
            " 15 15 91 15 60 15 97 77 32 38  4 72 55 89 89 89  6 78 76  5  3 65 43 20\n",
            " 25 77 19 71 40 13 17 22 57 41 47 55 59 16 75 93 27 11  5 89 82 10 55 41\n",
            " 48 77 11 22 24 37 84 11 11 24 13 48 33 12 53 12 67 19 74 77 32 88 79 40\n",
            " 59 11 13 48 97 47 41 22 53 19 65 81 16 88  2 13 29 36 82 55 59 12 81 77\n",
            " 25 55 70 70 39 39 91 55 47 47 55]\n"
          ]
        }
      ],
      "source": [
        "new_phrase = 'clear communication'\n",
        "\n",
        "cluster_labels = kmeans.labels_\n",
        "print(cluster_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHnFm0jNbXiU"
      },
      "outputs": [],
      "source": [
        "# Associate phrases with cluster labels\n",
        "data = {'phrase': phrases, 'cluster_label': cluster_labels}\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPmmahkDdrm6",
        "outputId": "74789f81-d18b-4075-c3bf-1f9b1f9aa41b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['debug issues with windbg/similar debuggers']\n",
            "['Develop and optimize machine learning models for real-time, edge applications', 'Deep learning engineering', 'Develop edge-computing stack', 'Build edge applications']\n"
          ]
        }
      ],
      "source": [
        "# Get names of phrases in a given cluster (e.g., cluster 0)\n",
        "desired_cluster = 0\n",
        "phrases_in_cluster = df.loc[df['cluster_label'] == desired_cluster, 'phrase'].tolist()\n",
        "print(phrases_in_cluster)\n",
        "\n",
        "# Get names of phrases in a given cluster (e.g., cluster 0)\n",
        "desired_cluster = 1\n",
        "phrases_in_cluster = df.loc[df['cluster_label'] == desired_cluster, 'phrase'].tolist()\n",
        "print(phrases_in_cluster)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAEJIzJseA0O"
      },
      "source": [
        "So far the output does not disappoint. Notice how the transformer was able to group all of the following together into cluster 1: ['Develop and optimize machine learning models for real-time, edge applications', 'Deep learning engineering', 'Develop edge-computing stack', 'Build edge applications']. This is exactly what we want. But we don't know if 100 clusters is too few, too many, or just the right amount. We will need to do some more EDA on what these clusters look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dXiCf66etc0",
        "outputId": "3d714363-35ee-4d46-d22f-6fb9e42c4f86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Write and execute end-to-end integration scenarios', 'End-to-end process integration', 'Integration', 'support integration and test actions', 'Analyzing data integration problems', 'Interact web services/APIs', 'Integration - Collaborate with teams and services for integration']\n"
          ]
        }
      ],
      "source": [
        "# Get names of phrases in a given cluster (e.g., cluster 0)\n",
        "desired_cluster = 2\n",
        "phrases_in_cluster = df.loc[df['cluster_label'] == desired_cluster, 'phrase'].tolist()\n",
        "print(phrases_in_cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R60Z5eUne04n",
        "outputId": "cb503a4f-5ace-42d4-c5ea-697873884e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Application Development', 'Firmware development', 'Core Windows development', 'reporting feature development status', 'Participate in development and testing sessions', 'Backend application building', 'Implement relevant applications', 'Model-based development review', 'Unity development', 'XR application development', 'Developing Microservices']\n"
          ]
        }
      ],
      "source": [
        "# Get names of phrases in a given cluster (e.g., cluster 0)\n",
        "desired_cluster = 3\n",
        "phrases_in_cluster = df.loc[df['cluster_label'] == desired_cluster, 'phrase'].tolist()\n",
        "print(phrases_in_cluster)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJNm8_YLe_AO"
      },
      "source": [
        "Cluster 3 is iffy and includes a lot of unrelated mumbo jumbo. But so far this is promising!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiDVOBpzfKUL",
        "outputId": "90400c95-663d-45e2-ead9-73090e17cb46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['document code quality', 'Develop secure high-quality code', 'code reviews', 'Coding', 'Production code development', 'Solve coding problems', 'Develop and maintain code', 'Programming languages', 'Implement source codes']\n"
          ]
        }
      ],
      "source": [
        "# Get names of phrases in a given cluster (e.g., cluster 0)\n",
        "desired_cluster = 4\n",
        "phrases_in_cluster = df.loc[df['cluster_label'] == desired_cluster, 'phrase'].tolist()\n",
        "print(phrases_in_cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQaZnhAcfRWl",
        "outputId": "f4644882-d790-4693-e632-5032f3b9cb1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['debug issues with windbg/similar debuggers']\n",
            "['Develop and optimize machine learning models for real-time, edge applications', 'Deep learning engineering', 'Develop edge-computing stack', 'Build edge applications']\n",
            "['Write and execute end-to-end integration scenarios', 'End-to-end process integration', 'Integration', 'support integration and test actions', 'Analyzing data integration problems', 'Interact web services/APIs', 'Integration - Collaborate with teams and services for integration']\n",
            "['Application Development', 'Firmware development', 'Core Windows development', 'reporting feature development status', 'Participate in development and testing sessions', 'Backend application building', 'Implement relevant applications', 'Model-based development review', 'Unity development', 'XR application development', 'Developing Microservices']\n",
            "['document code quality', 'Develop secure high-quality code', 'code reviews', 'Coding', 'Production code development', 'Solve coding problems', 'Develop and maintain code', 'Programming languages', 'Implement source codes']\n",
            "['Build and maintain automated test infrastructure', 'Set up test pipelines', 'Test serverless-based architecture on AWS', 'Deploy tests in AWS', 'Manage performance testing', 'Determine capacity testing', 'Support test chip layout', 'Testing', 'Developing test strategies', 'Creating test harnesses', 'Providing test infrastructure', 'Developing test plans', 'Plan and deploy infrastructure', 'Drive security tests']\n",
            "['Operate within agile scrum framework', 'Partner with internal business partners', 'Work with Product Management teams to assist market adoption and solution alignment with enterprise customer requirements', 'Scale capability, execution, and experience through Product, Engineering, and Partner teams, and drive customer success through prescriptive activation of internal and external teams', 'Partner with research, product, and design']\n",
            "[\"Create PowerPoint presentations for ISR's and Field Sales\", 'Technical Sales management', 'Technical Pre-Sales Support', 'Post-Sales Technical Support']\n",
            "['Implement algorithms, models, and data pipelines for decision-making and automation']\n",
            "['Identify cost savings initiatives', 'Perform market research', 'Credibility building', 'Marketing efforts', 'Trade shows attendance']\n",
            "['Collaborate with teams to ensure alignment', 'Coordinate with QA team', 'Coordinating with offshore team', 'Identify new directions, formulate objectives aligned with mission', 'Implement strategies for alignment', 'Coordinate findings with leadership']\n",
            "['User story documentation', 'Create and maintain process documents for team', 'Software Process', 'Document software specifications', 'Document software specifications', 'Document software designs, processes, and technical specifications', 'Document deployed processes', 'Technical writing', 'Create documentation for software', 'Documenting code and processes', 'Define technical specifications', 'Create technical content', 'Create architecture documentation']\n",
            "['Engage in thought leadership', 'Research fundamental problems', 'Solve problems', 'Research and solve', 'Identify and solve issues for uninterrupted service', 'Problem identification', 'Hypotheses', 'Problem Solving - Identify challenges, propose solutions']\n",
            "['Optimize system performance', 'Enhance existing components for performance', 'Identify bottlenecks', 'Optimize platform performance', 'Optimize code efficiency', 'Optimize enterprise applications', 'Optimize and scale systems', 'Develop own ideas to optimize platforms', 'Holography and Laser Beam Optimization', 'Drive system performance tuning', 'Performance Optimization - Monitor system performance, identify bottlenecks']\n",
            "['Financial Record Keeping', 'Manage Quickbooks', 'Manage client records', 'Maintain accurate tutoring records', 'Record maintenance']\n",
            "['Create telemetry', 'Maintains patient data files', 'Collects patient data', 'Prepares patient records for audits', 'May assist with direct patient care']\n",
            "['Communicate technology, plans effectively', 'Transformers experience', 'Provide feedback on market trends', 'Interact with technical decision makers', 'Interact with industry, standards, suppliers', 'Interaction with factory management', 'Represent OEF at standards discussions', 'Technical Leadership - Backend infrastructure design, development, maintenance']\n",
            "['Stay current with emerging technologies', 'Stay updated on advancements in machine learning and signal processing', 'Stay up-to-date with advancements in AI technologies', 'Stay updated on latest ML/DL technologies', 'Stay up-to-date with latest advancements in ML systems']\n",
            "['Research scientific reference material', 'Research scientific reference material', 'Keyword research', 'Research materials preparation']\n",
            "['Collaboration', 'Design collaboration', 'Collaborate with hardware/software engineers', 'Collaborate with process technologists', 'Collaborate with business', 'Collaborating with Customer Support, Engineering, Manufacturing', 'Collaboration', 'Collaboration with Quant Researchers and Business Users']\n",
            "['learn new systems/tools', 'Contribute to cutting-edge robotic systems', 'Work with Embedded Open-Source tools', 'Craft next gen SoC, CPUs', 'Set directions on hardware/software platforms', 'Docker, Messaging Tools (Kafka, Redis)']\n",
            "['Training support', 'Educational support', 'RFQs and RFIs support', 'Trial Support', 'Trains on specific laboratory aspects']\n",
            "['Design, Develop, Troubleshoot, Architect, Analyze', 'Enterprise architecture focus on AI models', 'Integration of architectural development', 'Design, architect, and build AI functionality', 'Expressing AI dedication', 'Report directly into the Head of Artificial Intelligence']\n",
            "['Build, install, configure, manage, scale ML platform', 'Implement scalable ML/DL solutions', 'Create & maintain ML/DL pipelines']\n",
            "['Support Business Development activities', 'Support Business Development activities', 'Build awareness-increase knowledge-drive adoption-operate as trusted advisor-lead talent development-collaborate on key innovation initiatives', 'Represent QES with business development']\n",
            "['investigate defects', 'Troubleshoot applications and make enhancements', 'bug fix', 'driving bug fixes', 'Debug and fix issues', 'Troubleshoot design and verification issues', 'Technical troubleshooting', 'Troubleshoot software issues', 'troubleshooting', 'Troubleshooting software-centric electromechanical vehicle systems', 'Troubleshooting and debugging programs']\n",
            "['Run reports to support customer meetings', 'Proactively monitor sales levels for dealers', 'Act as liaison between sales teams and customers', 'Support non-revenue generated work for sales teams', 'Guide account executives']\n",
            "['Establish Best Practices', 'Ensure product quality and best practices', 'Enhance processes by utilizing Continuous Improvement mindset', 'Adhere to industry standards', 'Follow software best practices']\n",
            "['Triage security and compliance issues', 'issues triage', 'incident triage', 'Initial defect analysis - Triage defects - Monitor defect dashboard - Create reports - Work with cross-functional teams - Drive defect triage calls']\n",
            "['Vector databases knowledge', 'SEO strategies', 'Data synchronization principles', 'Data management', 'Data Management - Data storage, retrieval, indexing strategies']\n",
            "['Create and test procedures']\n",
            "['Collaborate with cross-functional teams for AI-based product development']\n",
            "['Implement reporting system', 'Analyze system details', 'Monitor and analyze system health', 'Monitor, enhance system efficiency/stability', 'Analyze legacy systems']\n",
            "['Design experimental frameworks', 'Build Design of Experiments', 'Design experiments', 'Experimental Support and Data Analysis']\n",
            "['Travel to job sites', 'Pre-trip inspections']\n",
            "['Lead evaluation sessions', 'Evaluation sessions', 'Test and evaluation']\n",
            "['Enforce compliance with regulations', 'Maintain clean, safe space', 'Security - Implement security measures']\n",
            "['Drive customer engagements', 'Customer discussions', 'Engage with customers']\n",
            "['Design, develop, and refine prompts', 'Provide documentation', 'Documentation and Miscellaneous (20%)', 'Drive development of clear requirements', 'Identify security requirements', 'building effective documentation', 'Analyze Business Requirements', 'Requirements Documentation/Software Project Scope', 'Requirements engineering', 'Requirement gathering and documentation', 'Gather requirements for modeling techniques', 'Gather/analyze user requirements']\n",
            "['OpenXR libraries', 'Develops reusable architectures and designs for kernel software', 'Subject matter expert for kernel internals']\n",
            "['Collaborate with cross-functional teams', 'Collaborate with cross-functional teams', 'Interact with cross-functional teams', 'Collaborate with cross functional teams', 'Collaborate with cross-functional teams', 'Collaborate with cross-functional teams', 'Collaborate with cross-functional teams']\n",
            "['Optimizing and integrating AI model', 'Lead, collaborate, execute innovative AI research projects', 'Design and develop software solutions using AI technologies', 'Optimize and improve existing AI systems and algorithms', 'Participate in AI technical process standards', 'Implementing AI solutions', 'Utilize computer vision technology']\n",
            "['handling end-to-end delivery']\n",
            "['Manage CI/CD pipeline and troubleshoot issues', 'Design and develop GenAI use case model pipeline', 'Implement CI/CD pipelines for ML model deployment', 'CICD, REST APIs, Kubernetes']\n",
            "['Interacts with internal clients and responds to requests', 'Guide client through a plan of action', 'Utilize CRM tool', 'Interact positively with clients and staff', 'Client strategy design', 'Participant communication', 'Communicate project status', 'Communicate with clients and stakeholders', 'Professional communication']\n",
            "['Research portfolio accomplishments', 'National awards honors']\n",
            "['Process manual orders for dealers', 'Process name changes and business changes for dealers', 'Process orders', 'Process credit applications', 'Automate order generation and integrate compliance checks', 'NLP/LLM processing']\n",
            "['Plan roadmap, design ML systems, implement, test, monitor services', 'Design, develop, and implement ML models', 'Integrate machine learning models into products', 'Contribute to development of advanced ML models, algorithms, datasets', 'Implement NLP techniques', 'Address performance, scalability, governance of ML models', 'Define architecture and build infrastructure for ML solutions', 'Integrate best practices from ML research into systems', 'Build machine learning models', 'Build machine learning models', 'Develop text processing models', 'Design ML models at scale']\n",
            "['Implement advanced control algorithms', 'Developing machine learning algorithms', 'Testing algorithms on data system', 'Algorithm analysis', 'Implement algorithm solutions', 'Designing, developing AI algorithms', 'Algorithm Development', 'Develop algorithms for parallel computation']\n",
            "['feature level work', 'feature validations', 'scenario validation', 'drive regular scenario validation']\n",
            "['ETL Automation (~60%)', 'Front-End Dashboarding (~20%)', 'Generate dashboards', 'Build desktop UI tools for portfolio monitoring', 'Forecasting reports generation']\n",
            "['Migration to cloud infrastructure', 'Assist cloud enablement', 'Cloud computing']\n",
            "['Anticipate customer needs', 'Prepare estimates', 'Automate customer scenarios', 'Consult with customers to identify appropriate Google data management solutions', 'Research and explore usage scenarios', 'Implement customer opt-out choices', 'Respond to needs/questions', 'ServiceNow familiarity']\n",
            "['Execute creative software solutions', 'Drive packaging and deployment strategies', 'Creative software solutions', 'Formulation', 'Standard software solutions execution']\n",
            "['Lead ERP transformation project team', 'Provide direction for software design', 'Lead Software Engineer', 'Participate in project leadership', 'Guide engineering teams in multi-discipline approach', 'Lead complex software engineering projects']\n",
            "['be active team player', 'Collaborate with business groups and external teams', 'Collaborate with strategy teams', 'Collaborating with research staff', 'Collaborate with a dynamic team', 'Leading small team', 'Collaboration with teams', 'Work with staff/volunteers/interns', 'Collaborate with diverse team, foster open communication, shared learning', 'Collaborate with teams', 'Technical leadership on team building and maintaining services for data science and ML at Klaviyo', 'Collaborate with other teams', 'Participate in team building activities', 'Collaborating multidisciplinary teams', 'Collaboration - Work with other teams for seamless communication', 'Collaborating with team members', 'Participates in daily scrums', 'Collaborate with MLOps team']\n",
            "['Prepares day-to-day and month-end close entries', 'Assists with month-end and year-end closing process', 'Assists in preparing working papers for external audit and tax preparation', 'Maintain annual sales plan', 'Month-end Closing']\n",
            "['Help with initial robotic deployments', 'Train deep neural networks', 'Understand training data distributions', 'Deploy trained networks on robotic system', 'Model deployment', 'Deploy machine learning models', 'Train/deploy AI models', 'Develop tools for training, testing, serving, and monitoring models', 'Use large language model APIs']\n",
            "['Drive awareness of new technologies', 'Create new strategies', 'Drive innovative thinking', 'Identify new business opportunities', 'Innovate new ways']\n",
            "['Mentorship', 'Provide technical guidance and mentorship', 'Provide academic support through tutoring', 'Contribute to mentoring junior team members, foster growth', 'Mentor junior developers', 'Encourage and mentor Open Source contributors', 'Provide technical guidance', 'Mentorship - Provide technical guidance and mentorship']\n",
            "['Assures lab staff has kits accessible', 'Timely packing and shipping of lab samples', 'Maintains supplies for clinical research']\n",
            "['Develop project proposals', 'Follow-up on proposals', 'Taking Initiative on Projects', 'Technical proposals development', 'Product development input']\n",
            "['Passion for local agriculture', 'ARCore', 'ARFoundation']\n",
            "['Perform cost-benefit analyses', 'Audio/Video analysis', 'investigation and analysis', 'Performance analysis', 'Performance analysis', 'Facilitate financial analyses']\n",
            "['Data cleansing direction', 'Prepares complex reconciliations', 'Reconciliation', 'Reconcile chargebacks', 'Comply with data privacy', 'Data Dispute Resolution']\n",
            "['work on python applications', 'Write Python/R scripts', 'Utilize Python programming language', 'Python, Linux, C/C++, Shell Scripting', 'Utilizing Python, AWS, Gitlab', 'Coding in python and React/Java Script']\n",
            "['Architecture definition', 'Drive architecture definition', 'Define technical strategy and architecture']\n",
            "['Communicating research results', 'Translate research findings into actionable insights', 'Communicate effectively with faculty', 'Publish research papers', 'Publish in top-tier conferences, journals, communicate research findings', 'Publishing results']\n",
            "['Content creation', 'Create and deploy campaigns', 'Analyze campaigns', 'Manage paid search campaigns']\n",
            "['Provide customer service', 'Provide customer service', 'Support internal customers']\n",
            "['Makes recommendations for improving accounting processes', 'guidance and/or execution on corrective actions', 'recommendations for design enhancement', 'Analyzing user feedback and making adjustments', 'Recommending and executing program improvements']\n",
            "['Develop metrics for model performance', 'Evaluate and fine-tune models', 'Assess effectiveness of models', 'Perform detailed calculations', 'Evaluate AI-generated code', 'Research and apply large-scale models', 'Optimize and fine-tune existing training and inference platform']\n",
            "['Conduct testing and debugging of software components', 'Test/debug system software']\n",
            "['Research industry directions', 'External research funding', 'Contribute to advanced technical research', 'Engage in interdisciplinary research efforts for high-impact outcomes', 'Conduct research on advanced techniques']\n",
            "['Contribute to scientific code development', 'Contribute to scientific processing code', 'Refine aerospace/scientific software', 'Write research code', 'Designing qubit devices for error rates, qubit physics modeling, communication with team']\n",
            "['Develop components for data collection', 'Development of EDA software tools and flows', 'Design and develop software systems for research and production processes', 'Assist in building efficient tools for data organization and visualization', 'PySpark/Databricks programming', 'Develop software for data processing', 'Develop software for earth observation data', 'software design and development on complex, tactical geophysical systems', 'Develop data quality metrics', 'Develop software for large datasets', 'Developing software for finance industry']\n",
            "['Partner with developers', 'Collaborate with DevOps', 'Collaborate with stakeholders', 'Contribute to DevOps methodology', 'Participate in meetings', 'Collaborate with stakeholders', 'Collaborate with stakeholders for feedback on software solutions', 'Collaborate with stakeholders', 'Create inclusive culture']\n",
            "['Write well designed code with automated testing', 'C++ Developer', 'debugging in C++', 'Develop Design Rule Check software', 'Write robust test cases', 'code and unit testing', 'Develop, design, test software of embedded devices/systems', 'Software design, coding, testing, debugging', 'Ensuring software reliability', 'Guide development with C++', 'Design, code, build and test algorithms']\n",
            "['develop UI front-end', 'Create web-based interfaces', 'UX design', 'Design and build front-end systems']\n",
            "['Lead prototyping vehicles engineering process', 'Lead product team', 'Research and Development', 'Lead development activities', 'Lead modernization initiatives']\n",
            "['N/A', 'N/A']\n",
            "['Research trading strategies', 'Enhance existing strategies', 'Developing low latency trading systems', 'Gaining exposure to Pricing, Risk, and Trade Management functions', 'Translating trading strategies']\n",
            "['building automation', 'Maintenance automation', 'Maintainability analysis', 'Assist with security automation', 'Automation - Develop and maintain automated processes']\n",
            "['Design and implement network connectivity', 'Maintain applications and connections', 'Manage inbound and outbound calls and email correspondence', 'Designing and maintaining software services']\n",
            "['Create demos/systems to highlight AI innovations, foster collaboration', 'Initiate proof of concept', 'Demonstrate proof of concept']\n",
            "['Functional expert for SAP Analytics Cloud (SAC)', 'DRM implementation', 'Domain expert in RTML serving technology']\n",
            "['Operations and maintenance of Data.gov websites', 'Maintain and monitor customer portals on Generac websites', 'Maintain marketing and servicing websites']\n",
            "['Identify gaps in AR hardware roadmap']\n",
            "['integrate software/hardware components', 'Integrate software components', 'Design scalable software components', 'Scalability - Architect and implement scalable solutions']\n",
            "['Design/Document Cybersecurity features', 'Validate Cybersecurity features', 'Identify Cybersecurity risks', 'Perform vulnerability assessments']\n",
            "['Manage customer relationships', 'Develop new customer relationships', 'Develop supplier relationships', 'Relationship development']\n",
            "['Content calendar management', 'Scheduling', 'Assists with scheduling appointments', 'Organizes backlog for time-phasing']\n",
            "['One-to-one and small group instruction', 'Implement lesson plans']\n",
            "['Build scalable, automated workflows', 'Workstream planning', 'Design, develop, maintain NWP workflow features']\n",
            "['Map Data Center workloads', 'Identify appropriate workloads', 'Manage Databases workloads within assigned solutions and region', \"Lead field teams and Databases counterparts to drive demand, accelerate execution, and bring real digital transformation through Google's Databases Platform\"]\n",
            "['Handle emergencies', 'Transportation of passengers', 'Dispatching']\n",
            "['Test complex data pipelines', 'Build data pipelines', 'Build bioinformatics pipelines', 'Ensure pipeline flexibility', 'Design data pipelines', 'Create data preprocessing pipelines']\n",
            "['Evangelize architectural solutions', 'Provide reliable solutions', 'Solutions engineering', 'Solution definition', 'Solution Development - Hands-on Prototyping - Strategy - Collaboration - Mentoring', 'Work alongside BE Engineers']\n",
            "['Design chatbot structure', 'Analyze chatbot data']\n",
            "['Use Jira or qTest for tracking', 'Automate processes', 'Automate testing process', 'Create automation scripts', 'Prepare test execution plan']\n"
          ]
        }
      ],
      "source": [
        "# Get names of phrases in a given cluster (e.g., cluster 0)\n",
        "for i in range(100):\n",
        "  desired_cluster = i\n",
        "  phrases_in_cluster = df.loc[df['cluster_label'] == desired_cluster, 'phrase'].tolist()\n",
        "  print(phrases_in_cluster)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anJAqXsVf48l"
      },
      "source": [
        "I feel like we are very much on the right track. The next step I will take will be do what we just did, creating a mapping of words to embedding space, and then clustering them. I will probably choose a substantially larger number of clusters since there are about 15 columns with phrases. I'll probably choose somewhere between 100 and 1500, but closer to 100. Possibly 300. First we specify exactly which columns have lists of phrases, because some like the salary columns just have a number.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "g_-AJs6Dh_nF",
        "outputId": "5a43bd9e-ba7f-4b8c-c0ae-b656e9764e26"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 107,\n  \"fields\": [\n    {\n      \"column\": \"employment_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job_function\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description_of_product/service\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"industries\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"position_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"broader_role_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"company\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"responsibilities\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"goals/objectives\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name_of_department/team\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"required_qualifications\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preferred_qualifications\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"benefits\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"work_arrangement\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 67,\n        \"samples\": [\n          \"Sunnyvale\",\n          \"Boulder\",\n          \"Dallas-Fort Worth\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"VA\",\n          \"FL\",\n          \"WA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"United States\",\n          \"N/A\",\n          \"USA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_salary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          70,\n          181.145,\n          170\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_salary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          100,\n          288,\n          93.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"0\",\n        \"max\": \"3\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2\",\n          \"0\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-79cd78e1-8f62-4d25-be6e-595da0b0c991\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>employment_type</th>\n",
              "      <th>job_function</th>\n",
              "      <th>description_of_product/service</th>\n",
              "      <th>industries</th>\n",
              "      <th>position_name</th>\n",
              "      <th>broader_role_name</th>\n",
              "      <th>company</th>\n",
              "      <th>responsibilities</th>\n",
              "      <th>goals/objectives</th>\n",
              "      <th>name_of_department/team</th>\n",
              "      <th>required_qualifications</th>\n",
              "      <th>preferred_qualifications</th>\n",
              "      <th>benefits</th>\n",
              "      <th>work_arrangement</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "      <th>min_salary</th>\n",
              "      <th>max_salary</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[design-led software development, end-to-end d...</td>\n",
              "      <td>[Business Consulting, Services]</td>\n",
              "      <td>[Python Software Engineer (Robotics/Mechatroni...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Fresh Consulting]</td>\n",
              "      <td>[integrate software/hardware components, devel...</td>\n",
              "      <td>[manage delivery of high-quality work]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[0-1+ years experience, Python skills, program...</td>\n",
              "      <td>[clear communication, outside the box thinking...</td>\n",
              "      <td>[100% Medical, PTO, Holiday Pay, 401K Plan]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>Redmond</td>\n",
              "      <td>WA</td>\n",
              "      <td>USA</td>\n",
              "      <td>62.4</td>\n",
              "      <td>93.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Design, Art/Creative, Information Technology]</td>\n",
              "      <td>[Surgical Robotics Systems]</td>\n",
              "      <td>[Biotechnology Research, Pharmaceutical Manufa...</td>\n",
              "      <td>[Robotics Engineer]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Barrington James]</td>\n",
              "      <td>[Contribute to cutting-edge robotic systems, C...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Bachelor's, Master's, or Ph.D. in Robotics, M...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>New York</td>\n",
              "      <td></td>\n",
              "      <td>United States</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Information Technology, Consulting, Engineering]</td>\n",
              "      <td>[Amazon Robotics builds high-performance, real...</td>\n",
              "      <td>[Software Development, IT Services, IT Consult...</td>\n",
              "      <td>[SDE - Amazon Robotics]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Amazon]</td>\n",
              "      <td>[Help with initial robotic deployments, Plan r...</td>\n",
              "      <td>[Build high-performance robotic systems, Inven...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[3+ years professional software development ex...</td>\n",
              "      <td>[3+ years full software development life cycle...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>North Reading</td>\n",
              "      <td>MA</td>\n",
              "      <td>USA</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[Credit scoring models]</td>\n",
              "      <td>[Financial Services, Capital Markets, IT Servi...</td>\n",
              "      <td>[Senior Software Engineer]</td>\n",
              "      <td>[Software Engineer]</td>\n",
              "      <td>[VantageScore®]</td>\n",
              "      <td>[Application Development, Collaboration, Mento...</td>\n",
              "      <td>[Building public APIs]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Bachelor's degree, Master's degree, Computer ...</td>\n",
              "      <td>[Quantitative applications, Fintech experience...</td>\n",
              "      <td>[401(K) match, Flexible Time Off, 12 Paid Holi...</td>\n",
              "      <td>[Hybrid]</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>CA</td>\n",
              "      <td>USA</td>\n",
              "      <td>150</td>\n",
              "      <td>200</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Quality Assurance, Information T...</td>\n",
              "      <td>[Large-scale distributed software applications...</td>\n",
              "      <td>[IT Services, IT Consulting]</td>\n",
              "      <td>[Software Engineer in Test]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Optomi]</td>\n",
              "      <td>[Build and maintain automated test infrastruct...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[5+ years of test automation experience, Profi...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>Dallas-Fort Worth</td>\n",
              "      <td>TX</td>\n",
              "      <td>USA</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79cd78e1-8f62-4d25-be6e-595da0b0c991')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79cd78e1-8f62-4d25-be6e-595da0b0c991 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79cd78e1-8f62-4d25-be6e-595da0b0c991');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f203bf87-ff10-413d-9579-3cc1e1deefe9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f203bf87-ff10-413d-9579-3cc1e1deefe9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f203bf87-ff10-413d-9579-3cc1e1deefe9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  employment_type                                       job_function  \\\n",
              "0     [Full-time]              [Engineering, Information Technology]   \n",
              "1     [Full-time]     [Design, Art/Creative, Information Technology]   \n",
              "2     [Full-time]  [Information Technology, Consulting, Engineering]   \n",
              "3     [Full-time]              [Engineering, Information Technology]   \n",
              "4     [Full-time]  [Engineering, Quality Assurance, Information T...   \n",
              "\n",
              "                      description_of_product/service  \\\n",
              "0  [design-led software development, end-to-end d...   \n",
              "1                        [Surgical Robotics Systems]   \n",
              "2  [Amazon Robotics builds high-performance, real...   \n",
              "3                            [Credit scoring models]   \n",
              "4  [Large-scale distributed software applications...   \n",
              "\n",
              "                                          industries  \\\n",
              "0                    [Business Consulting, Services]   \n",
              "1  [Biotechnology Research, Pharmaceutical Manufa...   \n",
              "2  [Software Development, IT Services, IT Consult...   \n",
              "3  [Financial Services, Capital Markets, IT Servi...   \n",
              "4                       [IT Services, IT Consulting]   \n",
              "\n",
              "                                       position_name    broader_role_name  \\\n",
              "0  [Python Software Engineer (Robotics/Mechatroni...                [N/A]   \n",
              "1                                [Robotics Engineer]                [N/A]   \n",
              "2                            [SDE - Amazon Robotics]                [N/A]   \n",
              "3                         [Senior Software Engineer]  [Software Engineer]   \n",
              "4                        [Software Engineer in Test]                [N/A]   \n",
              "\n",
              "              company                                   responsibilities  \\\n",
              "0  [Fresh Consulting]  [integrate software/hardware components, devel...   \n",
              "1  [Barrington James]  [Contribute to cutting-edge robotic systems, C...   \n",
              "2            [Amazon]  [Help with initial robotic deployments, Plan r...   \n",
              "3     [VantageScore®]  [Application Development, Collaboration, Mento...   \n",
              "4            [Optomi]  [Build and maintain automated test infrastruct...   \n",
              "\n",
              "                                    goals/objectives name_of_department/team  \\\n",
              "0             [manage delivery of high-quality work]                   [N/A]   \n",
              "1                                                NaN                     NaN   \n",
              "2  [Build high-performance robotic systems, Inven...                   [N/A]   \n",
              "3                             [Building public APIs]                   [N/A]   \n",
              "4                                              [N/A]                   [N/A]   \n",
              "\n",
              "                             required_qualifications  \\\n",
              "0  [0-1+ years experience, Python skills, program...   \n",
              "1  [Bachelor's, Master's, or Ph.D. in Robotics, M...   \n",
              "2  [3+ years professional software development ex...   \n",
              "3  [Bachelor's degree, Master's degree, Computer ...   \n",
              "4  [5+ years of test automation experience, Profi...   \n",
              "\n",
              "                            preferred_qualifications  \\\n",
              "0  [clear communication, outside the box thinking...   \n",
              "1                                              [N/A]   \n",
              "2  [3+ years full software development life cycle...   \n",
              "3  [Quantitative applications, Fintech experience...   \n",
              "4                                              [N/A]   \n",
              "\n",
              "                                            benefits work_arrangement  \\\n",
              "0        [100% Medical, PTO, Holiday Pay, 401K Plan]            [N/A]   \n",
              "1                                              [N/A]            [N/A]   \n",
              "2                                              [N/A]        [On-site]   \n",
              "3  [401(K) match, Flexible Time Off, 12 Paid Holi...         [Hybrid]   \n",
              "4                                              [N/A]        [On-site]   \n",
              "\n",
              "                city state        country min_salary max_salary rating  \n",
              "0            Redmond    WA            USA       62.4       93.6      1  \n",
              "1           New York        United States        N/A        N/A      2  \n",
              "2      North Reading    MA            USA        N/A        N/A      2  \n",
              "3      San Francisco    CA            USA        150        200      3  \n",
              "4  Dallas-Fort Worth    TX            USA        N/A        N/A      1  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM_qmsVtiRdW"
      },
      "source": [
        "The columns we want to deal with are job_function, description_of_product/service, industries, position_name, broader_role_name, responsibilities, goals/objectives, required_qualifications, preferred_qualifications, benefits, work_arrangement. For now we will not deal with employment_type, company, name_of_department/team, work_arrangement, location, or salary columns. We will probably choose a different representation of the data for those columns, but like this it will likely involved One-hot encoded vectors for the different classes.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "id": "h4aLROygjsKb",
        "outputId": "31141037-d691-44fa-99c1-57999e9f06a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-df95fe132540>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-5-df95fe132540>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-5-df95fe132540>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-5-df95fe132540>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-5-df95fe132540>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-5-df95fe132540>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-5-df95fe132540>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-5-df95fe132540>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-5-df95fe132540>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-5-df95fe132540>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-5-df95fe132540>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-30e5f1e5-d5e1-4311-868e-72f9e28ac518\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>employment_type</th>\n",
              "      <th>job_function</th>\n",
              "      <th>description_of_product/service</th>\n",
              "      <th>industries</th>\n",
              "      <th>position_name</th>\n",
              "      <th>broader_role_name</th>\n",
              "      <th>company</th>\n",
              "      <th>responsibilities</th>\n",
              "      <th>goals/objectives</th>\n",
              "      <th>name_of_department/team</th>\n",
              "      <th>...</th>\n",
              "      <th>description_of_product/service_vectors</th>\n",
              "      <th>industries_vectors</th>\n",
              "      <th>position_name_vectors</th>\n",
              "      <th>broader_role_name_vectors</th>\n",
              "      <th>responsibilities_vectors</th>\n",
              "      <th>goals/objectives_vectors</th>\n",
              "      <th>required_qualifications_vectors</th>\n",
              "      <th>preferred_qualifications_vectors</th>\n",
              "      <th>benefits_vectors</th>\n",
              "      <th>work_arrangement_vectors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[design-led software development, end-to-end d...</td>\n",
              "      <td>[Business Consulting, Services]</td>\n",
              "      <td>[Python Software Engineer (Robotics/Mechatroni...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Fresh Consulting]</td>\n",
              "      <td>[integrate software/hardware components, devel...</td>\n",
              "      <td>[manage delivery of high-quality work]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>...</td>\n",
              "      <td>[[-0.008950297, -0.024362305, -0.028943209, -0...</td>\n",
              "      <td>[[-0.0140377255, -0.0013513202, -0.0045068203,...</td>\n",
              "      <td>[[0.002333824, -0.001959742, -0.07332361, -0.0...</td>\n",
              "      <td>[[-0.018589148, 0.029029015, -0.02251458, 0.02...</td>\n",
              "      <td>[[-0.019170765, 0.0026787166, -0.028830336, 0....</td>\n",
              "      <td>[[0.0036595012, 0.0032233356, -0.027429527, 0....</td>\n",
              "      <td>[[-0.016750332, 0.008516802, -0.020949557, -0....</td>\n",
              "      <td>[[-0.028760055, 0.022037888, -0.011516191, 0.0...</td>\n",
              "      <td>[[-0.00347977, 0.0042353524, -0.0025861228, 0....</td>\n",
              "      <td>[[-0.018589148, 0.029029015, -0.02251458, 0.02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Design, Art/Creative, Information Technology]</td>\n",
              "      <td>[Surgical Robotics Systems]</td>\n",
              "      <td>[Biotechnology Research, Pharmaceutical Manufa...</td>\n",
              "      <td>[Robotics Engineer]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Barrington James]</td>\n",
              "      <td>[Contribute to cutting-edge robotic systems, C...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>[[0.0034268484, 0.011781204, -0.039095383, 0.0...</td>\n",
              "      <td>[[0.0033113444, -0.0149269365, 0.0056012385, -...</td>\n",
              "      <td>[[-0.019822646, 0.009298457, -0.05740203, -0.0...</td>\n",
              "      <td>[[-0.018589148, 0.029029015, -0.02251458, 0.02...</td>\n",
              "      <td>[[0.0024299917, 0.0146516925, -0.056839146, -0...</td>\n",
              "      <td>[[-0.010837877, -0.01464083, -0.0032206476, -0...</td>\n",
              "      <td>[[-0.028160315, -0.007769336, -0.03255474, -0....</td>\n",
              "      <td>[[-0.018589148, 0.029029015, -0.02251458, 0.02...</td>\n",
              "      <td>[[-0.018589148, 0.029029015, -0.02251458, 0.02...</td>\n",
              "      <td>[[-0.018589148, 0.029029015, -0.02251458, 0.02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Information Technology, Consulting, Engineering]</td>\n",
              "      <td>[Amazon Robotics builds high-performance, real...</td>\n",
              "      <td>[Software Development, IT Services, IT Consult...</td>\n",
              "      <td>[SDE - Amazon Robotics]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Amazon]</td>\n",
              "      <td>[Help with initial robotic deployments, Plan r...</td>\n",
              "      <td>[Build high-performance robotic systems, Inven...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>...</td>\n",
              "      <td>[[0.0007271255, 0.024548363, -0.07057249, 0.00...</td>\n",
              "      <td>[[-0.015271782, -0.01995279, -0.031256113, -0....</td>\n",
              "      <td>[[-0.009249948, 0.038769644, -0.04732987, 0.00...</td>\n",
              "      <td>[[-0.018589148, 0.029029015, -0.02251458, 0.02...</td>\n",
              "      <td>[[0.011741049, 0.019328365, -0.03054015, -0.02...</td>\n",
              "      <td>[[-0.007027852, 0.011741031, -0.047570717, -0....</td>\n",
              "      <td>[[-0.0033205217, -0.013847235, -0.021546723, -...</td>\n",
              "      <td>[[-0.0010390067, 0.0038722185, -0.0071029966, ...</td>\n",
              "      <td>[[-0.018589148, 0.029029015, -0.02251458, 0.02...</td>\n",
              "      <td>[[-0.01998716, 0.011007821, -0.030419441, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Information Technology]</td>\n",
              "      <td>[Credit scoring models]</td>\n",
              "      <td>[Financial Services, Capital Markets, IT Servi...</td>\n",
              "      <td>[Senior Software Engineer]</td>\n",
              "      <td>[Software Engineer]</td>\n",
              "      <td>[VantageScore®]</td>\n",
              "      <td>[Application Development, Collaboration, Mento...</td>\n",
              "      <td>[Building public APIs]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>...</td>\n",
              "      <td>[[-0.019173436, -0.008519623, -0.016878087, -0...</td>\n",
              "      <td>[[-0.024509065, -0.016307179, -0.008852061, -0...</td>\n",
              "      <td>[[-0.0034123058, -0.026940402, -0.048339102, -...</td>\n",
              "      <td>[[-0.018150892, -0.015882488, -0.05580328, -0....</td>\n",
              "      <td>[[0.0023286135, -0.0104020545, -0.023544982, -...</td>\n",
              "      <td>[[0.012590345, 0.0018924024, -0.021819007, -0....</td>\n",
              "      <td>[[-0.0143035995, -0.029012425, 0.002238299, -0...</td>\n",
              "      <td>[[0.010022234, 0.0025239405, 0.003250777, -0.0...</td>\n",
              "      <td>[[0.018867146, 0.002178848, -0.016457036, 0.04...</td>\n",
              "      <td>[[-0.037121613, -0.0051279706, -0.02652636, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Full-time]</td>\n",
              "      <td>[Engineering, Quality Assurance, Information T...</td>\n",
              "      <td>[Large-scale distributed software applications...</td>\n",
              "      <td>[IT Services, IT Consulting]</td>\n",
              "      <td>[Software Engineer in Test]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[Optomi]</td>\n",
              "      <td>[Build and maintain automated test infrastruct...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>...</td>\n",
              "      <td>[[-0.008030059, 2.4834357e-05, -0.019593397, 0...</td>\n",
              "      <td>[[-0.023050034, -0.018900383, -0.016749054, -0...</td>\n",
              "      <td>[[-0.0038239043, -0.007742508, -0.034746215, -...</td>\n",
              "      <td>[[-0.018589148, 0.029029015, -0.02251458, 0.02...</td>\n",
              "      <td>[[-0.013181117, 0.0006007539, -0.035469025, 0....</td>\n",
              "      <td>[[-0.018589148, 0.029029015, -0.02251458, 0.02...</td>\n",
              "      <td>[[0.000843747, 0.00091183337, -0.019551175, 0....</td>\n",
              "      <td>[[-0.018589148, 0.029029015, -0.02251458, 0.02...</td>\n",
              "      <td>[[-0.018589148, 0.029029015, -0.02251458, 0.02...</td>\n",
              "      <td>[[-0.01998716, 0.011007821, -0.030419441, -0.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30e5f1e5-d5e1-4311-868e-72f9e28ac518')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30e5f1e5-d5e1-4311-868e-72f9e28ac518 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30e5f1e5-d5e1-4311-868e-72f9e28ac518');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fccb6ce1-697a-4d9e-88d9-58ec7a6b6f54\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fccb6ce1-697a-4d9e-88d9-58ec7a6b6f54')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fccb6ce1-697a-4d9e-88d9-58ec7a6b6f54 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  employment_type                                       job_function  \\\n",
              "0     [Full-time]              [Engineering, Information Technology]   \n",
              "1     [Full-time]     [Design, Art/Creative, Information Technology]   \n",
              "2     [Full-time]  [Information Technology, Consulting, Engineering]   \n",
              "3     [Full-time]              [Engineering, Information Technology]   \n",
              "4     [Full-time]  [Engineering, Quality Assurance, Information T...   \n",
              "\n",
              "                      description_of_product/service  \\\n",
              "0  [design-led software development, end-to-end d...   \n",
              "1                        [Surgical Robotics Systems]   \n",
              "2  [Amazon Robotics builds high-performance, real...   \n",
              "3                            [Credit scoring models]   \n",
              "4  [Large-scale distributed software applications...   \n",
              "\n",
              "                                          industries  \\\n",
              "0                    [Business Consulting, Services]   \n",
              "1  [Biotechnology Research, Pharmaceutical Manufa...   \n",
              "2  [Software Development, IT Services, IT Consult...   \n",
              "3  [Financial Services, Capital Markets, IT Servi...   \n",
              "4                       [IT Services, IT Consulting]   \n",
              "\n",
              "                                       position_name    broader_role_name  \\\n",
              "0  [Python Software Engineer (Robotics/Mechatroni...                [N/A]   \n",
              "1                                [Robotics Engineer]                [N/A]   \n",
              "2                            [SDE - Amazon Robotics]                [N/A]   \n",
              "3                         [Senior Software Engineer]  [Software Engineer]   \n",
              "4                        [Software Engineer in Test]                [N/A]   \n",
              "\n",
              "              company                                   responsibilities  \\\n",
              "0  [Fresh Consulting]  [integrate software/hardware components, devel...   \n",
              "1  [Barrington James]  [Contribute to cutting-edge robotic systems, C...   \n",
              "2            [Amazon]  [Help with initial robotic deployments, Plan r...   \n",
              "3     [VantageScore®]  [Application Development, Collaboration, Mento...   \n",
              "4            [Optomi]  [Build and maintain automated test infrastruct...   \n",
              "\n",
              "                                    goals/objectives name_of_department/team  \\\n",
              "0             [manage delivery of high-quality work]                   [N/A]   \n",
              "1                                                NaN                     NaN   \n",
              "2  [Build high-performance robotic systems, Inven...                   [N/A]   \n",
              "3                             [Building public APIs]                   [N/A]   \n",
              "4                                              [N/A]                   [N/A]   \n",
              "\n",
              "   ...             description_of_product/service_vectors  \\\n",
              "0  ...  [[-0.008950297, -0.024362305, -0.028943209, -0...   \n",
              "1  ...  [[0.0034268484, 0.011781204, -0.039095383, 0.0...   \n",
              "2  ...  [[0.0007271255, 0.024548363, -0.07057249, 0.00...   \n",
              "3  ...  [[-0.019173436, -0.008519623, -0.016878087, -0...   \n",
              "4  ...  [[-0.008030059, 2.4834357e-05, -0.019593397, 0...   \n",
              "\n",
              "                                  industries_vectors  \\\n",
              "0  [[-0.0140377255, -0.0013513202, -0.0045068203,...   \n",
              "1  [[0.0033113444, -0.0149269365, 0.0056012385, -...   \n",
              "2  [[-0.015271782, -0.01995279, -0.031256113, -0....   \n",
              "3  [[-0.024509065, -0.016307179, -0.008852061, -0...   \n",
              "4  [[-0.023050034, -0.018900383, -0.016749054, -0...   \n",
              "\n",
              "                               position_name_vectors  \\\n",
              "0  [[0.002333824, -0.001959742, -0.07332361, -0.0...   \n",
              "1  [[-0.019822646, 0.009298457, -0.05740203, -0.0...   \n",
              "2  [[-0.009249948, 0.038769644, -0.04732987, 0.00...   \n",
              "3  [[-0.0034123058, -0.026940402, -0.048339102, -...   \n",
              "4  [[-0.0038239043, -0.007742508, -0.034746215, -...   \n",
              "\n",
              "                           broader_role_name_vectors  \\\n",
              "0  [[-0.018589148, 0.029029015, -0.02251458, 0.02...   \n",
              "1  [[-0.018589148, 0.029029015, -0.02251458, 0.02...   \n",
              "2  [[-0.018589148, 0.029029015, -0.02251458, 0.02...   \n",
              "3  [[-0.018150892, -0.015882488, -0.05580328, -0....   \n",
              "4  [[-0.018589148, 0.029029015, -0.02251458, 0.02...   \n",
              "\n",
              "                            responsibilities_vectors  \\\n",
              "0  [[-0.019170765, 0.0026787166, -0.028830336, 0....   \n",
              "1  [[0.0024299917, 0.0146516925, -0.056839146, -0...   \n",
              "2  [[0.011741049, 0.019328365, -0.03054015, -0.02...   \n",
              "3  [[0.0023286135, -0.0104020545, -0.023544982, -...   \n",
              "4  [[-0.013181117, 0.0006007539, -0.035469025, 0....   \n",
              "\n",
              "                            goals/objectives_vectors  \\\n",
              "0  [[0.0036595012, 0.0032233356, -0.027429527, 0....   \n",
              "1  [[-0.010837877, -0.01464083, -0.0032206476, -0...   \n",
              "2  [[-0.007027852, 0.011741031, -0.047570717, -0....   \n",
              "3  [[0.012590345, 0.0018924024, -0.021819007, -0....   \n",
              "4  [[-0.018589148, 0.029029015, -0.02251458, 0.02...   \n",
              "\n",
              "                     required_qualifications_vectors  \\\n",
              "0  [[-0.016750332, 0.008516802, -0.020949557, -0....   \n",
              "1  [[-0.028160315, -0.007769336, -0.03255474, -0....   \n",
              "2  [[-0.0033205217, -0.013847235, -0.021546723, -...   \n",
              "3  [[-0.0143035995, -0.029012425, 0.002238299, -0...   \n",
              "4  [[0.000843747, 0.00091183337, -0.019551175, 0....   \n",
              "\n",
              "                    preferred_qualifications_vectors  \\\n",
              "0  [[-0.028760055, 0.022037888, -0.011516191, 0.0...   \n",
              "1  [[-0.018589148, 0.029029015, -0.02251458, 0.02...   \n",
              "2  [[-0.0010390067, 0.0038722185, -0.0071029966, ...   \n",
              "3  [[0.010022234, 0.0025239405, 0.003250777, -0.0...   \n",
              "4  [[-0.018589148, 0.029029015, -0.02251458, 0.02...   \n",
              "\n",
              "                                    benefits_vectors  \\\n",
              "0  [[-0.00347977, 0.0042353524, -0.0025861228, 0....   \n",
              "1  [[-0.018589148, 0.029029015, -0.02251458, 0.02...   \n",
              "2  [[-0.018589148, 0.029029015, -0.02251458, 0.02...   \n",
              "3  [[0.018867146, 0.002178848, -0.016457036, 0.04...   \n",
              "4  [[-0.018589148, 0.029029015, -0.02251458, 0.02...   \n",
              "\n",
              "                            work_arrangement_vectors  \n",
              "0  [[-0.018589148, 0.029029015, -0.02251458, 0.02...  \n",
              "1  [[-0.018589148, 0.029029015, -0.02251458, 0.02...  \n",
              "2  [[-0.01998716, 0.011007821, -0.030419441, -0.0...  \n",
              "3  [[-0.037121613, -0.0051279706, -0.02652636, -0...  \n",
              "4  [[-0.01998716, 0.011007821, -0.030419441, -0.0...  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-large\")\n",
        "model = AutoModel.from_pretrained(\"thenlper/gte-large\")\n",
        "\n",
        "def average_pool(last_hidden_states: Tensor,\n",
        "                 attention_mask: Tensor) -> Tensor:\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "cols = ['job_function', 'description_of_product/service', 'industries', 'position_name', 'broader_role_name',\n",
        "        'responsibilities', 'goals/objectives', 'required_qualifications', 'preferred_qualifications', 'benefits', 'work_arrangement']\n",
        "\n",
        "phrases = []\n",
        "row_labels = []\n",
        "phrase_lookup = {}\n",
        "for col in cols:\n",
        "  new_col_data = []\n",
        "  for index, value in df[col].iteritems():\n",
        "    if type(value) == list:\n",
        "      # Tokenize the input texts\n",
        "      for phrase in value:\n",
        "        phrases.append(phrase)\n",
        "        row_labels.append(index)\n",
        "    else:\n",
        "      phrases.append(str(value))\n",
        "      row_labels.append(index)\n",
        "      value = [str(value)]\n",
        "    batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model(**batch_dict)\n",
        "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "    # (Optionally) normalize embeddings\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "  df[f'{col}_vectors'] = new_col_data\n",
        "\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arvGyFLOmqhE"
      },
      "outputs": [],
      "source": [
        "L = ['h' , 'j', 2]\n",
        "assert type(L) == list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pYjU9sTFmH9V",
        "outputId": "2bf93082-01d9-49b7-d9c9-4a82e5c2b494"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2581,\n  \"fields\": [\n    {\n      \"column\": \"phrase\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1849,\n        \"samples\": [\n          \"handling end-to-end delivery\",\n          \"Understanding of cybersecurity concepts\",\n          \"Initial defect analysis - Triage defects - Monitor defect dashboard - Create reports - Work with cross-functional teams - Drive defect triage calls\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster_label\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          265,\n          181,\n          267\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-06908462-b608-41f6-9ab8-3031ef8733ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase</th>\n",
              "      <th>cluster_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Engineering</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Information Technology</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Design</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Art/Creative</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Information Technology</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06908462-b608-41f6-9ab8-3031ef8733ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06908462-b608-41f6-9ab8-3031ef8733ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06908462-b608-41f6-9ab8-3031ef8733ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d3a0d7a7-1ad6-4336-9191-181875ddfc73\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3a0d7a7-1ad6-4336-9191-181875ddfc73')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d3a0d7a7-1ad6-4336-9191-181875ddfc73 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                   phrase  cluster_label\n",
              "0             Engineering             14\n",
              "1  Information Technology              9\n",
              "2                  Design            113\n",
              "3            Art/Creative            257\n",
              "4  Information Technology              9"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "8CUSjDiHk53m",
        "outputId": "cde15224-33f8-4bb5-829e-a422867432f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=500, random_state=57)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=500, random_state=57)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KMeans(n_clusters=500, random_state=57)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "vector_cols = [f'{col}_vectors' for col in cols]\n",
        "phrase_vecs_list = []\n",
        "for col in vector_cols:\n",
        "  for i in df[col]:\n",
        "    for j in i:\n",
        "      phrase_vecs_list.append(j)\n",
        "kmeans = KMeans(n_clusters=500, random_state=57)\n",
        "kmeans.fit(phrase_vecs_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMmvSx9sxRIz",
        "outputId": "da9ef2b7-0cf9-44f1-e550-d5004d4298ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A']\n",
            "['Strong programming skills', 'Strong software development background', 'Strong programming skills', 'Strong SDLC understanding', 'Strong technical background', 'Strong background in CS and math']\n",
            "['Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Technology', 'Information Services and Technology']\n",
            "['Interdisciplinary Artificial Intelligence Research', 'AI Research', 'Artificial Intelligence', 'AI research', 'Data & AI solutions', 'AI Center', 'AI for Autonomy Lab researches applying AI-related technologies for autonomy systems', 'AI research and deployment', 'Research-driven artificial intelligence company', 'Postdoctoral Research Scientist, Artificial Intelligence (PhD)', 'AI Research Scientist', 'Lead, collaborate, execute innovative AI research projects', 'Expressing AI dedication', 'Report directly into the Head of Artificial Intelligence', 'Solve AI challenges', 'Develop impactful and responsible AI', 'Shape the future of AI', 'Research and demonstrate AI technologies for government customers', 'AI methods', 'AI/ML interest', 'Expertise on AI customer needs', 'Strong publication record in renowned ML and AI venues', 'Expertise in AI research topics and methodologies', 'Advanced education in Computer Science or AI', 'Industry experience in practical application of AI research']\n",
            "['BS in Electrical Engineering, Mechanical Engineering, Computer Science or equivalent', \"Bachelor's degree in Engineering, IS, CS or related field and 4+ years of experience\", 'Degree in Computer Engineering, Electrical Engineering, or Computer Science', \"Bachelor's Degree in Electrical Engineering, Computer Engineering, or Software Engineering\", \"Bachelor's Degree in Aerospace Engineering or related field\", \"Bachelor's Degree in Aerospace Engineering or related field\", 'BS in Computer Engineering, Software Engineering, or Electrical Engineering', \"Bachelor or Master's degree in Computer Vision, Computer Science or Electrical Engineering\"]\n",
            "['Medical/Dental/Vision', 'Medical, dental, vision plans', 'Vision Benefits', 'Medical, Dental, Vision, RX, 401K']\n",
            "['Connects professionals with enterprises', 'Collaborate with business groups and external teams', 'Partner with internal business partners', 'Collaborate with business', 'Collaboration with Quant Researchers and Business Users']\n",
            "['Bonus program', 'Bonuses', 'Quarterly merit bonuses', 'Performance Bonus', 'Referral bonuses', 'Annual bonus potential', 'Bonus and stock options']\n",
            "['Food and Beverage Manufacturing']\n",
            "['Quantitative trading team', 'Algorithmic trading programs', 'Algorithmic trading experience', '3 years experience in developing trading algorithms', 'Familiarity with trading platforms, APIs, and quantitative analysis tools', 'Algorithmic trading strategy design experience']\n",
            "['Determine capacity testing', 'Prepare test execution plan', 'Testing', 'Developing test strategies', 'Creating test harnesses', 'Developing test plans', 'Create and test procedures', 'Increase test coverage']\n",
            "['3+ years Python/Java exp', '2 years PostgreSQL exp', '2+ years of experience with programming languages (C, C++, Java, Python, etc.)', '6+ months experience in programming languages like Python, Tcl, C++', '2+ years of C/C++ programming experience', '3+ years of experience in software development using C, C++, and C#', '2+ years development experience in C++, C, Java', '2+ years scripting experience in Python', 'Experience in one or more general purpose languages', '1+ years experience in programming languages', '2+ years experience in programming languages']\n",
            "['On-site', 'On-site', 'On-site', 'On-site', 'On-site', 'On-site', 'Onsite', 'Onsite', '100% Onsite', 'On-site', 'On-site', 'On-site', 'On-site', 'On-site', 'Mainly on-site', 'On-site', 'Onsite', 'On-site', 'On-site, Travel up to 50%', 'On-site', 'On-site', 'On-site internship']\n",
            "['enterprise B2B SaaS solutions', '5 years of experience in SaaS, IaaS, and PaaS sales, or consulting', 'Ability to plan, pitch, and execute a start to finish business and customer transformation strategy that is aligned to cloud and data management', 'Experience in SaaS/Cloud technologies']\n",
            "['Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Engineering', 'Civil Engineering', 'Engineering', 'Engineering', 'Engineering']\n",
            "['Credibility building', 'Communication skills', 'Effective communication skills', 'Strong communication skills', 'Communication skills', 'Strong communication skills', 'Facilitation skills', 'Strong communication and interpersonal skills', 'Communication and presentation skills', 'Strong communication skills', 'Communication and teamwork skills']\n",
            "['Perform cost-benefit analyses', 'Facilitate financial analyses']\n",
            "['Applied machine learning experience', 'Background in machine learning systems', 'Background in Physical Sciences, Computer Sciences, Mathematics', 'Background in machine learning or related fields']\n",
            "['Flexible Time Off', 'Vacation', 'Generous vacation policies', 'Flexible Time Off', 'Flexible Vacation']\n",
            "['Maintain applications and connections', 'Experience handling connections to execution/order management systems']\n",
            "['401(K) match', '401k with employer matching', '401(k) matching', '401(k) match', 'Matching 401k', '401(k) and match', '401(k) with matching', '401k Matching', '401K w/ match']\n",
            "['Collaborate with teams to ensure alignment', 'Collaborate with strategy teams', 'Collaborating with research staff', 'Coordinate with QA team', 'Coordinating with offshore team', 'Collaborate with a dynamic team', 'Collaboration with teams', 'Work with staff/volunteers/interns', 'Collaborate with diverse team, foster open communication, shared learning', 'Collaborate with teams', 'Collaborate with other teams', 'Collaborating with Customer Support, Engineering, Manufacturing', 'Collaborating multidisciplinary teams', 'Collaboration - Work with other teams for seamless communication', 'Collaborating with team members', 'Ability to collaborate effectively in a team environment']\n",
            "['IT Services', 'IT Services', 'IT Services', 'IT Services', 'IT Services', 'IT Services', 'IT Services', 'IT Services', 'IT Services', 'IT Services', 'IT Services', 'IT Services', 'IT Services', 'IT Services']\n",
            "['Software Development', 'software applications', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Software Development', 'Application Development', 'Develop software for data processing']\n",
            "['nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan']\n",
            "['Information Technology - Other - Consulting', 'IT Consulting', 'IT Consulting', 'IT Consulting', 'IT Consulting', 'IT Consulting', 'IT Services and IT Consulting', 'IT Consulting', 'IT Consulting', 'IT Consulting', 'IT Consulting', 'IT Consulting', 'IT Consulting', 'IT Consulting', 'IT Consulting', 'IT Services and IT Consulting', 'IT Consulting']\n",
            "['Hybrid Working Model Available', 'Remote/hybrid work options', 'Hybrid with remote days', 'Hybrid - On-site - Remote', 'Hybrid, on-site, remote?', 'On-site, Remote', 'Hybrid - On-site/Off-site', 'Weekly hybrid onsite component', 'Hybrid, Remote, In-Person', 'Hybrid, on-site, remote']\n",
            "['Training', 'Training devices for military aircraft', 'Training support', 'Trial Support', 'Trains on specific laboratory aspects']\n",
            "['Information', 'Information', 'Information', 'Information', 'Information', 'Information', 'Information', 'Information', 'Information']\n",
            "['Computer Hardware Manufacturing', 'Computer Hardware Manufacturing', 'Computer Hardware Manufacturing', 'Computer Hardware Manufacturing', 'Computer Hardware Manufacturing']\n",
            "['Financial Services', 'Financial Services', 'Financial Services', 'Financial Services', 'Financial Services', 'Financial Services', 'Financial Services', 'Financial Services', 'Financial Services', 'Financial Services', 'Financial Services', 'Financial Services', 'Financial Services', 'Financial Services', 'Financial Services', 'Financial Services', 'Financial Services']\n",
            "['Python skills', 'Python, Bash, SQL proficiency', 'Python expertise', 'Python experience', 'Signal processing expertise', 'Strong Python skills', 'Knowledge in Python', 'Professional development experience in Python and MATLAB', 'Working knowledge of networking, computer/server hardware, python, ansible, virtualization, incident response, security onion', 'More than 5 years of Python proficiency', 'Python proficiency', 'Proficiency in Python programming', 'Python programming skills', 'Technical proficiency in Python (TensorFlow, PyTorch, Keras), Django, Flask, AWS, Docker, Kubernetes, Terraform, Github, MLFlow, PostgreSQL', 'Python proficiency', 'Expertise in Python and Bash']\n",
            "['Deep knowledge of OS/driver software', 'Linux kernel/device drivers']\n",
            "['Analytics for research', 'Higher Education and Research Services', 'Research Services', 'Information Services', 'Research Services', 'Research Services', 'Research Services', 'Research Services', 'Research Services']\n",
            "['Technology', 'Technology', 'Technology', 'Technology', 'Technology', 'Technology', 'Technology', 'Technology', 'Technology', 'Technology', 'Technology', 'Technology', 'Technology', 'Technology', 'Utilize computer vision technology', 'Enhance technology products', 'Technological acuity', 'Technology analysis', 'Tech/gadgets budget']\n",
            "['Solve problems', 'Problem Solving - Identify challenges, propose solutions', 'problem solving skills', 'Strong problem-solving skills', 'Problem-solving skills', 'Problem-solving skills', 'Strong problem-solving skills', 'Problem-solving skills', 'Problem-solving skills', 'Excellent problem-solving skills', 'Ability to analyze and solve problems', 'Problem-solving skills']\n",
            "['Undergrad/grad degree in Computer Science or related field', 'PhD in Computer Vision/ML/Graphics', 'MS in computer science or related field', 'BS/BA in computer science or related field', 'BS/MS/PhD in Computer Science or related field', \"Bachelor's, Master's, or Ph.D. in CS or equivalent\"]\n",
            "['Tuition reimbursement', 'Tuition assistance and hot skill development opportunities', 'Tuition reimbursement', 'Tuition reimbursement', 'Tuition reimbursement', 'Continuing education budgets', 'Tuition reimbursement', 'Tuition Reimbursement', 'Tuition reimbursement']\n",
            "['Quantum computing', 'Quantum Systems', 'Quantum computing system', 'Quantum Computing and Devices', 'Quantum algorithms', 'Quantum error-correction']\n",
            "['Embedded software for Bobcat equipment', 'Embedded Software Engineer', 'Embedded Engineer', 'Embedded Software Engineer', 'Embedded Cybersecurity Software Engineer', 'Embedded Software Engineer II', 'Work with Embedded Open-Source tools', 'Develop, design, test software of embedded devices/systems', 'Develop Embedded Cybersecurity solutions', 'C++ embedded development', 'Embedded systems background', 'Prior embedded software development experience']\n",
            "['Sales Coordinator']\n",
            "['Software engineering opportunity at JPMorgan Chase', 'Bioinformatics Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Staff Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer', 'Software Engineer II - Field Support', 'Software Engineer', 'Software Engineer']\n",
            "['Implement CI/CD pipelines for ML model deployment', 'Hands-on experience in shipping, monitoring, and debugging ML-based projects', 'Experience in deploying data pipelines and ML models in production environments']\n",
            "['Semiconductor Manufacturing', 'Semiconductor Manufacturing', 'Semiconductor Manufacturing']\n",
            "['Create and maintain process documents for team', 'Document deployed processes']\n",
            "['100% Medical', 'Medical Insurance', 'Medical insurance']\n",
            "['Relational databases', 'SQL', 'SQL', 'Oracle']\n",
            "['Local remote']\n",
            "['Design, develop, and refine prompts', 'Design, Develop, Troubleshoot, Architect, Analyze', 'Develop Design Rule Check software']\n",
            "['Sales', 'Sales', 'Sales', 'Sales', 'Sales', 'Sales', 'Selling multi-award-winning software']\n",
            "['Competitive pay', 'Competitive base salary', 'Competitive pay', 'Competitive salary', 'Competitive salary', 'Competitive compensation', 'Competitive salary']\n",
            "['Design', 'Design', 'Design', 'Design', 'Design', 'Client strategy design', 'recommendations for design enhancement', 'UX design', 'UX design']\n",
            "['Drive development of clear requirements', 'Identify security requirements', 'Analyze Business Requirements', 'Requirements Documentation/Software Project Scope', 'Requirements engineering', 'Requirement gathering and documentation', 'Gather requirements for modeling techniques', 'Gather/analyze user requirements', 'Ability to decompose requirements']\n",
            "['Subject Matter Expert in Cookie Management', 'Knowledge of managing cookies, tags, and pixels', 'Experience with external agencies responsible for website management']\n",
            "['Cyber Security services', 'Computer and Network Security', 'Computer and Network Security']\n",
            "['Proficiency in Java coding', 'Programming proficiency', 'Proficiency in C/C++', 'Proficiency in designing software systems', 'Proficiency in programming languages', 'Proficiency in various programming languages', 'Proficient with developer tools', 'Proficiency in additional languages like Swift, Ruby', 'Knowledge of programming/scripting language']\n",
            "['Proficiency in C++, Python, ROS', 'Proficiency in Linux OS and coding skills in Python/C++', 'Experience in C++, Python', 'Proficient in C/C++ or Python', 'Strong Python and C/C++ skills', 'Proficiency in C, familiarity with Python', 'Proficiency in Python and C++']\n",
            "['Data Science Platform empowers data scientists to build machine learning systems', 'Data Scientist', 'Data Science Platform Team', 'Technical leadership on team building and maintaining services for data science and ML at Klaviyo', 'Empower data scientists to build scalable, advanced machine learning systems', 'Understand basic data science concepts']\n",
            "['Education', 'Higher Education', 'Primary and Secondary Education', 'Higher Education', 'Higher Education']\n",
            "['Internet', 'Internet', 'Internet', 'Internet', 'Internet', 'Internet', 'Internet', 'Internet']\n",
            "['Remote', '100% remote with 10% travel may be required', 'Full remote, PST hours', 'Remote', 'Remote', 'Remote', 'remote', 'Remote', 'Remote', 'REMOTE', 'Remote', 'Remote', 'Remote', 'Remote', 'Remote', 'Virtual']\n",
            "['Benefit all of humanity at large', 'Comprehensive benefits program', \"Eligible for Garmin's benefit program\", 'Comprehensive benefits', 'Full Benefits', 'Comprehensive-competitive-inclusive health/financial benefits', 'Comprehensive Health benefits']\n",
            "['Analyst', 'Analyst', 'Analyst', 'Analyst', 'Analyst', 'Analyst', 'Marketing Analyst', 'investigation and analysis', 'Track capacity of analysts']\n",
            "['Scientific Application Programmer', 'Contribute to scientific code development', 'Contribute to scientific processing code']\n",
            "['5+ years FP&A experience']\n",
            "['Paid time off', 'Paid Time Off (PTO)', 'Paid and unpaid time away from work', 'Generous paid time off', 'Flexible paid time off', 'Unlimited time off', 'Unlimited paid time off', 'Paid Volunteer time off', 'Paid Time Off', 'Paid time away from work', 'Paid Time Off']\n",
            "[\"Bachelor's with 5 years experience\", '5+ years professional experience', '5 years experience', '4 years GCP experience', '5 years relevant experience', '1 year medical office experience', '5-10 years professional experience']\n",
            "['Machine Learning Engineer', 'Senior Machine Learning Engineer', 'Machine Learning Engineer', 'Machine Learning SoC Architect', 'Machine Learning Engineer', 'Machine Learning Consultant', 'Machine Learning Systems Engineer', 'Machine Learning Engineer', 'Systems Research Engineer, Machine Learning Systems', 'Machine Learning Engineer', 'Machine Learning Engineer', 'Deep learning engineering']\n",
            "['Proven experience in robotics, control systems, mechatronics', 'Robotics experience with focus on machine learning, computer vision, hardware integration, safety-critical systems']\n",
            "['Deadline oriented', 'Ability to manage competing priorities', 'Ability to meet deadlines']\n",
            "['Integrate machine learning models into products', 'Model deployment', 'Deploy machine learning models', 'Build machine learning models', 'Build machine learning models', '1+ Commercial experience with Machine Learning models']\n",
            "['Generative AI and NLP', 'Generative AI Engineer', 'Generative AI Engineer', 'Gen AI Engineer', 'Experience with generative AI models']\n",
            "['Manage performance testing', 'Performance analysis', 'Performance analysis', 'Orchestration', 'Performance Testing']\n",
            "['Other', 'Other', 'Other', 'Other']\n",
            "['Integrating new technologies into shipping products', 'Containers', 'Containerization experience', 'Familiarity with software containerization']\n",
            "['Set up test pipelines', 'Test complex data pipelines', 'Testing algorithms on data system', 'Experience in testing complex data pipelines', 'Experience building DevSecOps pipeline']\n",
            "['AR Systems Integration Lead', 'Identify gaps in AR hardware roadmap', 'Developing and shipping AR products at scale']\n",
            "['Driver', 'Drive security tests']\n",
            "['C++ Engineer', 'Guide development with C++', 'C++ expertise', 'C++ experience', 'Experience in Fortran, C++, MPI, scientific computing libraries']\n",
            "['Utilize CRM tool', 'Financial Record Keeping', 'Manage client records', 'Record maintenance', 'Showing value to clients']\n",
            "['AI Applications Engineer', 'AI Prompt Engineer', 'Staff AI Software Build and Release Engineer', 'AI Engineer', 'AI Research Engineer', 'AI Application Engineer', 'AI Software Engineer', 'AI Engineer', 'AI-ML Engineer', 'AI Engineer']\n",
            "['Identify appropriate workloads', 'Manage Databases workloads within assigned solutions and region', 'manage delivery of high-quality work', 'Manage workload', 'Multitasking skills']\n",
            "['CICD, REST APIs, Kubernetes', 'Cloud computing knowledge', 'Azure services knowledge', 'Kubernetes knowledge']\n",
            "['Front-End Dashboarding', 'Front-End Dashboarding (~20%)', 'Generate dashboards', 'Looker Dashboards']\n",
            "['Linux system administration', 'Linux internals', 'Linux system programming', 'Linux', 'System administration Unix/Linux']\n",
            "['Identify bottlenecks', 'Optimize platform performance', 'Develop own ideas to optimize platforms', 'Automate next gen platforms']\n",
            "['BSc in STEM, Marketing, Business', \"Bachelor's degree in Marketing, Communications, or related field\"]\n",
            "['Hybrid', 'Hybrid', 'Hybrid', 'Hybrid', 'Hybrid', 'Hybrid', 'Hybrid', 'Hybrid', 'Hybrid', 'Hybrid', 'Hybrid']\n",
            "['Accounting/Auditing', 'Accounting/Auditing', 'Accounting/Auditing', 'Accountant', 'Assists in preparing working papers for external audit and tax preparation', 'AA in Accounting or equivalent']\n",
            "['Finance', 'Finance', 'Finance', 'Finance', 'Finance', 'Finance', 'Finance', 'Financing', 'Real estate', 'Financial programs']\n",
            "['Collaborate with cross-functional teams', 'Collaborate with cross-functional teams', 'Interact with cross-functional teams', 'Collaborate with cross functional teams', 'Collaborate with cross-functional teams', 'Collaborate with cross-functional teams for AI-based product development', 'Collaborate with cross-functional teams', 'Collaborate with cross-functional teams', 'Ability to collaborate with cross-functional teams', 'Build collaborative relationships and work in a cross-functional environment']\n",
            "['Retirement benefits', 'Retirement savings plan', 'Retirement savings plan', 'Retirement plans', 'Retirement', 'Retirement savings plans', 'Retirement contributions', 'Retirement savings plan', 'Retirement savings plans']\n",
            "['Coding', 'Solve coding problems', 'Write research code', 'Develop and maintain code', 'Implement source codes', 'programming skills', 'Programming skills in Java and JavaScript', 'Ability to describe code clearly', 'Excellent coding ability', 'Coding skills']\n",
            "['Documentation', 'Provide documentation', 'User story documentation', 'Documentation and Miscellaneous (20%)', 'building effective documentation', 'Create architecture documentation']\n",
            "['Familiarity with CPU and SoC security']\n",
            "['Create inclusive culture', 'Inclusive and innovative environment']\n",
            "['Knowledge of agile methodologies', 'Knowledge of software methodologies', 'Agile methodologies understanding', 'Exposure to agile methodologies', 'Agile methodologies experience']\n",
            "['Mathematics', 'Physics', 'Mathematics', 'Linear algebra background', 'Exceptional mathematical ability']\n",
            "['Enforce compliance with regulations', 'Interact with industry, standards, suppliers', 'Adhere to industry standards', 'Represent OEF at standards discussions', 'IEC62304 standards']\n",
            "['Identify cost savings initiatives', 'Marketing efforts']\n",
            "['Technical Pre-Sales Support', 'Post-Sales Technical Support']\n",
            "['Science', 'STEM background', 'Scientific research background']\n",
            "['Manage customer relationships', 'Develop new customer relationships', 'Develop supplier relationships', 'Relationship development', 'Grow customer base']\n",
            "[\"Bachelor's degree\", 'Bachelors degree', \"Bachelor's Degree\", \"Bachelor's degree\", \"Bachelor's degree\", \"Bachelor's degree\", \"Bachelor's degree in psychology\", \"Bachelor's degree in engineering\"]\n",
            "['Business Development', 'Business Development', 'Support Business Development activities', 'Support Business Development activities', 'Identify new business opportunities', 'Represent QES with business development']\n",
            "['Equity', 'Equity', 'Stock options', 'Company equity', 'Stock', 'Startup equity']\n",
            "['Real Time ML Service', 'Develop and optimize machine learning models for real-time, edge applications']\n",
            "['Manage CI/CD pipeline and troubleshoot issues', 'CI/CD pipelines', 'Experience with CI/CD tools', 'CI Polygraph or willingness to pass one', 'Familiar with CI/CD process', 'Scripting and CI/CD pipeline experience', 'Experience with CI/CD practices', 'Experience with CICD using tools like Jenkins']\n",
            "['Access to mental health resources', 'Mental health support', 'Mental health support', 'Mental health support', 'Family Planning Support']\n",
            "['Appliances', 'Appliances', 'Appliances', 'Appliances', 'Stocked kitchen']\n",
            "['Mentorship', 'Provide technical guidance and mentorship', 'Collaborate with process technologists', 'Contribute to mentoring junior team members, foster growth', 'Mentor junior developers', 'Provide technical guidance', 'Mentorship - Provide technical guidance and mentorship', 'Strong mentorship and coaching']\n",
            "['Create solutions for complex problems', 'investigate defects', 'Problem identification', 'Comfort with building complex systems', 'Ability to troubleshoot complex systems']\n",
            "['Support academic success of student clients']\n",
            "['Small satellite industry solutions', 'Defense', 'Space Manufacturing', 'Defense and Space Manufacturing', 'Defense and Space Manufacturing', 'Defense and Space Manufacturing', 'Defense and Space Manufacturing', 'Defense and Space Manufacturing', 'Defense and Space Manufacturing']\n",
            "['Experience in Computer Architecture', 'Understanding of processor architectures', 'Experience with modern DL architectures', 'Experience with modern processor architectures']\n",
            "['Troubleshoot applications and make enhancements', 'Debug and fix issues', 'Troubleshoot design and verification issues', 'Technical troubleshooting', 'Troubleshoot software issues', 'troubleshooting', 'Identify and solve issues for uninterrupted service', 'Troubleshooting software-centric electromechanical vehicle systems', 'troubleshooting skills']\n",
            "['Lead development activities', 'Lead modernization initiatives']\n",
            "['Customer Service', 'Customer Service', 'Warranties']\n",
            "['Travel to job sites', 'Adaptability and flexibility', 'Flexible work options', 'Remote work options', 'Flexibility in terms of remote work', 'Remote work flexibility', '100% Remote work', 'Telecommuting up to 40%', 'Potential for remote work 1 day a week']\n",
            "['Educational support', 'Career development support', 'Professional development support', 'Personal & Professional development funds']\n",
            "['End-to-end ownership of decision explanation, fault detection, monitoring, A/B testing, large scale model training, simulation, hardware integration', 'learn new systems/tools', 'Develop tools for training, testing, serving, and monitoring models']\n",
            "['Build desktop UI tools for portfolio monitoring', 'Experience with monitoring tools and data lakes', 'Continuous monitoring knowledge', 'Monitoring tools familiarity', 'Data visualization familiarity', 'Familiarity with DC-source biasing']\n",
            "['cleanest cloud in the industry', 'Assist cloud enablement', 'Cloud native experience', 'Cloud Computing experience', 'Exchange connectivity experience', 'Cloud experience', 'Azure storage experience']\n",
            "['Experience with government contract types', 'Government/industry experience', 'Regulated industry experience']\n",
            "['Scale capability, execution, and experience through Product, Engineering, and Partner teams, and drive customer success through prescriptive activation of internal and external teams', 'Deliver integrated solutions', 'Customize solutions for partners']\n",
            "['Firmware development for hardware media pipeline', 'Firmware Engineer', 'Firmware development', 'Firmware development', 'RTOS development (Free RTOS)']\n",
            "[\"Bachelor's degree or equivalent practical experience\", 'Higher-level degrees can substitute for experience']\n",
            "['Build scalable, automated workflows', 'Automate processes', 'Create automation scripts', 'Maintenance automation', 'Automation - Develop and maintain automated processes']\n",
            "['Assistant/Associate/Full Professor', 'Research Associate', 'Research Assistant', 'Research Assistant']\n",
            "['Develop project proposals', 'Follow-up on proposals', 'Technical proposals development']\n",
            "[\"Bachelor's Degree-7 years experience in software engineering/solution architecture-3 years experience with public cloud technologies\", \"Master's Degree-10+ years experience in software engineering/solution architecture-7+ years experience in designing/building enterprise platform solutions-5+ years experience with Agile software development-4+ years experience with public cloud technologies-AWS Certifications\"]\n",
            "['Understanding of cybersecurity concepts', 'Understanding of various security domains', 'Experience in Cybersecurity']\n",
            "['0-1+ years experience', '5+ years experience', '5-15 years experience', '5+ years experience', '9+ Years experience', '5>7 years experience', '20+ years experience in high performance ASICs', '8+ yrs experience', '5+ years experience', '2+ years experience', '3+ years experience', '5+ years of experience in data center business', '4+ years of experience']\n",
            "['Company retreats/gatherings', 'Company lunches', 'Company Outings', 'Corporate social events']\n",
            "['Marketing', 'Marketing', 'Branding', 'Marketing', 'Marketing Services', 'Maintain marketing and servicing websites', 'Proficiency in marketing principles']\n",
            "['Media', 'Media']\n",
            "['Efficient and quality matching', 'Implement strategies for alignment', 'Optimize LLM alignment', 'Knowledgeable about LLM approaches']\n",
            "['Scheduling', 'Assists with scheduling appointments', 'Flexible with changing priorities', 'Flexible scheduling', 'Flexible schedules', 'Flexibility in work hours', 'Flexible schedules', 'Flexible work arrangements', 'Flexible schedule']\n",
            "['Anticipate customer needs', 'Automate customer scenarios']\n",
            "['Electrical', 'Electric vehicles', 'Electrical', 'Electrical', 'Electrical', 'Working in Transmission, Distribution & Generation industry']\n",
            "['Credit scoring models', 'Process credit applications', 'Credit scoring background']\n",
            "['Cutting-edge optical design solutions', 'Optics experience', 'Experience in Physics, Optics, Mathematics']\n",
            "['Document software specifications', 'Document software specifications', 'Document software designs, processes, and technical specifications', 'Create documentation for software', 'Documenting code and processes', 'Define technical specifications']\n",
            "['Improving ability to understand data', 'Research and data analysis skills', 'Advanced Excel skills', 'Analytical and organizational skills', 'Analytical skills', 'Analytical Skills', 'Strong analytical skills', 'Problem-solving and analytical skills', 'Excellent analytical and troubleshooting skills']\n",
            "['machine learning', 'Machine Learning', 'Machine learning']\n",
            "['GCP Data Engineer', 'Data Engineer', 'Develop data quality metrics', 'Data engineering experience', 'Minimum 6 years data engineering', \"3+ years' experience in data engineering or software development\", 'Data Science experience', 'Experience with dimensional data modeling']\n",
            "['Engineering and Information Technology', 'Engineering and Information Technology', 'Engineering and Information Technology', 'Engineering and Information Technology', 'Engineering and Information Technology', 'Engineering and Information Technology', 'Computer Engineering', 'Electrical and Computer Engineering']\n",
            "['BS in Computer Science with 8 years experience - MS with 5 years - PhD with 2 years - Eligible for DoD security clearance - Legal authorization to work in US']\n",
            "['iOS XCTest, XCUITest', 'XR application development', 'OpenXR libraries', 'XR application development']\n",
            "['AI Microsoft Chatbot Developer', 'AI Microsoft Chatbot Developer', 'Design chatbot structure', 'Analyze chatbot data', 'Microsoft Bot Framework']\n",
            "['Test serverless-based architecture on AWS', 'Deploy tests in AWS', 'Proficiency in testing serverless-based architecture on AWS', 'Experience deploying tests in AWS']\n",
            "['Stay updated on advancements in machine learning and signal processing', 'Stay up-to-date with advancements in AI technologies', 'Stay updated on latest ML/DL technologies', 'Stay up-to-date with latest advancements in ML systems']\n",
            "['Security clearance', 'Security clearance or ability to obtain one', 'Security clearance or ability to obtain one', 'Ability to obtain a DoD security clearance', 'Public Trust security clearance']\n",
            "['Think creatively']\n",
            "['Triage Software Engineer - Initial defect analysis - Dashboard creation - Problem-solving - Communication skills - Automotive Infotainment - Embedded software - JIRA/Confluence - Agile/Scrum - Requirement Analysis', 'Triage Software Engineer', 'Initial defect analysis - Triage defects - Monitor defect dashboard - Create reports - Work with cross-functional teams - Drive defect triage calls', 'Automotive Infotainment - C/C++/ Linux - JIRA/Confluence - System Architecture - Agile/Scrum - Thinking on the feet']\n",
            "['Health Care Provider', 'Hospitals and Health Care', 'Hospitals and Health Care', 'Hospitals and Health Care', 'Hospitals and Health Care', 'Healthcare']\n",
            "['Building computer vision systems, ML and AI models, robotic control and motion planning, process management', 'Robotics Engineering', 'Robotics Engineer', 'Contribute to cutting-edge robotic systems', 'Build high-performance robotic systems', 'understanding of HW/Embedded Systems/Mechatronics/Robotics', \"Bachelor's, Master's, or Ph.D. in Robotics, Mechanical Engineering, Electrical Engineering or related field\"]\n",
            "['Ads Creative Management', 'Advertising Services', 'Advertising Services', 'Ads industry experience']\n",
            "['Consulting', 'Consulting', 'Consulting', 'Consulting', 'Jury consulting services', 'Lifestyle consultancy', 'Services', 'Services']\n",
            "[\"Master's degree\", 'Masters degree', \"Master's Degree in Aerospace Engineering (substitute for experience)\", \"Master's degree and/or MBA\", \"Master's degree in related field\"]\n",
            "['External research funding', 'External funding record']\n",
            "['Designing qubit devices for error rates, qubit physics modeling, communication with team', '5+ years experience in Quantum Physics', 'Masters in Physics or related field, Qubit physics modeling', 'Experimental background in various qubits', 'PhD in physics, Superconducting qubit modeling, Publish in journals']\n",
            "['Python Developer', 'Python Developer', 'Python Developer', 'work on python applications', 'Utilize Python programming language', 'Coding in python and React/Java Script', 'Python programming', '5+ years experience in Python web development', 'Python']\n",
            "['Plan and deploy infrastructure', 'infrastructure protection']\n",
            "['Reporting system for clinic-ready reports', 'Clinician', 'Implement reporting system']\n",
            "['Company-provided home office equipment', 'Pet-friendly offices', 'Workspace benefits for home office']\n",
            "['Collaborate with DevOps', 'Contribute to DevOps methodology', '10+ years DevOps & MLOps experience', '5+ years experience as DevOps/Release engineer']\n",
            "['Create and deploy campaigns', 'Analyze campaigns', 'Manage paid search campaigns', 'Campaign management experience']\n",
            "['Financial Planning solutions', 'Financial Planning processes', 'Makes recommendations for improving accounting processes', 'Enhance Financial Planning processes', '5+ yrs Financial Planning exp', 'Deep understanding of financial planning processes']\n",
            "['401K Plan', '401(k) benefit', '401(k)', '401(k)', '401(k) plan', '401(k)', '401(k) Plan']\n",
            "['MS or PhD in computer or electrical engineering', 'MS or PhD in physics/engineering', \"Master's or PhD in Electrical Engineering\"]\n",
            "['Dispatcher', 'Dispatching']\n",
            "['Algorithm Engineer', 'Algorithm Developer', 'Algorithm analysis', 'Implement algorithm solutions', 'Algorithm Development', 'Develop algorithms for parallel computation', 'Support teams in building various algorithms']\n",
            "['Domain expert in RTML serving technology', 'Strong expertise in RTML model serving']\n",
            "['Experience with Salt, PyTorch', 'Experience with ONNX, Pytorch, Tensorflow']\n",
            "['integrate software/hardware components', 'Enhance existing components for performance', 'Collaborate with hardware/software engineers', 'Integrate software components', 'Drive system integration', 'Integrate 3rd party software']\n",
            "['Communicating research results', 'Publish research papers', 'Publish in top-tier conferences, journals, communicate research findings', 'Publishing results']\n",
            "['Engineering Services', 'Distinguished Engineer', 'Engineer', 'Engineer', 'Engineer', 'Principle Engineer', 'Work alongside BE Engineers']\n",
            "['Quantitative Developer for systematic corporate bond and credit derivatives strategies', 'Quantitative Software Engineer', 'C++ Quantitative Developer', 'Analytics Engineer', 'Quantitative Developer', 'Quantitative Software Engineer', 'Software Engineer II (Quant/Python)', 'Analytics & Quality Engineer']\n",
            "['Manage Quickbooks', 'Competency in Quickbooks', 'Competency in Excel']\n",
            "['Knowledge of ACAS or Nessus', 'Functional experience in SAC', 'Experience with w/ accessibility']\n",
            "['Prepares complex reconciliations', 'Reconciliation', 'Reconcile chargebacks']\n",
            "['3+ years professional software development experience', '1+ years contributing to architecture and design', '2-3 years NextFlow experience', '3+ years designing and developing trading infrastructure in financial institution', '4+ years of prof. software development testing exp.', '3 years experience', '3+ years software development', 'Minimum 3 years professional software development experience', '3+ years in security role', '3+ years full software development life cycle']\n",
            "['Holiday Pay', '12 Paid Holidays', 'Paid vacation/holidays', 'Company-paid holidays', 'Paid vacation, holidays', 'Paid holidays', 'Paid Holidays']\n",
            "['Prepares day-to-day and month-end close entries', 'Assists with month-end and year-end closing process', 'Month-end Closing', 'Organizes backlog for time-phasing']\n",
            "['consumer electronics', 'Consumer Electronics']\n",
            "['Translate research findings into actionable insights', 'Coordinate findings with leadership']\n",
            "['Digital Rights Management', 'DRM implementation']\n",
            "['Research', 'Research', 'Research', 'Research', 'Research', 'Research', 'Clinical Trial Research', 'Research', 'Research portfolio accomplishments']\n",
            "['Build and maintain automated test infrastructure', 'Automate testing process', 'Providing test infrastructure', 'Fluent in maintaining API tests', 'Test automation']\n",
            "['debugging in C++', 'debug issues with windbg/similar debuggers', 'Troubleshooting and debugging programs', 'Debugging skills', 'Debugging tools']\n",
            "['Transportation services', 'Transportation/Trucking/Railroad', 'Environmental Services', 'Transportation of passengers']\n",
            "['Experience with Linux open source community']\n",
            "['Bachelors in CS', 'Bachelor’s Degree in CS or related field', 'Bachelor/masters in CS or related field', \"Bachelor's in CS/CE or relevant field\", 'BS in Computer Science or related field', 'Bachelor’s degree in CS/Engineering', \"Bachelor's degree in CS or related field\", 'Degree in CS, physics, math or related field', \"Bachelor's in CS or related field\", \"Bachelor's or Master's degree in CS, Finance, Mathematics\"]\n",
            "['Improving data infrastructure for climate analysis using AI', 'Apply AI technologies to climate crisis', 'Harmonize climate datasets using AI Large Language']\n",
            "['high-performance computing applications', 'Parallel computing, HPC optimization']\n",
            "['Impact career', 'Impact business', 'Make lasting difference through work']\n",
            "['Competitive total rewards package', 'Total compensation package', 'Competitive compensation packages', 'Competitive compensation package', 'highly competitive benefits']\n",
            "['Software Engineer in Test', 'Software Engineer in Test', 'Software Development Engineer - Test', 'Product Security Test Engineer', 'Participate in development and testing sessions', 'Write robust test cases', 'Experience with TestNG or JUnit', 'Unit Tests, TDD']\n",
            "['Interact with technical decision makers', 'Collaborate with stakeholders for feedback on software solutions']\n",
            "['Healthcare, Wellness, Retirement Plan, Tuition Reimbursement, Mental Health Support, Financial Coaching', 'Outstanding benefits program including paid time off, tuition reimbursement, 401k contribution, flexible work environment', 'Employee resource groups', 'Paid healthcare', 'Medical, Dental, Vision, 401(k), PTO, Education Reimbursement, Snacks, Work/Life Balance, Discounts, Happy Hours', 'Healthcare coverage, Financial programs, Paid time off, Training resources, Employee resource groups']\n",
            "['Microservices development', 'Developing Microservices', '2+ years’ experience with microservices software architecture']\n",
            "['Non-profit Organizations', 'Non-profit Organizations']\n",
            "['Python/R scripts for data processing', 'Write Python/R scripts', 'Python/R', 'Programming Python or R']\n",
            "['Information and Internet', 'Broadcast Media Production and Distribution', 'Information and Internet', 'Information and Media', 'Information and Media', 'Information and Media']\n",
            "['Investment Management', 'general risk management']\n",
            "['Equal opportunity employer', 'Equal opportunity employer', 'Eligible roles']\n",
            "['Knowledge of orbit dynamics and space environment', 'In-depth knowledge of orbit dynamics and space environment', 'Expertise in space weather and GPS applications']\n",
            "['Quality Assurance', 'Quality Assurance', 'Pre-trip inspections', 'Quality assurance in electronics']\n",
            "['Reference letters']\n",
            "['SEO & Content Marketing Specialist', 'Search Engine Marketing Specialist', 'SEO strategies', 'SEO tools proficiency']\n",
            "['Linux/Unix', 'Experience with Linux, C#, IPC', 'Experience in Linux/Unix environment', 'Linux subsystem experience', 'Experience with Ada, Python, Linux OS, Git, GitLab, VersionOne, Jenkins, Simulation', 'Knowledge of UNIX systems']\n",
            "['ML based data pipelines', 'Bioinformatics pipelines using Nextflow', 'High-performance data analytics platform handling petabytes of data', 'Build data pipelines', 'Build bioinformatics pipelines', 'Design data pipelines', 'Design and develop GenAI use case model pipeline', 'Create & maintain ML/DL pipelines', 'Create data preprocessing pipelines', 'Develop software for large datasets']\n",
            "['C/Networking Software', 'C/Networking Software Engineer', 'Familiarity with networking protocols/standards', 'Experience with networking-related software on embedded systems', 'Familiarity with networking software implementations', 'Routing software experience']\n",
            "['Senior Level Resiliency Systems Engineer', 'System Engineer', 'Systems Engineer', 'Systems Research Engineer', '12 years experience in Systems Engineering']\n",
            "['CAD/EDA Tools Software Engineer for Test Chip Design', 'CAD/EDA Tools Software Engineer', 'Development of EDA software tools and flows', 'Support test chip layout', '6+ months experience in EDA tools like Cadence Virtuoso, Synopsys ICV, Siemens Calibre']\n",
            "['Collaborate with MLOps team', 'MLOps experience', 'ESOPs']\n",
            "['Principal System Software Architect', 'Software Architect - C++', 'Software Architect', 'Evangelize architectural solutions', '6+ years as Software Architect']\n",
            "['Triage security and compliance issues', 'issues triage', 'incident triage']\n",
            "['ETL Automation', 'ETL Automation (~60%)', 'Data Pipelining/ETL Automation']\n",
            "['Security risk assessment', 'Cybersecurity', 'Cybersecurity Data Services', 'Embedded Cybersecurity solutions for Caterpillar machines & engines', 'Information security risk specialist', 'Design/Document Cybersecurity features', 'Validate Cybersecurity features', 'Identify Cybersecurity risks', 'Mitigate cyber risks', 'Contribute to world-class cybersecurity solutions']\n",
            "['Java, JavaScript', 'Java', 'Java', 'Java knowledge']\n",
            "['Telecommunications', 'Telecommunications', 'CAN, J1939, data link protocols']\n",
            "['ServiceNow familiarity', 'Knowledge of iOS and Android toolsets', 'Familiarity with modern front-end technologies', 'Front-end tech familiarity', 'Familiarity with OT environments', 'Familiarity with React.JS']\n",
            "['Large-scale distributed software applications, systems, services', 'Implement relevant applications', 'Implement scalable ML/DL solutions', 'Design scalable software components', 'Scalability - Architect and implement scalable solutions', 'Ensure robustness, scalability, and performance of backend system', '2+ years leading the end-to-end design and development of scalable services']\n",
            "['Invent and scale AI systems for robotics in fulfillment', 'Invent and scale AI systems for robotics in fulfillment']\n",
            "['Collaboration', 'Design collaboration', 'Collaboration', 'Collaboration skills', 'Ability to work collaboratively']\n",
            "['Retail', 'Retail']\n",
            "['Manager On Duty']\n",
            "['Summer Internship - Quantum Systems', 'Research Intern - Quantum Information and Computation']\n",
            "['Manufacturing', 'Manufacturing', 'Pharmaceutical Manufacturing', 'Medical Equipment Manufacturing', 'Manufacturing', 'Manufacturing', 'Machinery Manufacturing', 'Manufacturing', 'Construction', 'Construction, Machinery Manufacturing', 'Interaction with factory management']\n",
            "[\"Associate's degree\", \"Associate's degree\", 'Associate degree in business or marketing']\n",
            "['Act as liaison between sales teams and customers', 'Support non-revenue generated work for sales teams', 'Improve productivity of inside and outside sales teams', 'Foster effective communication between sales department, internal business partners, and customers', 'Enhance processes and procedures for sales team support']\n",
            "['Innovation Manager (Marketing Technologist) - Cookie Management', 'Innovation Manager', 'Build awareness-increase knowledge-drive adoption-operate as trusted advisor-lead talent development-collaborate on key innovation initiatives']\n",
            "['Sales and Business Development', 'Sales and Business Development', 'Sales and Business Development', 'Sales and Business Development']\n",
            "['Experience in cloud infrastructures', 'Experience in large application development in cloud environments', 'Cloud-based systems experience', 'Cloud infrastructure experience', 'Background in virtualization technologies', 'Experience with core infrastructure, enterprise, and cloud technologies', 'Experience with Azure cloud technologies', 'Experience in media storage systems', 'Experience with Continuous Integration/Continuous Deployment']\n",
            "['Employee discounts', 'Educational fee discounts', 'Company-wide discounts', 'Store credit/discounted gear']\n",
            "['Git/Github', 'Git, GitHub']\n",
            "['Minimum grade of B in course being tutored']\n",
            "['Process manual orders for dealers', 'Process name changes and business changes for dealers', 'Proactively monitor sales levels for dealers', 'Process orders', 'Automate order generation and integrate compliance checks']\n",
            "['Design, develop, and implement ML models', 'Developing machine learning algorithms', 'Contribute to development of advanced ML models, algorithms, datasets', 'Implement algorithms, models, and data pipelines for decision-making and automation', 'Address performance, scalability, governance of ML models', 'Integrate best practices from ML research into systems', 'Develop text processing models', 'Design ML models at scale', 'Accelerating ML research', 'Machine learning modeling lifecycle', 'ML frameworks: Sci-kit, Keras, TensorFlow', 'Knowledge of ML/AI applications and models']\n",
            "['Data Engineering for Wholesale Building Materials', 'Wholesale Building Materials']\n",
            "['document code quality', 'code reviews', 'Improve code quality']\n",
            "['Provide customer service', 'Provide customer service', 'Help customer accomplish mission']\n",
            "['Academic support through tutoring', 'Tutor', 'Peer Tutor', 'Provide academic support through tutoring', 'Maintain accurate tutoring records', 'Previous tutoring or teaching experience', 'Online or in-person tutoring']\n",
            "['Monitor, enhance system efficiency/stability', 'Improve operational stability', 'Maintain Market operations', 'Stability and retention']\n",
            "['Perform market research', 'Provide feedback on market trends']\n",
            "['Holography and Laser Beam Optimization']\n",
            "['Strong understanding of ML algorithms', 'Strong in data structure and algorithm', 'Solid understanding of software development principles, data structures, and algorithms', 'Strong math and algorithm development background', 'Understanding of design patterns and algorithms', 'Strong knowledge on algorithms and data structures']\n",
            "['GPU experience', 'HPC - Nvidia, CUDA experience', 'Hands-on GPU or HPC']\n",
            "['Passion for local agriculture', 'Passion for local agriculture']\n",
            "['Prepare estimates', 'Perform detailed calculations', 'Detailed instructions provided']\n",
            "['Paid sick leave and time off', 'Sick leave', 'Paid sick leave']\n",
            "['Data synchronization principles', 'Data synchronization knowledge']\n",
            "['Interact web services/APIs']\n",
            "['bug fix', 'driving bug fixes']\n",
            "['Technical Sales Specialist', 'Technical Sales Manager', 'Tech Product Manager', 'Brand Technical Specialist', 'Technical Sales management']\n",
            "['Excellent communication skills', 'Excellent communication skills', 'Excellent communication skills', 'Excellent communication skills', 'Excellent communication skills', 'Excellent communication skills', 'Excellent communication skills', 'Excellent written and verbal communication skills', 'Excellent organization and coordination skills', 'Excellent communication skills', 'Excellent written or verbal communication, presentation, strategic, and problem-solving skills']\n",
            "['Research scientific reference material', 'Research scientific reference material', 'Research materials preparation']\n",
            "['Monthly catered meals', 'Monthly snacks']\n",
            "['Operations and maintenance of Data.gov websites', 'Data cleansing direction', 'Assist in building efficient tools for data organization and visualization', 'Consult with customers to identify appropriate Google data management solutions', 'Content calendar management', 'Data management', 'Comply with data privacy', 'Data Dispute Resolution', 'Data Management - Data storage, retrieval, indexing strategies', 'Data warehouse knowledge', 'Data-intensive environment']\n",
            "['Free Parking']\n",
            "['Maximizing impact through Open Source projects']\n",
            "['Ecommerce platform knowledge', 'Google Ads Certification in Search and Display', 'Knowledge of Google Ads and other marketing platforms']\n",
            "['Develop edge-computing stack', 'Build edge applications', 'Experience with Edge/IoT computing']\n",
            "['Introduction of automation to construction sector', 'Industrial Automation', 'Automation Machinery Manufacturing', 'building automation', 'Automation proficiency', 'Automation expertise']\n",
            "['Stay current with emerging technologies', 'Drive awareness of new technologies', 'Communicate technology, plans effectively', 'Bring technology to millions of users', 'Influence technology', 'Ability to learn new technologies']\n",
            "['seismic-acoustic signal processing', 'software design and development on complex, tactical geophysical systems']\n",
            "['Migration to cloud infrastructure', 'Cloud computing', 'Cloud infrastructure']\n",
            "['Lead evaluation sessions', 'Evaluation sessions', 'Test and evaluation']\n",
            "['PhD in related field', 'MS degree with 6+ months experience or PhD degree with 1+ years', 'Ph.D. degree or equivalent research experience', 'Bachelor, Master, or Doctorate in relevant field', 'PhD preferred']\n",
            "['Engineering Solutions', 'Provide reliable solutions', 'Solutions engineering', 'Solution definition', 'Solution Development - Hands-on Prototyping - Strategy - Collaboration - Mentoring']\n",
            "['Develop secure high-quality code', 'Production code development', 'Develop Secure Production Code']\n",
            "['Technical Leadership - Backend infrastructure design, development, maintenance', 'Leadership in tech transformation', 'Leadership experience in technology transformation']\n",
            "['Revolutionize computing', 'Computer Science', 'Computer Science', 'Winners of ACM/ICPC, NOI/IOI, Top Coder, Kaggle']\n",
            "['Marine Engineering Networking', 'User-owned talent network', 'Design and implement network connectivity', 'Network']\n",
            "['reporting feature development status', 'Communicate project status']\n",
            "['PTO', 'Flexible PTO', 'Generous PTO', 'PTO and holidays']\n",
            "['Operate within agile scrum framework', 'Participates in daily scrums', 'Agile/Scrum experience', 'Experience in Agile environment']\n",
            "['2+ years ML engineering experience', 'Minimum 5 years experience in AI/ML', '8+ years industry experience in ML Ops or related fields', '2+ years in AI/ML Engineering', '4+ years in ML or systems software engineering', 'Minimum 1 year machine learning experience', '5+ years of experience in AI and/or high-performance computing']\n",
            "['Design experimental frameworks', 'Build Design of Experiments', 'Design experiments', 'Experimental Support and Data Analysis']\n",
            "['Building public APIs', 'Technical understanding of restful APIs', 'Minimum 1 year creating API clients']\n",
            "['Proficiency in Python, Azure, Langchain', 'Proficiency in Python, Java, JavaScript/TypeScript', 'Strong knowledge of AI technologies and programming languages (e.g., Python, Java, C++)', 'Programming skills (C#, .NET, JavaScript, Python)', 'Experience with Python and Java', 'Proficiency in Python, Scala, or C++', 'Python/Java/C++', 'Proficiency in Python, Java, C++', 'Proficiency in Python, C++, Java']\n",
            "['Financial coaching', 'Financial coaching']\n",
            "['Develop software for earth observation data', 'Geospatial intelligence experience', 'Experience with geographical, aerial or satellite data']\n",
            "['Healthcare coverage', 'Health care coverage']\n",
            "['Software solutions for critical infrastructure', 'Secure critical infrastructure', 'Keep critical infrastructure secure']\n",
            "['Web & app development', 'develop UI front-end', 'Backend application building', 'Design and build front-end systems', 'Experience with TypeScript, React', 'Front-End experience', 'Frontend development experience']\n",
            "['Compensation for assessments', 'Additional benefits', 'Additional compensation', 'up to $150,000']\n",
            "['Ensure data and products are of highest quality for aerospace community', 'Aviation and Aerospace Component Manufacturing', 'Aviation and Aerospace Component Manufacturing', 'Aviation and Aerospace Component Manufacturing']\n",
            "['May assist with direct patient care']\n",
            "['Earth system models', 'Research and apply large-scale models', 'Use large language model APIs', 'Develop sophisticated modeling techniques']\n",
            "['Core Windows development', 'Windows']\n",
            "['Lead ML Ops Engineer', 'ML Ops Engineer', 'ML/ML Ops Engineer', 'ML Ops Engineer', 'Operational Support Engineer']\n",
            "['Electronics Manufacturing', 'Computers and Electronics Manufacturing', 'Electronics Manufacturing', 'Electronics Manufacturing', 'Electronics Manufacturing']\n",
            "['Guide account executives', \"Accelerating enterprises' success\", '12 years of experience promoting to executive enterprise customers']\n",
            "['Banking', 'Banking', 'Investment Banking']\n",
            "['Establish Best Practices', 'Ensure product quality and best practices', 'Follow software best practices', 'Ensure overall quality of solutions']\n",
            "['Create demos/systems to highlight AI innovations, foster collaboration', 'Initiate proof of concept', 'Demonstrate proof of concept']\n",
            "['Low Latency Trading Systems', 'Forex trading systems', 'C++ Low Latency Trading Systems Developer', 'Developing low latency trading systems']\n",
            "['Utilizing Python, AWS, Gitlab', 'AWS-native tools familiarity', 'Python framework experience on AWS', 'Experience moving Python libraries to NextFlow']\n",
            "['cutting-edge technology', 'cutting-edge technologies', 'Gain Experience in Cutting Edge Technologies']\n",
            "['Participate in project leadership', 'Taking Initiative on Projects']\n",
            "['CDL Driver', 'Non CDL Driver', 'CDL']\n",
            "[\"Experience with IBM's Watson products\", 'Experience with IBM Business Analytics tools', 'Experience in BI tools', 'IBM Watson ML or related experience']\n",
            "['Maintain annual sales plan', 'Meet annual sales plan']\n",
            "['Voluntary Life, Accident, and Critical Illness coverage', 'Life Ins.', 'Voluntary Life Insurance']\n",
            "['Four Tran']\n",
            "['Medical, dental, vision insurance', 'Optional group Medical, Dental, and Vision coverage', '100% company-paid private Dental and Vision Insurance', 'Health/dental/vision insurance', 'Health, dental, vision insurance', 'Medical, dental, vision coverage', 'Medical, Vision, Dental coverage', 'Medical, dental, vision insurance', 'Medical, dental, vision insurance', 'Health, dental, vision insurance']\n",
            "['Write well designed code with automated testing', 'Conduct testing and debugging of software components', 'code and unit testing', 'Test/debug system software', 'Software design, coding, testing, debugging', 'Ensuring software reliability', 'Design, code, build and test algorithms']\n",
            "['Mission capability integrator', 'End-to-end process integration', 'Integration', 'support integration and test actions', 'Analyzing data integration problems', 'Integration of architectural development', 'Integration - Collaborate with teams and services for integration']\n",
            "['Bus Driver', 'Bus Driving skills', 'Defensive Driving skills', 'Driver Training skills']\n",
            "['SAP Analytics Cloud (SAC)', 'Functional expert for SAP Analytics Cloud (SAC)', 'Knowledge of SAP Analytics Cloud']\n",
            "['Fintech experience', 'Financial markets experience', 'Finance experience', 'Experience in credit markets and fixed income pricing systems']\n",
            "['Good understanding of RT system stats collection', 'Basic understanding of RT Feature Engineering methodology']\n",
            "['AP Scores and SAT/ACT scores']\n",
            "['Enhance processes by utilizing Continuous Improvement mindset', 'Contributing to quality vision through continuous software improvement']\n",
            "['Art/Creative', 'Art/Creative', 'Creative studio']\n",
            "['Augmented Reality Systems Platform', 'AR/VR development', 'AR/VR Developer']\n",
            "['National awards honors']\n",
            "['CPUs', 'System on Chips', 'Craft next gen SoC, CPUs']\n",
            "['Drive customer engagements', 'Engage with customers', 'Provide engagement advice to Management']\n",
            "['NLP/LLM processing', 'Implement NLP techniques', 'Proven experience in generative AI, NLP, LLMs', 'Experience in NLP, Ranking, Ads, search engine, recommender system, distributed system, machine learning', '3+ years NLP experience', 'Familiar with NLP, CV-related algorithms, large-scale model training, RL algorithms']\n",
            "['Systematic trading strategies', 'Research trading strategies', 'Enhance existing strategies', 'Create new strategies', 'Gaining exposure to Pricing, Risk, and Trade Management functions', 'Translating trading strategies']\n",
            "['Assistant Manager', 'Management', 'Assistant Manager']\n",
            "['AI-driven solutions', 'Design and develop software solutions using AI technologies', 'Design, architect, and build AI functionality', 'Participate in AI technical process standards', 'Implementing AI solutions', 'Deep understanding of software engineering and AI']\n",
            "['Support workflow development for NOAA SFS', 'NWP modeling system', 'Workstream planning', 'feature level work', 'Design, develop, maintain NWP workflow features']\n",
            "['Wellness benefits', 'Wellness programs', 'Health, retirement, vacation benefits', 'Dental Benefits', 'Education benefits', \"Variety of perks and benefits to support employees' health and work-life balance\"]\n",
            "['Machine Learning Platform', 'Plan roadmap, design ML systems, implement, test, monitor services', 'Build, install, configure, manage, scale ML platform', 'Define architecture and build infrastructure for ML solutions', 'Experience with large-scale ML platforms', 'Monitoring ML platforms with Grafana, Zabbix']\n",
            "['2+ years design or architecture experience', \"Master's in CS or relevant field with 2 years experience\", '3-5 years of experience in finance or accounting', \"OR Master's degree and 3+ years of experience\", 'OR PhD and 2+ years of experience', 'One or more years of relevant experience', '2-5 years accounting experience', '2+ years of experience (higher degrees can substitute)', '2+ years applied experience']\n",
            "['Write and execute end-to-end integration scenarios', 'feature validations', 'scenario validation', 'drive regular scenario validation', 'Research and explore usage scenarios']\n",
            "['Audio/Video formats and containers', 'Audio/Video analysis', 'Audio/Video formats knowledge']\n",
            "['Strong OOP skills', 'OOP concepts', 'Design Patterns, OOP']\n",
            "['Partner with developers', 'Collaborate with stakeholders', 'Collaborate with stakeholders', 'Communicate with clients and stakeholders', 'Collaborate with stakeholders']\n",
            "['Google Cloud Platform', 'Experience with cloud platforms', 'Experience with cloud platforms', 'Experience with cloud platforms, containerization, ML techniques', 'Experience with Cloud Foundry', 'Experience with Terraform', 'Experience in Cloud platforms']\n",
            "['Implement customer opt-out choices', 'Familiarity with opt-out mechanisms']\n",
            "['Trusted Execution Environment', 'Standard software solutions execution']\n",
            "['Commit to excellence', 'Commitment to diversity, equity, and inclusion', 'Long-term commitment culture']\n",
            "['Cyber and RMF Specialist, Mid', 'DoD RMF experience', 'Experience supporting the military']\n",
            "['Technical sales experience', 'Technical Sales/Solution Consultant/Sales Engineer experience', 'Sales lifecycle experience', 'Minimum 5 years experience in Sales and Technology within Power Industry', 'Experience in Sales Engineer role', 'Experience with Salesforce', 'Automotive or safety critical support experience']\n",
            "['Hospitality', 'Experience in hospitality industry']\n",
            "['100% employer-paid Disability and Life insurance policies', 'Life and disability insurance']\n",
            "['Material handling equipment and systems', 'Material handling systems experience', 'Experience in off-highway equipment operation']\n",
            "['Work with Product Management teams to assist market adoption and solution alignment with enterprise customer requirements', 'Experience with go-to-market solutions', 'GO']\n",
            "['Operational knowledge of pulse sequencing with AWGs']\n",
            "['Forecast guidance', 'Forecasting reports generation']\n",
            "['Director']\n",
            "['Transformer products and solutions', 'Transformers experience', 'Experience with power transformers']\n",
            "['Develop components for data collection', 'Maintains patient data files', 'Collects patient data', 'Prepares patient records for audits']\n",
            "['Assures lab staff has kits accessible', 'Timely packing and shipping of lab samples', 'Maintains supplies for clinical research', 'At least 1 shipped product using LLM API']\n",
            "['Food and Beverage Services', 'Food and Beverage Services', 'Food & beverage']\n",
            "['OEM/Automotive', 'Motor Vehicle Manufacturing', 'Motor Vehicle Manufacturing', 'Lead prototyping vehicles engineering process']\n",
            "['Administrative', 'Government Administration']\n",
            "['Web-based user interfaces', 'Create web-based interfaces']\n",
            "['Maintain and monitor customer portals on Generac websites', 'Maintain accurate and complete customer portals']\n",
            "['On-site health and wellness centers', 'On-site health centers']\n",
            "['Security - Implement security measures', 'create actionable insights for use in physical security']\n",
            "['Analyzing user feedback and making adjustments', 'Recommending and executing program improvements']\n",
            "['High School Diploma', 'High school diploma or equivalent']\n",
            "['Airlines and Aviation', 'Airlines and Aviation']\n",
            "['Experience with parameterized cells (PCells) or PyCell', 'APL']\n",
            "['Comprehensive health care coverage', 'Comprehensive health care coverage', 'Full health care coverage', 'Comprehensive medical plans']\n",
            "['Scientific Software Engineer - Space', 'Join a company at the heart of space research and operations', 'Aerospace Software Engineer', 'Scientific Software Engineer - Space', 'Refine aerospace/scientific software']\n",
            "['Professional growth opportunities', 'Career development programs', 'Professional development opportunities', 'Professional development opportunities']\n",
            "['Email marketing experience']\n",
            "['AI/Client models', 'Go Expert - AI Training', 'Train/deploy AI models', 'Expertise in AI models and controls', 'Experience in AI model deployment', 'AI model training/deployment']\n",
            "['C++ Developer', 'STL/Boost', 'C/C++', 'C++', 'C++', 'C++ development background', 'Programming in C or C++']\n",
            "['Handle emergencies']\n",
            "['Analyze system details', 'Maintainability analysis', 'Monitor and analyze system health', 'Analyze legacy systems']\n",
            "['DoD/IC Acquisition knowledge', 'Knowledge of Federal Acquisition Regulations']\n",
            "['Global markets proprietary trading firm', 'Capital Markets']\n",
            "['Pre-owned vehicles', 'Vehicle appraisals']\n",
            "['end-to-end digital services', 'handling end-to-end delivery']\n",
            "['Trade shows attendance']\n",
            "['Google CCAI Services']\n",
            "['Advanced medical device', 'Implement advanced control algorithms', 'Contribute to advanced technical research', 'Conduct research on advanced techniques']\n",
            "['EAP']\n",
            "['MS/MA', 'M/D/V']\n",
            "[\"Create PowerPoint presentations for ISR's and Field Sales\", 'Content creation', 'Technical writing', 'Create technical content']\n",
            "['ARCore', 'ARFoundation']\n",
            "['Guide client through a plan of action', 'guidance and/or execution on corrective actions']\n",
            "['Docker, Messaging Tools (Kafka, Redis)', 'Experience with Docker, CI/CD', 'Experience with Docker and Source Control Management']\n",
            "['Rust Engineer', 'Rust']\n",
            "['Vector databases knowledge', 'Learn', 'Kernel structure knowledge', 'Strong understanding of machine learning principles', 'Familiarity with ML algorithms', 'Unsupervised learning expertise', 'Machine learning familiarity', 'Machine Learning testing exp', 'Machine learning knowledge', 'Mechanical knowledge', 'Knowledge of 3D Geometry']\n",
            "['data centers', 'Machine Learning ASICs for Data Center servers', 'Map Data Center workloads']\n",
            "['Research and Education', 'Biotechnology Research', 'Research industry directions', 'Research and Development', 'Product development input', 'Partner with research, product, and design']\n",
            "['Formulation']\n",
            "['Unity development', 'Unity development']\n",
            "['Quantitative methods understanding', 'Quantitative applications']\n",
            "['Python Software Engineer (Robotics/Mechatronics)', 'Lead Software Engineer - Python', 'Software Engineer III (Python/ML)', 'Lead Software Engineer', 'Lead Software Engineer', 'Serve as lead software engineer']\n",
            "['Modern Work Spaces', 'Diverse work environment', 'Diverse workplace']\n",
            "['Minimum 2 years industry experience in developing real-time software for embedded systems', 'Real-time embedded software development - DLT logs analysis', '3+ years of real-time software development experience', 'Real-time software development experience']\n",
            "['AI-driven education platform', 'AI Video Platform', 'AI platform at Together AI']\n",
            "['Experience deploying and supporting Kubernetes', 'Container deployment Docker & Kubernetes', 'Experience with Kubernetes', 'Experience with Kubernetes for complex workflows']\n",
            "['PowerBI']\n",
            "['Surgical Robotics Systems', 'Remotely-operated endovascular surgical robot', 'Knowledge of surgical robotics, medical device regulations, safety standards']\n",
            "['Familiarity with software development tools, version control systems, and cloud computing platforms', 'Version control systems knowledge (e.g. Git)', 'GIT configuration management', 'Familiarity with git']\n",
            "['Health insurance', 'Health', 'Health insurance', 'Life Insurance', 'Health insurance', 'Health insurance', 'Health insurance']\n",
            "['6+ years of product design/prototyping experience', '10+ years of software/architecture experience', '6 to 8 years of engineering experience', '4+ years of software development experience', '7+ years’ software-engineering experience', '8+ years of software development experience', '7+ years experience as software engineer']\n",
            "['Learning and applying system processes and methodologies', 'Systems engineering lifecycle understanding', 'Model Based Systems Engineering knowledge']\n",
            "['Advancing understanding of radio spectrum and wireless signals', 'RFQs and RFIs support']\n",
            "['Keyword research']\n",
            "['AI solutions for educational experience enhancement', 'AI algorithms', 'Optimizing and integrating AI model', 'Optimize and improve existing AI systems and algorithms', 'Optimize and fine-tune existing training and inference platform', 'Designing, developing AI algorithms']\n",
            "['General Business', 'Business leadership', 'Business Consulting', 'Outsourcing and Offshoring Consulting', 'Business Consulting and Services', 'Business Consulting']\n",
            "['Actively pursuing a degree', 'Enrolled in Undergraduate Program', \"Enrolled in PhD/master's program\"]\n",
            "['Certified AWS or Azure Cloud architect', 'Certification in data management or cloud architecture/engineering']\n",
            "['Research Scientist', 'Research Scientist']\n",
            "['Education Administration Programs']\n",
            "['Automation test frameworks - Selenium, Appium, Playwright', '5+ years of test automation experience', 'Experience with automation test frameworks']\n",
            "['Autonomous driving software', 'Productizing a scalable solution for self-driving', 'GPS navigation experience']\n",
            "['Software development for finance industry', 'Developing software for finance industry']\n",
            "['Lead product team', 'Lead ERP transformation project team', 'Guide engineering teams in multi-discipline approach', 'Lead complex software engineering projects', 'Technical leader in large scale projects']\n",
            "['Revenue & scale strategies', 'Growing sales revenue and profitability', 'Growth within role and career advancement', 'Knowledge of billing and revenue cycles']\n",
            "['Enterprise architecture focus on AI models', 'Continuous improvement of Jarvis framework', 'AI framework experience', 'Experience in AI-based applications and products', 'Solid comprehension of AI concepts and frameworks', 'Experience in AI breakthroughs']\n",
            "['Execute creative software solutions', 'Creative software solutions']\n",
            "['Python, Linux, C/C++, Shell Scripting', 'Python, Unix Shell Scripting']\n",
            "['Help with initial robotic deployments', 'Deploy trained networks on robotic system']\n",
            "['Education and Training', 'Training and educational resources']\n",
            "['Optimize system performance', 'Optimize code efficiency', 'Optimize enterprise applications', 'Optimize and scale systems', 'Drive system performance tuning', 'Performance Optimization - Monitor system performance, identify bottlenecks', 'Optimize system performance', 'Domain knowledge in power/performance tradeoffs']\n",
            "['Early Childhood Education certificate', 'INCOSE CSEP certification']\n",
            "['Create software for CityCatalyst project']\n",
            "['Run reports to support customer meetings', 'Participate in meetings', 'Customer discussions', 'Demonstrated experience with report generation']\n",
            "['TS/SCI clearance', 'Active TOP SECRET/SCI clearance', 'Top Secret Security clearance']\n",
            "['Interacts with internal clients and responds to requests', 'Manage inbound and outbound calls and email correspondence', 'Interact positively with clients and staff', 'Respond to needs/questions', 'Support internal customers']\n",
            "['Building open source digital systems and solutions to battle environmental threats', 'Developing open innovative technology to increase planetary resilience']\n",
            "['Experience with SPSS']\n",
            "['Terminal degree in relevant field', 'Bachelor’s degree in Finance or related discipline', \"Bachelor's degree in relevant field\", 'Bachelor’s Degree in relevant field', 'Degree in relevant field', \"Bachelor's degree in technical field\", \"Bachelor's degree in related field\", \"Bachelor's degree in technical field\"]\n",
            "['Cloud tech exposure', 'Exposure to cloud technologies']\n",
            "['US Citizen', 'Legal authorization to work in US']\n",
            "['Senior Software Engineer', 'Senior Software Engineer', 'Senior Software Engineer, Front End']\n",
            "['Engage in thought leadership', 'Drive innovative thinking', 'Innovate new ways', 'Propel technological innovations, advance scientific discovery', 'Drive impactful insights', 'outside the box thinking']\n",
            "['Sales Application Engineer - Automation', 'Technology Sales Engineer', 'Sales Engineer', 'Sales Application Engineer']\n",
            "['PySpark/Databricks programming']\n",
            "['BSCSE/MSCSE preferred', 'BS/BA', 'BSEE, BSCE, BSCS']\n",
            "['Architecture definition', 'Drive architecture definition', 'Define technical strategy and architecture']\n",
            "['X-ray Imaging', 'Experience in condensed matter or advanced x-ray techniques']\n",
            "['Reliable, self-motivated, flexible, positive']\n",
            "['Identify new directions, formulate objectives aligned with mission', 'Achieve strategic goals']\n",
            "['Bachelors in Computer Science or related field', 'Bachelor’s or Master’s in computer science', \"Bachelor's or Master's degree in Computer Science or related field\", \"Bachelor's degree in Computer Science or related field\", \"Bachelor's degree in computer science or equivalent\", \"Bachelor's or Master's degree in Computer Science\", 'Bachelors in Computer Science or Related Field']\n",
            "['Train deep neural networks', 'Understand training data distributions', 'Image-based neural network training']\n",
            "['work well with others']\n",
            "['Assist with security automation', 'Experience with profiling tools', 'Experience with OneTrust Cookie Management Tool', 'Experience with XCode Utilities', 'Experience with security tools']\n",
            "['Participant communication', 'Interpersonal communication skills', 'Interpersonal and communication skills']\n",
            "['Programming experience in Java, C++, or C#', 'Programming experience in Java, C++, C#']\n",
            "['E-Learning Providers', 'Experience in educational technology or e-learning platforms']\n",
            "['1 year AWS exp', '3+ years of experience with embedded Linux', 'Knowledge of Linux', '1 year Linux experience', '1+ years Linux operating systems']\n",
            "['Experience with large-scale data processing tools like Spark, Flink', 'Experience with big data processing frameworks']\n",
            "['Staffing', 'Recruiting', 'Staff Accountant']\n",
            "['Qualcomm Neural Processing SDK', 'Experience with Python and deep learning frameworks', 'Proficient in deep learning frameworks', 'Experience in building deep learning solutions', 'Experience with deep learning, neural networks, data preprocessing', 'Experience with neural rendering or 3D reconstruction', 'Experience in large-scale learning, high-performance implementations', 'Experience in building new datasets, data-driven problem-solving']\n",
            "['Maximize SoC potential', 'SoC architecture']\n",
            "['Tech Functional Architect, FP&A', 'Tech Functional Architect, FP&A', 'FP&A Tech Workstream Lead']\n",
            "['Rotorcraft Vehicle Simulation Software Engineer']\n",
            "['Fluency in English']\n",
            "['Hypotheses']\n",
            "['Experience with Deltek Costpoint or similar systems']\n",
            "[\"Kernel software development for Boeing's product portfolio\", 'Associate Software Engineer - Kernel Developer', 'Develops reusable architectures and designs for kernel software', 'Subject matter expert for kernel internals']\n",
            "['MizzouForward']\n",
            "['Drive packaging and deployment strategies', 'Package management', 'Configuration Management tools: Ansible, puppet']\n",
            "['Pay Transparency']\n",
            "['Financial services knowledge', 'Financial services industry knowledge', 'Credit Risk knowledge']\n",
            "['design-led software development', 'Software Engineering', 'Software Process', 'Design and develop software systems for research and production processes', 'Designing and maintaining software services', 'Formal training in software engineering', 'Understanding of software engineering principles', 'Software development experience', 'Knowledge of software development best practices', 'Passion for software design', 'Software development experience', 'CAD/CAM development experience']\n",
            "['Amazon Robotics builds high-performance, real-time robotic systems', 'SDE - Amazon Robotics']\n",
            "['Customer service skills', 'Excellent customer service skills']\n",
            "['One-to-one and small group instruction', 'Instructor approval']\n",
            "[\"Lead field teams and Databases counterparts to drive demand, accelerate execution, and bring real digital transformation through Google's Databases Platform\"]\n",
            "['Research fundamental problems', 'Research and solve', 'Competence in researching problems']\n",
            "['Database Acceleration Specialist', 'NoSQL databases', 'Experience in SQL and UI frameworks', 'Database systems experience', 'Experience with data entry', 'Experience with Databases technology stacks and deployment options', 'Database programming exposure']\n",
            "['be active team player', 'Participate in team building activities', 'Monthly Team Events', 'Team off-site events']\n",
            "['Android Espresso, UI Automator']\n",
            "['SEC+ cyber security certificate', 'Certification in delivery methodologies', 'Security+ certification', 'Certifications: CAP, CASP, CISM, CISSP']\n",
            "['Programming languages', 'Programming languages']\n",
            "['Contribute to leading open-source research, models, and datasets', 'Encourage and mentor Open Source contributors', 'Proven track record in leading conferences', 'Strong contribution record in scientific conferences or open source communities']\n",
            "['Creating software to track progress towards Paris Agreement goals', 'Drive interoperability across carbon and ESG disclosure standards']\n",
            "['Teaching students to read and comprehend', 'Implement lesson plans']\n",
            "['Prevent hallucinations']\n",
            "['Create telemetry']\n",
            "['Attention to detail']\n",
            "['Paid Parental Leave and coaching', 'Paid family leave', '4+ months paid Parental Leave']\n",
            "['RTML Model Serving Framework', 'RTML Framework', 'RTML Engineer']\n",
            "['Perform vulnerability assessments']\n",
            "['Yocto Experience']\n",
            "['Maintain clean, safe space']\n",
            "['Use Jira or qTest for tracking', 'Experience using Jira or qTest']\n",
            "['Quantum control solution (QCS)', 'Quantum communications', 'Quantum sensing', 'Azure Quantum', 'Quantum Solution Engineer']\n",
            "['Documentation for pipeline management', 'Ensure pipeline flexibility']\n",
            "['Visa sponsorship']\n",
            "['Develop metrics for model performance', 'Evaluate and fine-tune models', 'Assess effectiveness of models', 'Evaluate AI-generated code']\n",
            "['Experience with MT 4 and 5']\n",
            "['Boston Public Market']\n",
            "['Leading small team', 'Ability to work independently', 'Ability to work in a team', 'Work independently and with team']\n",
            "['Communicate effectively with faculty', 'Professional communication', 'Effective communication', 'clear communication']\n",
            "['K9 gear', 'Provide adventure']\n",
            "['Model-based development review']\n",
            "['Maintenance of Solr/SolrCloud instance']\n",
            "['Develop high-fidelity training simulators', 'Deliver real-time simulators']\n",
            "['Preferred experience in a start-up environment']\n",
            "['Engage in interdisciplinary research efforts for high-impact outcomes', 'Interdisciplinary orientation']\n",
            "['Eliminates middlemen and markups']\n",
            "['HSA, FSA, DCFSA accounts', 'Flexible Spending Account']\n",
            "['Provide direction for software design', 'Set directions on hardware/software platforms']\n"
          ]
        }
      ],
      "source": [
        "cluster_labels = kmeans.labels_\n",
        "# Associate phrases with cluster labels\n",
        "data = {'phrase': phrases, 'cluster_label': cluster_labels}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Get names of phrases in a given cluster (e.g., cluster 0)\n",
        "for i in range(500):\n",
        "  desired_cluster = i\n",
        "  phrases_in_cluster = df.loc[df['cluster_label'] == desired_cluster, 'phrase'].tolist()\n",
        "  print(phrases_in_cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wX0qC3Bkt765"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7-rKSCRyyGQ"
      },
      "source": [
        "The above output is quite nice, but there are fairly obvious issues. In certain cases, the groupings seem sub-optimal. For example, the following lists form 2 clusters:\n",
        "['Python, Linux, C/C++, Shell Scripting', 'Programming languages', 'Coding in python and React/Java Script', 'Experience with Python and Java', 'Python/Java/C++', 'Programming languages']\n",
        "\n",
        "['Telecommunications', 'Telecommunications'].\n",
        "\n",
        "The word telecommunications got it's own cluster whereas we have a cluster that contains phrases with 'Python', 'Linux', 'C', 'C++', 'React', 'Java', 'Java Script'. It's really all over the place, much too broad. It's not horrible but we should try to do better. We should see if we can require a minimum value for neighbors as well as see if more clusters, say 500, helps.\n",
        "\n",
        "Unfortunately there isn't a way to constrain the number of members of a KMeans cluster to a smaller subset. If I use DBSCAN from sklearn.cluster instead I can specify a min_cluster_size.\n",
        "\n",
        "For now I'll try regenerating clusters, this time 500.\n",
        "\n",
        "500 seems to be better; we will explore our clusters further by picking one and looking at the distance between its center and other cluster centers. We will compare phrases from the closest cluster centers.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUmDyssK1Q1p"
      },
      "outputs": [],
      "source": [
        "# Get centroids of clusters\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "dist_list = []\n",
        "\n",
        "for j in range(len(centroids)):\n",
        "  if j != 1:\n",
        "    dist = np.linalg.norm(centroids[1] - centroids[j])\n",
        "    dist_list.append(dist)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmZsfMJzSjRx",
        "outputId": "1ae72bcc-1214-4c5a-a919-69294a6ce0c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6883499462264719"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(dist_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMshHtc3SvL_"
      },
      "outputs": [],
      "source": [
        "ind = dist_list.index(max(dist_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SAvuJ9_S3x0",
        "outputId": "11e56788-cfc8-4596-da75-98537b09f098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "246\n"
          ]
        }
      ],
      "source": [
        "print(ind)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igsC8JTZTM50"
      },
      "source": [
        "The following clusters should have phrases that are quite dissimilar since the second cluster is the farthest one from the first cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yln2H3YmS-AJ",
        "outputId": "a031ad7d-e735-4261-f770-39fd8c2b8227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Strong programming skills', 'Strong software development background', 'Strong programming skills', 'Strong SDLC understanding', 'Strong technical background', 'Strong background in CS and math']\n",
            "['Perform market research', 'Provide feedback on market trends']\n"
          ]
        }
      ],
      "source": [
        "desired_cluster = 1\n",
        "phrases_in_cluster = df.loc[df['cluster_label'] == desired_cluster, 'phrase'].tolist()\n",
        "print(phrases_in_cluster)\n",
        "\n",
        "desired_cluster = 246\n",
        "phrases_in_cluster = df.loc[df['cluster_label'] == desired_cluster, 'phrase'].tolist()\n",
        "print(phrases_in_cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K9KXbIJTnAK",
        "outputId": "7bbe419c-13e6-46a0-d237-b82b0893a93c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "247\n"
          ]
        }
      ],
      "source": [
        "print(dist_list.index(min(dist_list)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtMtlsfOTy8f"
      },
      "source": [
        "The following clusters should have phrases that are somewhat similar since the second cluster is the closest one to the first cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkNCyhGvTxeX",
        "outputId": "0bdd71ef-734e-4ba2-8bad-16fa411902f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Strong programming skills', 'Strong software development background', 'Strong programming skills', 'Strong SDLC understanding', 'Strong technical background', 'Strong background in CS and math']\n",
            "['Holography and Laser Beam Optimization']\n"
          ]
        }
      ],
      "source": [
        "desired_cluster = 1\n",
        "phrases_in_cluster = df.loc[df['cluster_label'] == desired_cluster, 'phrase'].tolist()\n",
        "print(phrases_in_cluster)\n",
        "\n",
        "desired_cluster = 247\n",
        "phrases_in_cluster = df.loc[df['cluster_label'] == desired_cluster, 'phrase'].tolist()\n",
        "print(phrases_in_cluster)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmHfkralT-AQ"
      },
      "source": [
        "Interesting. This is isn't exactly what we'd expect. What is the distance, anyway?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGKjlgzpUGBb",
        "outputId": "59520d28-4815-45be-be06-8f931194e284"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.33785477362425126"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dist_list[247]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tSZYqkmyAp8",
        "outputId": "41dc5685-c8f5-48de-8686-600e2aeb4dde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "539"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(phrases)\n",
        "len(cluster_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKMl7-hkkiYT"
      },
      "source": [
        "Given that we have created clusters for our phrase space, we should be able to one-hot encode which clusters are present in the features selected for a given posting; another option is to do a count. I'll probably try counting them for each row, over columns that we made phrase embeddings for. Thus if we have 500 different clusters we will have 500 more columns in our dataframe. If 3 phrases belonging to cluster 395 are found in row 20, then the value under the cluster395_count column will be 3.\n",
        "\n",
        "We now want to make a function that will for each row count the number of occurences of a given cluster 0-499 and record that number to a special column, one for each phrase cluster. We can do this by associating the indices of the phrase, cluster_labels, and row_labels list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BQ-cAJMStU6"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(500):\n",
        "  column_name = f'cluster{i}_counts'  # Generate column name\n",
        "  df[column_name] = 0  # Fill the column with zeros\n",
        "\n",
        "cluster_labels = kmeans.labels_\n",
        "# Associate phrases with cluster labels\n",
        "data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "clusters_df = pd.DataFrame(data)\n",
        "\n",
        "for i in range(row_labels[-1] + 1):\n",
        "    clusters_in_row = clusters_df.loc[clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      df.at[i, f'cluster{cluster}_counts'] = counts[cluster]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "E2yeq3h1Bt71",
        "outputId": "5dae368b-1a09-48a0-8b52-7c650e10191e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"cluster4_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster5_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster6_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster7_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster8_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster9_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster10_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster11_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster12_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster13_counts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c832bf43-8903-4ee9-93b0-b91c2398f7a7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cluster4_counts</th>\n",
              "      <th>cluster5_counts</th>\n",
              "      <th>cluster6_counts</th>\n",
              "      <th>cluster7_counts</th>\n",
              "      <th>cluster8_counts</th>\n",
              "      <th>cluster9_counts</th>\n",
              "      <th>cluster10_counts</th>\n",
              "      <th>cluster11_counts</th>\n",
              "      <th>cluster12_counts</th>\n",
              "      <th>cluster13_counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c832bf43-8903-4ee9-93b0-b91c2398f7a7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c832bf43-8903-4ee9-93b0-b91c2398f7a7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c832bf43-8903-4ee9-93b0-b91c2398f7a7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-db795947-a5f8-41c8-8b83-a706cf7a4983\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db795947-a5f8-41c8-8b83-a706cf7a4983')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-db795947-a5f8-41c8-8b83-a706cf7a4983 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    cluster4_counts  cluster5_counts  cluster6_counts  cluster7_counts  \\\n",
              "10                0                0                0                0   \n",
              "11                0                0                0                0   \n",
              "12                0                0                0                0   \n",
              "13                0                0                0                0   \n",
              "14                0                0                0                0   \n",
              "\n",
              "    cluster8_counts  cluster9_counts  cluster10_counts  cluster11_counts  \\\n",
              "10                0                2                 0                 0   \n",
              "11                0                0                 0                 0   \n",
              "12                0                0                 0                 0   \n",
              "13                0                0                 0                 0   \n",
              "14                0                0                 0                 0   \n",
              "\n",
              "    cluster12_counts  cluster13_counts  \n",
              "10                 1                 0  \n",
              "11                 0                 0  \n",
              "12                 0                 0  \n",
              "13                 0                 0  \n",
              "14                 0                 0  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.iloc[10:15,35:45]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFtwGoZFCpGe"
      },
      "source": [
        "Cool! It looks like what we did worked!!!\n",
        "\n",
        "Now there are still a few columns that we need to think carefully about to decide how we process their data. Those columns are: employment_type, company, name_of_department/team, city, state, country, min_salary, and max_salary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "v03KA929C9dR",
        "outputId": "f084feec-94dc-46ac-9f00-a818319d6940"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"required_qualifications\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preferred_qualifications\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"benefits\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"work_arrangement\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"New York\",\n          \"Dallas-Fort Worth\",\n          \"North Reading\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\",\n          \"TX\",\n          \"MA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"United States\",\n          \"USA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 61.94255403194156,\n        \"min\": 62.4,\n        \"max\": 150.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          150.0,\n          62.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 75.23616151824866,\n        \"min\": 93.6,\n        \"max\": 200.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          200.0,\n          93.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-17596bad-5741-4571-9ad3-99fd0874532b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>required_qualifications</th>\n",
              "      <th>preferred_qualifications</th>\n",
              "      <th>benefits</th>\n",
              "      <th>work_arrangement</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "      <th>min_salary</th>\n",
              "      <th>max_salary</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0-1+ years experience, Python skills, program...</td>\n",
              "      <td>[clear communication, outside the box thinking...</td>\n",
              "      <td>[100% Medical, PTO, Holiday Pay, 401K Plan]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>Redmond</td>\n",
              "      <td>WA</td>\n",
              "      <td>USA</td>\n",
              "      <td>62.4</td>\n",
              "      <td>93.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Bachelor's, Master's, or Ph.D. in Robotics, M...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>New York</td>\n",
              "      <td></td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[3+ years professional software development ex...</td>\n",
              "      <td>[3+ years full software development life cycle...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>North Reading</td>\n",
              "      <td>MA</td>\n",
              "      <td>USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Bachelor's degree, Master's degree, Computer ...</td>\n",
              "      <td>[Quantitative applications, Fintech experience...</td>\n",
              "      <td>[401(K) match, Flexible Time Off, 12 Paid Holi...</td>\n",
              "      <td>[Hybrid]</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>CA</td>\n",
              "      <td>USA</td>\n",
              "      <td>150.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[5+ years of test automation experience, Profi...</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[N/A]</td>\n",
              "      <td>[On-site]</td>\n",
              "      <td>Dallas-Fort Worth</td>\n",
              "      <td>TX</td>\n",
              "      <td>USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17596bad-5741-4571-9ad3-99fd0874532b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17596bad-5741-4571-9ad3-99fd0874532b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17596bad-5741-4571-9ad3-99fd0874532b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f69115b1-3602-42fa-88ee-b12ca2eab024\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f69115b1-3602-42fa-88ee-b12ca2eab024')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f69115b1-3602-42fa-88ee-b12ca2eab024 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                             required_qualifications  \\\n",
              "0  [0-1+ years experience, Python skills, program...   \n",
              "1  [Bachelor's, Master's, or Ph.D. in Robotics, M...   \n",
              "2  [3+ years professional software development ex...   \n",
              "3  [Bachelor's degree, Master's degree, Computer ...   \n",
              "4  [5+ years of test automation experience, Profi...   \n",
              "\n",
              "                            preferred_qualifications  \\\n",
              "0  [clear communication, outside the box thinking...   \n",
              "1                                              [N/A]   \n",
              "2  [3+ years full software development life cycle...   \n",
              "3  [Quantitative applications, Fintech experience...   \n",
              "4                                              [N/A]   \n",
              "\n",
              "                                            benefits work_arrangement  \\\n",
              "0        [100% Medical, PTO, Holiday Pay, 401K Plan]            [N/A]   \n",
              "1                                              [N/A]            [N/A]   \n",
              "2                                              [N/A]        [On-site]   \n",
              "3  [401(K) match, Flexible Time Off, 12 Paid Holi...         [Hybrid]   \n",
              "4                                              [N/A]        [On-site]   \n",
              "\n",
              "                city state        country  min_salary  max_salary  rating  \n",
              "0            Redmond    WA            USA        62.4        93.6       1  \n",
              "1           New York        United States         NaN         NaN       2  \n",
              "2      North Reading    MA            USA         NaN         NaN       2  \n",
              "3      San Francisco    CA            USA       150.0       200.0       3  \n",
              "4  Dallas-Fort Worth    TX            USA         NaN         NaN       1  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.iloc[:, 10:20].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYZ8_DQMDjif"
      },
      "outputs": [],
      "source": [
        "unique_values = set(df['state'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7dEd6ODDqK0",
        "outputId": "66626ae9-4314-4607-b7d8-9225b6538747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'', 'VA', 'TX', 'NC', 'IA', 'WI', 'AZ', 'WA', 'AR', 'UT', 'GA', 'NJ', 'OR', None, 'PA', 'MI', 'IN', 'MO', 'CO', 'MA', 'CA', 'IL', 'NY', 'ND', 'MD', nan, 'FL'}\n"
          ]
        }
      ],
      "source": [
        "print(unique_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYy02_gGDtlh",
        "outputId": "6b48caf1-adad-4c25-c71f-0c02a0fb62b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Memphis Metropolitan Area', '', 'Lexington Park', 'East Orange', 'Menlo Park', 'College Park', 'Milwaukee', 'Chantilly', 'Berkeley Heights', 'Houston', 'Chillicothe', 'Atlanta', 'Jersey City', 'San Antonio', 'Country Club', 'Boston', 'Pittsburgh', 'California', 'Manhattan', 'Boulder', 'Bentonville', 'Santa Rosa', 'Bismarck', 'Cambridge', 'Irving', 'Portland', 'Dallas', 'Plano', 'New York', 'San Francisco', 'King of Prussia', 'Hazelwood', 'Mesa', 'Ann Arbor', 'Evansville', 'Dallas-Fort Worth', 'Redmond', 'Hillsboro', 'Greater Boston', 'Lakeville', 'Alpharetta', 'Los Angeles', 'Colorado', 'Yorktown Heights', 'Colorado Springs', 'Bellevue', 'Cary', 'Foster City', 'Pewaukee', 'Chicago', 'Austin', 'Lehi', 'San Jose', 'Sunnyvale', 'Pella', 'Columbia', 'North Reading', 'San Diego', 'Irvine', 'Indianapolis', 'Sterling', 'Oakland', 'Mountain View', 'Brooklyn', 'Texas', nan, 'Palm Beach'}\n"
          ]
        }
      ],
      "source": [
        "unique_values = set(df['city'].unique())\n",
        "print(unique_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS4jH4kQD7k3"
      },
      "source": [
        "After looking at the data under the city and state columns, it looks like we probably want to treat states as categorical variables for which we will need to use a label encoder or make new columns to one-hot encode the presence of the occurence of these states in the 'state' column. For the city data, we probably want to make a separate embedding space to cluster all of the city names, as we will want things like 'Dallas' and 'Dallas Metropolitan Area' and 'Dallas/Fort Worth' to all get grouped together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdi065VGFQR7",
        "outputId": "4bfd9604-298e-4694-b867-eb0482262d8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'United States', 'USA', nan, ''}\n"
          ]
        }
      ],
      "source": [
        "unique_values = set(df['country'].unique())\n",
        "print(unique_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTMC7oAAFXqv"
      },
      "source": [
        "We probably want to treat the country data the same way we will treat the state data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuiTk70IFjpx",
        "outputId": "9e8863a9-c314-4644-a53e-ee58e10c27ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['Full-time'], ['Part-time'], ['Contract'], ['Other'], ['Full-time', 'Remote'], ['Internship']]\n",
            "[['Fresh Consulting'], ['Barrington James'], ['Amazon'], ['VantageScore®'], ['Optomi'], ['Crossover'], ['JPMorgan Chase & Co.'], ['maven'], ['REI Systems'], ['Jobot'], ['Remedy Robotics'], ['Insight Global'], ['Ocean Spray Cranberries'], ['Capgemini'], ['Harnham'], ['Huxley'], ['Oxenham Group'], ['Meta'], ['MSH'], ['NVIDIA'], ['University of Missouri-Columbia'], ['Altarum'], ['Booz Allen Hamilton'], ['Qualcomm'], ['Generac Power Systems'], ['Conveyor Solutions, Inc.'], ['Bespoke Beauty Brands'], ['SLAC National Accelerator Laboratory'], ['Dice'], ['Photon'], ['Lindamood-Bell Learning Processes'], ['Intel Corporation'], ['Bobcat Company'], ['ASB Resources'], ['Google'], ['Fractal'], ['Garmin'], ['Amazon Lab126'], ['Peraton'], ['Oho Group Ltd'], ['Braintrust'], ['CoreTek Labs'], ['EVONA'], ['HireIO, Inc.'], ['Diverse Lynx'], ['Oregon Health & Science University'], ['MindSource'], ['Ray Allen Manufacturing'], ['Boston Public Market Association'], ['LG AI Research'], ['Catholic Institute of Technology'], ['Boeing'], ['IBM'], ['Dana Meeks Consulting'], ['Sealing Technologies, a Parsons Company'], ['Pella Corporation'], ['The Mice Groups, Inc.'], ['The Madison Melle Agency'], ['HICO America'], ['alphaMountain.ai'], ['Klaviyo'], ['Apexon'], ['Grid Dynamics'], ['InfoVision Inc.'], ['hackajob'], ['Ghost Autonomy'], ['Raft'], ['MASS TRANSPORTATION SERVICES, INC'], ['The US Oncology Network'], ['Software Engineering Institute | Carnegie Mellon University'], ['Caterpillar Inc.'], ['OpenAI'], ['TEKsystems'], ['Motiv Power Systems'], ['Together AI'], ['Open Earth Foundation'], ['SAIC'], ['Verve Industrial, A Rockwell Automation Company'], ['Zoom'], ['Capital One'], ['Keysight Technologies'], ['QuEra Computing Inc.'], ['Microsoft'], ['Synopsys Inc'], ['Reddit, Inc.'], ['Nurp'], ['Blu Omega']]\n",
            "87\n",
            "[['N/A'], nan, ['AI Engineering & Operations', 'Academic Engineering', 'AI Operations', 'Program Operations'], ['Risk Technology Team'], ['CIB Management and Support Functions'], ['FP&A Tech Workstream Lead'], ['Reality Labs team'], ['Linac Coherent Light Source', 'Stanford Institute for Materials and Energy Sciences'], ['Academic Success Center'], ['Operations Team'], ['Reality Labs Research'], ['Global AI Center'], ['Training Systems team', 'Rotorcraft Training Systems Vehicle Simulation team'], ['Not Applicable'], ['Data Science Platform Team'], ['Real Time ML Service team'], ['AI Division'], ['Embedded Product Cybersecurity team'], ['ChatGPT'], ['Engineering'], ['AI infrastructure team'], ['CIB Management and Support functions group'], ['Creative Management Team']]\n",
            "23\n",
            "[['N/A'], ['On-site'], ['Hybrid'], ['Remote'], ['100% remote with 10% travel may be required'], ['Hybrid with remote days'], ['Hybrid - On-site - Remote'], ['Full remote, PST hours'], ['Onsite'], ['Hybrid', 'Telecommuting up to 40%'], ['100% Onsite'], ['Hybrid, on-site, remote?'], ['On-site, Remote'], ['Online or in-person tutoring'], ['Hybrid - On-site/Off-site'], ['remote'], ['Mainly on-site', 'Potential for remote work 1 day a week'], ['REMOTE'], ['Weekly hybrid onsite component'], ['Local remote'], nan, ['On-site, Travel up to 50%'], ['Hybrid', 'On-site', 'Remote'], ['Hybrid, Remote, In-Person'], ['On-site internship'], ['Hybrid, on-site, remote'], ['Virtual']]\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "possible_vals = []\n",
        "for i in df['employment_type']:\n",
        "  if i not in possible_vals:\n",
        "    possible_vals.append(i)\n",
        "print(possible_vals)\n",
        "\n",
        "possible_vals = []\n",
        "for i in df['company']:\n",
        "  if i not in possible_vals:\n",
        "    possible_vals.append(i)\n",
        "print(possible_vals)\n",
        "\n",
        "print(len(possible_vals))\n",
        "\n",
        "possible_vals = []\n",
        "for i in df['name_of_department/team']:\n",
        "  if i not in possible_vals:\n",
        "    possible_vals.append(i)\n",
        "print(possible_vals)\n",
        "print(len(possible_vals))\n",
        "\n",
        "possible_vals = []\n",
        "for i in df['work_arrangement']:\n",
        "  if i not in possible_vals:\n",
        "    possible_vals.append(i)\n",
        "print(possible_vals)\n",
        "print(len(possible_vals))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6ySmrGJGsjI"
      },
      "source": [
        "I am thinking that for each of the three above categories, we will create unique phrase maps that we do clustering on to shrink down the dimensionality of the category space for each one. Then we will do as we've done with the other columns and count the occurence of given phrases, recording them in new feature columns. For the number of clusters for the given map, it will probably be proportional to the number of rows in the dataframe. To start, for company, we will assume n_clusters = .75*rows = .75*107 = 80. But we probably want it to instead be a logarithmic function, some scaling factor multiplied by ln(row_number), which in this case means 80 = K_comp * 4.67 = K_comp * ln(107) implies K_comp is about 17. For departments, there looks to be maybe a quarter this, so let K_dep = 4. I am making the call now to pull 'work_arrangement' out of the common corpus list and give it and 'employment_type' their own corpus/cluster map. For those two, we will probably want 10 or so clusters, defined by the unique categories 'remote', 'on-site', 'hybrid', 'travel required', 'full-time', 'part-time', 'internship', etc, 'other'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBFLaMniVQbV"
      },
      "source": [
        "We will list out each original feature column and how we encode the data in each one.\n",
        "\n",
        "employment_type - it shares a corpus with work_arrangement\n",
        "\n",
        "job_function - common corpus of phrase embeddings\n",
        "\n",
        "description_of_product/service - common corpus\n",
        "\n",
        "industries - common corpus\n",
        "\n",
        "position_name - common corpus\n",
        "\n",
        "broader_role_name - common corpus\n",
        "\n",
        "company - its own corpus\n",
        "\n",
        "responsibilities - common\n",
        "\n",
        "goals/objectives - common\n",
        "\n",
        "name_of_department/team - its own corpus\n",
        "\n",
        "required_qualifications - common\n",
        "\n",
        "preferred_qualifications - common\n",
        "\n",
        "benefits - common\n",
        "\n",
        "work_arrangement - shared corpus with employment_type\n",
        "\n",
        "city - its own corpus\n",
        "\n",
        "state - label or one-hot encoding\n",
        "\n",
        "country - label or one-hot encoding\n",
        "\n",
        "min_salary - leave as is\n",
        "\n",
        "max_salary - leave as is\n",
        "\n",
        "rating - leave as is (is the target variable)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp3L5rnTYEQH"
      },
      "source": [
        "We need to take the code we have written and generalize it to all the columns. We also need to handle the state and country data as categorical labels which we need to properly encode. We run this first code block to generate our dataframe from the JSON files and links/ratings spreadsheet and fill 'N/A' values with Nan, and then we run the second code block to post-process our dataframe into our many feature count and vector columns. We will drop original columns later right before we pass the data to our ML classifier!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75QQ_FSJjawd",
        "outputId": "b1c7ef55-1079-4719-8e08-d4b3cf7a42ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n"
          ]
        }
      ],
      "source": [
        "json_files_path = \"drive/MyDrive/LI-Jobs-JSON/\"\n",
        "links_csv_path = \"drive/MyDrive/successfulLinksGDRIVE.csv\"\n",
        "\n",
        "import pandas as pd\n",
        "links_dataframe = pd.read_csv(links_csv_path, header=None, names=['url', 'rating'])\n",
        "#links_dataframe.head()\n",
        "#print(links_dataframe.loc[0, 'rating'])\n",
        "\n",
        "# let's snakecase our column names to avoid having spaces in them\n",
        "# also we add a rating column at the end of the list to store the target variable\n",
        "df_columns = [\"employment_type\", \"job_function\", \"description_of_product/service\", \"industries\",\n",
        "              \"position_name\", \"broader_role_name\", \"company\", #\"location\", \"salary/compensation_range\",\n",
        "              \"responsibilities\", \"goals/objectives\", \"name_of_department/team\", \"required_qualifications\",\n",
        "              \"preferred_qualifications\", \"benefits\", \"work_arrangement\", \"city\", \"state\", \"country\",\n",
        "              \"min_salary\", \"max_salary\", \"rating\"]\n",
        "# Initialize DataFrame with column names\n",
        "df = pd.DataFrame(columns=df_columns)\n",
        "\n",
        "import os\n",
        "import json\n",
        "locale_json_files_path = \"drive/MyDrive/jobLocations/\"\n",
        "salary_json_files_path = \"drive/MyDrive/jobSalaries/\"\n",
        "\n",
        "for i in range(1, 108):\n",
        "  row_num = df.last_valid_index()\n",
        "  print(row_num)\n",
        "  if row_num == None:\n",
        "    row_num = 0\n",
        "  else:\n",
        "    row_num = row_num + 1\n",
        "  assert i == row_num + 1\n",
        "  json_file_path = os.path.join(json_files_path, f'row{i}.json')\n",
        "  # Read JSON file\n",
        "  with open(json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  if 'fields' in json_data.keys():\n",
        "    #print(json_data)\n",
        "    field_names = json_data['fields']\n",
        "    for index, value in enumerate(field_names):\n",
        "      info = json_data['info'][index]\n",
        "      # Check if the value exists as a column name (ignoring case)\n",
        "      column_name = value.replace(\" \", \"_\").lower()\n",
        "      if column_name in df.columns:\n",
        "        # Add the info to the corresponding column and row\n",
        "        df.at[row_num, column_name] = info\n",
        "  else:\n",
        "    for key, value in json_data.items():\n",
        "      # Check if the key exists as a column name (ignoring case)\n",
        "      column_name = key.replace(\" \", \"_\").lower()\n",
        "      if column_name == 'emploment_type':\n",
        "        column_name = 'employment_type'\n",
        "      if column_name in df.columns:\n",
        "        # Add the value to the corresponding column and row\n",
        "        df.at[row_num, column_name] = value\n",
        "\n",
        "  locale_json_file_path = os.path.join(locale_json_files_path, f'row{i}.json')\n",
        "  salary_json_file_path = os.path.join(salary_json_files_path, f'row{i}.json')\n",
        "  # Read locale JSON file\n",
        "  with open(locale_json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  try:\n",
        "    city = json_data[\"city\"]\n",
        "    state = json_data[\"state\"]\n",
        "    country = json_data[\"country\"]\n",
        "    df.at[row_num, 'city'] = city\n",
        "    df.at[row_num, 'state'] = state\n",
        "    df.at[row_num, 'country'] = country\n",
        "  except:\n",
        "    df.at[row_num, 'city'] = \"N/A\"\n",
        "    df.at[row_num, 'state'] = \"N/A\"\n",
        "    df.at[row_num, 'country'] = \"N/A\"\n",
        "  # Read salary JSON file\n",
        "  with open(salary_json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  min_salary = json_data[\"salary_min\"]\n",
        "  max_salary = json_data[\"salary_max\"]\n",
        "  df.at[row_num, 'min_salary'] = min_salary\n",
        "  df.at[row_num, 'max_salary'] = max_salary\n",
        "  rating = links_dataframe.loc[row_num, 'rating']\n",
        "  df.at[row_num, 'rating'] = rating\n",
        "\n",
        "import numpy as np\n",
        "# Replace 'N/A' with NaN in the whole DataFrame\n",
        "df.replace('N/A', np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yu49mwH8W4g7"
      },
      "outputs": [],
      "source": [
        "common_corpus_columns = ['job_function', 'description_of_product/service', 'industries', 'position_name', 'broader_role_name',\n",
        "                         'responsibilities', 'goals/objectives', 'required_qualifications', 'preferred_qualifications', 'benefits']\n",
        "\n",
        "singular_corpus_columns = ['company', 'name_of_department/team', 'city']\n",
        "\n",
        "work_arrangement_columns = ['employment_type', 'work_arrangement']\n",
        "\n",
        "categorical_label_columns = ['state', 'country']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "37e03d8587c34545b4b45130035ab3c4",
            "c995ab9ec9e948519b9dc6a1100e4b32",
            "c86eb8be076a47fca8d6c376dc199d64",
            "a851782de0e74d769643a5f034506602",
            "3074bbc2aa2e49379053d93f5676c05b",
            "d9d1aef86724446a9090a435a4b58af9",
            "afadb7d47ca5462c88159d04d282a756",
            "b2be7f77fced4758afcdc9551e284339",
            "64a2f5bb769c4a159e707d22ed8aff15",
            "6e0c2a0459f144c28d426df9064fc4a2",
            "d0c8839910d642afb20382cd2d03fbab",
            "0e1a8db993844266a9c10f5328debd59",
            "bdebfcd1592e40e0b82e06c3fd27dfee",
            "609d5691aabf4b6b9b55888b19b1cbc2",
            "0ef8e78e195741719bc5e7733e9e9eec",
            "094056fcc97941a0bb7d9523917b5e9f",
            "56f485276f6e4818a45033bd0aa35f28",
            "d9d5b446a43d4815b8a44ccfaf749247",
            "fc24527bd3f6412189237de127c64b67",
            "a6cc356f3f4443299b5e0b3c9b6dad82",
            "6613cf44acff41c4906d397a37212da3",
            "8462f524daf84ae9bf61906528f46b53",
            "16c11f8ff03c48cdb841fddeab29da6c",
            "d6f2d8e6c3404cb986bb68e272d357aa",
            "91d660e6544d4539b3183682c3756da8",
            "930d71535cf640fa81849eeaf06f13f5",
            "d0201d9f2f194230b37e8a8eff1a5e23",
            "8c8245fe58cf440d94bd0c357efd7c64",
            "e5a33594ecfb4b0cb5c01df8a461b2b1",
            "6dc87f15a0b64eca8bf31234c800f8cb",
            "05cea2751e3d48ef8b19a6cd59251cfe",
            "c38173bb67bd422ab510eb77b176c8d4",
            "afbc3d2150fc4aa0bf56eb8727efe662",
            "7b4829cb21704b06b003573e64b5d5a8",
            "d00ca8b9c67340f2a05442ab16f725e9",
            "77db1d0d07924f7fa0c649548c2ea20b",
            "28b8699a575a456c9100474092c922e3",
            "26a58318089b47e2924cb56309e328bc",
            "42c41d83887e4530a0fa9a778c809a5e",
            "c38dfeee5e26454a8e309e78f5142ea5",
            "785541714ea8480296bd1e7135e0757b",
            "572f74ebed604fa6bea72afd5e8742c5",
            "f4b80923582949128a306c78fefde2e9",
            "a642ca0966cd44e8bbb69b13e79ba01a",
            "b4e0a1423be7463eb7991a336fff0497",
            "2738ef58041347b784638de6bcf63a9e",
            "d77de8c82136466c9175e45c38521446",
            "a1d3661d6cd142119fc3119f1de8b2e2",
            "cba2026e8b1a45ceb63253e79dfd2402",
            "0e253b7723114d3babab10c41eb6d494",
            "14870ebc6f474eb8a758c246aac860b9",
            "8f9f16d94f404bb09e0f276988946ccc",
            "7dd279ca1a4d430c86b46637ca0cd52e",
            "3eb10357400346f5875edc353b400c8c",
            "8304a7fce13446dc8c8e84aa810597a3",
            "fa55045d4fd14deca3e8de8dc0448bc7",
            "d2e0777a877946209a5e445b5800ce15",
            "c6fe69a140e446b180d7ad902bf96f59",
            "08838b80e51542c193247c2e964dba12",
            "c1d4ebc9801b4ddc85628a7a7b00a5c1",
            "716eca1540a34cad8a86cb75e68fe5ca",
            "cca6cc2f3f3046d8836aef6d21348dd0",
            "b21c99b5d76d4f64805a02d0e94188fa",
            "97d515b654eb4e64a9bd892e7f514a23",
            "0edfad61528e4497ba54ddce869cb46b",
            "df4a3f1952ac47038ab80a2a69c41d58"
          ]
        },
        "id": "I9jMFCkFYD4f",
        "outputId": "a1e80efb-9897-4f77-d5dd-de6ce0ffacb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37e03d8587c34545b4b45130035ab3c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e1a8db993844266a9c10f5328debd59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16c11f8ff03c48cdb841fddeab29da6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b4829cb21704b06b003573e64b5d5a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4e0a1423be7463eb7991a336fff0497",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa55045d4fd14deca3e8de8dc0448bc7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-033dc7504748>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-3-033dc7504748>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-3-033dc7504748>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-3-033dc7504748>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-3-033dc7504748>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-3-033dc7504748>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-3-033dc7504748>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-3-033dc7504748>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-3-033dc7504748>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-3-033dc7504748>:21: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:72: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-3-033dc7504748>:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:72: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-3-033dc7504748>:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:72: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-3-033dc7504748>:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:121: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-3-033dc7504748>:140: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "<ipython-input-3-033dc7504748>:121: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-3-033dc7504748>:140: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-3-033dc7504748>:153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-3-033dc7504748>:153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "common_corpus_columns = ['job_function', 'description_of_product/service', 'industries', 'position_name', 'broader_role_name',\n",
        "                         'responsibilities', 'goals/objectives', 'required_qualifications', 'preferred_qualifications', 'benefits']\n",
        "\n",
        "singular_corpus_columns = ['company', 'name_of_department/team', 'city']\n",
        "\n",
        "work_arrangement_columns = ['employment_type', 'work_arrangement']\n",
        "\n",
        "categorical_label_columns = ['state', 'country']\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-large\")\n",
        "model = AutoModel.from_pretrained(\"thenlper/gte-large\")\n",
        "\n",
        "def average_pool(last_hidden_states: Tensor,\n",
        "                 attention_mask: Tensor) -> Tensor:\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "phrases = []\n",
        "row_labels = []\n",
        "for col in common_corpus_columns:\n",
        "  new_col_data = []\n",
        "  for index, value in df[col].iteritems():\n",
        "    if type(value) == list:\n",
        "      # Tokenize the input texts\n",
        "      for phrase in value:\n",
        "        phrases.append(phrase)\n",
        "        row_labels.append(index)\n",
        "    else:\n",
        "      phrases.append(str(value))\n",
        "      row_labels.append(index)\n",
        "      value = [str(value)]\n",
        "    batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model(**batch_dict)\n",
        "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "    # (Optionally) normalize embeddings\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "  df[f'{col}_vectors'] = new_col_data\n",
        "\n",
        "vector_cols = [f'{col}_vectors' for col in common_corpus_columns]\n",
        "phrase_vecs_list = []\n",
        "for col in vector_cols:\n",
        "  for i in df[col]:\n",
        "    for j in i:\n",
        "      phrase_vecs_list.append(j)\n",
        "kmeans = KMeans(n_clusters=500, random_state=57)\n",
        "kmeans.fit(phrase_vecs_list)\n",
        "\n",
        "for i in range(500):\n",
        "  column_name = f'common_cluster{i}_counts'  # Generate column name\n",
        "  df[column_name] = 0  # Fill the column with zeros\n",
        "\n",
        "cluster_labels = kmeans.labels_\n",
        "# Associate phrases with cluster labels\n",
        "data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "common_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "for i in range(row_labels[-1] + 1):\n",
        "  clusters_in_row = clusters_df.loc[common_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "  # Generate value counts\n",
        "  counts = Counter(clusters_in_row)\n",
        "  for cluster in counts.keys():\n",
        "    df.at[i, f'common_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "n_clusters_scale_factor = {'city': .5, 'company': .75, 'name_of_department/team': .2}\n",
        "singular_corpus_clusters_df_dict = {}\n",
        "for col in singular_corpus_columns:\n",
        "  phrases = []\n",
        "  row_labels = []\n",
        "  new_col_data = []\n",
        "  for index, value in df[col].iteritems():\n",
        "    if type(value) == list:\n",
        "      # Tokenize the input texts\n",
        "      for phrase in value:\n",
        "        phrases.append(phrase)\n",
        "        row_labels.append(index)\n",
        "    else:\n",
        "      phrases.append(str(value))\n",
        "      row_labels.append(index)\n",
        "      value = [str(value)]\n",
        "    batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model(**batch_dict)\n",
        "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "    # (Optionally) normalize embeddings\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "  df[f'{col}_vectors'] = new_col_data\n",
        "  vector_col = f'{col}_vectors'\n",
        "  phrase_vecs_list = []\n",
        "  for i in df[vector_col]:\n",
        "    for j in i:\n",
        "      phrase_vecs_list.append(j)\n",
        "  n_clusters = int(df.shape[0]*n_clusters_scale_factor[col])\n",
        "  kmeans = KMeans(n_clusters=n_clusters, random_state=57)\n",
        "  kmeans.fit(phrase_vecs_list)\n",
        "\n",
        "  for i in range(n_clusters):\n",
        "    column_name = f'{col}_cluster{i}_counts'  # Generate column name\n",
        "    df[column_name] = 0  # Fill the column with zeros\n",
        "\n",
        "  cluster_labels = kmeans.labels_\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "  clusters_df = pd.DataFrame(data)\n",
        "  singular_corpus_clusters_df_dict[col] = clusters_df\n",
        "\n",
        "  for i in range(row_labels[-1] + 1):\n",
        "    clusters_in_row = clusters_df.loc[clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      df.at[i, f'{col}_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "phrases = []\n",
        "row_labels = []\n",
        "for col in work_arrangement_columns:\n",
        "  new_col_data = []\n",
        "  for index, value in df[col].iteritems():\n",
        "    if type(value) == list:\n",
        "      # Tokenize the input texts\n",
        "      for phrase in value:\n",
        "        phrases.append(phrase)\n",
        "        row_labels.append(index)\n",
        "    else:\n",
        "      phrases.append(str(value))\n",
        "      row_labels.append(index)\n",
        "      value = [str(value)]\n",
        "    batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model(**batch_dict)\n",
        "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "    # (Optionally) normalize embeddings\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "  df[f'{col}_vectors'] = new_col_data\n",
        "\n",
        "vector_cols = [f'{col}_vectors' for col in work_arrangement_columns]\n",
        "phrase_vecs_list = []\n",
        "for col in vector_cols:\n",
        "  for i in df[col]:\n",
        "    for j in i:\n",
        "      phrase_vecs_list.append(j)\n",
        "kmeans = KMeans(n_clusters=10, random_state=57)\n",
        "kmeans.fit(phrase_vecs_list)\n",
        "\n",
        "for i in range(10):\n",
        "  column_name = f'work_arrangement_cluster{i}_counts'  # Generate column name\n",
        "  df[column_name] = 0  # Fill the column with zeros\n",
        "\n",
        "cluster_labels = kmeans.labels_\n",
        "# Associate phrases with cluster labels\n",
        "data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "work_arrangement_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "for i in range(row_labels[-1] + 1):\n",
        "  clusters_in_row = clusters_df.loc[clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "  # Generate value counts\n",
        "  counts = Counter(clusters_in_row)\n",
        "  for cluster in counts.keys():\n",
        "    df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "for col in categorical_label_columns:\n",
        "  # Perform one-hot encoding\n",
        "  one_hot_encoded_df = pd.get_dummies(df[col])\n",
        "\n",
        "  # Concatenate the original dataframe with the one-hot encoded dataframe\n",
        "  df = pd.concat([df, one_hot_encoded_df], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N3UONUKpdiq"
      },
      "source": [
        "This took 11 mins but it worked (I think). For reference generating the original dataframe took about a minute. Doing it a second time, it took 15 mins. Hopefully I can find a better or more efficient way to do what I'm trying to do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "EY6wUW6_VRKF",
        "outputId": "03fd32f0-0d69-4a7c-c749-471b22823700"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"OR\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PA\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TX\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UT\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VA\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WA\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WI\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"USA\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"United States\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-787c1850-a5eb-45f4-8eb9-226ba129da1b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OR</th>\n",
              "      <th>PA</th>\n",
              "      <th>TX</th>\n",
              "      <th>UT</th>\n",
              "      <th>VA</th>\n",
              "      <th>WA</th>\n",
              "      <th>WI</th>\n",
              "      <th></th>\n",
              "      <th>USA</th>\n",
              "      <th>United States</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-787c1850-a5eb-45f4-8eb9-226ba129da1b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-787c1850-a5eb-45f4-8eb9-226ba129da1b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-787c1850-a5eb-45f4-8eb9-226ba129da1b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-320d2352-bde3-4f9c-ba1e-83825a725a8b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-320d2352-bde3-4f9c-ba1e-83825a725a8b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-320d2352-bde3-4f9c-ba1e-83825a725a8b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   OR  PA  TX  UT  VA  WA  WI     USA  United States\n",
              "0   0   0   0   0   0   1   0  0    1              0\n",
              "1   0   0   0   0   0   0   0  0    0              1\n",
              "2   0   0   0   0   0   0   0  0    1              0\n",
              "3   0   0   0   0   0   0   0  0    1              0\n",
              "4   0   0   1   0   0   0   0  0    1              0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHfnsYjQOI8D"
      },
      "source": [
        "This is where we can finally train our first classifier on our data, with sklearn's DecisionTreeClassifier class! We will make a copy of our dataframe df with some of the rows dropped, meaning the rows that we encoded which were most except for the rating, min_salary, and max_salary. The columns to drop will be the list (common_corpus_columns + singular_corpus_columns + work_arrangement_columns + categorical_labels_columns). Also, now that I'm trying to pass the dataframe to the decision tree, I am getting an error and realizing that I still need to drop the vector columns. In the previous code block where I generate embeddings I will not create columns for these"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "GhPzJvitOIiw",
        "outputId": "d30926a0-94d5-4a7f-8c9f-eb68f0e13356"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Input X contains NaN.\nDecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-9e5a14f2eff0>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Train the decision tree classifier on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Test the classifier on the testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                     \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nDecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ],
      "source": [
        "columns_to_drop = common_corpus_columns + singular_corpus_columns + work_arrangement_columns + categorical_label_columns\n",
        "embedded_data_columns = common_corpus_columns + singular_corpus_columns + work_arrangement_columns\n",
        "embedded_data_columns = [f'{col}_vectors' for col in embedded_data_columns]\n",
        "\n",
        "columns_to_drop = columns_to_drop + embedded_data_columns\n",
        "\n",
        "# Make a copy of the dataframe with specified columns dropped\n",
        "df_copy = df.drop(columns=columns_to_drop).copy()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming df_encoded is your dataframe with one-hot encoded features and target variable\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = df_copy.drop(columns=['rating'])  # Features\n",
        "y = df_copy['rating']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the decision tree classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train the decision tree classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMnpRjylTVPs"
      },
      "source": [
        "It turns out the Decision Tree from sklearn does not support having NaNs in the dataframe. The Python interpreter recommends sklearn.ensemble.HistGradientBoostingClassifier so we will try that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ24GLR2Tk12",
        "outputId": "e8d80fc7-9899-4191-ab71-cd6df65787bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.3181818181818182\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "columns_to_drop = common_corpus_columns + singular_corpus_columns + work_arrangement_columns + categorical_label_columns\n",
        "embedded_data_columns = common_corpus_columns + singular_corpus_columns + work_arrangement_columns\n",
        "embedded_data_columns = [f'{col}_vectors' for col in embedded_data_columns]\n",
        "\n",
        "columns_to_drop = columns_to_drop + embedded_data_columns\n",
        "\n",
        "# Make a copy of the dataframe with specified columns dropped\n",
        "df_copy = df.drop(columns=columns_to_drop).copy()\n",
        "\n",
        "# Assuming df_encoded is your dataframe with one-hot encoded features and target variable\n",
        "# Split the data into features (X) and target variable (y)\n",
        "y = df_copy['rating'] # Target variable\n",
        "X = df_copy.drop(columns=['rating'])  # Features\n",
        "\n",
        "# Assuming X and y are your feature matrix and target variable respectively\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the HistGradientBoostingClassifier\n",
        "clf = HistGradientBoostingClassifier()\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5UJWblWUsx6",
        "outputId": "a278e010-4fb6-418d-b4a1-897611a7de5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.8636363636363636\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgXDz3dFUvsC"
      },
      "source": [
        "So evidently we got terrible accuracy. We were only right 31.8% of the time and our mean absolute error was almost an entire rating increment! A random model would have given an accuracy of 25% and a mean absolute error of 1.25. So we have taken a step in the right direction but want something that works reliably. What should reasonable values for accuracy and mean absolute error be? It's hard to say, but let's set ourselves the reasonable goals of 50% and .5 respectively. This means we correctly classify the job posting into the correct of 4 bins 50% of the time, and we on average our prediction is only off by half a point.\n",
        "\n",
        "There are many things to try to increase our performance. The first being get more data or make the dataset larger. The next is reengineer our features so that they are easier for the model to learn from. The next after that is to drop some feature columns (which reengineering may help solve). The next thing would be to try a different algorithm. What about the decision tree? We can revisit it by setting the NaNs in our dataframe to the mode of the column it is in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68cCKPL4ZO16",
        "outputId": "0171eac2-e308-43fa-9c04-17e184acf920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "min_salary\n",
            "100.0\n",
            "max_salary\n",
            "200.0\n",
            "rating\n",
            "2\n",
            "common_cluster0_counts\n",
            "0\n",
            "common_cluster1_counts\n",
            "0\n",
            "common_cluster2_counts\n",
            "2\n",
            "common_cluster3_counts\n",
            "0\n",
            "common_cluster4_counts\n",
            "0\n",
            "common_cluster5_counts\n",
            "0\n",
            "common_cluster6_counts\n",
            "0\n",
            "common_cluster7_counts\n",
            "0\n",
            "common_cluster8_counts\n",
            "0\n",
            "common_cluster9_counts\n",
            "0\n",
            "common_cluster10_counts\n",
            "0\n",
            "common_cluster11_counts\n",
            "0\n",
            "common_cluster12_counts\n",
            "0\n",
            "common_cluster13_counts\n",
            "0\n",
            "common_cluster14_counts\n",
            "0\n",
            "common_cluster15_counts\n",
            "0\n",
            "common_cluster16_counts\n",
            "0\n",
            "common_cluster17_counts\n",
            "0\n",
            "common_cluster18_counts\n",
            "0\n",
            "common_cluster19_counts\n",
            "0\n",
            "common_cluster20_counts\n",
            "0\n",
            "common_cluster21_counts\n",
            "0\n",
            "common_cluster22_counts\n",
            "0\n",
            "common_cluster23_counts\n",
            "0\n",
            "common_cluster24_counts\n",
            "1\n",
            "common_cluster25_counts\n",
            "0\n",
            "common_cluster26_counts\n",
            "0\n",
            "common_cluster27_counts\n",
            "0\n",
            "common_cluster28_counts\n",
            "0\n",
            "common_cluster29_counts\n",
            "0\n",
            "common_cluster30_counts\n",
            "0\n",
            "common_cluster31_counts\n",
            "0\n",
            "common_cluster32_counts\n",
            "0\n",
            "common_cluster33_counts\n",
            "0\n",
            "common_cluster34_counts\n",
            "0\n",
            "common_cluster35_counts\n",
            "0\n",
            "common_cluster36_counts\n",
            "0\n",
            "common_cluster37_counts\n",
            "0\n",
            "common_cluster38_counts\n",
            "0\n",
            "common_cluster39_counts\n",
            "0\n",
            "common_cluster40_counts\n",
            "0\n",
            "common_cluster41_counts\n",
            "0\n",
            "common_cluster42_counts\n",
            "0\n",
            "common_cluster43_counts\n",
            "0\n",
            "common_cluster44_counts\n",
            "0\n",
            "common_cluster45_counts\n",
            "0\n",
            "common_cluster46_counts\n",
            "0\n",
            "common_cluster47_counts\n",
            "0\n",
            "common_cluster48_counts\n",
            "0\n",
            "common_cluster49_counts\n",
            "0\n",
            "common_cluster50_counts\n",
            "0\n",
            "common_cluster51_counts\n",
            "0\n",
            "common_cluster52_counts\n",
            "0\n",
            "common_cluster53_counts\n",
            "0\n",
            "common_cluster54_counts\n",
            "0\n",
            "common_cluster55_counts\n",
            "0\n",
            "common_cluster56_counts\n",
            "0\n",
            "common_cluster57_counts\n",
            "0\n",
            "common_cluster58_counts\n",
            "0\n",
            "common_cluster59_counts\n",
            "0\n",
            "common_cluster60_counts\n",
            "0\n",
            "common_cluster61_counts\n",
            "0\n",
            "common_cluster62_counts\n",
            "0\n",
            "common_cluster63_counts\n",
            "0\n",
            "common_cluster64_counts\n",
            "0\n",
            "common_cluster65_counts\n",
            "0\n",
            "common_cluster66_counts\n",
            "0\n",
            "common_cluster67_counts\n",
            "0\n",
            "common_cluster68_counts\n",
            "0\n",
            "common_cluster69_counts\n",
            "0\n",
            "common_cluster70_counts\n",
            "0\n",
            "common_cluster71_counts\n",
            "0\n",
            "common_cluster72_counts\n",
            "0\n",
            "common_cluster73_counts\n",
            "0\n",
            "common_cluster74_counts\n",
            "0\n",
            "common_cluster75_counts\n",
            "0\n",
            "common_cluster76_counts\n",
            "0\n",
            "common_cluster77_counts\n",
            "0\n",
            "common_cluster78_counts\n",
            "0\n",
            "common_cluster79_counts\n",
            "0\n",
            "common_cluster80_counts\n",
            "0\n",
            "common_cluster81_counts\n",
            "0\n",
            "common_cluster82_counts\n",
            "0\n",
            "common_cluster83_counts\n",
            "0\n",
            "common_cluster84_counts\n",
            "0\n",
            "common_cluster85_counts\n",
            "0\n",
            "common_cluster86_counts\n",
            "0\n",
            "common_cluster87_counts\n",
            "0\n",
            "common_cluster88_counts\n",
            "0\n",
            "common_cluster89_counts\n",
            "0\n",
            "common_cluster90_counts\n",
            "0\n",
            "common_cluster91_counts\n",
            "0\n",
            "common_cluster92_counts\n",
            "0\n",
            "common_cluster93_counts\n",
            "0\n",
            "common_cluster94_counts\n",
            "0\n",
            "common_cluster95_counts\n",
            "0\n",
            "common_cluster96_counts\n",
            "0\n",
            "common_cluster97_counts\n",
            "0\n",
            "common_cluster98_counts\n",
            "0\n",
            "common_cluster99_counts\n",
            "0\n",
            "common_cluster100_counts\n",
            "0\n",
            "common_cluster101_counts\n",
            "0\n",
            "common_cluster102_counts\n",
            "0\n",
            "common_cluster103_counts\n",
            "0\n",
            "common_cluster104_counts\n",
            "0\n",
            "common_cluster105_counts\n",
            "0\n",
            "common_cluster106_counts\n",
            "0\n",
            "common_cluster107_counts\n",
            "0\n",
            "common_cluster108_counts\n",
            "0\n",
            "common_cluster109_counts\n",
            "0\n",
            "common_cluster110_counts\n",
            "0\n",
            "common_cluster111_counts\n",
            "0\n",
            "common_cluster112_counts\n",
            "0\n",
            "common_cluster113_counts\n",
            "0\n",
            "common_cluster114_counts\n",
            "0\n",
            "common_cluster115_counts\n",
            "0\n",
            "common_cluster116_counts\n",
            "0\n",
            "common_cluster117_counts\n",
            "0\n",
            "common_cluster118_counts\n",
            "0\n",
            "common_cluster119_counts\n",
            "0\n",
            "common_cluster120_counts\n",
            "0\n",
            "common_cluster121_counts\n",
            "0\n",
            "common_cluster122_counts\n",
            "0\n",
            "common_cluster123_counts\n",
            "0\n",
            "common_cluster124_counts\n",
            "0\n",
            "common_cluster125_counts\n",
            "0\n",
            "common_cluster126_counts\n",
            "0\n",
            "common_cluster127_counts\n",
            "0\n",
            "common_cluster128_counts\n",
            "0\n",
            "common_cluster129_counts\n",
            "0\n",
            "common_cluster130_counts\n",
            "0\n",
            "common_cluster131_counts\n",
            "0\n",
            "common_cluster132_counts\n",
            "0\n",
            "common_cluster133_counts\n",
            "0\n",
            "common_cluster134_counts\n",
            "0\n",
            "common_cluster135_counts\n",
            "0\n",
            "common_cluster136_counts\n",
            "0\n",
            "common_cluster137_counts\n",
            "0\n",
            "common_cluster138_counts\n",
            "0\n",
            "common_cluster139_counts\n",
            "0\n",
            "common_cluster140_counts\n",
            "0\n",
            "common_cluster141_counts\n",
            "0\n",
            "common_cluster142_counts\n",
            "0\n",
            "common_cluster143_counts\n",
            "0\n",
            "common_cluster144_counts\n",
            "0\n",
            "common_cluster145_counts\n",
            "0\n",
            "common_cluster146_counts\n",
            "0\n",
            "common_cluster147_counts\n",
            "0\n",
            "common_cluster148_counts\n",
            "0\n",
            "common_cluster149_counts\n",
            "0\n",
            "common_cluster150_counts\n",
            "0\n",
            "common_cluster151_counts\n",
            "0\n",
            "common_cluster152_counts\n",
            "0\n",
            "common_cluster153_counts\n",
            "0\n",
            "common_cluster154_counts\n",
            "0\n",
            "common_cluster155_counts\n",
            "0\n",
            "common_cluster156_counts\n",
            "0\n",
            "common_cluster157_counts\n",
            "0\n",
            "common_cluster158_counts\n",
            "0\n",
            "common_cluster159_counts\n",
            "0\n",
            "common_cluster160_counts\n",
            "0\n",
            "common_cluster161_counts\n",
            "0\n",
            "common_cluster162_counts\n",
            "0\n",
            "common_cluster163_counts\n",
            "0\n",
            "common_cluster164_counts\n",
            "0\n",
            "common_cluster165_counts\n",
            "0\n",
            "common_cluster166_counts\n",
            "0\n",
            "common_cluster167_counts\n",
            "0\n",
            "common_cluster168_counts\n",
            "0\n",
            "common_cluster169_counts\n",
            "0\n",
            "common_cluster170_counts\n",
            "0\n",
            "common_cluster171_counts\n",
            "0\n",
            "common_cluster172_counts\n",
            "0\n",
            "common_cluster173_counts\n",
            "0\n",
            "common_cluster174_counts\n",
            "0\n",
            "common_cluster175_counts\n",
            "0\n",
            "common_cluster176_counts\n",
            "0\n",
            "common_cluster177_counts\n",
            "0\n",
            "common_cluster178_counts\n",
            "0\n",
            "common_cluster179_counts\n",
            "0\n",
            "common_cluster180_counts\n",
            "0\n",
            "common_cluster181_counts\n",
            "0\n",
            "common_cluster182_counts\n",
            "0\n",
            "common_cluster183_counts\n",
            "0\n",
            "common_cluster184_counts\n",
            "0\n",
            "common_cluster185_counts\n",
            "0\n",
            "common_cluster186_counts\n",
            "0\n",
            "common_cluster187_counts\n",
            "0\n",
            "common_cluster188_counts\n",
            "0\n",
            "common_cluster189_counts\n",
            "0\n",
            "common_cluster190_counts\n",
            "0\n",
            "common_cluster191_counts\n",
            "0\n",
            "common_cluster192_counts\n",
            "0\n",
            "common_cluster193_counts\n",
            "0\n",
            "common_cluster194_counts\n",
            "0\n",
            "common_cluster195_counts\n",
            "0\n",
            "common_cluster196_counts\n",
            "0\n",
            "common_cluster197_counts\n",
            "0\n",
            "common_cluster198_counts\n",
            "0\n",
            "common_cluster199_counts\n",
            "0\n",
            "common_cluster200_counts\n",
            "0\n",
            "common_cluster201_counts\n",
            "0\n",
            "common_cluster202_counts\n",
            "0\n",
            "common_cluster203_counts\n",
            "0\n",
            "common_cluster204_counts\n",
            "0\n",
            "common_cluster205_counts\n",
            "0\n",
            "common_cluster206_counts\n",
            "0\n",
            "common_cluster207_counts\n",
            "0\n",
            "common_cluster208_counts\n",
            "0\n",
            "common_cluster209_counts\n",
            "0\n",
            "common_cluster210_counts\n",
            "0\n",
            "common_cluster211_counts\n",
            "0\n",
            "common_cluster212_counts\n",
            "0\n",
            "common_cluster213_counts\n",
            "0\n",
            "common_cluster214_counts\n",
            "0\n",
            "common_cluster215_counts\n",
            "0\n",
            "common_cluster216_counts\n",
            "0\n",
            "common_cluster217_counts\n",
            "0\n",
            "common_cluster218_counts\n",
            "0\n",
            "common_cluster219_counts\n",
            "0\n",
            "common_cluster220_counts\n",
            "0\n",
            "common_cluster221_counts\n",
            "0\n",
            "common_cluster222_counts\n",
            "0\n",
            "common_cluster223_counts\n",
            "0\n",
            "common_cluster224_counts\n",
            "0\n",
            "common_cluster225_counts\n",
            "0\n",
            "common_cluster226_counts\n",
            "0\n",
            "common_cluster227_counts\n",
            "0\n",
            "common_cluster228_counts\n",
            "0\n",
            "common_cluster229_counts\n",
            "0\n",
            "common_cluster230_counts\n",
            "0\n",
            "common_cluster231_counts\n",
            "0\n",
            "common_cluster232_counts\n",
            "0\n",
            "common_cluster233_counts\n",
            "0\n",
            "common_cluster234_counts\n",
            "0\n",
            "common_cluster235_counts\n",
            "0\n",
            "common_cluster236_counts\n",
            "0\n",
            "common_cluster237_counts\n",
            "0\n",
            "common_cluster238_counts\n",
            "0\n",
            "common_cluster239_counts\n",
            "0\n",
            "common_cluster240_counts\n",
            "0\n",
            "common_cluster241_counts\n",
            "0\n",
            "common_cluster242_counts\n",
            "0\n",
            "common_cluster243_counts\n",
            "0\n",
            "common_cluster244_counts\n",
            "0\n",
            "common_cluster245_counts\n",
            "0\n",
            "common_cluster246_counts\n",
            "0\n",
            "common_cluster247_counts\n",
            "0\n",
            "common_cluster248_counts\n",
            "0\n",
            "common_cluster249_counts\n",
            "0\n",
            "common_cluster250_counts\n",
            "0\n",
            "common_cluster251_counts\n",
            "0\n",
            "common_cluster252_counts\n",
            "0\n",
            "common_cluster253_counts\n",
            "0\n",
            "common_cluster254_counts\n",
            "0\n",
            "common_cluster255_counts\n",
            "0\n",
            "common_cluster256_counts\n",
            "0\n",
            "common_cluster257_counts\n",
            "0\n",
            "common_cluster258_counts\n",
            "0\n",
            "common_cluster259_counts\n",
            "0\n",
            "common_cluster260_counts\n",
            "0\n",
            "common_cluster261_counts\n",
            "0\n",
            "common_cluster262_counts\n",
            "0\n",
            "common_cluster263_counts\n",
            "0\n",
            "common_cluster264_counts\n",
            "0\n",
            "common_cluster265_counts\n",
            "0\n",
            "common_cluster266_counts\n",
            "0\n",
            "common_cluster267_counts\n",
            "0\n",
            "common_cluster268_counts\n",
            "0\n",
            "common_cluster269_counts\n",
            "0\n",
            "common_cluster270_counts\n",
            "0\n",
            "common_cluster271_counts\n",
            "0\n",
            "common_cluster272_counts\n",
            "0\n",
            "common_cluster273_counts\n",
            "0\n",
            "common_cluster274_counts\n",
            "0\n",
            "common_cluster275_counts\n",
            "0\n",
            "common_cluster276_counts\n",
            "0\n",
            "common_cluster277_counts\n",
            "0\n",
            "common_cluster278_counts\n",
            "0\n",
            "common_cluster279_counts\n",
            "0\n",
            "common_cluster280_counts\n",
            "0\n",
            "common_cluster281_counts\n",
            "0\n",
            "common_cluster282_counts\n",
            "0\n",
            "common_cluster283_counts\n",
            "0\n",
            "common_cluster284_counts\n",
            "0\n",
            "common_cluster285_counts\n",
            "0\n",
            "common_cluster286_counts\n",
            "0\n",
            "common_cluster287_counts\n",
            "0\n",
            "common_cluster288_counts\n",
            "0\n",
            "common_cluster289_counts\n",
            "0\n",
            "common_cluster290_counts\n",
            "0\n",
            "common_cluster291_counts\n",
            "0\n",
            "common_cluster292_counts\n",
            "0\n",
            "common_cluster293_counts\n",
            "0\n",
            "common_cluster294_counts\n",
            "0\n",
            "common_cluster295_counts\n",
            "0\n",
            "common_cluster296_counts\n",
            "0\n",
            "common_cluster297_counts\n",
            "0\n",
            "common_cluster298_counts\n",
            "0\n",
            "common_cluster299_counts\n",
            "0\n",
            "common_cluster300_counts\n",
            "0\n",
            "common_cluster301_counts\n",
            "0\n",
            "common_cluster302_counts\n",
            "0\n",
            "common_cluster303_counts\n",
            "0\n",
            "common_cluster304_counts\n",
            "0\n",
            "common_cluster305_counts\n",
            "0\n",
            "common_cluster306_counts\n",
            "0\n",
            "common_cluster307_counts\n",
            "0\n",
            "common_cluster308_counts\n",
            "0\n",
            "common_cluster309_counts\n",
            "0\n",
            "common_cluster310_counts\n",
            "0\n",
            "common_cluster311_counts\n",
            "0\n",
            "common_cluster312_counts\n",
            "0\n",
            "common_cluster313_counts\n",
            "0\n",
            "common_cluster314_counts\n",
            "0\n",
            "common_cluster315_counts\n",
            "0\n",
            "common_cluster316_counts\n",
            "0\n",
            "common_cluster317_counts\n",
            "0\n",
            "common_cluster318_counts\n",
            "0\n",
            "common_cluster319_counts\n",
            "0\n",
            "common_cluster320_counts\n",
            "0\n",
            "common_cluster321_counts\n",
            "0\n",
            "common_cluster322_counts\n",
            "0\n",
            "common_cluster323_counts\n",
            "0\n",
            "common_cluster324_counts\n",
            "0\n",
            "common_cluster325_counts\n",
            "0\n",
            "common_cluster326_counts\n",
            "0\n",
            "common_cluster327_counts\n",
            "0\n",
            "common_cluster328_counts\n",
            "0\n",
            "common_cluster329_counts\n",
            "0\n",
            "common_cluster330_counts\n",
            "0\n",
            "common_cluster331_counts\n",
            "0\n",
            "common_cluster332_counts\n",
            "0\n",
            "common_cluster333_counts\n",
            "0\n",
            "common_cluster334_counts\n",
            "0\n",
            "common_cluster335_counts\n",
            "0\n",
            "common_cluster336_counts\n",
            "0\n",
            "common_cluster337_counts\n",
            "0\n",
            "common_cluster338_counts\n",
            "0\n",
            "common_cluster339_counts\n",
            "0\n",
            "common_cluster340_counts\n",
            "0\n",
            "common_cluster341_counts\n",
            "0\n",
            "common_cluster342_counts\n",
            "0\n",
            "common_cluster343_counts\n",
            "0\n",
            "common_cluster344_counts\n",
            "0\n",
            "common_cluster345_counts\n",
            "0\n",
            "common_cluster346_counts\n",
            "0\n",
            "common_cluster347_counts\n",
            "0\n",
            "common_cluster348_counts\n",
            "0\n",
            "common_cluster349_counts\n",
            "0\n",
            "common_cluster350_counts\n",
            "0\n",
            "common_cluster351_counts\n",
            "0\n",
            "common_cluster352_counts\n",
            "0\n",
            "common_cluster353_counts\n",
            "0\n",
            "common_cluster354_counts\n",
            "0\n",
            "common_cluster355_counts\n",
            "0\n",
            "common_cluster356_counts\n",
            "0\n",
            "common_cluster357_counts\n",
            "0\n",
            "common_cluster358_counts\n",
            "0\n",
            "common_cluster359_counts\n",
            "0\n",
            "common_cluster360_counts\n",
            "0\n",
            "common_cluster361_counts\n",
            "0\n",
            "common_cluster362_counts\n",
            "0\n",
            "common_cluster363_counts\n",
            "0\n",
            "common_cluster364_counts\n",
            "0\n",
            "common_cluster365_counts\n",
            "0\n",
            "common_cluster366_counts\n",
            "0\n",
            "common_cluster367_counts\n",
            "0\n",
            "common_cluster368_counts\n",
            "0\n",
            "common_cluster369_counts\n",
            "0\n",
            "common_cluster370_counts\n",
            "0\n",
            "common_cluster371_counts\n",
            "0\n",
            "common_cluster372_counts\n",
            "0\n",
            "common_cluster373_counts\n",
            "0\n",
            "common_cluster374_counts\n",
            "0\n",
            "common_cluster375_counts\n",
            "0\n",
            "common_cluster376_counts\n",
            "0\n",
            "common_cluster377_counts\n",
            "0\n",
            "common_cluster378_counts\n",
            "0\n",
            "common_cluster379_counts\n",
            "0\n",
            "common_cluster380_counts\n",
            "0\n",
            "common_cluster381_counts\n",
            "0\n",
            "common_cluster382_counts\n",
            "0\n",
            "common_cluster383_counts\n",
            "0\n",
            "common_cluster384_counts\n",
            "0\n",
            "common_cluster385_counts\n",
            "0\n",
            "common_cluster386_counts\n",
            "0\n",
            "common_cluster387_counts\n",
            "0\n",
            "common_cluster388_counts\n",
            "0\n",
            "common_cluster389_counts\n",
            "0\n",
            "common_cluster390_counts\n",
            "0\n",
            "common_cluster391_counts\n",
            "0\n",
            "common_cluster392_counts\n",
            "0\n",
            "common_cluster393_counts\n",
            "0\n",
            "common_cluster394_counts\n",
            "0\n",
            "common_cluster395_counts\n",
            "0\n",
            "common_cluster396_counts\n",
            "0\n",
            "common_cluster397_counts\n",
            "0\n",
            "common_cluster398_counts\n",
            "0\n",
            "common_cluster399_counts\n",
            "0\n",
            "common_cluster400_counts\n",
            "0\n",
            "common_cluster401_counts\n",
            "0\n",
            "common_cluster402_counts\n",
            "0\n",
            "common_cluster403_counts\n",
            "0\n",
            "common_cluster404_counts\n",
            "0\n",
            "common_cluster405_counts\n",
            "0\n",
            "common_cluster406_counts\n",
            "0\n",
            "common_cluster407_counts\n",
            "0\n",
            "common_cluster408_counts\n",
            "0\n",
            "common_cluster409_counts\n",
            "0\n",
            "common_cluster410_counts\n",
            "0\n",
            "common_cluster411_counts\n",
            "0\n",
            "common_cluster412_counts\n",
            "0\n",
            "common_cluster413_counts\n",
            "0\n",
            "common_cluster414_counts\n",
            "0\n",
            "common_cluster415_counts\n",
            "0\n",
            "common_cluster416_counts\n",
            "0\n",
            "common_cluster417_counts\n",
            "0\n",
            "common_cluster418_counts\n",
            "0\n",
            "common_cluster419_counts\n",
            "0\n",
            "common_cluster420_counts\n",
            "0\n",
            "common_cluster421_counts\n",
            "0\n",
            "common_cluster422_counts\n",
            "0\n",
            "common_cluster423_counts\n",
            "0\n",
            "common_cluster424_counts\n",
            "0\n",
            "common_cluster425_counts\n",
            "0\n",
            "common_cluster426_counts\n",
            "0\n",
            "common_cluster427_counts\n",
            "0\n",
            "common_cluster428_counts\n",
            "0\n",
            "common_cluster429_counts\n",
            "0\n",
            "common_cluster430_counts\n",
            "0\n",
            "common_cluster431_counts\n",
            "0\n",
            "common_cluster432_counts\n",
            "0\n",
            "common_cluster433_counts\n",
            "0\n",
            "common_cluster434_counts\n",
            "0\n",
            "common_cluster435_counts\n",
            "0\n",
            "common_cluster436_counts\n",
            "0\n",
            "common_cluster437_counts\n",
            "0\n",
            "common_cluster438_counts\n",
            "0\n",
            "common_cluster439_counts\n",
            "0\n",
            "common_cluster440_counts\n",
            "0\n",
            "common_cluster441_counts\n",
            "0\n",
            "common_cluster442_counts\n",
            "0\n",
            "common_cluster443_counts\n",
            "0\n",
            "common_cluster444_counts\n",
            "0\n",
            "common_cluster445_counts\n",
            "0\n",
            "common_cluster446_counts\n",
            "0\n",
            "common_cluster447_counts\n",
            "0\n",
            "common_cluster448_counts\n",
            "0\n",
            "common_cluster449_counts\n",
            "0\n",
            "common_cluster450_counts\n",
            "0\n",
            "common_cluster451_counts\n",
            "0\n",
            "common_cluster452_counts\n",
            "0\n",
            "common_cluster453_counts\n",
            "0\n",
            "common_cluster454_counts\n",
            "0\n",
            "common_cluster455_counts\n",
            "0\n",
            "common_cluster456_counts\n",
            "0\n",
            "common_cluster457_counts\n",
            "0\n",
            "common_cluster458_counts\n",
            "0\n",
            "common_cluster459_counts\n",
            "0\n",
            "common_cluster460_counts\n",
            "0\n",
            "common_cluster461_counts\n",
            "0\n",
            "common_cluster462_counts\n",
            "0\n",
            "common_cluster463_counts\n",
            "0\n",
            "common_cluster464_counts\n",
            "0\n",
            "common_cluster465_counts\n",
            "0\n",
            "common_cluster466_counts\n",
            "0\n",
            "common_cluster467_counts\n",
            "0\n",
            "common_cluster468_counts\n",
            "0\n",
            "common_cluster469_counts\n",
            "0\n",
            "common_cluster470_counts\n",
            "0\n",
            "common_cluster471_counts\n",
            "0\n",
            "common_cluster472_counts\n",
            "0\n",
            "common_cluster473_counts\n",
            "0\n",
            "common_cluster474_counts\n",
            "0\n",
            "common_cluster475_counts\n",
            "0\n",
            "common_cluster476_counts\n",
            "0\n",
            "common_cluster477_counts\n",
            "0\n",
            "common_cluster478_counts\n",
            "0\n",
            "common_cluster479_counts\n",
            "0\n",
            "common_cluster480_counts\n",
            "0\n",
            "common_cluster481_counts\n",
            "0\n",
            "common_cluster482_counts\n",
            "0\n",
            "common_cluster483_counts\n",
            "0\n",
            "common_cluster484_counts\n",
            "0\n",
            "common_cluster485_counts\n",
            "0\n",
            "common_cluster486_counts\n",
            "0\n",
            "common_cluster487_counts\n",
            "0\n",
            "common_cluster488_counts\n",
            "0\n",
            "common_cluster489_counts\n",
            "0\n",
            "common_cluster490_counts\n",
            "0\n",
            "common_cluster491_counts\n",
            "0\n",
            "common_cluster492_counts\n",
            "0\n",
            "common_cluster493_counts\n",
            "0\n",
            "common_cluster494_counts\n",
            "0\n",
            "common_cluster495_counts\n",
            "0\n",
            "common_cluster496_counts\n",
            "0\n",
            "common_cluster497_counts\n",
            "0\n",
            "common_cluster498_counts\n",
            "0\n",
            "common_cluster499_counts\n",
            "0\n",
            "company_cluster0_counts\n",
            "0\n",
            "company_cluster1_counts\n",
            "0\n",
            "company_cluster2_counts\n",
            "0\n",
            "company_cluster3_counts\n",
            "0\n",
            "company_cluster4_counts\n",
            "0\n",
            "company_cluster5_counts\n",
            "0\n",
            "company_cluster6_counts\n",
            "0\n",
            "company_cluster7_counts\n",
            "0\n",
            "company_cluster8_counts\n",
            "0\n",
            "company_cluster9_counts\n",
            "0\n",
            "company_cluster10_counts\n",
            "0\n",
            "company_cluster11_counts\n",
            "0\n",
            "company_cluster12_counts\n",
            "0\n",
            "company_cluster13_counts\n",
            "0\n",
            "company_cluster14_counts\n",
            "0\n",
            "company_cluster15_counts\n",
            "0\n",
            "company_cluster16_counts\n",
            "0\n",
            "company_cluster17_counts\n",
            "0\n",
            "company_cluster18_counts\n",
            "0\n",
            "company_cluster19_counts\n",
            "0\n",
            "company_cluster20_counts\n",
            "0\n",
            "company_cluster21_counts\n",
            "0\n",
            "company_cluster22_counts\n",
            "0\n",
            "company_cluster23_counts\n",
            "0\n",
            "company_cluster24_counts\n",
            "0\n",
            "company_cluster25_counts\n",
            "0\n",
            "company_cluster26_counts\n",
            "0\n",
            "company_cluster27_counts\n",
            "0\n",
            "company_cluster28_counts\n",
            "0\n",
            "company_cluster29_counts\n",
            "0\n",
            "company_cluster30_counts\n",
            "0\n",
            "company_cluster31_counts\n",
            "0\n",
            "company_cluster32_counts\n",
            "0\n",
            "company_cluster33_counts\n",
            "0\n",
            "company_cluster34_counts\n",
            "0\n",
            "company_cluster35_counts\n",
            "0\n",
            "company_cluster36_counts\n",
            "0\n",
            "company_cluster37_counts\n",
            "0\n",
            "company_cluster38_counts\n",
            "0\n",
            "company_cluster39_counts\n",
            "0\n",
            "company_cluster40_counts\n",
            "0\n",
            "company_cluster41_counts\n",
            "0\n",
            "company_cluster42_counts\n",
            "0\n",
            "company_cluster43_counts\n",
            "0\n",
            "company_cluster44_counts\n",
            "0\n",
            "company_cluster45_counts\n",
            "0\n",
            "company_cluster46_counts\n",
            "0\n",
            "company_cluster47_counts\n",
            "0\n",
            "company_cluster48_counts\n",
            "0\n",
            "company_cluster49_counts\n",
            "0\n",
            "company_cluster50_counts\n",
            "0\n",
            "company_cluster51_counts\n",
            "0\n",
            "company_cluster52_counts\n",
            "0\n",
            "company_cluster53_counts\n",
            "0\n",
            "company_cluster54_counts\n",
            "0\n",
            "company_cluster55_counts\n",
            "0\n",
            "company_cluster56_counts\n",
            "0\n",
            "company_cluster57_counts\n",
            "0\n",
            "company_cluster58_counts\n",
            "0\n",
            "company_cluster59_counts\n",
            "0\n",
            "company_cluster60_counts\n",
            "0\n",
            "company_cluster61_counts\n",
            "0\n",
            "company_cluster62_counts\n",
            "0\n",
            "company_cluster63_counts\n",
            "0\n",
            "company_cluster64_counts\n",
            "0\n",
            "company_cluster65_counts\n",
            "0\n",
            "company_cluster66_counts\n",
            "0\n",
            "company_cluster67_counts\n",
            "0\n",
            "company_cluster68_counts\n",
            "0\n",
            "company_cluster69_counts\n",
            "0\n",
            "company_cluster70_counts\n",
            "0\n",
            "company_cluster71_counts\n",
            "0\n",
            "company_cluster72_counts\n",
            "0\n",
            "company_cluster73_counts\n",
            "0\n",
            "company_cluster74_counts\n",
            "0\n",
            "company_cluster75_counts\n",
            "0\n",
            "company_cluster76_counts\n",
            "0\n",
            "company_cluster77_counts\n",
            "0\n",
            "company_cluster78_counts\n",
            "0\n",
            "company_cluster79_counts\n",
            "0\n",
            "name_of_department/team_cluster0_counts\n",
            "0\n",
            "name_of_department/team_cluster1_counts\n",
            "0\n",
            "name_of_department/team_cluster2_counts\n",
            "0\n",
            "name_of_department/team_cluster3_counts\n",
            "0\n",
            "name_of_department/team_cluster4_counts\n",
            "0\n",
            "name_of_department/team_cluster5_counts\n",
            "0\n",
            "name_of_department/team_cluster6_counts\n",
            "0\n",
            "name_of_department/team_cluster7_counts\n",
            "0\n",
            "name_of_department/team_cluster8_counts\n",
            "0\n",
            "name_of_department/team_cluster9_counts\n",
            "0\n",
            "name_of_department/team_cluster10_counts\n",
            "0\n",
            "name_of_department/team_cluster11_counts\n",
            "0\n",
            "name_of_department/team_cluster12_counts\n",
            "0\n",
            "name_of_department/team_cluster13_counts\n",
            "0\n",
            "name_of_department/team_cluster14_counts\n",
            "0\n",
            "name_of_department/team_cluster15_counts\n",
            "0\n",
            "name_of_department/team_cluster16_counts\n",
            "0\n",
            "name_of_department/team_cluster17_counts\n",
            "0\n",
            "name_of_department/team_cluster18_counts\n",
            "0\n",
            "name_of_department/team_cluster19_counts\n",
            "0\n",
            "name_of_department/team_cluster20_counts\n",
            "0\n",
            "city_cluster0_counts\n",
            "0\n",
            "city_cluster1_counts\n",
            "0\n",
            "city_cluster2_counts\n",
            "0\n",
            "city_cluster3_counts\n",
            "0\n",
            "city_cluster4_counts\n",
            "0\n",
            "city_cluster5_counts\n",
            "0\n",
            "city_cluster6_counts\n",
            "0\n",
            "city_cluster7_counts\n",
            "0\n",
            "city_cluster8_counts\n",
            "0\n",
            "city_cluster9_counts\n",
            "0\n",
            "city_cluster10_counts\n",
            "0\n",
            "city_cluster11_counts\n",
            "0\n",
            "city_cluster12_counts\n",
            "0\n",
            "city_cluster13_counts\n",
            "0\n",
            "city_cluster14_counts\n",
            "0\n",
            "city_cluster15_counts\n",
            "0\n",
            "city_cluster16_counts\n",
            "0\n",
            "city_cluster17_counts\n",
            "0\n",
            "city_cluster18_counts\n",
            "0\n",
            "city_cluster19_counts\n",
            "0\n",
            "city_cluster20_counts\n",
            "0\n",
            "city_cluster21_counts\n",
            "0\n",
            "city_cluster22_counts\n",
            "0\n",
            "city_cluster23_counts\n",
            "0\n",
            "city_cluster24_counts\n",
            "0\n",
            "city_cluster25_counts\n",
            "0\n",
            "city_cluster26_counts\n",
            "0\n",
            "city_cluster27_counts\n",
            "0\n",
            "city_cluster28_counts\n",
            "0\n",
            "city_cluster29_counts\n",
            "0\n",
            "city_cluster30_counts\n",
            "0\n",
            "city_cluster31_counts\n",
            "0\n",
            "city_cluster32_counts\n",
            "0\n",
            "city_cluster33_counts\n",
            "0\n",
            "city_cluster34_counts\n",
            "0\n",
            "city_cluster35_counts\n",
            "0\n",
            "city_cluster36_counts\n",
            "0\n",
            "city_cluster37_counts\n",
            "0\n",
            "city_cluster38_counts\n",
            "0\n",
            "city_cluster39_counts\n",
            "0\n",
            "city_cluster40_counts\n",
            "0\n",
            "city_cluster41_counts\n",
            "0\n",
            "city_cluster42_counts\n",
            "0\n",
            "city_cluster43_counts\n",
            "0\n",
            "city_cluster44_counts\n",
            "0\n",
            "city_cluster45_counts\n",
            "0\n",
            "city_cluster46_counts\n",
            "0\n",
            "city_cluster47_counts\n",
            "0\n",
            "city_cluster48_counts\n",
            "0\n",
            "city_cluster49_counts\n",
            "0\n",
            "city_cluster50_counts\n",
            "0\n",
            "city_cluster51_counts\n",
            "0\n",
            "city_cluster52_counts\n",
            "0\n",
            "work_arrangement_cluster0_counts\n",
            "1\n",
            "work_arrangement_cluster1_counts\n",
            "0\n",
            "work_arrangement_cluster2_counts\n",
            "0\n",
            "work_arrangement_cluster3_counts\n",
            "0\n",
            "work_arrangement_cluster4_counts\n",
            "0\n",
            "work_arrangement_cluster5_counts\n",
            "0\n",
            "work_arrangement_cluster6_counts\n",
            "0\n",
            "work_arrangement_cluster7_counts\n",
            "0\n",
            "work_arrangement_cluster8_counts\n",
            "0\n",
            "work_arrangement_cluster9_counts\n",
            "0\n",
            "\n",
            "AR\n",
            "0\n",
            "AZ\n",
            "0\n",
            "CA\n",
            "0\n",
            "CO\n",
            "0\n",
            "FL\n",
            "0\n",
            "GA\n",
            "0\n",
            "IA\n",
            "0\n",
            "IL\n",
            "0\n",
            "IN\n",
            "0\n",
            "MA\n",
            "0\n",
            "MD\n",
            "0\n",
            "MI\n",
            "0\n",
            "MO\n",
            "0\n",
            "NC\n",
            "0\n",
            "ND\n",
            "0\n",
            "NJ\n",
            "0\n",
            "NY\n",
            "0\n",
            "OR\n",
            "0\n",
            "PA\n",
            "0\n",
            "TX\n",
            "0\n",
            "UT\n",
            "0\n",
            "VA\n",
            "0\n",
            "WA\n",
            "0\n",
            "WI\n",
            "0\n",
            "\n",
            "USA\n",
            "1\n",
            "United States\n",
            "0\n",
            "Accuracy: 0.5909090909090909\n"
          ]
        }
      ],
      "source": [
        "columns_to_drop = common_corpus_columns + singular_corpus_columns + work_arrangement_columns + categorical_label_columns\n",
        "embedded_data_columns = common_corpus_columns + singular_corpus_columns + work_arrangement_columns\n",
        "embedded_data_columns = [f'{col}_vectors' for col in embedded_data_columns]\n",
        "\n",
        "columns_to_drop = columns_to_drop + embedded_data_columns\n",
        "\n",
        "# Make a copy of the dataframe with specified columns dropped\n",
        "df_copy = df.drop(columns=columns_to_drop).copy()\n",
        "\n",
        "# Iterate over columns and fill NaN values with the mode of each column\n",
        "for col in df_copy.columns:\n",
        "  try:\n",
        "    print(col)\n",
        "    mode_val = df_copy[col].mode()[0]\n",
        "    print(mode_val)  # Get the mode value for the column\n",
        "    df_copy[col].fillna(mode_val, inplace=True)  # Fill NaN values with the mode\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming df_encoded is your dataframe with one-hot encoded features and target variable\n",
        "# Split the data into features (X) and target variable (y)\n",
        "y = df_copy['rating']  # Target variable\n",
        "X = df_copy.drop(columns=['rating'])  # Features\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the decision tree classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train the decision tree classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLwHz9WrcfVR"
      },
      "source": [
        "Wow! So our decision tree has an accuracy of .59, alerady better than our baseline goal of .5. What's the mean absolute error?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoVvHitPcygz",
        "outputId": "0ac25639-37c7-4660-f636-2079ccbdaa8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.6363636363636364\n"
          ]
        }
      ],
      "source": [
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEVMGlkrc0rK"
      },
      "source": [
        "Not bad. It went down from .86 to .64. And this is just a baseline decision tree classifier that we used with our data that we haven't reengineered in any way. We should explore what model will give us the best performance with our data. Clearly, the decision tree classifier gives much better performance than the HistGradientBoostingClassifier. We might just adopt the \"fill NaNs with the mode\" method for the remainder of our work as it seemed to work well.\n",
        "\n",
        "The natural next thing to try for model exploration would be a Random Forest Algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulvX2Bi6eLjH",
        "outputId": "7c238e31-cc3c-4fc4-b548-0206e608137e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5454545454545454\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MYdFD3jerRS"
      },
      "source": [
        "Interestingly enough, we got worse accuracy with the random forest. What was the MAE?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aMrq10qewxE",
        "outputId": "ec41f977-6b56-4d7a-d778-3563fb05e357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.5\n"
          ]
        }
      ],
      "source": [
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xmtcaiRe2eg"
      },
      "source": [
        "But the mean absolute error was less. What about using more estimators?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc9xJHfyfB5g",
        "outputId": "d45c1a6a-afbd-4a37-9863-d28989324e4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5454545454545454\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHgvbJcHffZU"
      },
      "source": [
        "That didn't change anything. What about using n_estimators = 50? Same results. The problem is that our test set is quite small. And it also seems that the algorithm is just guessing 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6TF1jThfL9s",
        "outputId": "d4eab89e-429f-4590-b36c-848b384791e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.5\n",
            "76     2\n",
            "10     2\n",
            "4      1\n",
            "99     2\n",
            "70     2\n",
            "66     0\n",
            "30     2\n",
            "45     2\n",
            "94     3\n",
            "11     3\n",
            "78     2\n",
            "47     2\n",
            "0      1\n",
            "79     2\n",
            "18     3\n",
            "105    2\n",
            "55     1\n",
            "77     3\n",
            "65     2\n",
            "42     1\n",
            "12     2\n",
            "36     1\n",
            "Name: rating, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb_L2ocwf-56"
      },
      "source": [
        "Now we'll try XGBoost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw7IHN3BfzNO",
        "outputId": "757e9660-adaa-4b2f-9dcd-72525ff06eb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ech-pvzegNRU",
        "outputId": "142163fe-197c-4b1f-e7ff-113922263a2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "min_salary\n",
            "100.0\n",
            "max_salary\n",
            "200.0\n",
            "rating\n",
            "2\n",
            "common_cluster0_counts\n",
            "0\n",
            "common_cluster1_counts\n",
            "0\n",
            "common_cluster2_counts\n",
            "2\n",
            "common_cluster3_counts\n",
            "0\n",
            "common_cluster4_counts\n",
            "0\n",
            "common_cluster5_counts\n",
            "0\n",
            "common_cluster6_counts\n",
            "0\n",
            "common_cluster7_counts\n",
            "0\n",
            "common_cluster8_counts\n",
            "0\n",
            "common_cluster9_counts\n",
            "0\n",
            "common_cluster10_counts\n",
            "0\n",
            "common_cluster11_counts\n",
            "0\n",
            "common_cluster12_counts\n",
            "0\n",
            "common_cluster13_counts\n",
            "0\n",
            "common_cluster14_counts\n",
            "0\n",
            "common_cluster15_counts\n",
            "0\n",
            "common_cluster16_counts\n",
            "0\n",
            "common_cluster17_counts\n",
            "0\n",
            "common_cluster18_counts\n",
            "0\n",
            "common_cluster19_counts\n",
            "0\n",
            "common_cluster20_counts\n",
            "0\n",
            "common_cluster21_counts\n",
            "0\n",
            "common_cluster22_counts\n",
            "0\n",
            "common_cluster23_counts\n",
            "0\n",
            "common_cluster24_counts\n",
            "1\n",
            "common_cluster25_counts\n",
            "0\n",
            "common_cluster26_counts\n",
            "0\n",
            "common_cluster27_counts\n",
            "0\n",
            "common_cluster28_counts\n",
            "0\n",
            "common_cluster29_counts\n",
            "0\n",
            "common_cluster30_counts\n",
            "0\n",
            "common_cluster31_counts\n",
            "0\n",
            "common_cluster32_counts\n",
            "0\n",
            "common_cluster33_counts\n",
            "0\n",
            "common_cluster34_counts\n",
            "0\n",
            "common_cluster35_counts\n",
            "0\n",
            "common_cluster36_counts\n",
            "0\n",
            "common_cluster37_counts\n",
            "0\n",
            "common_cluster38_counts\n",
            "0\n",
            "common_cluster39_counts\n",
            "0\n",
            "common_cluster40_counts\n",
            "0\n",
            "common_cluster41_counts\n",
            "0\n",
            "common_cluster42_counts\n",
            "0\n",
            "common_cluster43_counts\n",
            "0\n",
            "common_cluster44_counts\n",
            "0\n",
            "common_cluster45_counts\n",
            "0\n",
            "common_cluster46_counts\n",
            "0\n",
            "common_cluster47_counts\n",
            "0\n",
            "common_cluster48_counts\n",
            "0\n",
            "common_cluster49_counts\n",
            "0\n",
            "common_cluster50_counts\n",
            "0\n",
            "common_cluster51_counts\n",
            "0\n",
            "common_cluster52_counts\n",
            "0\n",
            "common_cluster53_counts\n",
            "0\n",
            "common_cluster54_counts\n",
            "0\n",
            "common_cluster55_counts\n",
            "0\n",
            "common_cluster56_counts\n",
            "0\n",
            "common_cluster57_counts\n",
            "0\n",
            "common_cluster58_counts\n",
            "0\n",
            "common_cluster59_counts\n",
            "0\n",
            "common_cluster60_counts\n",
            "0\n",
            "common_cluster61_counts\n",
            "0\n",
            "common_cluster62_counts\n",
            "0\n",
            "common_cluster63_counts\n",
            "0\n",
            "common_cluster64_counts\n",
            "0\n",
            "common_cluster65_counts\n",
            "0\n",
            "common_cluster66_counts\n",
            "0\n",
            "common_cluster67_counts\n",
            "0\n",
            "common_cluster68_counts\n",
            "0\n",
            "common_cluster69_counts\n",
            "0\n",
            "common_cluster70_counts\n",
            "0\n",
            "common_cluster71_counts\n",
            "0\n",
            "common_cluster72_counts\n",
            "0\n",
            "common_cluster73_counts\n",
            "0\n",
            "common_cluster74_counts\n",
            "0\n",
            "common_cluster75_counts\n",
            "0\n",
            "common_cluster76_counts\n",
            "0\n",
            "common_cluster77_counts\n",
            "0\n",
            "common_cluster78_counts\n",
            "0\n",
            "common_cluster79_counts\n",
            "0\n",
            "common_cluster80_counts\n",
            "0\n",
            "common_cluster81_counts\n",
            "0\n",
            "common_cluster82_counts\n",
            "0\n",
            "common_cluster83_counts\n",
            "0\n",
            "common_cluster84_counts\n",
            "0\n",
            "common_cluster85_counts\n",
            "0\n",
            "common_cluster86_counts\n",
            "0\n",
            "common_cluster87_counts\n",
            "0\n",
            "common_cluster88_counts\n",
            "0\n",
            "common_cluster89_counts\n",
            "0\n",
            "common_cluster90_counts\n",
            "0\n",
            "common_cluster91_counts\n",
            "0\n",
            "common_cluster92_counts\n",
            "0\n",
            "common_cluster93_counts\n",
            "0\n",
            "common_cluster94_counts\n",
            "0\n",
            "common_cluster95_counts\n",
            "0\n",
            "common_cluster96_counts\n",
            "0\n",
            "common_cluster97_counts\n",
            "0\n",
            "common_cluster98_counts\n",
            "0\n",
            "common_cluster99_counts\n",
            "0\n",
            "common_cluster100_counts\n",
            "0\n",
            "common_cluster101_counts\n",
            "0\n",
            "common_cluster102_counts\n",
            "0\n",
            "common_cluster103_counts\n",
            "0\n",
            "common_cluster104_counts\n",
            "0\n",
            "common_cluster105_counts\n",
            "0\n",
            "common_cluster106_counts\n",
            "0\n",
            "common_cluster107_counts\n",
            "0\n",
            "common_cluster108_counts\n",
            "0\n",
            "common_cluster109_counts\n",
            "0\n",
            "common_cluster110_counts\n",
            "0\n",
            "common_cluster111_counts\n",
            "0\n",
            "common_cluster112_counts\n",
            "0\n",
            "common_cluster113_counts\n",
            "0\n",
            "common_cluster114_counts\n",
            "0\n",
            "common_cluster115_counts\n",
            "0\n",
            "common_cluster116_counts\n",
            "0\n",
            "common_cluster117_counts\n",
            "0\n",
            "common_cluster118_counts\n",
            "0\n",
            "common_cluster119_counts\n",
            "0\n",
            "common_cluster120_counts\n",
            "0\n",
            "common_cluster121_counts\n",
            "0\n",
            "common_cluster122_counts\n",
            "0\n",
            "common_cluster123_counts\n",
            "0\n",
            "common_cluster124_counts\n",
            "0\n",
            "common_cluster125_counts\n",
            "0\n",
            "common_cluster126_counts\n",
            "0\n",
            "common_cluster127_counts\n",
            "0\n",
            "common_cluster128_counts\n",
            "0\n",
            "common_cluster129_counts\n",
            "0\n",
            "common_cluster130_counts\n",
            "0\n",
            "common_cluster131_counts\n",
            "0\n",
            "common_cluster132_counts\n",
            "0\n",
            "common_cluster133_counts\n",
            "0\n",
            "common_cluster134_counts\n",
            "0\n",
            "common_cluster135_counts\n",
            "0\n",
            "common_cluster136_counts\n",
            "0\n",
            "common_cluster137_counts\n",
            "0\n",
            "common_cluster138_counts\n",
            "0\n",
            "common_cluster139_counts\n",
            "0\n",
            "common_cluster140_counts\n",
            "0\n",
            "common_cluster141_counts\n",
            "0\n",
            "common_cluster142_counts\n",
            "0\n",
            "common_cluster143_counts\n",
            "0\n",
            "common_cluster144_counts\n",
            "0\n",
            "common_cluster145_counts\n",
            "0\n",
            "common_cluster146_counts\n",
            "0\n",
            "common_cluster147_counts\n",
            "0\n",
            "common_cluster148_counts\n",
            "0\n",
            "common_cluster149_counts\n",
            "0\n",
            "common_cluster150_counts\n",
            "0\n",
            "common_cluster151_counts\n",
            "0\n",
            "common_cluster152_counts\n",
            "0\n",
            "common_cluster153_counts\n",
            "0\n",
            "common_cluster154_counts\n",
            "0\n",
            "common_cluster155_counts\n",
            "0\n",
            "common_cluster156_counts\n",
            "0\n",
            "common_cluster157_counts\n",
            "0\n",
            "common_cluster158_counts\n",
            "0\n",
            "common_cluster159_counts\n",
            "0\n",
            "common_cluster160_counts\n",
            "0\n",
            "common_cluster161_counts\n",
            "0\n",
            "common_cluster162_counts\n",
            "0\n",
            "common_cluster163_counts\n",
            "0\n",
            "common_cluster164_counts\n",
            "0\n",
            "common_cluster165_counts\n",
            "0\n",
            "common_cluster166_counts\n",
            "0\n",
            "common_cluster167_counts\n",
            "0\n",
            "common_cluster168_counts\n",
            "0\n",
            "common_cluster169_counts\n",
            "0\n",
            "common_cluster170_counts\n",
            "0\n",
            "common_cluster171_counts\n",
            "0\n",
            "common_cluster172_counts\n",
            "0\n",
            "common_cluster173_counts\n",
            "0\n",
            "common_cluster174_counts\n",
            "0\n",
            "common_cluster175_counts\n",
            "0\n",
            "common_cluster176_counts\n",
            "0\n",
            "common_cluster177_counts\n",
            "0\n",
            "common_cluster178_counts\n",
            "0\n",
            "common_cluster179_counts\n",
            "0\n",
            "common_cluster180_counts\n",
            "0\n",
            "common_cluster181_counts\n",
            "0\n",
            "common_cluster182_counts\n",
            "0\n",
            "common_cluster183_counts\n",
            "0\n",
            "common_cluster184_counts\n",
            "0\n",
            "common_cluster185_counts\n",
            "0\n",
            "common_cluster186_counts\n",
            "0\n",
            "common_cluster187_counts\n",
            "0\n",
            "common_cluster188_counts\n",
            "0\n",
            "common_cluster189_counts\n",
            "0\n",
            "common_cluster190_counts\n",
            "0\n",
            "common_cluster191_counts\n",
            "0\n",
            "common_cluster192_counts\n",
            "0\n",
            "common_cluster193_counts\n",
            "0\n",
            "common_cluster194_counts\n",
            "0\n",
            "common_cluster195_counts\n",
            "0\n",
            "common_cluster196_counts\n",
            "0\n",
            "common_cluster197_counts\n",
            "0\n",
            "common_cluster198_counts\n",
            "0\n",
            "common_cluster199_counts\n",
            "0\n",
            "common_cluster200_counts\n",
            "0\n",
            "common_cluster201_counts\n",
            "0\n",
            "common_cluster202_counts\n",
            "0\n",
            "common_cluster203_counts\n",
            "0\n",
            "common_cluster204_counts\n",
            "0\n",
            "common_cluster205_counts\n",
            "0\n",
            "common_cluster206_counts\n",
            "0\n",
            "common_cluster207_counts\n",
            "0\n",
            "common_cluster208_counts\n",
            "0\n",
            "common_cluster209_counts\n",
            "0\n",
            "common_cluster210_counts\n",
            "0\n",
            "common_cluster211_counts\n",
            "0\n",
            "common_cluster212_counts\n",
            "0\n",
            "common_cluster213_counts\n",
            "0\n",
            "common_cluster214_counts\n",
            "0\n",
            "common_cluster215_counts\n",
            "0\n",
            "common_cluster216_counts\n",
            "0\n",
            "common_cluster217_counts\n",
            "0\n",
            "common_cluster218_counts\n",
            "0\n",
            "common_cluster219_counts\n",
            "0\n",
            "common_cluster220_counts\n",
            "0\n",
            "common_cluster221_counts\n",
            "0\n",
            "common_cluster222_counts\n",
            "0\n",
            "common_cluster223_counts\n",
            "0\n",
            "common_cluster224_counts\n",
            "0\n",
            "common_cluster225_counts\n",
            "0\n",
            "common_cluster226_counts\n",
            "0\n",
            "common_cluster227_counts\n",
            "0\n",
            "common_cluster228_counts\n",
            "0\n",
            "common_cluster229_counts\n",
            "0\n",
            "common_cluster230_counts\n",
            "0\n",
            "common_cluster231_counts\n",
            "0\n",
            "common_cluster232_counts\n",
            "0\n",
            "common_cluster233_counts\n",
            "0\n",
            "common_cluster234_counts\n",
            "0\n",
            "common_cluster235_counts\n",
            "0\n",
            "common_cluster236_counts\n",
            "0\n",
            "common_cluster237_counts\n",
            "0\n",
            "common_cluster238_counts\n",
            "0\n",
            "common_cluster239_counts\n",
            "0\n",
            "common_cluster240_counts\n",
            "0\n",
            "common_cluster241_counts\n",
            "0\n",
            "common_cluster242_counts\n",
            "0\n",
            "common_cluster243_counts\n",
            "0\n",
            "common_cluster244_counts\n",
            "0\n",
            "common_cluster245_counts\n",
            "0\n",
            "common_cluster246_counts\n",
            "0\n",
            "common_cluster247_counts\n",
            "0\n",
            "common_cluster248_counts\n",
            "0\n",
            "common_cluster249_counts\n",
            "0\n",
            "common_cluster250_counts\n",
            "0\n",
            "common_cluster251_counts\n",
            "0\n",
            "common_cluster252_counts\n",
            "0\n",
            "common_cluster253_counts\n",
            "0\n",
            "common_cluster254_counts\n",
            "0\n",
            "common_cluster255_counts\n",
            "0\n",
            "common_cluster256_counts\n",
            "0\n",
            "common_cluster257_counts\n",
            "0\n",
            "common_cluster258_counts\n",
            "0\n",
            "common_cluster259_counts\n",
            "0\n",
            "common_cluster260_counts\n",
            "0\n",
            "common_cluster261_counts\n",
            "0\n",
            "common_cluster262_counts\n",
            "0\n",
            "common_cluster263_counts\n",
            "0\n",
            "common_cluster264_counts\n",
            "0\n",
            "common_cluster265_counts\n",
            "0\n",
            "common_cluster266_counts\n",
            "0\n",
            "common_cluster267_counts\n",
            "0\n",
            "common_cluster268_counts\n",
            "0\n",
            "common_cluster269_counts\n",
            "0\n",
            "common_cluster270_counts\n",
            "0\n",
            "common_cluster271_counts\n",
            "0\n",
            "common_cluster272_counts\n",
            "0\n",
            "common_cluster273_counts\n",
            "0\n",
            "common_cluster274_counts\n",
            "0\n",
            "common_cluster275_counts\n",
            "0\n",
            "common_cluster276_counts\n",
            "0\n",
            "common_cluster277_counts\n",
            "0\n",
            "common_cluster278_counts\n",
            "0\n",
            "common_cluster279_counts\n",
            "0\n",
            "common_cluster280_counts\n",
            "0\n",
            "common_cluster281_counts\n",
            "0\n",
            "common_cluster282_counts\n",
            "0\n",
            "common_cluster283_counts\n",
            "0\n",
            "common_cluster284_counts\n",
            "0\n",
            "common_cluster285_counts\n",
            "0\n",
            "common_cluster286_counts\n",
            "0\n",
            "common_cluster287_counts\n",
            "0\n",
            "common_cluster288_counts\n",
            "0\n",
            "common_cluster289_counts\n",
            "0\n",
            "common_cluster290_counts\n",
            "0\n",
            "common_cluster291_counts\n",
            "0\n",
            "common_cluster292_counts\n",
            "0\n",
            "common_cluster293_counts\n",
            "0\n",
            "common_cluster294_counts\n",
            "0\n",
            "common_cluster295_counts\n",
            "0\n",
            "common_cluster296_counts\n",
            "0\n",
            "common_cluster297_counts\n",
            "0\n",
            "common_cluster298_counts\n",
            "0\n",
            "common_cluster299_counts\n",
            "0\n",
            "common_cluster300_counts\n",
            "0\n",
            "common_cluster301_counts\n",
            "0\n",
            "common_cluster302_counts\n",
            "0\n",
            "common_cluster303_counts\n",
            "0\n",
            "common_cluster304_counts\n",
            "0\n",
            "common_cluster305_counts\n",
            "0\n",
            "common_cluster306_counts\n",
            "0\n",
            "common_cluster307_counts\n",
            "0\n",
            "common_cluster308_counts\n",
            "0\n",
            "common_cluster309_counts\n",
            "0\n",
            "common_cluster310_counts\n",
            "0\n",
            "common_cluster311_counts\n",
            "0\n",
            "common_cluster312_counts\n",
            "0\n",
            "common_cluster313_counts\n",
            "0\n",
            "common_cluster314_counts\n",
            "0\n",
            "common_cluster315_counts\n",
            "0\n",
            "common_cluster316_counts\n",
            "0\n",
            "common_cluster317_counts\n",
            "0\n",
            "common_cluster318_counts\n",
            "0\n",
            "common_cluster319_counts\n",
            "0\n",
            "common_cluster320_counts\n",
            "0\n",
            "common_cluster321_counts\n",
            "0\n",
            "common_cluster322_counts\n",
            "0\n",
            "common_cluster323_counts\n",
            "0\n",
            "common_cluster324_counts\n",
            "0\n",
            "common_cluster325_counts\n",
            "0\n",
            "common_cluster326_counts\n",
            "0\n",
            "common_cluster327_counts\n",
            "0\n",
            "common_cluster328_counts\n",
            "0\n",
            "common_cluster329_counts\n",
            "0\n",
            "common_cluster330_counts\n",
            "0\n",
            "common_cluster331_counts\n",
            "0\n",
            "common_cluster332_counts\n",
            "0\n",
            "common_cluster333_counts\n",
            "0\n",
            "common_cluster334_counts\n",
            "0\n",
            "common_cluster335_counts\n",
            "0\n",
            "common_cluster336_counts\n",
            "0\n",
            "common_cluster337_counts\n",
            "0\n",
            "common_cluster338_counts\n",
            "0\n",
            "common_cluster339_counts\n",
            "0\n",
            "common_cluster340_counts\n",
            "0\n",
            "common_cluster341_counts\n",
            "0\n",
            "common_cluster342_counts\n",
            "0\n",
            "common_cluster343_counts\n",
            "0\n",
            "common_cluster344_counts\n",
            "0\n",
            "common_cluster345_counts\n",
            "0\n",
            "common_cluster346_counts\n",
            "0\n",
            "common_cluster347_counts\n",
            "0\n",
            "common_cluster348_counts\n",
            "0\n",
            "common_cluster349_counts\n",
            "0\n",
            "common_cluster350_counts\n",
            "0\n",
            "common_cluster351_counts\n",
            "0\n",
            "common_cluster352_counts\n",
            "0\n",
            "common_cluster353_counts\n",
            "0\n",
            "common_cluster354_counts\n",
            "0\n",
            "common_cluster355_counts\n",
            "0\n",
            "common_cluster356_counts\n",
            "0\n",
            "common_cluster357_counts\n",
            "0\n",
            "common_cluster358_counts\n",
            "0\n",
            "common_cluster359_counts\n",
            "0\n",
            "common_cluster360_counts\n",
            "0\n",
            "common_cluster361_counts\n",
            "0\n",
            "common_cluster362_counts\n",
            "0\n",
            "common_cluster363_counts\n",
            "0\n",
            "common_cluster364_counts\n",
            "0\n",
            "common_cluster365_counts\n",
            "0\n",
            "common_cluster366_counts\n",
            "0\n",
            "common_cluster367_counts\n",
            "0\n",
            "common_cluster368_counts\n",
            "0\n",
            "common_cluster369_counts\n",
            "0\n",
            "common_cluster370_counts\n",
            "0\n",
            "common_cluster371_counts\n",
            "0\n",
            "common_cluster372_counts\n",
            "0\n",
            "common_cluster373_counts\n",
            "0\n",
            "common_cluster374_counts\n",
            "0\n",
            "common_cluster375_counts\n",
            "0\n",
            "common_cluster376_counts\n",
            "0\n",
            "common_cluster377_counts\n",
            "0\n",
            "common_cluster378_counts\n",
            "0\n",
            "common_cluster379_counts\n",
            "0\n",
            "common_cluster380_counts\n",
            "0\n",
            "common_cluster381_counts\n",
            "0\n",
            "common_cluster382_counts\n",
            "0\n",
            "common_cluster383_counts\n",
            "0\n",
            "common_cluster384_counts\n",
            "0\n",
            "common_cluster385_counts\n",
            "0\n",
            "common_cluster386_counts\n",
            "0\n",
            "common_cluster387_counts\n",
            "0\n",
            "common_cluster388_counts\n",
            "0\n",
            "common_cluster389_counts\n",
            "0\n",
            "common_cluster390_counts\n",
            "0\n",
            "common_cluster391_counts\n",
            "0\n",
            "common_cluster392_counts\n",
            "0\n",
            "common_cluster393_counts\n",
            "0\n",
            "common_cluster394_counts\n",
            "0\n",
            "common_cluster395_counts\n",
            "0\n",
            "common_cluster396_counts\n",
            "0\n",
            "common_cluster397_counts\n",
            "0\n",
            "common_cluster398_counts\n",
            "0\n",
            "common_cluster399_counts\n",
            "0\n",
            "common_cluster400_counts\n",
            "0\n",
            "common_cluster401_counts\n",
            "0\n",
            "common_cluster402_counts\n",
            "0\n",
            "common_cluster403_counts\n",
            "0\n",
            "common_cluster404_counts\n",
            "0\n",
            "common_cluster405_counts\n",
            "0\n",
            "common_cluster406_counts\n",
            "0\n",
            "common_cluster407_counts\n",
            "0\n",
            "common_cluster408_counts\n",
            "0\n",
            "common_cluster409_counts\n",
            "0\n",
            "common_cluster410_counts\n",
            "0\n",
            "common_cluster411_counts\n",
            "0\n",
            "common_cluster412_counts\n",
            "0\n",
            "common_cluster413_counts\n",
            "0\n",
            "common_cluster414_counts\n",
            "0\n",
            "common_cluster415_counts\n",
            "0\n",
            "common_cluster416_counts\n",
            "0\n",
            "common_cluster417_counts\n",
            "0\n",
            "common_cluster418_counts\n",
            "0\n",
            "common_cluster419_counts\n",
            "0\n",
            "common_cluster420_counts\n",
            "0\n",
            "common_cluster421_counts\n",
            "0\n",
            "common_cluster422_counts\n",
            "0\n",
            "common_cluster423_counts\n",
            "0\n",
            "common_cluster424_counts\n",
            "0\n",
            "common_cluster425_counts\n",
            "0\n",
            "common_cluster426_counts\n",
            "0\n",
            "common_cluster427_counts\n",
            "0\n",
            "common_cluster428_counts\n",
            "0\n",
            "common_cluster429_counts\n",
            "0\n",
            "common_cluster430_counts\n",
            "0\n",
            "common_cluster431_counts\n",
            "0\n",
            "common_cluster432_counts\n",
            "0\n",
            "common_cluster433_counts\n",
            "0\n",
            "common_cluster434_counts\n",
            "0\n",
            "common_cluster435_counts\n",
            "0\n",
            "common_cluster436_counts\n",
            "0\n",
            "common_cluster437_counts\n",
            "0\n",
            "common_cluster438_counts\n",
            "0\n",
            "common_cluster439_counts\n",
            "0\n",
            "common_cluster440_counts\n",
            "0\n",
            "common_cluster441_counts\n",
            "0\n",
            "common_cluster442_counts\n",
            "0\n",
            "common_cluster443_counts\n",
            "0\n",
            "common_cluster444_counts\n",
            "0\n",
            "common_cluster445_counts\n",
            "0\n",
            "common_cluster446_counts\n",
            "0\n",
            "common_cluster447_counts\n",
            "0\n",
            "common_cluster448_counts\n",
            "0\n",
            "common_cluster449_counts\n",
            "0\n",
            "common_cluster450_counts\n",
            "0\n",
            "common_cluster451_counts\n",
            "0\n",
            "common_cluster452_counts\n",
            "0\n",
            "common_cluster453_counts\n",
            "0\n",
            "common_cluster454_counts\n",
            "0\n",
            "common_cluster455_counts\n",
            "0\n",
            "common_cluster456_counts\n",
            "0\n",
            "common_cluster457_counts\n",
            "0\n",
            "common_cluster458_counts\n",
            "0\n",
            "common_cluster459_counts\n",
            "0\n",
            "common_cluster460_counts\n",
            "0\n",
            "common_cluster461_counts\n",
            "0\n",
            "common_cluster462_counts\n",
            "0\n",
            "common_cluster463_counts\n",
            "0\n",
            "common_cluster464_counts\n",
            "0\n",
            "common_cluster465_counts\n",
            "0\n",
            "common_cluster466_counts\n",
            "0\n",
            "common_cluster467_counts\n",
            "0\n",
            "common_cluster468_counts\n",
            "0\n",
            "common_cluster469_counts\n",
            "0\n",
            "common_cluster470_counts\n",
            "0\n",
            "common_cluster471_counts\n",
            "0\n",
            "common_cluster472_counts\n",
            "0\n",
            "common_cluster473_counts\n",
            "0\n",
            "common_cluster474_counts\n",
            "0\n",
            "common_cluster475_counts\n",
            "0\n",
            "common_cluster476_counts\n",
            "0\n",
            "common_cluster477_counts\n",
            "0\n",
            "common_cluster478_counts\n",
            "0\n",
            "common_cluster479_counts\n",
            "0\n",
            "common_cluster480_counts\n",
            "0\n",
            "common_cluster481_counts\n",
            "0\n",
            "common_cluster482_counts\n",
            "0\n",
            "common_cluster483_counts\n",
            "0\n",
            "common_cluster484_counts\n",
            "0\n",
            "common_cluster485_counts\n",
            "0\n",
            "common_cluster486_counts\n",
            "0\n",
            "common_cluster487_counts\n",
            "0\n",
            "common_cluster488_counts\n",
            "0\n",
            "common_cluster489_counts\n",
            "0\n",
            "common_cluster490_counts\n",
            "0\n",
            "common_cluster491_counts\n",
            "0\n",
            "common_cluster492_counts\n",
            "0\n",
            "common_cluster493_counts\n",
            "0\n",
            "common_cluster494_counts\n",
            "0\n",
            "common_cluster495_counts\n",
            "0\n",
            "common_cluster496_counts\n",
            "0\n",
            "common_cluster497_counts\n",
            "0\n",
            "common_cluster498_counts\n",
            "0\n",
            "common_cluster499_counts\n",
            "0\n",
            "company_cluster0_counts\n",
            "0\n",
            "company_cluster1_counts\n",
            "0\n",
            "company_cluster2_counts\n",
            "0\n",
            "company_cluster3_counts\n",
            "0\n",
            "company_cluster4_counts\n",
            "0\n",
            "company_cluster5_counts\n",
            "0\n",
            "company_cluster6_counts\n",
            "0\n",
            "company_cluster7_counts\n",
            "0\n",
            "company_cluster8_counts\n",
            "0\n",
            "company_cluster9_counts\n",
            "0\n",
            "company_cluster10_counts\n",
            "0\n",
            "company_cluster11_counts\n",
            "0\n",
            "company_cluster12_counts\n",
            "0\n",
            "company_cluster13_counts\n",
            "0\n",
            "company_cluster14_counts\n",
            "0\n",
            "company_cluster15_counts\n",
            "0\n",
            "company_cluster16_counts\n",
            "0\n",
            "company_cluster17_counts\n",
            "0\n",
            "company_cluster18_counts\n",
            "0\n",
            "company_cluster19_counts\n",
            "0\n",
            "company_cluster20_counts\n",
            "0\n",
            "company_cluster21_counts\n",
            "0\n",
            "company_cluster22_counts\n",
            "0\n",
            "company_cluster23_counts\n",
            "0\n",
            "company_cluster24_counts\n",
            "0\n",
            "company_cluster25_counts\n",
            "0\n",
            "company_cluster26_counts\n",
            "0\n",
            "company_cluster27_counts\n",
            "0\n",
            "company_cluster28_counts\n",
            "0\n",
            "company_cluster29_counts\n",
            "0\n",
            "company_cluster30_counts\n",
            "0\n",
            "company_cluster31_counts\n",
            "0\n",
            "company_cluster32_counts\n",
            "0\n",
            "company_cluster33_counts\n",
            "0\n",
            "company_cluster34_counts\n",
            "0\n",
            "company_cluster35_counts\n",
            "0\n",
            "company_cluster36_counts\n",
            "0\n",
            "company_cluster37_counts\n",
            "0\n",
            "company_cluster38_counts\n",
            "0\n",
            "company_cluster39_counts\n",
            "0\n",
            "company_cluster40_counts\n",
            "0\n",
            "company_cluster41_counts\n",
            "0\n",
            "company_cluster42_counts\n",
            "0\n",
            "company_cluster43_counts\n",
            "0\n",
            "company_cluster44_counts\n",
            "0\n",
            "company_cluster45_counts\n",
            "0\n",
            "company_cluster46_counts\n",
            "0\n",
            "company_cluster47_counts\n",
            "0\n",
            "company_cluster48_counts\n",
            "0\n",
            "company_cluster49_counts\n",
            "0\n",
            "company_cluster50_counts\n",
            "0\n",
            "company_cluster51_counts\n",
            "0\n",
            "company_cluster52_counts\n",
            "0\n",
            "company_cluster53_counts\n",
            "0\n",
            "company_cluster54_counts\n",
            "0\n",
            "company_cluster55_counts\n",
            "0\n",
            "company_cluster56_counts\n",
            "0\n",
            "company_cluster57_counts\n",
            "0\n",
            "company_cluster58_counts\n",
            "0\n",
            "company_cluster59_counts\n",
            "0\n",
            "company_cluster60_counts\n",
            "0\n",
            "company_cluster61_counts\n",
            "0\n",
            "company_cluster62_counts\n",
            "0\n",
            "company_cluster63_counts\n",
            "0\n",
            "company_cluster64_counts\n",
            "0\n",
            "company_cluster65_counts\n",
            "0\n",
            "company_cluster66_counts\n",
            "0\n",
            "company_cluster67_counts\n",
            "0\n",
            "company_cluster68_counts\n",
            "0\n",
            "company_cluster69_counts\n",
            "0\n",
            "company_cluster70_counts\n",
            "0\n",
            "company_cluster71_counts\n",
            "0\n",
            "company_cluster72_counts\n",
            "0\n",
            "company_cluster73_counts\n",
            "0\n",
            "company_cluster74_counts\n",
            "0\n",
            "company_cluster75_counts\n",
            "0\n",
            "company_cluster76_counts\n",
            "0\n",
            "company_cluster77_counts\n",
            "0\n",
            "company_cluster78_counts\n",
            "0\n",
            "company_cluster79_counts\n",
            "0\n",
            "name_of_department/team_cluster0_counts\n",
            "0\n",
            "name_of_department/team_cluster1_counts\n",
            "0\n",
            "name_of_department/team_cluster2_counts\n",
            "0\n",
            "name_of_department/team_cluster3_counts\n",
            "0\n",
            "name_of_department/team_cluster4_counts\n",
            "0\n",
            "name_of_department/team_cluster5_counts\n",
            "0\n",
            "name_of_department/team_cluster6_counts\n",
            "0\n",
            "name_of_department/team_cluster7_counts\n",
            "0\n",
            "name_of_department/team_cluster8_counts\n",
            "0\n",
            "name_of_department/team_cluster9_counts\n",
            "0\n",
            "name_of_department/team_cluster10_counts\n",
            "0\n",
            "name_of_department/team_cluster11_counts\n",
            "0\n",
            "name_of_department/team_cluster12_counts\n",
            "0\n",
            "name_of_department/team_cluster13_counts\n",
            "0\n",
            "name_of_department/team_cluster14_counts\n",
            "0\n",
            "name_of_department/team_cluster15_counts\n",
            "0\n",
            "name_of_department/team_cluster16_counts\n",
            "0\n",
            "name_of_department/team_cluster17_counts\n",
            "0\n",
            "name_of_department/team_cluster18_counts\n",
            "0\n",
            "name_of_department/team_cluster19_counts\n",
            "0\n",
            "name_of_department/team_cluster20_counts\n",
            "0\n",
            "city_cluster0_counts\n",
            "0\n",
            "city_cluster1_counts\n",
            "0\n",
            "city_cluster2_counts\n",
            "0\n",
            "city_cluster3_counts\n",
            "0\n",
            "city_cluster4_counts\n",
            "0\n",
            "city_cluster5_counts\n",
            "0\n",
            "city_cluster6_counts\n",
            "0\n",
            "city_cluster7_counts\n",
            "0\n",
            "city_cluster8_counts\n",
            "0\n",
            "city_cluster9_counts\n",
            "0\n",
            "city_cluster10_counts\n",
            "0\n",
            "city_cluster11_counts\n",
            "0\n",
            "city_cluster12_counts\n",
            "0\n",
            "city_cluster13_counts\n",
            "0\n",
            "city_cluster14_counts\n",
            "0\n",
            "city_cluster15_counts\n",
            "0\n",
            "city_cluster16_counts\n",
            "0\n",
            "city_cluster17_counts\n",
            "0\n",
            "city_cluster18_counts\n",
            "0\n",
            "city_cluster19_counts\n",
            "0\n",
            "city_cluster20_counts\n",
            "0\n",
            "city_cluster21_counts\n",
            "0\n",
            "city_cluster22_counts\n",
            "0\n",
            "city_cluster23_counts\n",
            "0\n",
            "city_cluster24_counts\n",
            "0\n",
            "city_cluster25_counts\n",
            "0\n",
            "city_cluster26_counts\n",
            "0\n",
            "city_cluster27_counts\n",
            "0\n",
            "city_cluster28_counts\n",
            "0\n",
            "city_cluster29_counts\n",
            "0\n",
            "city_cluster30_counts\n",
            "0\n",
            "city_cluster31_counts\n",
            "0\n",
            "city_cluster32_counts\n",
            "0\n",
            "city_cluster33_counts\n",
            "0\n",
            "city_cluster34_counts\n",
            "0\n",
            "city_cluster35_counts\n",
            "0\n",
            "city_cluster36_counts\n",
            "0\n",
            "city_cluster37_counts\n",
            "0\n",
            "city_cluster38_counts\n",
            "0\n",
            "city_cluster39_counts\n",
            "0\n",
            "city_cluster40_counts\n",
            "0\n",
            "city_cluster41_counts\n",
            "0\n",
            "city_cluster42_counts\n",
            "0\n",
            "city_cluster43_counts\n",
            "0\n",
            "city_cluster44_counts\n",
            "0\n",
            "city_cluster45_counts\n",
            "0\n",
            "city_cluster46_counts\n",
            "0\n",
            "city_cluster47_counts\n",
            "0\n",
            "city_cluster48_counts\n",
            "0\n",
            "city_cluster49_counts\n",
            "0\n",
            "city_cluster50_counts\n",
            "0\n",
            "city_cluster51_counts\n",
            "0\n",
            "city_cluster52_counts\n",
            "0\n",
            "work_arrangement_cluster0_counts\n",
            "1\n",
            "work_arrangement_cluster1_counts\n",
            "0\n",
            "work_arrangement_cluster2_counts\n",
            "0\n",
            "work_arrangement_cluster3_counts\n",
            "0\n",
            "work_arrangement_cluster4_counts\n",
            "0\n",
            "work_arrangement_cluster5_counts\n",
            "0\n",
            "work_arrangement_cluster6_counts\n",
            "0\n",
            "work_arrangement_cluster7_counts\n",
            "0\n",
            "work_arrangement_cluster8_counts\n",
            "0\n",
            "work_arrangement_cluster9_counts\n",
            "0\n",
            "AR\n",
            "0\n",
            "AZ\n",
            "0\n",
            "CA\n",
            "0\n",
            "CO\n",
            "0\n",
            "FL\n",
            "0\n",
            "GA\n",
            "0\n",
            "IA\n",
            "0\n",
            "IL\n",
            "0\n",
            "IN\n",
            "0\n",
            "MA\n",
            "0\n",
            "MD\n",
            "0\n",
            "MI\n",
            "0\n",
            "MO\n",
            "0\n",
            "NC\n",
            "0\n",
            "ND\n",
            "0\n",
            "NJ\n",
            "0\n",
            "NY\n",
            "0\n",
            "OR\n",
            "0\n",
            "PA\n",
            "0\n",
            "TX\n",
            "0\n",
            "UT\n",
            "0\n",
            "VA\n",
            "0\n",
            "WA\n",
            "0\n",
            "WI\n",
            "0\n",
            "USA\n",
            "1\n",
            "United States\n",
            "0\n",
            "Accuracy: 0.45454545454545453\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "columns_to_drop = common_corpus_columns + singular_corpus_columns + work_arrangement_columns + categorical_label_columns\n",
        "embedded_data_columns = common_corpus_columns + singular_corpus_columns + work_arrangement_columns\n",
        "embedded_data_columns = [f'{col}_vectors' for col in embedded_data_columns]\n",
        "\n",
        "columns_to_drop = columns_to_drop + embedded_data_columns\n",
        "\n",
        "# Make a copy of the dataframe with specified columns dropped\n",
        "df_copy = df.drop(columns=columns_to_drop).copy()\n",
        "df_copy = df_copy.drop(columns=[''])\n",
        "\n",
        "# Iterate over columns and fill NaN values with the mode of each column\n",
        "for col in df_copy.columns:\n",
        "  try:\n",
        "    print(col)\n",
        "    mode_val = df_copy[col].mode()[0]\n",
        "    print(mode_val)  # Get the mode value for the column\n",
        "    df_copy[col].fillna(mode_val, inplace=True)  # Fill NaN values with the mode\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "# Assuming df_encoded is your dataframe with one-hot encoded features and target variable\n",
        "# Split the data into features (X) and target variable (y)\n",
        "y = df_copy['rating']  # Target variable\n",
        "X = df_copy.drop(columns=['rating'])  # Features\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = xgb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqBsgGQPhwMD"
      },
      "source": [
        "So XGBoost had an accuracy of .45. What about MAE?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y16ufDBShF3V",
        "outputId": "a5bb90e3-6584-48bf-ba23-26b274fa3f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.7272727272727273\n"
          ]
        }
      ],
      "source": [
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBCAdTBliGSX"
      },
      "source": [
        "So far, it's not clear based on one test run whether the decision tree or random forest did better, but it looks like XGBoost did substantially worse. However, we did not perform any model tuning, so it's best to not jump to any conclusions yet.\n",
        "\n",
        "One thing we might want to do and probably will do soon is collect more data. However, we might want to consider reducing the size of our feature space or the complexity of our feature engineering bc it is costly from a user's time perspective and it may be negatively impacting model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_acGew5yk35Z"
      },
      "source": [
        "Let us return to the Decision Tree to perform hyperparameter tuning to find the set of hyperparameters that yield the best performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcAJrl6Lk19X",
        "outputId": "f2dc1d82-4391-4977-95f4-6802aa26f888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "min_salary\n",
            "100.0\n",
            "max_salary\n",
            "200.0\n",
            "rating\n",
            "2\n",
            "common_cluster0_counts\n",
            "0\n",
            "common_cluster1_counts\n",
            "0\n",
            "common_cluster2_counts\n",
            "2\n",
            "common_cluster3_counts\n",
            "0\n",
            "common_cluster4_counts\n",
            "0\n",
            "common_cluster5_counts\n",
            "0\n",
            "common_cluster6_counts\n",
            "0\n",
            "common_cluster7_counts\n",
            "0\n",
            "common_cluster8_counts\n",
            "0\n",
            "common_cluster9_counts\n",
            "0\n",
            "common_cluster10_counts\n",
            "0\n",
            "common_cluster11_counts\n",
            "0\n",
            "common_cluster12_counts\n",
            "0\n",
            "common_cluster13_counts\n",
            "0\n",
            "common_cluster14_counts\n",
            "0\n",
            "common_cluster15_counts\n",
            "0\n",
            "common_cluster16_counts\n",
            "0\n",
            "common_cluster17_counts\n",
            "0\n",
            "common_cluster18_counts\n",
            "0\n",
            "common_cluster19_counts\n",
            "0\n",
            "common_cluster20_counts\n",
            "0\n",
            "common_cluster21_counts\n",
            "0\n",
            "common_cluster22_counts\n",
            "0\n",
            "common_cluster23_counts\n",
            "0\n",
            "common_cluster24_counts\n",
            "1\n",
            "common_cluster25_counts\n",
            "0\n",
            "common_cluster26_counts\n",
            "0\n",
            "common_cluster27_counts\n",
            "0\n",
            "common_cluster28_counts\n",
            "0\n",
            "common_cluster29_counts\n",
            "0\n",
            "common_cluster30_counts\n",
            "0\n",
            "common_cluster31_counts\n",
            "0\n",
            "common_cluster32_counts\n",
            "0\n",
            "common_cluster33_counts\n",
            "0\n",
            "common_cluster34_counts\n",
            "0\n",
            "common_cluster35_counts\n",
            "0\n",
            "common_cluster36_counts\n",
            "0\n",
            "common_cluster37_counts\n",
            "0\n",
            "common_cluster38_counts\n",
            "0\n",
            "common_cluster39_counts\n",
            "0\n",
            "common_cluster40_counts\n",
            "0\n",
            "common_cluster41_counts\n",
            "0\n",
            "common_cluster42_counts\n",
            "0\n",
            "common_cluster43_counts\n",
            "0\n",
            "common_cluster44_counts\n",
            "0\n",
            "common_cluster45_counts\n",
            "0\n",
            "common_cluster46_counts\n",
            "0\n",
            "common_cluster47_counts\n",
            "0\n",
            "common_cluster48_counts\n",
            "0\n",
            "common_cluster49_counts\n",
            "0\n",
            "common_cluster50_counts\n",
            "0\n",
            "common_cluster51_counts\n",
            "0\n",
            "common_cluster52_counts\n",
            "0\n",
            "common_cluster53_counts\n",
            "0\n",
            "common_cluster54_counts\n",
            "0\n",
            "common_cluster55_counts\n",
            "0\n",
            "common_cluster56_counts\n",
            "0\n",
            "common_cluster57_counts\n",
            "0\n",
            "common_cluster58_counts\n",
            "0\n",
            "common_cluster59_counts\n",
            "0\n",
            "common_cluster60_counts\n",
            "0\n",
            "common_cluster61_counts\n",
            "0\n",
            "common_cluster62_counts\n",
            "0\n",
            "common_cluster63_counts\n",
            "0\n",
            "common_cluster64_counts\n",
            "0\n",
            "common_cluster65_counts\n",
            "0\n",
            "common_cluster66_counts\n",
            "0\n",
            "common_cluster67_counts\n",
            "0\n",
            "common_cluster68_counts\n",
            "0\n",
            "common_cluster69_counts\n",
            "0\n",
            "common_cluster70_counts\n",
            "0\n",
            "common_cluster71_counts\n",
            "0\n",
            "common_cluster72_counts\n",
            "0\n",
            "common_cluster73_counts\n",
            "0\n",
            "common_cluster74_counts\n",
            "0\n",
            "common_cluster75_counts\n",
            "0\n",
            "common_cluster76_counts\n",
            "0\n",
            "common_cluster77_counts\n",
            "0\n",
            "common_cluster78_counts\n",
            "0\n",
            "common_cluster79_counts\n",
            "0\n",
            "common_cluster80_counts\n",
            "0\n",
            "common_cluster81_counts\n",
            "0\n",
            "common_cluster82_counts\n",
            "0\n",
            "common_cluster83_counts\n",
            "0\n",
            "common_cluster84_counts\n",
            "0\n",
            "common_cluster85_counts\n",
            "0\n",
            "common_cluster86_counts\n",
            "0\n",
            "common_cluster87_counts\n",
            "0\n",
            "common_cluster88_counts\n",
            "0\n",
            "common_cluster89_counts\n",
            "0\n",
            "common_cluster90_counts\n",
            "0\n",
            "common_cluster91_counts\n",
            "0\n",
            "common_cluster92_counts\n",
            "0\n",
            "common_cluster93_counts\n",
            "0\n",
            "common_cluster94_counts\n",
            "0\n",
            "common_cluster95_counts\n",
            "0\n",
            "common_cluster96_counts\n",
            "0\n",
            "common_cluster97_counts\n",
            "0\n",
            "common_cluster98_counts\n",
            "0\n",
            "common_cluster99_counts\n",
            "0\n",
            "common_cluster100_counts\n",
            "0\n",
            "common_cluster101_counts\n",
            "0\n",
            "common_cluster102_counts\n",
            "0\n",
            "common_cluster103_counts\n",
            "0\n",
            "common_cluster104_counts\n",
            "0\n",
            "common_cluster105_counts\n",
            "0\n",
            "common_cluster106_counts\n",
            "0\n",
            "common_cluster107_counts\n",
            "0\n",
            "common_cluster108_counts\n",
            "0\n",
            "common_cluster109_counts\n",
            "0\n",
            "common_cluster110_counts\n",
            "0\n",
            "common_cluster111_counts\n",
            "0\n",
            "common_cluster112_counts\n",
            "0\n",
            "common_cluster113_counts\n",
            "0\n",
            "common_cluster114_counts\n",
            "0\n",
            "common_cluster115_counts\n",
            "0\n",
            "common_cluster116_counts\n",
            "0\n",
            "common_cluster117_counts\n",
            "0\n",
            "common_cluster118_counts\n",
            "0\n",
            "common_cluster119_counts\n",
            "0\n",
            "common_cluster120_counts\n",
            "0\n",
            "common_cluster121_counts\n",
            "0\n",
            "common_cluster122_counts\n",
            "0\n",
            "common_cluster123_counts\n",
            "0\n",
            "common_cluster124_counts\n",
            "0\n",
            "common_cluster125_counts\n",
            "0\n",
            "common_cluster126_counts\n",
            "0\n",
            "common_cluster127_counts\n",
            "0\n",
            "common_cluster128_counts\n",
            "0\n",
            "common_cluster129_counts\n",
            "0\n",
            "common_cluster130_counts\n",
            "0\n",
            "common_cluster131_counts\n",
            "0\n",
            "common_cluster132_counts\n",
            "0\n",
            "common_cluster133_counts\n",
            "0\n",
            "common_cluster134_counts\n",
            "0\n",
            "common_cluster135_counts\n",
            "0\n",
            "common_cluster136_counts\n",
            "0\n",
            "common_cluster137_counts\n",
            "0\n",
            "common_cluster138_counts\n",
            "0\n",
            "common_cluster139_counts\n",
            "0\n",
            "common_cluster140_counts\n",
            "0\n",
            "common_cluster141_counts\n",
            "0\n",
            "common_cluster142_counts\n",
            "0\n",
            "common_cluster143_counts\n",
            "0\n",
            "common_cluster144_counts\n",
            "0\n",
            "common_cluster145_counts\n",
            "0\n",
            "common_cluster146_counts\n",
            "0\n",
            "common_cluster147_counts\n",
            "0\n",
            "common_cluster148_counts\n",
            "0\n",
            "common_cluster149_counts\n",
            "0\n",
            "common_cluster150_counts\n",
            "0\n",
            "common_cluster151_counts\n",
            "0\n",
            "common_cluster152_counts\n",
            "0\n",
            "common_cluster153_counts\n",
            "0\n",
            "common_cluster154_counts\n",
            "0\n",
            "common_cluster155_counts\n",
            "0\n",
            "common_cluster156_counts\n",
            "0\n",
            "common_cluster157_counts\n",
            "0\n",
            "common_cluster158_counts\n",
            "0\n",
            "common_cluster159_counts\n",
            "0\n",
            "common_cluster160_counts\n",
            "0\n",
            "common_cluster161_counts\n",
            "0\n",
            "common_cluster162_counts\n",
            "0\n",
            "common_cluster163_counts\n",
            "0\n",
            "common_cluster164_counts\n",
            "0\n",
            "common_cluster165_counts\n",
            "0\n",
            "common_cluster166_counts\n",
            "0\n",
            "common_cluster167_counts\n",
            "0\n",
            "common_cluster168_counts\n",
            "0\n",
            "common_cluster169_counts\n",
            "0\n",
            "common_cluster170_counts\n",
            "0\n",
            "common_cluster171_counts\n",
            "0\n",
            "common_cluster172_counts\n",
            "0\n",
            "common_cluster173_counts\n",
            "0\n",
            "common_cluster174_counts\n",
            "0\n",
            "common_cluster175_counts\n",
            "0\n",
            "common_cluster176_counts\n",
            "0\n",
            "common_cluster177_counts\n",
            "0\n",
            "common_cluster178_counts\n",
            "0\n",
            "common_cluster179_counts\n",
            "0\n",
            "common_cluster180_counts\n",
            "0\n",
            "common_cluster181_counts\n",
            "0\n",
            "common_cluster182_counts\n",
            "0\n",
            "common_cluster183_counts\n",
            "0\n",
            "common_cluster184_counts\n",
            "0\n",
            "common_cluster185_counts\n",
            "0\n",
            "common_cluster186_counts\n",
            "0\n",
            "common_cluster187_counts\n",
            "0\n",
            "common_cluster188_counts\n",
            "0\n",
            "common_cluster189_counts\n",
            "0\n",
            "common_cluster190_counts\n",
            "0\n",
            "common_cluster191_counts\n",
            "0\n",
            "common_cluster192_counts\n",
            "0\n",
            "common_cluster193_counts\n",
            "0\n",
            "common_cluster194_counts\n",
            "0\n",
            "common_cluster195_counts\n",
            "0\n",
            "common_cluster196_counts\n",
            "0\n",
            "common_cluster197_counts\n",
            "0\n",
            "common_cluster198_counts\n",
            "0\n",
            "common_cluster199_counts\n",
            "0\n",
            "common_cluster200_counts\n",
            "0\n",
            "common_cluster201_counts\n",
            "0\n",
            "common_cluster202_counts\n",
            "0\n",
            "common_cluster203_counts\n",
            "0\n",
            "common_cluster204_counts\n",
            "0\n",
            "common_cluster205_counts\n",
            "0\n",
            "common_cluster206_counts\n",
            "0\n",
            "common_cluster207_counts\n",
            "0\n",
            "common_cluster208_counts\n",
            "0\n",
            "common_cluster209_counts\n",
            "0\n",
            "common_cluster210_counts\n",
            "0\n",
            "common_cluster211_counts\n",
            "0\n",
            "common_cluster212_counts\n",
            "0\n",
            "common_cluster213_counts\n",
            "0\n",
            "common_cluster214_counts\n",
            "0\n",
            "common_cluster215_counts\n",
            "0\n",
            "common_cluster216_counts\n",
            "0\n",
            "common_cluster217_counts\n",
            "0\n",
            "common_cluster218_counts\n",
            "0\n",
            "common_cluster219_counts\n",
            "0\n",
            "common_cluster220_counts\n",
            "0\n",
            "common_cluster221_counts\n",
            "0\n",
            "common_cluster222_counts\n",
            "0\n",
            "common_cluster223_counts\n",
            "0\n",
            "common_cluster224_counts\n",
            "0\n",
            "common_cluster225_counts\n",
            "0\n",
            "common_cluster226_counts\n",
            "0\n",
            "common_cluster227_counts\n",
            "0\n",
            "common_cluster228_counts\n",
            "0\n",
            "common_cluster229_counts\n",
            "0\n",
            "common_cluster230_counts\n",
            "0\n",
            "common_cluster231_counts\n",
            "0\n",
            "common_cluster232_counts\n",
            "0\n",
            "common_cluster233_counts\n",
            "0\n",
            "common_cluster234_counts\n",
            "0\n",
            "common_cluster235_counts\n",
            "0\n",
            "common_cluster236_counts\n",
            "0\n",
            "common_cluster237_counts\n",
            "0\n",
            "common_cluster238_counts\n",
            "0\n",
            "common_cluster239_counts\n",
            "0\n",
            "common_cluster240_counts\n",
            "0\n",
            "common_cluster241_counts\n",
            "0\n",
            "common_cluster242_counts\n",
            "0\n",
            "common_cluster243_counts\n",
            "0\n",
            "common_cluster244_counts\n",
            "0\n",
            "common_cluster245_counts\n",
            "0\n",
            "common_cluster246_counts\n",
            "0\n",
            "common_cluster247_counts\n",
            "0\n",
            "common_cluster248_counts\n",
            "0\n",
            "common_cluster249_counts\n",
            "0\n",
            "common_cluster250_counts\n",
            "0\n",
            "common_cluster251_counts\n",
            "0\n",
            "common_cluster252_counts\n",
            "0\n",
            "common_cluster253_counts\n",
            "0\n",
            "common_cluster254_counts\n",
            "0\n",
            "common_cluster255_counts\n",
            "0\n",
            "common_cluster256_counts\n",
            "0\n",
            "common_cluster257_counts\n",
            "0\n",
            "common_cluster258_counts\n",
            "0\n",
            "common_cluster259_counts\n",
            "0\n",
            "common_cluster260_counts\n",
            "0\n",
            "common_cluster261_counts\n",
            "0\n",
            "common_cluster262_counts\n",
            "0\n",
            "common_cluster263_counts\n",
            "0\n",
            "common_cluster264_counts\n",
            "0\n",
            "common_cluster265_counts\n",
            "0\n",
            "common_cluster266_counts\n",
            "0\n",
            "common_cluster267_counts\n",
            "0\n",
            "common_cluster268_counts\n",
            "0\n",
            "common_cluster269_counts\n",
            "0\n",
            "common_cluster270_counts\n",
            "0\n",
            "common_cluster271_counts\n",
            "0\n",
            "common_cluster272_counts\n",
            "0\n",
            "common_cluster273_counts\n",
            "0\n",
            "common_cluster274_counts\n",
            "0\n",
            "common_cluster275_counts\n",
            "0\n",
            "common_cluster276_counts\n",
            "0\n",
            "common_cluster277_counts\n",
            "0\n",
            "common_cluster278_counts\n",
            "0\n",
            "common_cluster279_counts\n",
            "0\n",
            "common_cluster280_counts\n",
            "0\n",
            "common_cluster281_counts\n",
            "0\n",
            "common_cluster282_counts\n",
            "0\n",
            "common_cluster283_counts\n",
            "0\n",
            "common_cluster284_counts\n",
            "0\n",
            "common_cluster285_counts\n",
            "0\n",
            "common_cluster286_counts\n",
            "0\n",
            "common_cluster287_counts\n",
            "0\n",
            "common_cluster288_counts\n",
            "0\n",
            "common_cluster289_counts\n",
            "0\n",
            "common_cluster290_counts\n",
            "0\n",
            "common_cluster291_counts\n",
            "0\n",
            "common_cluster292_counts\n",
            "0\n",
            "common_cluster293_counts\n",
            "0\n",
            "common_cluster294_counts\n",
            "0\n",
            "common_cluster295_counts\n",
            "0\n",
            "common_cluster296_counts\n",
            "0\n",
            "common_cluster297_counts\n",
            "0\n",
            "common_cluster298_counts\n",
            "0\n",
            "common_cluster299_counts\n",
            "0\n",
            "common_cluster300_counts\n",
            "0\n",
            "common_cluster301_counts\n",
            "0\n",
            "common_cluster302_counts\n",
            "0\n",
            "common_cluster303_counts\n",
            "0\n",
            "common_cluster304_counts\n",
            "0\n",
            "common_cluster305_counts\n",
            "0\n",
            "common_cluster306_counts\n",
            "0\n",
            "common_cluster307_counts\n",
            "0\n",
            "common_cluster308_counts\n",
            "0\n",
            "common_cluster309_counts\n",
            "0\n",
            "common_cluster310_counts\n",
            "0\n",
            "common_cluster311_counts\n",
            "0\n",
            "common_cluster312_counts\n",
            "0\n",
            "common_cluster313_counts\n",
            "0\n",
            "common_cluster314_counts\n",
            "0\n",
            "common_cluster315_counts\n",
            "0\n",
            "common_cluster316_counts\n",
            "0\n",
            "common_cluster317_counts\n",
            "0\n",
            "common_cluster318_counts\n",
            "0\n",
            "common_cluster319_counts\n",
            "0\n",
            "common_cluster320_counts\n",
            "0\n",
            "common_cluster321_counts\n",
            "0\n",
            "common_cluster322_counts\n",
            "0\n",
            "common_cluster323_counts\n",
            "0\n",
            "common_cluster324_counts\n",
            "0\n",
            "common_cluster325_counts\n",
            "0\n",
            "common_cluster326_counts\n",
            "0\n",
            "common_cluster327_counts\n",
            "0\n",
            "common_cluster328_counts\n",
            "0\n",
            "common_cluster329_counts\n",
            "0\n",
            "common_cluster330_counts\n",
            "0\n",
            "common_cluster331_counts\n",
            "0\n",
            "common_cluster332_counts\n",
            "0\n",
            "common_cluster333_counts\n",
            "0\n",
            "common_cluster334_counts\n",
            "0\n",
            "common_cluster335_counts\n",
            "0\n",
            "common_cluster336_counts\n",
            "0\n",
            "common_cluster337_counts\n",
            "0\n",
            "common_cluster338_counts\n",
            "0\n",
            "common_cluster339_counts\n",
            "0\n",
            "common_cluster340_counts\n",
            "0\n",
            "common_cluster341_counts\n",
            "0\n",
            "common_cluster342_counts\n",
            "0\n",
            "common_cluster343_counts\n",
            "0\n",
            "common_cluster344_counts\n",
            "0\n",
            "common_cluster345_counts\n",
            "0\n",
            "common_cluster346_counts\n",
            "0\n",
            "common_cluster347_counts\n",
            "0\n",
            "common_cluster348_counts\n",
            "0\n",
            "common_cluster349_counts\n",
            "0\n",
            "common_cluster350_counts\n",
            "0\n",
            "common_cluster351_counts\n",
            "0\n",
            "common_cluster352_counts\n",
            "0\n",
            "common_cluster353_counts\n",
            "0\n",
            "common_cluster354_counts\n",
            "0\n",
            "common_cluster355_counts\n",
            "0\n",
            "common_cluster356_counts\n",
            "0\n",
            "common_cluster357_counts\n",
            "0\n",
            "common_cluster358_counts\n",
            "0\n",
            "common_cluster359_counts\n",
            "0\n",
            "common_cluster360_counts\n",
            "0\n",
            "common_cluster361_counts\n",
            "0\n",
            "common_cluster362_counts\n",
            "0\n",
            "common_cluster363_counts\n",
            "0\n",
            "common_cluster364_counts\n",
            "0\n",
            "common_cluster365_counts\n",
            "0\n",
            "common_cluster366_counts\n",
            "0\n",
            "common_cluster367_counts\n",
            "0\n",
            "common_cluster368_counts\n",
            "0\n",
            "common_cluster369_counts\n",
            "0\n",
            "common_cluster370_counts\n",
            "0\n",
            "common_cluster371_counts\n",
            "0\n",
            "common_cluster372_counts\n",
            "0\n",
            "common_cluster373_counts\n",
            "0\n",
            "common_cluster374_counts\n",
            "0\n",
            "common_cluster375_counts\n",
            "0\n",
            "common_cluster376_counts\n",
            "0\n",
            "common_cluster377_counts\n",
            "0\n",
            "common_cluster378_counts\n",
            "0\n",
            "common_cluster379_counts\n",
            "0\n",
            "common_cluster380_counts\n",
            "0\n",
            "common_cluster381_counts\n",
            "0\n",
            "common_cluster382_counts\n",
            "0\n",
            "common_cluster383_counts\n",
            "0\n",
            "common_cluster384_counts\n",
            "0\n",
            "common_cluster385_counts\n",
            "0\n",
            "common_cluster386_counts\n",
            "0\n",
            "common_cluster387_counts\n",
            "0\n",
            "common_cluster388_counts\n",
            "0\n",
            "common_cluster389_counts\n",
            "0\n",
            "common_cluster390_counts\n",
            "0\n",
            "common_cluster391_counts\n",
            "0\n",
            "common_cluster392_counts\n",
            "0\n",
            "common_cluster393_counts\n",
            "0\n",
            "common_cluster394_counts\n",
            "0\n",
            "common_cluster395_counts\n",
            "0\n",
            "common_cluster396_counts\n",
            "0\n",
            "common_cluster397_counts\n",
            "0\n",
            "common_cluster398_counts\n",
            "0\n",
            "common_cluster399_counts\n",
            "0\n",
            "common_cluster400_counts\n",
            "0\n",
            "common_cluster401_counts\n",
            "0\n",
            "common_cluster402_counts\n",
            "0\n",
            "common_cluster403_counts\n",
            "0\n",
            "common_cluster404_counts\n",
            "0\n",
            "common_cluster405_counts\n",
            "0\n",
            "common_cluster406_counts\n",
            "0\n",
            "common_cluster407_counts\n",
            "0\n",
            "common_cluster408_counts\n",
            "0\n",
            "common_cluster409_counts\n",
            "0\n",
            "common_cluster410_counts\n",
            "0\n",
            "common_cluster411_counts\n",
            "0\n",
            "common_cluster412_counts\n",
            "0\n",
            "common_cluster413_counts\n",
            "0\n",
            "common_cluster414_counts\n",
            "0\n",
            "common_cluster415_counts\n",
            "0\n",
            "common_cluster416_counts\n",
            "0\n",
            "common_cluster417_counts\n",
            "0\n",
            "common_cluster418_counts\n",
            "0\n",
            "common_cluster419_counts\n",
            "0\n",
            "common_cluster420_counts\n",
            "0\n",
            "common_cluster421_counts\n",
            "0\n",
            "common_cluster422_counts\n",
            "0\n",
            "common_cluster423_counts\n",
            "0\n",
            "common_cluster424_counts\n",
            "0\n",
            "common_cluster425_counts\n",
            "0\n",
            "common_cluster426_counts\n",
            "0\n",
            "common_cluster427_counts\n",
            "0\n",
            "common_cluster428_counts\n",
            "0\n",
            "common_cluster429_counts\n",
            "0\n",
            "common_cluster430_counts\n",
            "0\n",
            "common_cluster431_counts\n",
            "0\n",
            "common_cluster432_counts\n",
            "0\n",
            "common_cluster433_counts\n",
            "0\n",
            "common_cluster434_counts\n",
            "0\n",
            "common_cluster435_counts\n",
            "0\n",
            "common_cluster436_counts\n",
            "0\n",
            "common_cluster437_counts\n",
            "0\n",
            "common_cluster438_counts\n",
            "0\n",
            "common_cluster439_counts\n",
            "0\n",
            "common_cluster440_counts\n",
            "0\n",
            "common_cluster441_counts\n",
            "0\n",
            "common_cluster442_counts\n",
            "0\n",
            "common_cluster443_counts\n",
            "0\n",
            "common_cluster444_counts\n",
            "0\n",
            "common_cluster445_counts\n",
            "0\n",
            "common_cluster446_counts\n",
            "0\n",
            "common_cluster447_counts\n",
            "0\n",
            "common_cluster448_counts\n",
            "0\n",
            "common_cluster449_counts\n",
            "0\n",
            "common_cluster450_counts\n",
            "0\n",
            "common_cluster451_counts\n",
            "0\n",
            "common_cluster452_counts\n",
            "0\n",
            "common_cluster453_counts\n",
            "0\n",
            "common_cluster454_counts\n",
            "0\n",
            "common_cluster455_counts\n",
            "0\n",
            "common_cluster456_counts\n",
            "0\n",
            "common_cluster457_counts\n",
            "0\n",
            "common_cluster458_counts\n",
            "0\n",
            "common_cluster459_counts\n",
            "0\n",
            "common_cluster460_counts\n",
            "0\n",
            "common_cluster461_counts\n",
            "0\n",
            "common_cluster462_counts\n",
            "0\n",
            "common_cluster463_counts\n",
            "0\n",
            "common_cluster464_counts\n",
            "0\n",
            "common_cluster465_counts\n",
            "0\n",
            "common_cluster466_counts\n",
            "0\n",
            "common_cluster467_counts\n",
            "0\n",
            "common_cluster468_counts\n",
            "0\n",
            "common_cluster469_counts\n",
            "0\n",
            "common_cluster470_counts\n",
            "0\n",
            "common_cluster471_counts\n",
            "0\n",
            "common_cluster472_counts\n",
            "0\n",
            "common_cluster473_counts\n",
            "0\n",
            "common_cluster474_counts\n",
            "0\n",
            "common_cluster475_counts\n",
            "0\n",
            "common_cluster476_counts\n",
            "0\n",
            "common_cluster477_counts\n",
            "0\n",
            "common_cluster478_counts\n",
            "0\n",
            "common_cluster479_counts\n",
            "0\n",
            "common_cluster480_counts\n",
            "0\n",
            "common_cluster481_counts\n",
            "0\n",
            "common_cluster482_counts\n",
            "0\n",
            "common_cluster483_counts\n",
            "0\n",
            "common_cluster484_counts\n",
            "0\n",
            "common_cluster485_counts\n",
            "0\n",
            "common_cluster486_counts\n",
            "0\n",
            "common_cluster487_counts\n",
            "0\n",
            "common_cluster488_counts\n",
            "0\n",
            "common_cluster489_counts\n",
            "0\n",
            "common_cluster490_counts\n",
            "0\n",
            "common_cluster491_counts\n",
            "0\n",
            "common_cluster492_counts\n",
            "0\n",
            "common_cluster493_counts\n",
            "0\n",
            "common_cluster494_counts\n",
            "0\n",
            "common_cluster495_counts\n",
            "0\n",
            "common_cluster496_counts\n",
            "0\n",
            "common_cluster497_counts\n",
            "0\n",
            "common_cluster498_counts\n",
            "0\n",
            "common_cluster499_counts\n",
            "0\n",
            "company_cluster0_counts\n",
            "0\n",
            "company_cluster1_counts\n",
            "0\n",
            "company_cluster2_counts\n",
            "0\n",
            "company_cluster3_counts\n",
            "0\n",
            "company_cluster4_counts\n",
            "0\n",
            "company_cluster5_counts\n",
            "0\n",
            "company_cluster6_counts\n",
            "0\n",
            "company_cluster7_counts\n",
            "0\n",
            "company_cluster8_counts\n",
            "0\n",
            "company_cluster9_counts\n",
            "0\n",
            "company_cluster10_counts\n",
            "0\n",
            "company_cluster11_counts\n",
            "0\n",
            "company_cluster12_counts\n",
            "0\n",
            "company_cluster13_counts\n",
            "0\n",
            "company_cluster14_counts\n",
            "0\n",
            "company_cluster15_counts\n",
            "0\n",
            "company_cluster16_counts\n",
            "0\n",
            "company_cluster17_counts\n",
            "0\n",
            "company_cluster18_counts\n",
            "0\n",
            "company_cluster19_counts\n",
            "0\n",
            "company_cluster20_counts\n",
            "0\n",
            "company_cluster21_counts\n",
            "0\n",
            "company_cluster22_counts\n",
            "0\n",
            "company_cluster23_counts\n",
            "0\n",
            "company_cluster24_counts\n",
            "0\n",
            "company_cluster25_counts\n",
            "0\n",
            "company_cluster26_counts\n",
            "0\n",
            "company_cluster27_counts\n",
            "0\n",
            "company_cluster28_counts\n",
            "0\n",
            "company_cluster29_counts\n",
            "0\n",
            "company_cluster30_counts\n",
            "0\n",
            "company_cluster31_counts\n",
            "0\n",
            "company_cluster32_counts\n",
            "0\n",
            "company_cluster33_counts\n",
            "0\n",
            "company_cluster34_counts\n",
            "0\n",
            "company_cluster35_counts\n",
            "0\n",
            "company_cluster36_counts\n",
            "0\n",
            "company_cluster37_counts\n",
            "0\n",
            "company_cluster38_counts\n",
            "0\n",
            "company_cluster39_counts\n",
            "0\n",
            "company_cluster40_counts\n",
            "0\n",
            "company_cluster41_counts\n",
            "0\n",
            "company_cluster42_counts\n",
            "0\n",
            "company_cluster43_counts\n",
            "0\n",
            "company_cluster44_counts\n",
            "0\n",
            "company_cluster45_counts\n",
            "0\n",
            "company_cluster46_counts\n",
            "0\n",
            "company_cluster47_counts\n",
            "0\n",
            "company_cluster48_counts\n",
            "0\n",
            "company_cluster49_counts\n",
            "0\n",
            "company_cluster50_counts\n",
            "0\n",
            "company_cluster51_counts\n",
            "0\n",
            "company_cluster52_counts\n",
            "0\n",
            "company_cluster53_counts\n",
            "0\n",
            "company_cluster54_counts\n",
            "0\n",
            "company_cluster55_counts\n",
            "0\n",
            "company_cluster56_counts\n",
            "0\n",
            "company_cluster57_counts\n",
            "0\n",
            "company_cluster58_counts\n",
            "0\n",
            "company_cluster59_counts\n",
            "0\n",
            "company_cluster60_counts\n",
            "0\n",
            "company_cluster61_counts\n",
            "0\n",
            "company_cluster62_counts\n",
            "0\n",
            "company_cluster63_counts\n",
            "0\n",
            "company_cluster64_counts\n",
            "0\n",
            "company_cluster65_counts\n",
            "0\n",
            "company_cluster66_counts\n",
            "0\n",
            "company_cluster67_counts\n",
            "0\n",
            "company_cluster68_counts\n",
            "0\n",
            "company_cluster69_counts\n",
            "0\n",
            "company_cluster70_counts\n",
            "0\n",
            "company_cluster71_counts\n",
            "0\n",
            "company_cluster72_counts\n",
            "0\n",
            "company_cluster73_counts\n",
            "0\n",
            "company_cluster74_counts\n",
            "0\n",
            "company_cluster75_counts\n",
            "0\n",
            "company_cluster76_counts\n",
            "0\n",
            "company_cluster77_counts\n",
            "0\n",
            "company_cluster78_counts\n",
            "0\n",
            "company_cluster79_counts\n",
            "0\n",
            "name_of_department/team_cluster0_counts\n",
            "0\n",
            "name_of_department/team_cluster1_counts\n",
            "0\n",
            "name_of_department/team_cluster2_counts\n",
            "0\n",
            "name_of_department/team_cluster3_counts\n",
            "0\n",
            "name_of_department/team_cluster4_counts\n",
            "0\n",
            "name_of_department/team_cluster5_counts\n",
            "0\n",
            "name_of_department/team_cluster6_counts\n",
            "0\n",
            "name_of_department/team_cluster7_counts\n",
            "0\n",
            "name_of_department/team_cluster8_counts\n",
            "0\n",
            "name_of_department/team_cluster9_counts\n",
            "0\n",
            "name_of_department/team_cluster10_counts\n",
            "0\n",
            "name_of_department/team_cluster11_counts\n",
            "0\n",
            "name_of_department/team_cluster12_counts\n",
            "0\n",
            "name_of_department/team_cluster13_counts\n",
            "0\n",
            "name_of_department/team_cluster14_counts\n",
            "0\n",
            "name_of_department/team_cluster15_counts\n",
            "0\n",
            "name_of_department/team_cluster16_counts\n",
            "0\n",
            "name_of_department/team_cluster17_counts\n",
            "0\n",
            "name_of_department/team_cluster18_counts\n",
            "0\n",
            "name_of_department/team_cluster19_counts\n",
            "0\n",
            "name_of_department/team_cluster20_counts\n",
            "0\n",
            "city_cluster0_counts\n",
            "0\n",
            "city_cluster1_counts\n",
            "0\n",
            "city_cluster2_counts\n",
            "0\n",
            "city_cluster3_counts\n",
            "0\n",
            "city_cluster4_counts\n",
            "0\n",
            "city_cluster5_counts\n",
            "0\n",
            "city_cluster6_counts\n",
            "0\n",
            "city_cluster7_counts\n",
            "0\n",
            "city_cluster8_counts\n",
            "0\n",
            "city_cluster9_counts\n",
            "0\n",
            "city_cluster10_counts\n",
            "0\n",
            "city_cluster11_counts\n",
            "0\n",
            "city_cluster12_counts\n",
            "0\n",
            "city_cluster13_counts\n",
            "0\n",
            "city_cluster14_counts\n",
            "0\n",
            "city_cluster15_counts\n",
            "0\n",
            "city_cluster16_counts\n",
            "0\n",
            "city_cluster17_counts\n",
            "0\n",
            "city_cluster18_counts\n",
            "0\n",
            "city_cluster19_counts\n",
            "0\n",
            "city_cluster20_counts\n",
            "0\n",
            "city_cluster21_counts\n",
            "0\n",
            "city_cluster22_counts\n",
            "0\n",
            "city_cluster23_counts\n",
            "0\n",
            "city_cluster24_counts\n",
            "0\n",
            "city_cluster25_counts\n",
            "0\n",
            "city_cluster26_counts\n",
            "0\n",
            "city_cluster27_counts\n",
            "0\n",
            "city_cluster28_counts\n",
            "0\n",
            "city_cluster29_counts\n",
            "0\n",
            "city_cluster30_counts\n",
            "0\n",
            "city_cluster31_counts\n",
            "0\n",
            "city_cluster32_counts\n",
            "0\n",
            "city_cluster33_counts\n",
            "0\n",
            "city_cluster34_counts\n",
            "0\n",
            "city_cluster35_counts\n",
            "0\n",
            "city_cluster36_counts\n",
            "0\n",
            "city_cluster37_counts\n",
            "0\n",
            "city_cluster38_counts\n",
            "0\n",
            "city_cluster39_counts\n",
            "0\n",
            "city_cluster40_counts\n",
            "0\n",
            "city_cluster41_counts\n",
            "0\n",
            "city_cluster42_counts\n",
            "0\n",
            "city_cluster43_counts\n",
            "0\n",
            "city_cluster44_counts\n",
            "0\n",
            "city_cluster45_counts\n",
            "0\n",
            "city_cluster46_counts\n",
            "0\n",
            "city_cluster47_counts\n",
            "0\n",
            "city_cluster48_counts\n",
            "0\n",
            "city_cluster49_counts\n",
            "0\n",
            "city_cluster50_counts\n",
            "0\n",
            "city_cluster51_counts\n",
            "0\n",
            "city_cluster52_counts\n",
            "0\n",
            "work_arrangement_cluster0_counts\n",
            "1\n",
            "work_arrangement_cluster1_counts\n",
            "0\n",
            "work_arrangement_cluster2_counts\n",
            "0\n",
            "work_arrangement_cluster3_counts\n",
            "0\n",
            "work_arrangement_cluster4_counts\n",
            "0\n",
            "work_arrangement_cluster5_counts\n",
            "0\n",
            "work_arrangement_cluster6_counts\n",
            "0\n",
            "work_arrangement_cluster7_counts\n",
            "0\n",
            "work_arrangement_cluster8_counts\n",
            "0\n",
            "work_arrangement_cluster9_counts\n",
            "0\n",
            "AR\n",
            "0\n",
            "AZ\n",
            "0\n",
            "CA\n",
            "0\n",
            "CO\n",
            "0\n",
            "FL\n",
            "0\n",
            "GA\n",
            "0\n",
            "IA\n",
            "0\n",
            "IL\n",
            "0\n",
            "IN\n",
            "0\n",
            "MA\n",
            "0\n",
            "MD\n",
            "0\n",
            "MI\n",
            "0\n",
            "MO\n",
            "0\n",
            "NC\n",
            "0\n",
            "ND\n",
            "0\n",
            "NJ\n",
            "0\n",
            "NY\n",
            "0\n",
            "OR\n",
            "0\n",
            "PA\n",
            "0\n",
            "TX\n",
            "0\n",
            "UT\n",
            "0\n",
            "VA\n",
            "0\n",
            "WA\n",
            "0\n",
            "WI\n",
            "0\n",
            "USA\n",
            "1\n",
            "United States\n",
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters: {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "Accuracy: 0.5\n"
          ]
        }
      ],
      "source": [
        "#import xgboost as xgb\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "columns_to_drop = common_corpus_columns + singular_corpus_columns + work_arrangement_columns + categorical_label_columns\n",
        "embedded_data_columns = common_corpus_columns + singular_corpus_columns + work_arrangement_columns\n",
        "embedded_data_columns = [f'{col}_vectors' for col in embedded_data_columns]\n",
        "\n",
        "columns_to_drop = columns_to_drop + embedded_data_columns\n",
        "\n",
        "# Make a copy of the dataframe with specified columns dropped\n",
        "df_copy = df.drop(columns=columns_to_drop).copy()\n",
        "df_copy = df_copy.drop(columns=[''])\n",
        "\n",
        "# Iterate over columns and fill NaN values with the mode of each column\n",
        "for col in df_copy.columns:\n",
        "  print(col)\n",
        "  mode_val = df_copy[col].mode()[0]\n",
        "  print(mode_val)  # Get the mode value for the column\n",
        "  df_copy[col].fillna(mode_val, inplace=True)  # Fill NaN values with the mode\n",
        "\n",
        "\n",
        "# Assuming df_encoded is your dataframe with one-hot encoded features and target variable\n",
        "# Split the data into features (X) and target variable (y)\n",
        "y = df_copy['rating']  # Target variable\n",
        "X = df_copy.drop(columns=['rating'])  # Features\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=68)\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4],     # Minimum number of samples required to be at a leaf node\n",
        "    'max_features': ['auto', 'sqrt', 'log2']  # Number of features to consider when looking for the best split\n",
        "}\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Test the classifier on the testing data using the best hyperparameters\n",
        "best_dt_classifier = grid_search.best_estimator_\n",
        "y_pred = best_dt_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5VWpNi7ly4F",
        "outputId": "6ae7856c-69b5-4e08-a30c-9dfb879b261c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.6363636363636364\n"
          ]
        }
      ],
      "source": [
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEF7t_w-nay-"
      },
      "source": [
        "It looks like hyperparameter tuning doesn't get us much in the case of the decision tree. Accuracy seems stuck around .5, with a mean absolute error of no less than .6. Let's see if we can get better performance out of the Random Forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-IfUQLEn52-",
        "outputId": "51a79286-6c53-4ee5-b138-bbeb5abf3e7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "min_salary\n",
            "100.0\n",
            "max_salary\n",
            "200.0\n",
            "rating\n",
            "2\n",
            "common_cluster0_counts\n",
            "0\n",
            "common_cluster1_counts\n",
            "0\n",
            "common_cluster2_counts\n",
            "2\n",
            "common_cluster3_counts\n",
            "0\n",
            "common_cluster4_counts\n",
            "0\n",
            "common_cluster5_counts\n",
            "0\n",
            "common_cluster6_counts\n",
            "0\n",
            "common_cluster7_counts\n",
            "0\n",
            "common_cluster8_counts\n",
            "0\n",
            "common_cluster9_counts\n",
            "0\n",
            "common_cluster10_counts\n",
            "0\n",
            "common_cluster11_counts\n",
            "0\n",
            "common_cluster12_counts\n",
            "0\n",
            "common_cluster13_counts\n",
            "0\n",
            "common_cluster14_counts\n",
            "0\n",
            "common_cluster15_counts\n",
            "0\n",
            "common_cluster16_counts\n",
            "0\n",
            "common_cluster17_counts\n",
            "0\n",
            "common_cluster18_counts\n",
            "0\n",
            "common_cluster19_counts\n",
            "0\n",
            "common_cluster20_counts\n",
            "0\n",
            "common_cluster21_counts\n",
            "0\n",
            "common_cluster22_counts\n",
            "0\n",
            "common_cluster23_counts\n",
            "0\n",
            "common_cluster24_counts\n",
            "1\n",
            "common_cluster25_counts\n",
            "0\n",
            "common_cluster26_counts\n",
            "0\n",
            "common_cluster27_counts\n",
            "0\n",
            "common_cluster28_counts\n",
            "0\n",
            "common_cluster29_counts\n",
            "0\n",
            "common_cluster30_counts\n",
            "0\n",
            "common_cluster31_counts\n",
            "0\n",
            "common_cluster32_counts\n",
            "0\n",
            "common_cluster33_counts\n",
            "0\n",
            "common_cluster34_counts\n",
            "0\n",
            "common_cluster35_counts\n",
            "0\n",
            "common_cluster36_counts\n",
            "0\n",
            "common_cluster37_counts\n",
            "0\n",
            "common_cluster38_counts\n",
            "0\n",
            "common_cluster39_counts\n",
            "0\n",
            "common_cluster40_counts\n",
            "0\n",
            "common_cluster41_counts\n",
            "0\n",
            "common_cluster42_counts\n",
            "0\n",
            "common_cluster43_counts\n",
            "0\n",
            "common_cluster44_counts\n",
            "0\n",
            "common_cluster45_counts\n",
            "0\n",
            "common_cluster46_counts\n",
            "0\n",
            "common_cluster47_counts\n",
            "0\n",
            "common_cluster48_counts\n",
            "0\n",
            "common_cluster49_counts\n",
            "0\n",
            "common_cluster50_counts\n",
            "0\n",
            "common_cluster51_counts\n",
            "0\n",
            "common_cluster52_counts\n",
            "0\n",
            "common_cluster53_counts\n",
            "0\n",
            "common_cluster54_counts\n",
            "0\n",
            "common_cluster55_counts\n",
            "0\n",
            "common_cluster56_counts\n",
            "0\n",
            "common_cluster57_counts\n",
            "0\n",
            "common_cluster58_counts\n",
            "0\n",
            "common_cluster59_counts\n",
            "0\n",
            "common_cluster60_counts\n",
            "0\n",
            "common_cluster61_counts\n",
            "0\n",
            "common_cluster62_counts\n",
            "0\n",
            "common_cluster63_counts\n",
            "0\n",
            "common_cluster64_counts\n",
            "0\n",
            "common_cluster65_counts\n",
            "0\n",
            "common_cluster66_counts\n",
            "0\n",
            "common_cluster67_counts\n",
            "0\n",
            "common_cluster68_counts\n",
            "0\n",
            "common_cluster69_counts\n",
            "0\n",
            "common_cluster70_counts\n",
            "0\n",
            "common_cluster71_counts\n",
            "0\n",
            "common_cluster72_counts\n",
            "0\n",
            "common_cluster73_counts\n",
            "0\n",
            "common_cluster74_counts\n",
            "0\n",
            "common_cluster75_counts\n",
            "0\n",
            "common_cluster76_counts\n",
            "0\n",
            "common_cluster77_counts\n",
            "0\n",
            "common_cluster78_counts\n",
            "0\n",
            "common_cluster79_counts\n",
            "0\n",
            "common_cluster80_counts\n",
            "0\n",
            "common_cluster81_counts\n",
            "0\n",
            "common_cluster82_counts\n",
            "0\n",
            "common_cluster83_counts\n",
            "0\n",
            "common_cluster84_counts\n",
            "0\n",
            "common_cluster85_counts\n",
            "0\n",
            "common_cluster86_counts\n",
            "0\n",
            "common_cluster87_counts\n",
            "0\n",
            "common_cluster88_counts\n",
            "0\n",
            "common_cluster89_counts\n",
            "0\n",
            "common_cluster90_counts\n",
            "0\n",
            "common_cluster91_counts\n",
            "0\n",
            "common_cluster92_counts\n",
            "0\n",
            "common_cluster93_counts\n",
            "0\n",
            "common_cluster94_counts\n",
            "0\n",
            "common_cluster95_counts\n",
            "0\n",
            "common_cluster96_counts\n",
            "0\n",
            "common_cluster97_counts\n",
            "0\n",
            "common_cluster98_counts\n",
            "0\n",
            "common_cluster99_counts\n",
            "0\n",
            "common_cluster100_counts\n",
            "0\n",
            "common_cluster101_counts\n",
            "0\n",
            "common_cluster102_counts\n",
            "0\n",
            "common_cluster103_counts\n",
            "0\n",
            "common_cluster104_counts\n",
            "0\n",
            "common_cluster105_counts\n",
            "0\n",
            "common_cluster106_counts\n",
            "0\n",
            "common_cluster107_counts\n",
            "0\n",
            "common_cluster108_counts\n",
            "0\n",
            "common_cluster109_counts\n",
            "0\n",
            "common_cluster110_counts\n",
            "0\n",
            "common_cluster111_counts\n",
            "0\n",
            "common_cluster112_counts\n",
            "0\n",
            "common_cluster113_counts\n",
            "0\n",
            "common_cluster114_counts\n",
            "0\n",
            "common_cluster115_counts\n",
            "0\n",
            "common_cluster116_counts\n",
            "0\n",
            "common_cluster117_counts\n",
            "0\n",
            "common_cluster118_counts\n",
            "0\n",
            "common_cluster119_counts\n",
            "0\n",
            "common_cluster120_counts\n",
            "0\n",
            "common_cluster121_counts\n",
            "0\n",
            "common_cluster122_counts\n",
            "0\n",
            "common_cluster123_counts\n",
            "0\n",
            "common_cluster124_counts\n",
            "0\n",
            "common_cluster125_counts\n",
            "0\n",
            "common_cluster126_counts\n",
            "0\n",
            "common_cluster127_counts\n",
            "0\n",
            "common_cluster128_counts\n",
            "0\n",
            "common_cluster129_counts\n",
            "0\n",
            "common_cluster130_counts\n",
            "0\n",
            "common_cluster131_counts\n",
            "0\n",
            "common_cluster132_counts\n",
            "0\n",
            "common_cluster133_counts\n",
            "0\n",
            "common_cluster134_counts\n",
            "0\n",
            "common_cluster135_counts\n",
            "0\n",
            "common_cluster136_counts\n",
            "0\n",
            "common_cluster137_counts\n",
            "0\n",
            "common_cluster138_counts\n",
            "0\n",
            "common_cluster139_counts\n",
            "0\n",
            "common_cluster140_counts\n",
            "0\n",
            "common_cluster141_counts\n",
            "0\n",
            "common_cluster142_counts\n",
            "0\n",
            "common_cluster143_counts\n",
            "0\n",
            "common_cluster144_counts\n",
            "0\n",
            "common_cluster145_counts\n",
            "0\n",
            "common_cluster146_counts\n",
            "0\n",
            "common_cluster147_counts\n",
            "0\n",
            "common_cluster148_counts\n",
            "0\n",
            "common_cluster149_counts\n",
            "0\n",
            "common_cluster150_counts\n",
            "0\n",
            "common_cluster151_counts\n",
            "0\n",
            "common_cluster152_counts\n",
            "0\n",
            "common_cluster153_counts\n",
            "0\n",
            "common_cluster154_counts\n",
            "0\n",
            "common_cluster155_counts\n",
            "0\n",
            "common_cluster156_counts\n",
            "0\n",
            "common_cluster157_counts\n",
            "0\n",
            "common_cluster158_counts\n",
            "0\n",
            "common_cluster159_counts\n",
            "0\n",
            "common_cluster160_counts\n",
            "0\n",
            "common_cluster161_counts\n",
            "0\n",
            "common_cluster162_counts\n",
            "0\n",
            "common_cluster163_counts\n",
            "0\n",
            "common_cluster164_counts\n",
            "0\n",
            "common_cluster165_counts\n",
            "0\n",
            "common_cluster166_counts\n",
            "0\n",
            "common_cluster167_counts\n",
            "0\n",
            "common_cluster168_counts\n",
            "0\n",
            "common_cluster169_counts\n",
            "0\n",
            "common_cluster170_counts\n",
            "0\n",
            "common_cluster171_counts\n",
            "0\n",
            "common_cluster172_counts\n",
            "0\n",
            "common_cluster173_counts\n",
            "0\n",
            "common_cluster174_counts\n",
            "0\n",
            "common_cluster175_counts\n",
            "0\n",
            "common_cluster176_counts\n",
            "0\n",
            "common_cluster177_counts\n",
            "0\n",
            "common_cluster178_counts\n",
            "0\n",
            "common_cluster179_counts\n",
            "0\n",
            "common_cluster180_counts\n",
            "0\n",
            "common_cluster181_counts\n",
            "0\n",
            "common_cluster182_counts\n",
            "0\n",
            "common_cluster183_counts\n",
            "0\n",
            "common_cluster184_counts\n",
            "0\n",
            "common_cluster185_counts\n",
            "0\n",
            "common_cluster186_counts\n",
            "0\n",
            "common_cluster187_counts\n",
            "0\n",
            "common_cluster188_counts\n",
            "0\n",
            "common_cluster189_counts\n",
            "0\n",
            "common_cluster190_counts\n",
            "0\n",
            "common_cluster191_counts\n",
            "0\n",
            "common_cluster192_counts\n",
            "0\n",
            "common_cluster193_counts\n",
            "0\n",
            "common_cluster194_counts\n",
            "0\n",
            "common_cluster195_counts\n",
            "0\n",
            "common_cluster196_counts\n",
            "0\n",
            "common_cluster197_counts\n",
            "0\n",
            "common_cluster198_counts\n",
            "0\n",
            "common_cluster199_counts\n",
            "0\n",
            "common_cluster200_counts\n",
            "0\n",
            "common_cluster201_counts\n",
            "0\n",
            "common_cluster202_counts\n",
            "0\n",
            "common_cluster203_counts\n",
            "0\n",
            "common_cluster204_counts\n",
            "0\n",
            "common_cluster205_counts\n",
            "0\n",
            "common_cluster206_counts\n",
            "0\n",
            "common_cluster207_counts\n",
            "0\n",
            "common_cluster208_counts\n",
            "0\n",
            "common_cluster209_counts\n",
            "0\n",
            "common_cluster210_counts\n",
            "0\n",
            "common_cluster211_counts\n",
            "0\n",
            "common_cluster212_counts\n",
            "0\n",
            "common_cluster213_counts\n",
            "0\n",
            "common_cluster214_counts\n",
            "0\n",
            "common_cluster215_counts\n",
            "0\n",
            "common_cluster216_counts\n",
            "0\n",
            "common_cluster217_counts\n",
            "0\n",
            "common_cluster218_counts\n",
            "0\n",
            "common_cluster219_counts\n",
            "0\n",
            "common_cluster220_counts\n",
            "0\n",
            "common_cluster221_counts\n",
            "0\n",
            "common_cluster222_counts\n",
            "0\n",
            "common_cluster223_counts\n",
            "0\n",
            "common_cluster224_counts\n",
            "0\n",
            "common_cluster225_counts\n",
            "0\n",
            "common_cluster226_counts\n",
            "0\n",
            "common_cluster227_counts\n",
            "0\n",
            "common_cluster228_counts\n",
            "0\n",
            "common_cluster229_counts\n",
            "0\n",
            "common_cluster230_counts\n",
            "0\n",
            "common_cluster231_counts\n",
            "0\n",
            "common_cluster232_counts\n",
            "0\n",
            "common_cluster233_counts\n",
            "0\n",
            "common_cluster234_counts\n",
            "0\n",
            "common_cluster235_counts\n",
            "0\n",
            "common_cluster236_counts\n",
            "0\n",
            "common_cluster237_counts\n",
            "0\n",
            "common_cluster238_counts\n",
            "0\n",
            "common_cluster239_counts\n",
            "0\n",
            "common_cluster240_counts\n",
            "0\n",
            "common_cluster241_counts\n",
            "0\n",
            "common_cluster242_counts\n",
            "0\n",
            "common_cluster243_counts\n",
            "0\n",
            "common_cluster244_counts\n",
            "0\n",
            "common_cluster245_counts\n",
            "0\n",
            "common_cluster246_counts\n",
            "0\n",
            "common_cluster247_counts\n",
            "0\n",
            "common_cluster248_counts\n",
            "0\n",
            "common_cluster249_counts\n",
            "0\n",
            "common_cluster250_counts\n",
            "0\n",
            "common_cluster251_counts\n",
            "0\n",
            "common_cluster252_counts\n",
            "0\n",
            "common_cluster253_counts\n",
            "0\n",
            "common_cluster254_counts\n",
            "0\n",
            "common_cluster255_counts\n",
            "0\n",
            "common_cluster256_counts\n",
            "0\n",
            "common_cluster257_counts\n",
            "0\n",
            "common_cluster258_counts\n",
            "0\n",
            "common_cluster259_counts\n",
            "0\n",
            "common_cluster260_counts\n",
            "0\n",
            "common_cluster261_counts\n",
            "0\n",
            "common_cluster262_counts\n",
            "0\n",
            "common_cluster263_counts\n",
            "0\n",
            "common_cluster264_counts\n",
            "0\n",
            "common_cluster265_counts\n",
            "0\n",
            "common_cluster266_counts\n",
            "0\n",
            "common_cluster267_counts\n",
            "0\n",
            "common_cluster268_counts\n",
            "0\n",
            "common_cluster269_counts\n",
            "0\n",
            "common_cluster270_counts\n",
            "0\n",
            "common_cluster271_counts\n",
            "0\n",
            "common_cluster272_counts\n",
            "0\n",
            "common_cluster273_counts\n",
            "0\n",
            "common_cluster274_counts\n",
            "0\n",
            "common_cluster275_counts\n",
            "0\n",
            "common_cluster276_counts\n",
            "0\n",
            "common_cluster277_counts\n",
            "0\n",
            "common_cluster278_counts\n",
            "0\n",
            "common_cluster279_counts\n",
            "0\n",
            "common_cluster280_counts\n",
            "0\n",
            "common_cluster281_counts\n",
            "0\n",
            "common_cluster282_counts\n",
            "0\n",
            "common_cluster283_counts\n",
            "0\n",
            "common_cluster284_counts\n",
            "0\n",
            "common_cluster285_counts\n",
            "0\n",
            "common_cluster286_counts\n",
            "0\n",
            "common_cluster287_counts\n",
            "0\n",
            "common_cluster288_counts\n",
            "0\n",
            "common_cluster289_counts\n",
            "0\n",
            "common_cluster290_counts\n",
            "0\n",
            "common_cluster291_counts\n",
            "0\n",
            "common_cluster292_counts\n",
            "0\n",
            "common_cluster293_counts\n",
            "0\n",
            "common_cluster294_counts\n",
            "0\n",
            "common_cluster295_counts\n",
            "0\n",
            "common_cluster296_counts\n",
            "0\n",
            "common_cluster297_counts\n",
            "0\n",
            "common_cluster298_counts\n",
            "0\n",
            "common_cluster299_counts\n",
            "0\n",
            "common_cluster300_counts\n",
            "0\n",
            "common_cluster301_counts\n",
            "0\n",
            "common_cluster302_counts\n",
            "0\n",
            "common_cluster303_counts\n",
            "0\n",
            "common_cluster304_counts\n",
            "0\n",
            "common_cluster305_counts\n",
            "0\n",
            "common_cluster306_counts\n",
            "0\n",
            "common_cluster307_counts\n",
            "0\n",
            "common_cluster308_counts\n",
            "0\n",
            "common_cluster309_counts\n",
            "0\n",
            "common_cluster310_counts\n",
            "0\n",
            "common_cluster311_counts\n",
            "0\n",
            "common_cluster312_counts\n",
            "0\n",
            "common_cluster313_counts\n",
            "0\n",
            "common_cluster314_counts\n",
            "0\n",
            "common_cluster315_counts\n",
            "0\n",
            "common_cluster316_counts\n",
            "0\n",
            "common_cluster317_counts\n",
            "0\n",
            "common_cluster318_counts\n",
            "0\n",
            "common_cluster319_counts\n",
            "0\n",
            "common_cluster320_counts\n",
            "0\n",
            "common_cluster321_counts\n",
            "0\n",
            "common_cluster322_counts\n",
            "0\n",
            "common_cluster323_counts\n",
            "0\n",
            "common_cluster324_counts\n",
            "0\n",
            "common_cluster325_counts\n",
            "0\n",
            "common_cluster326_counts\n",
            "0\n",
            "common_cluster327_counts\n",
            "0\n",
            "common_cluster328_counts\n",
            "0\n",
            "common_cluster329_counts\n",
            "0\n",
            "common_cluster330_counts\n",
            "0\n",
            "common_cluster331_counts\n",
            "0\n",
            "common_cluster332_counts\n",
            "0\n",
            "common_cluster333_counts\n",
            "0\n",
            "common_cluster334_counts\n",
            "0\n",
            "common_cluster335_counts\n",
            "0\n",
            "common_cluster336_counts\n",
            "0\n",
            "common_cluster337_counts\n",
            "0\n",
            "common_cluster338_counts\n",
            "0\n",
            "common_cluster339_counts\n",
            "0\n",
            "common_cluster340_counts\n",
            "0\n",
            "common_cluster341_counts\n",
            "0\n",
            "common_cluster342_counts\n",
            "0\n",
            "common_cluster343_counts\n",
            "0\n",
            "common_cluster344_counts\n",
            "0\n",
            "common_cluster345_counts\n",
            "0\n",
            "common_cluster346_counts\n",
            "0\n",
            "common_cluster347_counts\n",
            "0\n",
            "common_cluster348_counts\n",
            "0\n",
            "common_cluster349_counts\n",
            "0\n",
            "common_cluster350_counts\n",
            "0\n",
            "common_cluster351_counts\n",
            "0\n",
            "common_cluster352_counts\n",
            "0\n",
            "common_cluster353_counts\n",
            "0\n",
            "common_cluster354_counts\n",
            "0\n",
            "common_cluster355_counts\n",
            "0\n",
            "common_cluster356_counts\n",
            "0\n",
            "common_cluster357_counts\n",
            "0\n",
            "common_cluster358_counts\n",
            "0\n",
            "common_cluster359_counts\n",
            "0\n",
            "common_cluster360_counts\n",
            "0\n",
            "common_cluster361_counts\n",
            "0\n",
            "common_cluster362_counts\n",
            "0\n",
            "common_cluster363_counts\n",
            "0\n",
            "common_cluster364_counts\n",
            "0\n",
            "common_cluster365_counts\n",
            "0\n",
            "common_cluster366_counts\n",
            "0\n",
            "common_cluster367_counts\n",
            "0\n",
            "common_cluster368_counts\n",
            "0\n",
            "common_cluster369_counts\n",
            "0\n",
            "common_cluster370_counts\n",
            "0\n",
            "common_cluster371_counts\n",
            "0\n",
            "common_cluster372_counts\n",
            "0\n",
            "common_cluster373_counts\n",
            "0\n",
            "common_cluster374_counts\n",
            "0\n",
            "common_cluster375_counts\n",
            "0\n",
            "common_cluster376_counts\n",
            "0\n",
            "common_cluster377_counts\n",
            "0\n",
            "common_cluster378_counts\n",
            "0\n",
            "common_cluster379_counts\n",
            "0\n",
            "common_cluster380_counts\n",
            "0\n",
            "common_cluster381_counts\n",
            "0\n",
            "common_cluster382_counts\n",
            "0\n",
            "common_cluster383_counts\n",
            "0\n",
            "common_cluster384_counts\n",
            "0\n",
            "common_cluster385_counts\n",
            "0\n",
            "common_cluster386_counts\n",
            "0\n",
            "common_cluster387_counts\n",
            "0\n",
            "common_cluster388_counts\n",
            "0\n",
            "common_cluster389_counts\n",
            "0\n",
            "common_cluster390_counts\n",
            "0\n",
            "common_cluster391_counts\n",
            "0\n",
            "common_cluster392_counts\n",
            "0\n",
            "common_cluster393_counts\n",
            "0\n",
            "common_cluster394_counts\n",
            "0\n",
            "common_cluster395_counts\n",
            "0\n",
            "common_cluster396_counts\n",
            "0\n",
            "common_cluster397_counts\n",
            "0\n",
            "common_cluster398_counts\n",
            "0\n",
            "common_cluster399_counts\n",
            "0\n",
            "common_cluster400_counts\n",
            "0\n",
            "common_cluster401_counts\n",
            "0\n",
            "common_cluster402_counts\n",
            "0\n",
            "common_cluster403_counts\n",
            "0\n",
            "common_cluster404_counts\n",
            "0\n",
            "common_cluster405_counts\n",
            "0\n",
            "common_cluster406_counts\n",
            "0\n",
            "common_cluster407_counts\n",
            "0\n",
            "common_cluster408_counts\n",
            "0\n",
            "common_cluster409_counts\n",
            "0\n",
            "common_cluster410_counts\n",
            "0\n",
            "common_cluster411_counts\n",
            "0\n",
            "common_cluster412_counts\n",
            "0\n",
            "common_cluster413_counts\n",
            "0\n",
            "common_cluster414_counts\n",
            "0\n",
            "common_cluster415_counts\n",
            "0\n",
            "common_cluster416_counts\n",
            "0\n",
            "common_cluster417_counts\n",
            "0\n",
            "common_cluster418_counts\n",
            "0\n",
            "common_cluster419_counts\n",
            "0\n",
            "common_cluster420_counts\n",
            "0\n",
            "common_cluster421_counts\n",
            "0\n",
            "common_cluster422_counts\n",
            "0\n",
            "common_cluster423_counts\n",
            "0\n",
            "common_cluster424_counts\n",
            "0\n",
            "common_cluster425_counts\n",
            "0\n",
            "common_cluster426_counts\n",
            "0\n",
            "common_cluster427_counts\n",
            "0\n",
            "common_cluster428_counts\n",
            "0\n",
            "common_cluster429_counts\n",
            "0\n",
            "common_cluster430_counts\n",
            "0\n",
            "common_cluster431_counts\n",
            "0\n",
            "common_cluster432_counts\n",
            "0\n",
            "common_cluster433_counts\n",
            "0\n",
            "common_cluster434_counts\n",
            "0\n",
            "common_cluster435_counts\n",
            "0\n",
            "common_cluster436_counts\n",
            "0\n",
            "common_cluster437_counts\n",
            "0\n",
            "common_cluster438_counts\n",
            "0\n",
            "common_cluster439_counts\n",
            "0\n",
            "common_cluster440_counts\n",
            "0\n",
            "common_cluster441_counts\n",
            "0\n",
            "common_cluster442_counts\n",
            "0\n",
            "common_cluster443_counts\n",
            "0\n",
            "common_cluster444_counts\n",
            "0\n",
            "common_cluster445_counts\n",
            "0\n",
            "common_cluster446_counts\n",
            "0\n",
            "common_cluster447_counts\n",
            "0\n",
            "common_cluster448_counts\n",
            "0\n",
            "common_cluster449_counts\n",
            "0\n",
            "common_cluster450_counts\n",
            "0\n",
            "common_cluster451_counts\n",
            "0\n",
            "common_cluster452_counts\n",
            "0\n",
            "common_cluster453_counts\n",
            "0\n",
            "common_cluster454_counts\n",
            "0\n",
            "common_cluster455_counts\n",
            "0\n",
            "common_cluster456_counts\n",
            "0\n",
            "common_cluster457_counts\n",
            "0\n",
            "common_cluster458_counts\n",
            "0\n",
            "common_cluster459_counts\n",
            "0\n",
            "common_cluster460_counts\n",
            "0\n",
            "common_cluster461_counts\n",
            "0\n",
            "common_cluster462_counts\n",
            "0\n",
            "common_cluster463_counts\n",
            "0\n",
            "common_cluster464_counts\n",
            "0\n",
            "common_cluster465_counts\n",
            "0\n",
            "common_cluster466_counts\n",
            "0\n",
            "common_cluster467_counts\n",
            "0\n",
            "common_cluster468_counts\n",
            "0\n",
            "common_cluster469_counts\n",
            "0\n",
            "common_cluster470_counts\n",
            "0\n",
            "common_cluster471_counts\n",
            "0\n",
            "common_cluster472_counts\n",
            "0\n",
            "common_cluster473_counts\n",
            "0\n",
            "common_cluster474_counts\n",
            "0\n",
            "common_cluster475_counts\n",
            "0\n",
            "common_cluster476_counts\n",
            "0\n",
            "common_cluster477_counts\n",
            "0\n",
            "common_cluster478_counts\n",
            "0\n",
            "common_cluster479_counts\n",
            "0\n",
            "common_cluster480_counts\n",
            "0\n",
            "common_cluster481_counts\n",
            "0\n",
            "common_cluster482_counts\n",
            "0\n",
            "common_cluster483_counts\n",
            "0\n",
            "common_cluster484_counts\n",
            "0\n",
            "common_cluster485_counts\n",
            "0\n",
            "common_cluster486_counts\n",
            "0\n",
            "common_cluster487_counts\n",
            "0\n",
            "common_cluster488_counts\n",
            "0\n",
            "common_cluster489_counts\n",
            "0\n",
            "common_cluster490_counts\n",
            "0\n",
            "common_cluster491_counts\n",
            "0\n",
            "common_cluster492_counts\n",
            "0\n",
            "common_cluster493_counts\n",
            "0\n",
            "common_cluster494_counts\n",
            "0\n",
            "common_cluster495_counts\n",
            "0\n",
            "common_cluster496_counts\n",
            "0\n",
            "common_cluster497_counts\n",
            "0\n",
            "common_cluster498_counts\n",
            "0\n",
            "common_cluster499_counts\n",
            "0\n",
            "company_cluster0_counts\n",
            "0\n",
            "company_cluster1_counts\n",
            "0\n",
            "company_cluster2_counts\n",
            "0\n",
            "company_cluster3_counts\n",
            "0\n",
            "company_cluster4_counts\n",
            "0\n",
            "company_cluster5_counts\n",
            "0\n",
            "company_cluster6_counts\n",
            "0\n",
            "company_cluster7_counts\n",
            "0\n",
            "company_cluster8_counts\n",
            "0\n",
            "company_cluster9_counts\n",
            "0\n",
            "company_cluster10_counts\n",
            "0\n",
            "company_cluster11_counts\n",
            "0\n",
            "company_cluster12_counts\n",
            "0\n",
            "company_cluster13_counts\n",
            "0\n",
            "company_cluster14_counts\n",
            "0\n",
            "company_cluster15_counts\n",
            "0\n",
            "company_cluster16_counts\n",
            "0\n",
            "company_cluster17_counts\n",
            "0\n",
            "company_cluster18_counts\n",
            "0\n",
            "company_cluster19_counts\n",
            "0\n",
            "company_cluster20_counts\n",
            "0\n",
            "company_cluster21_counts\n",
            "0\n",
            "company_cluster22_counts\n",
            "0\n",
            "company_cluster23_counts\n",
            "0\n",
            "company_cluster24_counts\n",
            "0\n",
            "company_cluster25_counts\n",
            "0\n",
            "company_cluster26_counts\n",
            "0\n",
            "company_cluster27_counts\n",
            "0\n",
            "company_cluster28_counts\n",
            "0\n",
            "company_cluster29_counts\n",
            "0\n",
            "company_cluster30_counts\n",
            "0\n",
            "company_cluster31_counts\n",
            "0\n",
            "company_cluster32_counts\n",
            "0\n",
            "company_cluster33_counts\n",
            "0\n",
            "company_cluster34_counts\n",
            "0\n",
            "company_cluster35_counts\n",
            "0\n",
            "company_cluster36_counts\n",
            "0\n",
            "company_cluster37_counts\n",
            "0\n",
            "company_cluster38_counts\n",
            "0\n",
            "company_cluster39_counts\n",
            "0\n",
            "company_cluster40_counts\n",
            "0\n",
            "company_cluster41_counts\n",
            "0\n",
            "company_cluster42_counts\n",
            "0\n",
            "company_cluster43_counts\n",
            "0\n",
            "company_cluster44_counts\n",
            "0\n",
            "company_cluster45_counts\n",
            "0\n",
            "company_cluster46_counts\n",
            "0\n",
            "company_cluster47_counts\n",
            "0\n",
            "company_cluster48_counts\n",
            "0\n",
            "company_cluster49_counts\n",
            "0\n",
            "company_cluster50_counts\n",
            "0\n",
            "company_cluster51_counts\n",
            "0\n",
            "company_cluster52_counts\n",
            "0\n",
            "company_cluster53_counts\n",
            "0\n",
            "company_cluster54_counts\n",
            "0\n",
            "company_cluster55_counts\n",
            "0\n",
            "company_cluster56_counts\n",
            "0\n",
            "company_cluster57_counts\n",
            "0\n",
            "company_cluster58_counts\n",
            "0\n",
            "company_cluster59_counts\n",
            "0\n",
            "company_cluster60_counts\n",
            "0\n",
            "company_cluster61_counts\n",
            "0\n",
            "company_cluster62_counts\n",
            "0\n",
            "company_cluster63_counts\n",
            "0\n",
            "company_cluster64_counts\n",
            "0\n",
            "company_cluster65_counts\n",
            "0\n",
            "company_cluster66_counts\n",
            "0\n",
            "company_cluster67_counts\n",
            "0\n",
            "company_cluster68_counts\n",
            "0\n",
            "company_cluster69_counts\n",
            "0\n",
            "company_cluster70_counts\n",
            "0\n",
            "company_cluster71_counts\n",
            "0\n",
            "company_cluster72_counts\n",
            "0\n",
            "company_cluster73_counts\n",
            "0\n",
            "company_cluster74_counts\n",
            "0\n",
            "company_cluster75_counts\n",
            "0\n",
            "company_cluster76_counts\n",
            "0\n",
            "company_cluster77_counts\n",
            "0\n",
            "company_cluster78_counts\n",
            "0\n",
            "company_cluster79_counts\n",
            "0\n",
            "name_of_department/team_cluster0_counts\n",
            "0\n",
            "name_of_department/team_cluster1_counts\n",
            "0\n",
            "name_of_department/team_cluster2_counts\n",
            "0\n",
            "name_of_department/team_cluster3_counts\n",
            "0\n",
            "name_of_department/team_cluster4_counts\n",
            "0\n",
            "name_of_department/team_cluster5_counts\n",
            "0\n",
            "name_of_department/team_cluster6_counts\n",
            "0\n",
            "name_of_department/team_cluster7_counts\n",
            "0\n",
            "name_of_department/team_cluster8_counts\n",
            "0\n",
            "name_of_department/team_cluster9_counts\n",
            "0\n",
            "name_of_department/team_cluster10_counts\n",
            "0\n",
            "name_of_department/team_cluster11_counts\n",
            "0\n",
            "name_of_department/team_cluster12_counts\n",
            "0\n",
            "name_of_department/team_cluster13_counts\n",
            "0\n",
            "name_of_department/team_cluster14_counts\n",
            "0\n",
            "name_of_department/team_cluster15_counts\n",
            "0\n",
            "name_of_department/team_cluster16_counts\n",
            "0\n",
            "name_of_department/team_cluster17_counts\n",
            "0\n",
            "name_of_department/team_cluster18_counts\n",
            "0\n",
            "name_of_department/team_cluster19_counts\n",
            "0\n",
            "name_of_department/team_cluster20_counts\n",
            "0\n",
            "city_cluster0_counts\n",
            "0\n",
            "city_cluster1_counts\n",
            "0\n",
            "city_cluster2_counts\n",
            "0\n",
            "city_cluster3_counts\n",
            "0\n",
            "city_cluster4_counts\n",
            "0\n",
            "city_cluster5_counts\n",
            "0\n",
            "city_cluster6_counts\n",
            "0\n",
            "city_cluster7_counts\n",
            "0\n",
            "city_cluster8_counts\n",
            "0\n",
            "city_cluster9_counts\n",
            "0\n",
            "city_cluster10_counts\n",
            "0\n",
            "city_cluster11_counts\n",
            "0\n",
            "city_cluster12_counts\n",
            "0\n",
            "city_cluster13_counts\n",
            "0\n",
            "city_cluster14_counts\n",
            "0\n",
            "city_cluster15_counts\n",
            "0\n",
            "city_cluster16_counts\n",
            "0\n",
            "city_cluster17_counts\n",
            "0\n",
            "city_cluster18_counts\n",
            "0\n",
            "city_cluster19_counts\n",
            "0\n",
            "city_cluster20_counts\n",
            "0\n",
            "city_cluster21_counts\n",
            "0\n",
            "city_cluster22_counts\n",
            "0\n",
            "city_cluster23_counts\n",
            "0\n",
            "city_cluster24_counts\n",
            "0\n",
            "city_cluster25_counts\n",
            "0\n",
            "city_cluster26_counts\n",
            "0\n",
            "city_cluster27_counts\n",
            "0\n",
            "city_cluster28_counts\n",
            "0\n",
            "city_cluster29_counts\n",
            "0\n",
            "city_cluster30_counts\n",
            "0\n",
            "city_cluster31_counts\n",
            "0\n",
            "city_cluster32_counts\n",
            "0\n",
            "city_cluster33_counts\n",
            "0\n",
            "city_cluster34_counts\n",
            "0\n",
            "city_cluster35_counts\n",
            "0\n",
            "city_cluster36_counts\n",
            "0\n",
            "city_cluster37_counts\n",
            "0\n",
            "city_cluster38_counts\n",
            "0\n",
            "city_cluster39_counts\n",
            "0\n",
            "city_cluster40_counts\n",
            "0\n",
            "city_cluster41_counts\n",
            "0\n",
            "city_cluster42_counts\n",
            "0\n",
            "city_cluster43_counts\n",
            "0\n",
            "city_cluster44_counts\n",
            "0\n",
            "city_cluster45_counts\n",
            "0\n",
            "city_cluster46_counts\n",
            "0\n",
            "city_cluster47_counts\n",
            "0\n",
            "city_cluster48_counts\n",
            "0\n",
            "city_cluster49_counts\n",
            "0\n",
            "city_cluster50_counts\n",
            "0\n",
            "city_cluster51_counts\n",
            "0\n",
            "city_cluster52_counts\n",
            "0\n",
            "work_arrangement_cluster0_counts\n",
            "1\n",
            "work_arrangement_cluster1_counts\n",
            "0\n",
            "work_arrangement_cluster2_counts\n",
            "0\n",
            "work_arrangement_cluster3_counts\n",
            "0\n",
            "work_arrangement_cluster4_counts\n",
            "0\n",
            "work_arrangement_cluster5_counts\n",
            "0\n",
            "work_arrangement_cluster6_counts\n",
            "0\n",
            "work_arrangement_cluster7_counts\n",
            "0\n",
            "work_arrangement_cluster8_counts\n",
            "0\n",
            "work_arrangement_cluster9_counts\n",
            "0\n",
            "AR\n",
            "0\n",
            "AZ\n",
            "0\n",
            "CA\n",
            "0\n",
            "CO\n",
            "0\n",
            "FL\n",
            "0\n",
            "GA\n",
            "0\n",
            "IA\n",
            "0\n",
            "IL\n",
            "0\n",
            "IN\n",
            "0\n",
            "MA\n",
            "0\n",
            "MD\n",
            "0\n",
            "MI\n",
            "0\n",
            "MO\n",
            "0\n",
            "NC\n",
            "0\n",
            "ND\n",
            "0\n",
            "NJ\n",
            "0\n",
            "NY\n",
            "0\n",
            "OR\n",
            "0\n",
            "PA\n",
            "0\n",
            "TX\n",
            "0\n",
            "UT\n",
            "0\n",
            "VA\n",
            "0\n",
            "WA\n",
            "0\n",
            "WI\n",
            "0\n",
            "USA\n",
            "1\n",
            "United States\n",
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters: {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Accuracy: 0.5909090909090909\n"
          ]
        }
      ],
      "source": [
        "#import xgboost as xgb\n",
        "#from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "columns_to_drop = common_corpus_columns + singular_corpus_columns + work_arrangement_columns + categorical_label_columns\n",
        "embedded_data_columns = common_corpus_columns + singular_corpus_columns + work_arrangement_columns\n",
        "embedded_data_columns = [f'{col}_vectors' for col in embedded_data_columns]\n",
        "\n",
        "columns_to_drop = columns_to_drop + embedded_data_columns\n",
        "\n",
        "# Make a copy of the dataframe with specified columns dropped\n",
        "df_copy = df.drop(columns=columns_to_drop).copy()\n",
        "df_copy = df_copy.drop(columns=[''])\n",
        "\n",
        "# Iterate over columns and fill NaN values with the mode of each column\n",
        "for col in df_copy.columns:\n",
        "  print(col)\n",
        "  mode_val = df_copy[col].mode()[0]\n",
        "  print(mode_val)  # Get the mode value for the column\n",
        "  df_copy[col].fillna(mode_val, inplace=True)  # Fill NaN values with the mode\n",
        "\n",
        "\n",
        "# Assuming df_encoded is your dataframe with one-hot encoded features and target variable\n",
        "# Split the data into features (X) and target variable (y)\n",
        "y = df_copy['rating']  # Target variable\n",
        "X = df_copy.drop(columns=['rating'])  # Features\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=68)\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],        # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20],             # Maximum depth of the trees\n",
        "    'min_samples_split': [2, 5, 10],         # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4],           # Minimum number of samples required to be at a leaf node\n",
        "    'max_features': ['auto', 'sqrt', 'log2'] # Number of features to consider when looking for the best split\n",
        "}\n",
        "\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Test the classifier on the testing data using the best hyperparameters\n",
        "best_rf_classifier = grid_search.best_estimator_\n",
        "y_pred = best_rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJquT35Wrq-T"
      },
      "source": [
        "Excellent, so the best accuracy with the random forest is .59 using grid hyperparemeter search. Note that the search took 8 mins. This makes sense if the upper bound for accuracy is around that of the first decision tree we tried which gave an accuracy of .59 and MAE of .63. What is the MAE for this best random forest model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSK6Dhm0sKIY",
        "outputId": "c8d9e7c0-c361-4a7c-9a64-a946d0637c52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.5454545454545454\n"
          ]
        }
      ],
      "source": [
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEafylHnsOFk"
      },
      "source": [
        "OK, so we have found our most accurate model so far to be a random forest model with the following hyperparameters and accuracy:\n",
        "\n",
        "Best Hyperparameters: {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
        "Accuracy: 0.5909090909090909\n",
        "Mean Absolute Error: 0.5454545454545454"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCsWzqODsxh1"
      },
      "source": [
        "We will now try a grid search with XGBoost. This could take a while. So far it has taken 2 hrs and 42 min and it's still going."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXD_qvjNsvKZ",
        "outputId": "b1173227-8a3d-4b33-c013-69951b3b3f13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 100, 'subsample': 1.0}\n",
            "Accuracy: 0.5\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "#from sklearn.tree import DecisionTreeClassifier\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "columns_to_drop = common_corpus_columns + singular_corpus_columns + work_arrangement_columns + categorical_label_columns\n",
        "embedded_data_columns = common_corpus_columns + singular_corpus_columns + work_arrangement_columns\n",
        "embedded_data_columns = [f'{col}_vectors' for col in embedded_data_columns]\n",
        "\n",
        "columns_to_drop = columns_to_drop + embedded_data_columns\n",
        "\n",
        "# Make a copy of the dataframe with specified columns dropped\n",
        "df_copy = df.drop(columns=columns_to_drop).copy()\n",
        "df_copy = df_copy.drop(columns=[''])\n",
        "\n",
        "# Iterate over columns and fill NaN values with the mode of each column\n",
        "for col in df_copy.columns:\n",
        "  mode_val = df_copy[col].mode()[0]\n",
        "  df_copy[col].fillna(mode_val, inplace=True)  # Fill NaN values with the mode\n",
        "\n",
        "\n",
        "# Assuming df_encoded is your dataframe with one-hot encoded features and target variable\n",
        "# Split the data into features (X) and target variable (y)\n",
        "y = df_copy['rating']  # Target variable\n",
        "X = df_copy.drop(columns=['rating'])  # Features\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=68)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5],\n",
        "    'min_child_weight': [1, 5, 10],\n",
        "    'subsample': [0.5, 1.0],\n",
        "    'colsample_bytree': [0.5, 1.0],\n",
        "    'reg_lambda': [1, 10, 100],\n",
        "    'reg_alpha': [0, 1, 10]\n",
        "}\n",
        "\n",
        "# Initialize XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Test the classifier on the testing data using the best hyperparameters\n",
        "best_rf_classifier = grid_search.best_estimator_\n",
        "y_pred = best_rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j22Zc6g0UCBb",
        "outputId": "168b91fa-5391-4b0b-b971-3d7900c18a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.5909090909090909\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy7BGBAzUNpg"
      },
      "source": [
        "We see that our best XGBoost model had an accuracy of .5 and MAE of .59. Thus we will assume for now that the random forest is the best model choice, but we have yet to explore models that are not decision tree-based."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFU8tJ2QFBsp"
      },
      "source": [
        "We want to do more model exploration, so we will try a Support Vector Machine Algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGINEWUfMxTN",
        "outputId": "73535be7-c357-4d4e-ed78-d2dad810fcc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5454545454545454\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "columns_to_drop = common_corpus_columns + singular_corpus_columns + work_arrangement_columns + categorical_label_columns\n",
        "embedded_data_columns = common_corpus_columns + singular_corpus_columns + work_arrangement_columns\n",
        "embedded_data_columns = [f'{col}_vectors' for col in embedded_data_columns]\n",
        "\n",
        "columns_to_drop = columns_to_drop + embedded_data_columns\n",
        "\n",
        "# Make a copy of the dataframe with specified columns dropped\n",
        "df_copy = df.drop(columns=columns_to_drop).copy()\n",
        "df_copy = df_copy.drop(columns=[''])\n",
        "\n",
        "# Iterate over columns and fill NaN values with the mode of each column\n",
        "for col in df_copy.columns:\n",
        "  mode_val = df_copy[col].mode()[0]\n",
        "  df_copy[col].fillna(mode_val, inplace=True)  # Fill NaN values with the mode\n",
        "\n",
        "\n",
        "# Assuming df_encoded is your dataframe with one-hot encoded features and target variable\n",
        "# Split the data into features (X) and target variable (y)\n",
        "y = df_copy['rating']  # Target variable\n",
        "X = df_copy.drop(columns=['rating'])  # Features\n",
        "\n",
        "# Step 2: Split the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 4: Initialize and Train the SVM Classifier\n",
        "svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale')  # Example hyperparameters\n",
        "svm_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 5: Evaluate the Classifier\n",
        "accuracy = svm_classifier.score(X_test_scaled, y_test)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "6aHA81-cOEnq",
        "outputId": "85d208af-73c2-4d52-b58b-b54c306e73ce"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'y_pred' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-be2e426cd3b0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean Absolute Error:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_BgO1bbOWWy"
      },
      "source": [
        "Turns out there isn't an easy way to calculate mean absolute error of an SVM model, so we will try a basic regression model and see how much error there is for that model.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf3sLSMtOuyS",
        "outputId": "d21bee89-c17a-483d-c385-f4ff30b82e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.4504494974568123\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing data\n",
        "# Train a regression model instead of SVM classifier\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regression_model.predict(X_test)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDF8fpi_O_QF"
      },
      "source": [
        "So the regression model gives the best mean absolute error of any model! In order to measure accuracy we would need it to discretize it's output space to 0, 1, 2, or 3. We can achieve this by rounding all the predictions made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_kxZUvtPtu4",
        "outputId": "712c25f4-fe9d-4275-8de3-a482544a5032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6818181818181818\n"
          ]
        }
      ],
      "source": [
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFjF8afOQGYg"
      },
      "source": [
        "Fascinating! We achieved a notably better accuracy using the linear regression model with predictions rounding as well as a notably lower mean absolute error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb-fAfnwQncN",
        "outputId": "5474aa98-f396-41b3-eb64-a36b3219e1fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5454545454545454\n",
            "mae: 0.5\n",
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
        "\n",
        "columns_to_drop = common_corpus_columns + singular_corpus_columns + work_arrangement_columns + categorical_label_columns\n",
        "embedded_data_columns = common_corpus_columns + singular_corpus_columns + work_arrangement_columns\n",
        "embedded_data_columns = [f'{col}_vectors' for col in embedded_data_columns]\n",
        "\n",
        "columns_to_drop = columns_to_drop + embedded_data_columns\n",
        "\n",
        "# Make a copy of the dataframe with specified columns dropped\n",
        "df_copy = df.drop(columns=columns_to_drop).copy()\n",
        "df_copy = df_copy.drop(columns=[''])\n",
        "\n",
        "# Iterate over columns and fill NaN values with the mode of each column\n",
        "for col in df_copy.columns:\n",
        "  mode_val = df_copy[col].mode()[0]\n",
        "  df_copy[col].fillna(mode_val, inplace=True)  # Fill NaN values with the mode\n",
        "\n",
        "\n",
        "# Assuming df_encoded is your dataframe with one-hot encoded features and target variable\n",
        "# Split the data into features (X) and target variable (y)\n",
        "y = df_copy['rating']  # Target variable\n",
        "X = df_copy.drop(columns=['rating'])  # Features\n",
        "\n",
        "# Assuming X and y are your feature matrix and target variable respectively\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(max_depth=None, max_features='auto', min_samples_leaf=1, min_samples_split=5, n_estimators=300, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mae:\", mae)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFTLRDQ3UbuA"
      },
      "source": [
        "So maybe a model that treats our ratings as continuous variables for its predictions is the way to go after all feature engineering is complete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma4O7lfdUs70"
      },
      "source": [
        "If it wasn't already clear from how I've been going about, my general plan is to work from the results backward. Meaning I will try everything from raw data to model fine tuning and evaluation to try to maximize this predicted accuracy number which will hopefully in turn be associated with a nearly minimized MAE. But I am starting with the model fine tuning and evaluation to see what the best possible performance is I can get with what model on this preliminary fixed data set of 107 job postings. For now I keep the feature representation of my data fixed as well and just focus on model exploration. Then I will take a step backward and revisit/revamp/improve the feature engineering phase performance-wise in terms of adding accuracy to the predictions and decreasing computational time/cost of my feature engineering process. After I have evaluated the best scheme for feature engineering, I will take a step back and look at exploring the initial data set more deeply, evaluating a blind test on myself to reproduce the ratings I made for a subset of the initial 107 job postings I collected. I will look at my accuracy there. I am expecting I will be around 90-95%. I will possibly obtain more data to make the dataframe larger since the downstream feature engineering will hoepfully have been improved and should be able to take the computational toll of more rows since ideally there will be fewer columns. Then I will see if I can ask any humans to perform classification on a test set of job postings based on a training set of examples. I would like to evaluate their performance. For now I would like to do a little EDA on the big dataframe we have.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF_3SIiLXH6v",
        "outputId": "8451ca90-a0d4-4a29-d574-b0114a89ab24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2    50\n",
            "3    26\n",
            "1    18\n",
            "0    13\n",
            "Name: rating, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "ratings_value_counts = df_copy['rating'].value_counts()\n",
        "\n",
        "print(ratings_value_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--Fy8W8CXQXi"
      },
      "source": [
        "We see our dataset is not the most balanced, as nearly half of the data points are 2, about a quarter are 3, about 15% are 1 and 10% are 0.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8NqCTwYXkoR"
      },
      "source": [
        "I am a little concerned that the initial dataset I used isn't a good representative sample of the population of jobs on LinkedIn, but then again, if I used a representative sample from the greater population of LI Jobs, most of them would have 0 or 1 in the rating column and we would like to accurately discern 2s and 3s with our model.\n",
        "\n",
        "So for now, I would say our dataset is not balanced, but it's not bad to start with.\n",
        "\n",
        "So the thing is, if a model were to predict just 2 no matter what, it would have achieved a 50/107 = 46.7% accuracy. So let's not get too excited about 68% accuracy, but I'm glad we tried linear regression. The fact that we're not getting much higher than the majority class predicting model for many of these algorithms we've tried suggests our performance can be greatly improved from some feature engineering. But we will try some other models still."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN6HS8EjZPc1"
      },
      "source": [
        "What about K-Nearest Neighbors?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d427Ji1KZf91"
      },
      "source": [
        "Turns out we can do KNN classifier OR regressor. I will try both. I think this is also true for decision tree and random forest in sklearn as well, so if I gain interesting insight from this comparison, I will try a RandomForestRegressor next, after trying the KNeighborsClassifirer and KNeighborsRegressor. Maybe we will find that this problem should be thought of strictly as a regression problem.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiNe7ZEaZR0m",
        "outputId": "3ea9155f-dccb-40d9-ff12-804fc11bf87b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5454545454545454\n",
            "Mean absolute Error: 0.5\n",
            "Mean absolute Error: 0.5181818181818183\n",
            "Accuracy: 0.5454545454545454\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming X and y represent your features and target variable, respectively\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the KNN classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
        "\n",
        "# Train the classifier\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mse = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute Error:\", mse)\n",
        "\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Assuming X and y represent your features and target variable, respectively\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the KNN regressor\n",
        "knn_regressor = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
        "\n",
        "# Train the regressor\n",
        "knn_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = knn_regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the mean squared error of the regressor\n",
        "mse = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute Error:\", mse)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoEjtbiva_jP"
      },
      "source": [
        "We see that the regressor and the classifier had the same accuracy of .545, and the regressor had a mean absolute error of .518, slightly more than the mean absolute error of the classifier model. I'm still curious about the RandomForestRegressor model performance though."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIVUUkqtbi-p",
        "outputId": "c3557655-cc58-4778-837c-badd9b2cde2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean absolute Error: 0.5328987767283221\n",
            "Accuracy: 0.5\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "\n",
        "# Assuming X and y represent your features and target variable, respectively\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest Regressor\n",
        "random_forest_regressor = RandomForestRegressor(max_depth=None, max_features='auto', min_samples_leaf=1, min_samples_split=5, n_estimators=300, random_state=42)  # You can adjust the number of trees as needed\n",
        "\n",
        "# Train the regressor\n",
        "random_forest_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = random_forest_regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the mean squared error of the regressor\n",
        "mse = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute Error:\", mse)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoiRHhA3cNzM"
      },
      "source": [
        "Interesting, the Random Forest classifier with the same hyperparameters did better on accuracy and mean_absolute_error than the Random Forest Regressor. Now I will try Gaussian Naive Bayes, because ChatGPT told me to do so, lol. It says it is \"particularly useful for text classification and other high-dimensional datasets\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWN_Ig04dpZk",
        "outputId": "391f7b68-4440-4820-85f2-e40eefb0bd35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.45454545454545453\n",
            "Mean absolute error: 0.6363636363636364\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
        "\n",
        "# Step 2: Split the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Initialize and Train the GNB Classifier\n",
        "gnb_classifier = GaussianNB()\n",
        "gnb_classifier.fit(X_train, y_train)  # Convert sparse matrix to dense array for GNB\n",
        "\n",
        "# Step 4: Evaluate the Classifier\n",
        "y_pred = gnb_classifier.predict(X_test)  # Convert sparse matrix to dense array for prediction\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean absolute error:\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H38hxIdeLMR"
      },
      "source": [
        "Wow, that did poorly, although the mae wasn't too bad. Maybe we should focus on the fact that linear regression outclassed all the other algorithms. Does this mean that we are mostly treating our features as continuous variables, or that correlation and more basic statistical analyses can yield better results than a more advanced machine learning method?\n",
        "\n",
        "At this point, we should probably move backward to feature engineering.\n",
        "\n",
        "How can we improve our feature engineering?\n",
        "-- The very first thing that comes to mind is that we have too many columns. What if we got rid of half of our columns? What approach might we take to doing this?\n",
        "\n",
        "To answer these questions, some further analysis of the results of our linear regression predictions can give us some insight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LGFB8gTfzV_",
        "outputId": "1efa37e5-0482-4487-c26b-38298476b34f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.4504494974568123\n",
            "accuracy is 0.6818181818181818\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing data\n",
        "# Train a regression model instead of SVM classifier\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regression_model.predict(X_test)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "\n",
        "print(\"accuracy is\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCXWJgxTgDDu",
        "outputId": "4b30e3d5-e345-4e87-ef65-bb322961e177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "min_salary: 0.014271424173008057\n",
            "max_salary: -0.003580867394416598\n",
            "common_cluster0_counts: -0.10102475734098516\n",
            "common_cluster1_counts: 0.05388115344764163\n",
            "common_cluster2_counts: 0.024739920659176656\n",
            "common_cluster3_counts: 0.04604276456888401\n",
            "common_cluster4_counts: 0.013424107117969986\n",
            "common_cluster5_counts: -0.02295420112312413\n",
            "common_cluster6_counts: -0.034905316256727326\n",
            "common_cluster7_counts: -0.07834933190040484\n",
            "common_cluster8_counts: 0.06041962991392335\n",
            "common_cluster9_counts: 0.081272470419058\n",
            "common_cluster10_counts: 0.0872817123054643\n",
            "common_cluster11_counts: -0.11035313268900035\n",
            "common_cluster12_counts: -0.019370651676300726\n",
            "common_cluster13_counts: 0.06119439447983172\n",
            "common_cluster14_counts: 0.10929243197839297\n",
            "common_cluster15_counts: 0.0635951933612277\n",
            "common_cluster16_counts: -0.07895611827870287\n",
            "common_cluster17_counts: -0.031492607389980845\n",
            "common_cluster18_counts: 0.13253736759690016\n",
            "common_cluster19_counts: -0.03488946836048462\n",
            "common_cluster20_counts: 0.1614916896684704\n",
            "common_cluster21_counts: -0.005448467511588118\n",
            "common_cluster22_counts: 0.04364423401811214\n",
            "common_cluster23_counts: 0.11363543635409779\n",
            "common_cluster24_counts: 0.03904799599464914\n",
            "common_cluster25_counts: 0.07619159687909569\n",
            "common_cluster26_counts: -0.02697421716793033\n",
            "common_cluster27_counts: 0.12926305201273605\n",
            "common_cluster28_counts: 0.07867103583200774\n",
            "common_cluster29_counts: 0.06311027956431176\n",
            "common_cluster30_counts: 0.005769957708157358\n",
            "common_cluster31_counts: -0.04688543070009464\n",
            "common_cluster32_counts: 0.007831400569617597\n",
            "common_cluster33_counts: -0.06416193303711665\n",
            "common_cluster34_counts: 0.017729825236806333\n",
            "common_cluster35_counts: 0.038918861267019024\n",
            "common_cluster36_counts: -0.05494408268224821\n",
            "common_cluster37_counts: -0.018038948568513485\n",
            "common_cluster38_counts: -0.02921534094843967\n",
            "common_cluster39_counts: 0.007599461404372655\n",
            "common_cluster40_counts: -0.0771028311213622\n",
            "common_cluster41_counts: -0.0745061898640784\n",
            "common_cluster42_counts: 0.0320805292119415\n",
            "common_cluster43_counts: 0.0019341534826712893\n",
            "common_cluster44_counts: 0.024953162170056747\n",
            "common_cluster45_counts: 0.024823993183852394\n",
            "common_cluster46_counts: -0.0009170653070962927\n",
            "common_cluster47_counts: 0.023640326333345903\n",
            "common_cluster48_counts: -0.008738272671898695\n",
            "common_cluster49_counts: -0.0036394208081406334\n",
            "common_cluster50_counts: -0.014870736810936574\n",
            "common_cluster51_counts: -0.0631590829504891\n",
            "common_cluster52_counts: -0.011425384046314505\n",
            "common_cluster53_counts: 0.00322379437754846\n",
            "common_cluster54_counts: 0.020116296810761297\n",
            "common_cluster55_counts: 0.034098393209942984\n",
            "common_cluster56_counts: -0.0014019898293216974\n",
            "common_cluster57_counts: 0.13616491025323296\n",
            "common_cluster58_counts: 0.019525590148595527\n",
            "common_cluster59_counts: 0.10257067694574534\n",
            "common_cluster60_counts: 0.016803868901061714\n",
            "common_cluster61_counts: 0.02033504743919816\n",
            "common_cluster62_counts: -0.0222647652077863\n",
            "common_cluster63_counts: -0.04200478032588745\n",
            "common_cluster64_counts: -0.08896163679389704\n",
            "common_cluster65_counts: 0.0727225514901839\n",
            "common_cluster66_counts: -0.12237242013624235\n",
            "common_cluster67_counts: 0.01584289784213817\n",
            "common_cluster68_counts: 0.0016090624198920184\n",
            "common_cluster69_counts: 0.03716591672838617\n",
            "common_cluster70_counts: 0.0654985413193747\n",
            "common_cluster71_counts: -0.026837594151010863\n",
            "common_cluster72_counts: 0.07264535871864274\n",
            "common_cluster73_counts: 0.0006073140994269505\n",
            "common_cluster74_counts: -0.052644611896688884\n",
            "common_cluster75_counts: 0.02691140653005408\n",
            "common_cluster76_counts: 0.00016988422289129345\n",
            "common_cluster77_counts: -0.06789906461563186\n",
            "common_cluster78_counts: -0.03188804652890103\n",
            "common_cluster79_counts: -0.006962281420102714\n",
            "common_cluster80_counts: 0.011792393502807665\n",
            "common_cluster81_counts: -0.07651909517684642\n",
            "common_cluster82_counts: 0.03921968794017089\n",
            "common_cluster83_counts: 0.010556931390590224\n",
            "common_cluster84_counts: -0.19528603235169736\n",
            "common_cluster85_counts: 0.048896936783348034\n",
            "common_cluster86_counts: 0.008533748868210005\n",
            "common_cluster87_counts: 0.022544295177125737\n",
            "common_cluster88_counts: 0.0449956072075476\n",
            "common_cluster89_counts: 0.01751387957118557\n",
            "common_cluster90_counts: -0.06254575755080771\n",
            "common_cluster91_counts: 0.023041071190074654\n",
            "common_cluster92_counts: -0.023127277308816786\n",
            "common_cluster93_counts: 0.05336040917258131\n",
            "common_cluster94_counts: 0.04974178369911726\n",
            "common_cluster95_counts: -0.005911121981210691\n",
            "common_cluster96_counts: -0.08332162401840038\n",
            "common_cluster97_counts: -0.12119617908237043\n",
            "common_cluster98_counts: 0.025076214766012732\n",
            "common_cluster99_counts: 0.02915783337492476\n",
            "common_cluster100_counts: -0.1288097727419905\n",
            "common_cluster101_counts: 0.06529083443449536\n",
            "common_cluster102_counts: 0.044250798651874285\n",
            "common_cluster103_counts: 0.07600472591177594\n",
            "common_cluster104_counts: -0.05408715878045925\n",
            "common_cluster105_counts: -0.14878135930662967\n",
            "common_cluster106_counts: -0.05301334750093365\n",
            "common_cluster107_counts: -0.06092324691105934\n",
            "common_cluster108_counts: -0.07687462857945374\n",
            "common_cluster109_counts: 0.04468011531360037\n",
            "common_cluster110_counts: 0.002352263466621046\n",
            "common_cluster111_counts: 0.0676816408218378\n",
            "common_cluster112_counts: 0.011719516619230402\n",
            "common_cluster113_counts: 0.016610842700378645\n",
            "common_cluster114_counts: 0.05068446389015252\n",
            "common_cluster115_counts: 0.019964595488261613\n",
            "common_cluster116_counts: -0.0034305209129407467\n",
            "common_cluster117_counts: 0.04239844897527724\n",
            "common_cluster118_counts: 0.062696008678203\n",
            "common_cluster119_counts: 0.07567092018893222\n",
            "common_cluster120_counts: 0.04209567438448426\n",
            "common_cluster121_counts: -0.022627080067791214\n",
            "common_cluster122_counts: -0.13200862080208015\n",
            "common_cluster123_counts: 0.0008888771491879222\n",
            "common_cluster124_counts: 0.004012015522191818\n",
            "common_cluster125_counts: 0.034743272453118285\n",
            "common_cluster126_counts: -0.036089183536289156\n",
            "common_cluster127_counts: -0.0639725907887039\n",
            "common_cluster128_counts: 0.0073571967917226986\n",
            "common_cluster129_counts: 0.01286335695437455\n",
            "common_cluster130_counts: -0.01925899658449816\n",
            "common_cluster131_counts: 0.044747281719758426\n",
            "common_cluster132_counts: 0.051311806028293286\n",
            "common_cluster133_counts: 0.032352551395381235\n",
            "common_cluster134_counts: 0.03586504247879068\n",
            "common_cluster135_counts: -0.016632293940510162\n",
            "common_cluster136_counts: 0.03140794929376032\n",
            "common_cluster137_counts: 0.0\n",
            "common_cluster138_counts: 0.0923439794377326\n",
            "common_cluster139_counts: -0.055099986808592044\n",
            "common_cluster140_counts: 0.0\n",
            "common_cluster141_counts: -0.04180144589626043\n",
            "common_cluster142_counts: -0.14529016105854844\n",
            "common_cluster143_counts: 0.020664439245001047\n",
            "common_cluster144_counts: -0.0907944273347813\n",
            "common_cluster145_counts: -0.15056147240398027\n",
            "common_cluster146_counts: -0.07905913768094014\n",
            "common_cluster147_counts: 0.04631429713236427\n",
            "common_cluster148_counts: 0.049495320631111686\n",
            "common_cluster149_counts: -0.010894911367205294\n",
            "common_cluster150_counts: -0.04640162764749362\n",
            "common_cluster151_counts: 0.02192574056146576\n",
            "common_cluster152_counts: -0.008195279629803091\n",
            "common_cluster153_counts: -0.08731234953656478\n",
            "common_cluster154_counts: 0.07668664693994771\n",
            "common_cluster155_counts: -0.03556546633323149\n",
            "common_cluster156_counts: -0.05626596709557481\n",
            "common_cluster157_counts: -0.004897267440746016\n",
            "common_cluster158_counts: 0.0\n",
            "common_cluster159_counts: 0.05532715680592769\n",
            "common_cluster160_counts: 0.09572814096064787\n",
            "common_cluster161_counts: -0.011190297625855546\n",
            "common_cluster162_counts: 0.023747331214470122\n",
            "common_cluster163_counts: -0.05827731800479131\n",
            "common_cluster164_counts: 0.059100803731211106\n",
            "common_cluster165_counts: 0.034818559672122176\n",
            "common_cluster166_counts: 0.03724216608177353\n",
            "common_cluster167_counts: 0.10307193611788021\n",
            "common_cluster168_counts: 0.08546137056867031\n",
            "common_cluster169_counts: -0.04537922192796337\n",
            "common_cluster170_counts: -0.0221276505348231\n",
            "common_cluster171_counts: 0.10487978190926707\n",
            "common_cluster172_counts: -0.017756387011733134\n",
            "common_cluster173_counts: -0.01867020716118093\n",
            "common_cluster174_counts: 0.04178726438262749\n",
            "common_cluster175_counts: -0.08259643795366392\n",
            "common_cluster176_counts: 0.11147439192861644\n",
            "common_cluster177_counts: 0.12662336426446272\n",
            "common_cluster178_counts: 0.04429885710155587\n",
            "common_cluster179_counts: 0.022907493813753108\n",
            "common_cluster180_counts: -0.011423231520500347\n",
            "common_cluster181_counts: 0.025634066582845855\n",
            "common_cluster182_counts: -0.04780921338648802\n",
            "common_cluster183_counts: 0.059931710863187215\n",
            "common_cluster184_counts: -0.06860822311571843\n",
            "common_cluster185_counts: 0.04659078897957311\n",
            "common_cluster186_counts: 0.0073302574020250155\n",
            "common_cluster187_counts: 0.009040350223933465\n",
            "common_cluster188_counts: -0.05214760432473771\n",
            "common_cluster189_counts: 0.05791683449278263\n",
            "common_cluster190_counts: 0.10433165400383346\n",
            "common_cluster191_counts: -0.0035707971835923346\n",
            "common_cluster192_counts: 0.08108428481935218\n",
            "common_cluster193_counts: 0.03251646581145266\n",
            "common_cluster194_counts: -0.11876432231070823\n",
            "common_cluster195_counts: 0.03412245002317666\n",
            "common_cluster196_counts: 0.014734606043901916\n",
            "common_cluster197_counts: 0.110302051158503\n",
            "common_cluster198_counts: 0.02192574056146576\n",
            "common_cluster199_counts: 0.015278644454230446\n",
            "common_cluster200_counts: 0.05202353399418557\n",
            "common_cluster201_counts: 0.0014919082634174304\n",
            "common_cluster202_counts: 0.053962395440991115\n",
            "common_cluster203_counts: -0.06597628905251816\n",
            "common_cluster204_counts: -0.020956942997329576\n",
            "common_cluster205_counts: -0.08468668967972884\n",
            "common_cluster206_counts: 0.08073794484924629\n",
            "common_cluster207_counts: 0.006814658385206559\n",
            "common_cluster208_counts: -0.060405719699092\n",
            "common_cluster209_counts: 0.07654874072992994\n",
            "common_cluster210_counts: -0.02292903176663753\n",
            "common_cluster211_counts: 0.027054090042974144\n",
            "common_cluster212_counts: -0.055056078008184406\n",
            "common_cluster213_counts: -0.049236487761342436\n",
            "common_cluster214_counts: -0.10517754967606496\n",
            "common_cluster215_counts: 0.0\n",
            "common_cluster216_counts: 0.01643711678119495\n",
            "common_cluster217_counts: 0.0006514634889230042\n",
            "common_cluster218_counts: -0.022461112832186297\n",
            "common_cluster219_counts: 0.0\n",
            "common_cluster220_counts: -0.0012143029991578541\n",
            "common_cluster221_counts: 0.11934649601821937\n",
            "common_cluster222_counts: -0.0221276505348231\n",
            "common_cluster223_counts: 0.031941878356494334\n",
            "common_cluster224_counts: 0.16043499358396066\n",
            "common_cluster225_counts: 0.009596833594780632\n",
            "common_cluster226_counts: 0.022477247907991826\n",
            "common_cluster227_counts: 0.004137694959964389\n",
            "common_cluster228_counts: 0.0\n",
            "common_cluster229_counts: -0.03860807175573858\n",
            "common_cluster230_counts: -0.07643242268391598\n",
            "common_cluster231_counts: 0.07728983666444209\n",
            "common_cluster232_counts: 0.0\n",
            "common_cluster233_counts: -0.009479569757486976\n",
            "common_cluster234_counts: -0.021938652454553204\n",
            "common_cluster235_counts: -0.06362482348200836\n",
            "common_cluster236_counts: 0.0\n",
            "common_cluster237_counts: -0.011946775412606412\n",
            "common_cluster238_counts: 0.08318427122222774\n",
            "common_cluster239_counts: 0.00896626061969767\n",
            "common_cluster240_counts: -0.04490198284179643\n",
            "common_cluster241_counts: -0.0666197192306618\n",
            "common_cluster242_counts: 0.028587510297197822\n",
            "common_cluster243_counts: 0.09463773600112121\n",
            "common_cluster244_counts: -0.025853858646724445\n",
            "common_cluster245_counts: -0.006595344280318757\n",
            "common_cluster246_counts: -0.06158015731128066\n",
            "common_cluster247_counts: -0.11677798452198339\n",
            "common_cluster248_counts: 0.029732030720973628\n",
            "common_cluster249_counts: -0.019681393832661712\n",
            "common_cluster250_counts: 0.06948654490623657\n",
            "common_cluster251_counts: 0.02628253060110709\n",
            "common_cluster252_counts: -0.004491893783399124\n",
            "common_cluster253_counts: -0.03205184829993121\n",
            "common_cluster254_counts: 0.07921132345485705\n",
            "common_cluster255_counts: -0.003490261244700636\n",
            "common_cluster256_counts: -0.05395584685024492\n",
            "common_cluster257_counts: -0.04861399791692159\n",
            "common_cluster258_counts: 0.03355739581657535\n",
            "common_cluster259_counts: 0.02074641276306782\n",
            "common_cluster260_counts: 0.0385397105456394\n",
            "common_cluster261_counts: 0.004012015522191818\n",
            "common_cluster262_counts: 0.037062654698681675\n",
            "common_cluster263_counts: 0.0\n",
            "common_cluster264_counts: 0.0\n",
            "common_cluster265_counts: -0.07945420480910954\n",
            "common_cluster266_counts: 0.035214270627582846\n",
            "common_cluster267_counts: -0.07666785074637814\n",
            "common_cluster268_counts: 0.060135015855780065\n",
            "common_cluster269_counts: 0.005458071132915507\n",
            "common_cluster270_counts: -0.023300610715885677\n",
            "common_cluster271_counts: -0.0026810900637003025\n",
            "common_cluster272_counts: -0.06158015731128066\n",
            "common_cluster273_counts: -0.07905553862977827\n",
            "common_cluster274_counts: 0.018626098421307677\n",
            "common_cluster275_counts: -0.03205184829993121\n",
            "common_cluster276_counts: 0.06554673481144441\n",
            "common_cluster277_counts: 0.04687740000427435\n",
            "common_cluster278_counts: -0.005615278208046574\n",
            "common_cluster279_counts: -0.002552124132850369\n",
            "common_cluster280_counts: 0.034743272453118285\n",
            "common_cluster281_counts: 0.054088869433578976\n",
            "common_cluster282_counts: 0.02592301846469105\n",
            "common_cluster283_counts: -0.05786584356956609\n",
            "common_cluster284_counts: 0.10436263263384633\n",
            "common_cluster285_counts: -0.04414533461926174\n",
            "common_cluster286_counts: -0.02614429267794039\n",
            "common_cluster287_counts: -0.03013709781861348\n",
            "common_cluster288_counts: 0.007550637639137809\n",
            "common_cluster289_counts: -0.0666197192306618\n",
            "common_cluster290_counts: -0.08586196810974817\n",
            "common_cluster291_counts: 0.0078778490856306\n",
            "common_cluster292_counts: 0.0\n",
            "common_cluster293_counts: 0.008909559614877351\n",
            "common_cluster294_counts: 0.012280321864647191\n",
            "common_cluster295_counts: -0.019220486440253516\n",
            "common_cluster296_counts: 0.042341873015361645\n",
            "common_cluster297_counts: 0.05360017435081247\n",
            "common_cluster298_counts: -0.042359771651986115\n",
            "common_cluster299_counts: -0.04693553498444698\n",
            "common_cluster300_counts: -0.01901795544301205\n",
            "common_cluster301_counts: -0.00981474944060608\n",
            "common_cluster302_counts: -0.06311463606340904\n",
            "common_cluster303_counts: 0.0193133914860849\n",
            "common_cluster304_counts: 0.03604248320400638\n",
            "common_cluster305_counts: 0.059860241225316156\n",
            "common_cluster306_counts: 0.030728653351650606\n",
            "common_cluster307_counts: -0.041575407154774605\n",
            "common_cluster308_counts: 0.05924220689483995\n",
            "common_cluster309_counts: 0.0013369980516895266\n",
            "common_cluster310_counts: 0.057677478285732095\n",
            "common_cluster311_counts: -9.126303139502662e-05\n",
            "common_cluster312_counts: 0.029852440654392243\n",
            "common_cluster313_counts: 0.08477407826222509\n",
            "common_cluster314_counts: -0.10732124407998934\n",
            "common_cluster315_counts: 0.009037612474630837\n",
            "common_cluster316_counts: 0.020736154867045515\n",
            "common_cluster317_counts: 0.029351571489177906\n",
            "common_cluster318_counts: 0.032206469577602766\n",
            "common_cluster319_counts: 0.01791925957681522\n",
            "common_cluster320_counts: -0.015051138911905307\n",
            "common_cluster321_counts: -0.007196469863263921\n",
            "common_cluster322_counts: 0.024839084282486747\n",
            "common_cluster323_counts: -0.06771916078958876\n",
            "common_cluster324_counts: -0.010894911367205294\n",
            "common_cluster325_counts: 0.06150582224599535\n",
            "common_cluster326_counts: 0.03734080964733187\n",
            "common_cluster327_counts: -0.06022598716801485\n",
            "common_cluster328_counts: 0.00011589821260046991\n",
            "common_cluster329_counts: 0.08767445731104927\n",
            "common_cluster330_counts: -0.05821404283991983\n",
            "common_cluster331_counts: -0.0005369279927208998\n",
            "common_cluster332_counts: -0.13483603180594597\n",
            "common_cluster333_counts: 0.001022186934642625\n",
            "common_cluster334_counts: -0.08133181410667875\n",
            "common_cluster335_counts: 0.029102363199684067\n",
            "common_cluster336_counts: 0.07487333855438806\n",
            "common_cluster337_counts: 0.04040701159540302\n",
            "common_cluster338_counts: 0.04189049992431174\n",
            "common_cluster339_counts: 0.01991573740183688\n",
            "common_cluster340_counts: 0.04854864227515325\n",
            "common_cluster341_counts: -0.02361050068948927\n",
            "common_cluster342_counts: 0.06756793496907913\n",
            "common_cluster343_counts: -0.07439067965331483\n",
            "common_cluster344_counts: -0.02292903176663753\n",
            "common_cluster345_counts: 0.0\n",
            "common_cluster346_counts: -0.10556694946035197\n",
            "common_cluster347_counts: -0.10983014105108986\n",
            "common_cluster348_counts: 0.06732356785516791\n",
            "common_cluster349_counts: 0.02074641276306782\n",
            "common_cluster350_counts: 0.04159213561111387\n",
            "common_cluster351_counts: 0.03036521979591813\n",
            "common_cluster352_counts: -0.08304086757114273\n",
            "common_cluster353_counts: -0.020179445671312225\n",
            "common_cluster354_counts: 0.00922621346258791\n",
            "common_cluster355_counts: 0.035371099449833826\n",
            "common_cluster356_counts: -0.009342962695586942\n",
            "common_cluster357_counts: 0.07729757864312817\n",
            "common_cluster358_counts: 0.014830420553376543\n",
            "common_cluster359_counts: 0.008399385534022844\n",
            "common_cluster360_counts: -0.06676083182040093\n",
            "common_cluster361_counts: -0.04129821897683196\n",
            "common_cluster362_counts: 0.029455240527423758\n",
            "common_cluster363_counts: -0.04129821897683196\n",
            "common_cluster364_counts: 0.03552910501587195\n",
            "common_cluster365_counts: -0.018416532253291127\n",
            "common_cluster366_counts: 0.0\n",
            "common_cluster367_counts: -0.027423593883354847\n",
            "common_cluster368_counts: -0.03023219611836838\n",
            "common_cluster369_counts: -0.05827731800479131\n",
            "common_cluster370_counts: 0.06085089600763708\n",
            "common_cluster371_counts: 0.05057165395533119\n",
            "common_cluster372_counts: 0.058910481054847516\n",
            "common_cluster373_counts: -0.04474397777406649\n",
            "common_cluster374_counts: -0.02647194629386628\n",
            "common_cluster375_counts: -0.0218970499547563\n",
            "common_cluster376_counts: 0.07884116353387453\n",
            "common_cluster377_counts: 0.0\n",
            "common_cluster378_counts: 0.050249376178846575\n",
            "common_cluster379_counts: -0.056290979532721344\n",
            "common_cluster380_counts: -0.03127962063327693\n",
            "common_cluster381_counts: -0.00664763165269697\n",
            "common_cluster382_counts: -0.07439067965331483\n",
            "common_cluster383_counts: -0.022627080067791214\n",
            "common_cluster384_counts: 0.0\n",
            "common_cluster385_counts: 0.035371099449833826\n",
            "common_cluster386_counts: -0.04214231816430464\n",
            "common_cluster387_counts: -0.00184555814186123\n",
            "common_cluster388_counts: -0.11567181630332107\n",
            "common_cluster389_counts: 0.004012015522191818\n",
            "common_cluster390_counts: 0.0\n",
            "common_cluster391_counts: 0.0\n",
            "common_cluster392_counts: 0.017014027774459067\n",
            "common_cluster393_counts: -0.02224498825036491\n",
            "common_cluster394_counts: 0.0\n",
            "common_cluster395_counts: -0.03927922260012173\n",
            "common_cluster396_counts: -0.016716026185962178\n",
            "common_cluster397_counts: -0.052783474730175986\n",
            "common_cluster398_counts: -0.037439410494178656\n",
            "common_cluster399_counts: 0.029455240527423758\n",
            "common_cluster400_counts: 0.0\n",
            "common_cluster401_counts: 0.0\n",
            "common_cluster402_counts: 0.048990874462057465\n",
            "common_cluster403_counts: -0.011230556416093149\n",
            "common_cluster404_counts: -0.01639819139730172\n",
            "common_cluster405_counts: 0.002416167244832783\n",
            "common_cluster406_counts: -0.036750873949398716\n",
            "common_cluster407_counts: 0.03637039357136405\n",
            "common_cluster408_counts: -0.020956942997329576\n",
            "common_cluster409_counts: 0.0339349293298704\n",
            "common_cluster410_counts: 0.04535126021145729\n",
            "common_cluster411_counts: -0.01639819139730172\n",
            "common_cluster412_counts: 0.00898273161698726\n",
            "common_cluster413_counts: 0.06806924970181776\n",
            "common_cluster414_counts: 0.03547181103341715\n",
            "common_cluster415_counts: 0.042341873015361645\n",
            "common_cluster416_counts: -0.02531318183577194\n",
            "common_cluster417_counts: -0.033581972004706334\n",
            "common_cluster418_counts: -0.020872135750863705\n",
            "common_cluster419_counts: 0.0592625435627092\n",
            "common_cluster420_counts: 0.010637462016583903\n",
            "common_cluster421_counts: 0.030728653351650606\n",
            "common_cluster422_counts: 0.04159213561111387\n",
            "common_cluster423_counts: 0.02760380587019235\n",
            "common_cluster424_counts: -0.00782012830675441\n",
            "common_cluster425_counts: -0.020710180703053027\n",
            "common_cluster426_counts: 0.011178544577039703\n",
            "common_cluster427_counts: 0.011364258217570838\n",
            "common_cluster428_counts: 0.02201193314361479\n",
            "common_cluster429_counts: 0.07495067576613706\n",
            "common_cluster430_counts: 0.0\n",
            "common_cluster431_counts: 0.0\n",
            "common_cluster432_counts: -0.007660547398154856\n",
            "common_cluster433_counts: 0.00896626061969767\n",
            "common_cluster434_counts: -0.11623132443861087\n",
            "common_cluster435_counts: -0.036750873949398716\n",
            "common_cluster436_counts: -0.025952605047752993\n",
            "common_cluster437_counts: 0.011178544577039703\n",
            "common_cluster438_counts: -0.048615283568013624\n",
            "common_cluster439_counts: 0.0073302574020250155\n",
            "common_cluster440_counts: 0.01286335695437455\n",
            "common_cluster441_counts: -0.04761158863420786\n",
            "common_cluster442_counts: -0.0600826740763894\n",
            "common_cluster443_counts: -0.026051295987723697\n",
            "common_cluster444_counts: 0.051304210613862256\n",
            "common_cluster445_counts: 0.012944856170133134\n",
            "common_cluster446_counts: 0.019733439313355382\n",
            "common_cluster447_counts: -0.039271853491700426\n",
            "common_cluster448_counts: 0.0\n",
            "common_cluster449_counts: 0.029455240527423758\n",
            "common_cluster450_counts: 0.020358533596397287\n",
            "common_cluster451_counts: -0.004711623534350086\n",
            "common_cluster452_counts: 0.05503417963514989\n",
            "common_cluster453_counts: -0.02866076858029014\n",
            "common_cluster454_counts: -0.009794534881492033\n",
            "common_cluster455_counts: 0.06371055542793952\n",
            "common_cluster456_counts: 0.002006007761095909\n",
            "common_cluster457_counts: -0.0221276505348231\n",
            "common_cluster458_counts: -0.00664763165269697\n",
            "common_cluster459_counts: -0.0221276505348231\n",
            "common_cluster460_counts: 0.0\n",
            "common_cluster461_counts: 0.011940247848784655\n",
            "common_cluster462_counts: -0.058388992260991694\n",
            "common_cluster463_counts: 0.10260842122772451\n",
            "common_cluster464_counts: 0.0318563925543554\n",
            "common_cluster465_counts: 0.0\n",
            "common_cluster466_counts: 0.06149528025358149\n",
            "common_cluster467_counts: 0.00896626061969767\n",
            "common_cluster468_counts: 0.0\n",
            "common_cluster469_counts: 0.04031001666098414\n",
            "common_cluster470_counts: -0.03734041432236186\n",
            "common_cluster471_counts: 0.0867844846933231\n",
            "common_cluster472_counts: 0.0\n",
            "common_cluster473_counts: -0.033581972004706334\n",
            "common_cluster474_counts: -0.037439410494178656\n",
            "common_cluster475_counts: 0.017333614582220585\n",
            "common_cluster476_counts: -0.06735214675685906\n",
            "common_cluster477_counts: -0.0360047425274355\n",
            "common_cluster478_counts: -0.03534329871137088\n",
            "common_cluster479_counts: 0.01643711678119495\n",
            "common_cluster480_counts: 0.07493888456064732\n",
            "common_cluster481_counts: -0.07350174789879743\n",
            "common_cluster482_counts: -0.07487882098835731\n",
            "common_cluster483_counts: -0.04958426459119503\n",
            "common_cluster484_counts: 0.0\n",
            "common_cluster485_counts: 0.051304210613862256\n",
            "common_cluster486_counts: 0.0\n",
            "common_cluster487_counts: -0.002179191219379366\n",
            "common_cluster488_counts: 0.03426765408871468\n",
            "common_cluster489_counts: -0.06946492113875424\n",
            "common_cluster490_counts: -0.02531318183577194\n",
            "common_cluster491_counts: 0.0\n",
            "common_cluster492_counts: -0.024182142954791\n",
            "common_cluster493_counts: -0.05783590815166054\n",
            "common_cluster494_counts: -0.007700658115965989\n",
            "common_cluster495_counts: 0.0\n",
            "common_cluster496_counts: 0.16319496594053065\n",
            "common_cluster497_counts: 0.010291414551035015\n",
            "common_cluster498_counts: 0.04967208813047515\n",
            "common_cluster499_counts: 0.0\n",
            "company_cluster0_counts: 0.012944856170133134\n",
            "company_cluster1_counts: -0.005035655392773155\n",
            "company_cluster2_counts: 0.020736154867045515\n",
            "company_cluster3_counts: 0.0007536678778636233\n",
            "company_cluster4_counts: -0.019177997496131093\n",
            "company_cluster5_counts: 0.029059297042216978\n",
            "company_cluster6_counts: -0.00664763165269697\n",
            "company_cluster7_counts: 0.020833470664767866\n",
            "company_cluster8_counts: 0.008853354863302063\n",
            "company_cluster9_counts: -0.022627080067791214\n",
            "company_cluster10_counts: 0.08663206476766708\n",
            "company_cluster11_counts: -0.02614429267794039\n",
            "company_cluster12_counts: 0.01991573740183688\n",
            "company_cluster13_counts: 0.05409700463285052\n",
            "company_cluster14_counts: -0.02292903176663753\n",
            "company_cluster15_counts: -0.020683317013422506\n",
            "company_cluster16_counts: -0.006367322303624925\n",
            "company_cluster17_counts: 0.0\n",
            "company_cluster18_counts: 0.0014843428140323\n",
            "company_cluster19_counts: -0.04880716165976415\n",
            "company_cluster20_counts: -0.02531318183577194\n",
            "company_cluster21_counts: 0.0\n",
            "company_cluster22_counts: -0.04129821897683196\n",
            "company_cluster23_counts: 0.05830424999701864\n",
            "company_cluster24_counts: -0.05183873381327872\n",
            "company_cluster25_counts: 0.0\n",
            "company_cluster26_counts: -0.01901795544301205\n",
            "company_cluster27_counts: 0.0\n",
            "company_cluster28_counts: -0.007700658115965989\n",
            "company_cluster29_counts: 0.03787291293575959\n",
            "company_cluster30_counts: 0.0\n",
            "company_cluster31_counts: -0.05783590815166054\n",
            "company_cluster32_counts: 0.06371055542793952\n",
            "company_cluster33_counts: 0.02192574056146576\n",
            "company_cluster34_counts: -0.01191639547605516\n",
            "company_cluster35_counts: -0.028132983547787406\n",
            "company_cluster36_counts: 0.005679575789590684\n",
            "company_cluster37_counts: 0.02074641276306782\n",
            "company_cluster38_counts: -0.03952776931488913\n",
            "company_cluster39_counts: 0.0716411924911093\n",
            "company_cluster40_counts: -0.005615278208046574\n",
            "company_cluster41_counts: 0.010556931390590224\n",
            "company_cluster42_counts: 0.004199692767011422\n",
            "company_cluster43_counts: 0.016176275697690617\n",
            "company_cluster44_counts: -0.021179885825993058\n",
            "company_cluster45_counts: -0.033581972004706334\n",
            "company_cluster46_counts: 0.0\n",
            "company_cluster47_counts: 0.0051457072755175075\n",
            "company_cluster48_counts: 0.0030755280603034785\n",
            "company_cluster49_counts: -0.058388992260991694\n",
            "company_cluster50_counts: 0.017333614582220585\n",
            "company_cluster51_counts: 0.0\n",
            "company_cluster52_counts: -0.052783474730175986\n",
            "company_cluster53_counts: -0.01639819139730172\n",
            "company_cluster54_counts: 0.046195597086991586\n",
            "company_cluster55_counts: 0.0\n",
            "company_cluster56_counts: 0.029455240527423758\n",
            "company_cluster57_counts: 0.042341873015361645\n",
            "company_cluster58_counts: -0.037439410494178656\n",
            "company_cluster59_counts: 0.04159213561111387\n",
            "company_cluster60_counts: 0.001022186934642625\n",
            "company_cluster61_counts: 0.0\n",
            "company_cluster62_counts: -0.028838777945548077\n",
            "company_cluster63_counts: -0.0018971154703405907\n",
            "company_cluster64_counts: 0.00896626061969767\n",
            "company_cluster65_counts: 0.0\n",
            "company_cluster66_counts: -0.0221276505348231\n",
            "company_cluster67_counts: 0.0\n",
            "company_cluster68_counts: 0.030728653351650606\n",
            "company_cluster69_counts: 0.0\n",
            "company_cluster70_counts: 0.018531327349340838\n",
            "company_cluster71_counts: -0.03833392537318907\n",
            "company_cluster72_counts: 0.002416167244832783\n",
            "company_cluster73_counts: 0.02628253060110709\n",
            "company_cluster74_counts: -0.004897267440746016\n",
            "company_cluster75_counts: 0.01643711678119495\n",
            "company_cluster76_counts: 0.0\n",
            "company_cluster77_counts: 0.0\n",
            "company_cluster78_counts: -0.07194182779184143\n",
            "company_cluster79_counts: 0.0\n",
            "name_of_department/team_cluster0_counts: 0.04392527194732304\n",
            "name_of_department/team_cluster1_counts: -0.026949396578893843\n",
            "name_of_department/team_cluster2_counts: -0.04043669568068709\n",
            "name_of_department/team_cluster3_counts: -0.005882819976962529\n",
            "name_of_department/team_cluster4_counts: 0.035371099449833826\n",
            "name_of_department/team_cluster5_counts: -0.022627080067791214\n",
            "name_of_department/team_cluster6_counts: 0.014830420553376543\n",
            "name_of_department/team_cluster7_counts: -0.01901795544301205\n",
            "name_of_department/team_cluster8_counts: -0.019177997496131093\n",
            "name_of_department/team_cluster9_counts: -0.02292903176663753\n",
            "name_of_department/team_cluster10_counts: -0.021179885825993058\n",
            "name_of_department/team_cluster11_counts: -0.021179885825993058\n",
            "name_of_department/team_cluster12_counts: -0.006514825173861788\n",
            "name_of_department/team_cluster13_counts: 0.01286335695437455\n",
            "name_of_department/team_cluster14_counts: 0.02074641276306782\n",
            "name_of_department/team_cluster15_counts: -0.02292903176663753\n",
            "name_of_department/team_cluster16_counts: 0.02192574056146576\n",
            "name_of_department/team_cluster17_counts: 0.012944856170133134\n",
            "name_of_department/team_cluster18_counts: 0.0\n",
            "name_of_department/team_cluster19_counts: 0.00898273161698726\n",
            "name_of_department/team_cluster20_counts: 0.016176275697690617\n",
            "city_cluster0_counts: -0.0008508891525140019\n",
            "city_cluster1_counts: 0.04193828204986035\n",
            "city_cluster2_counts: 0.02181239214309855\n",
            "city_cluster3_counts: 0.05708963295740366\n",
            "city_cluster4_counts: 0.07143506363584456\n",
            "city_cluster5_counts: 0.053505111071785225\n",
            "city_cluster6_counts: -0.00664763165269697\n",
            "city_cluster7_counts: -0.041345117749555196\n",
            "city_cluster8_counts: -0.047305671615532674\n",
            "city_cluster9_counts: -0.007500276792804751\n",
            "city_cluster10_counts: -0.08719274942099833\n",
            "city_cluster11_counts: 0.0\n",
            "city_cluster12_counts: 0.0193710607357176\n",
            "city_cluster13_counts: 0.0\n",
            "city_cluster14_counts: 0.02074641276306782\n",
            "city_cluster15_counts: -0.058388992260991694\n",
            "city_cluster16_counts: 0.01814972096791749\n",
            "city_cluster17_counts: -0.036750873949398716\n",
            "city_cluster18_counts: -0.03952776931488913\n",
            "city_cluster19_counts: 0.0\n",
            "city_cluster20_counts: 0.0\n",
            "city_cluster21_counts: -0.010589664195271492\n",
            "city_cluster22_counts: -0.04474397777406649\n",
            "city_cluster23_counts: 0.12172765917274267\n",
            "city_cluster24_counts: 0.0\n",
            "city_cluster25_counts: 0.0339349293298704\n",
            "city_cluster26_counts: -0.007610917382213353\n",
            "city_cluster27_counts: -0.02292903176663753\n",
            "city_cluster28_counts: 0.02192574056146576\n",
            "city_cluster29_counts: 0.002006007761095909\n",
            "city_cluster30_counts: -0.03079007865564033\n",
            "city_cluster31_counts: 0.030728653351650606\n",
            "city_cluster32_counts: 0.0\n",
            "city_cluster33_counts: 0.054429008856638345\n",
            "city_cluster34_counts: 0.03787291293575959\n",
            "city_cluster35_counts: -0.016144501617514215\n",
            "city_cluster36_counts: 0.0\n",
            "city_cluster37_counts: -0.028838777945548077\n",
            "city_cluster38_counts: -0.006367322303624925\n",
            "city_cluster39_counts: -0.037439410494178656\n",
            "city_cluster40_counts: -0.01867020716118093\n",
            "city_cluster41_counts: -0.03833392537318907\n",
            "city_cluster42_counts: 0.002416167244832783\n",
            "city_cluster43_counts: 0.005679575789590684\n",
            "city_cluster44_counts: 0.01286335695437455\n",
            "city_cluster45_counts: -0.020956942997329576\n",
            "city_cluster46_counts: -0.021179885825993058\n",
            "city_cluster47_counts: -0.022627080067791214\n",
            "city_cluster48_counts: 0.020736154867045515\n",
            "city_cluster49_counts: 0.018531327349340838\n",
            "city_cluster50_counts: -9.126303139502662e-05\n",
            "city_cluster51_counts: -0.05783590815166054\n",
            "city_cluster52_counts: 0.042341873015361645\n",
            "work_arrangement_cluster0_counts: 0.08158961483000679\n",
            "work_arrangement_cluster1_counts: 0.0001706507772141555\n",
            "work_arrangement_cluster2_counts: -0.11456496023285165\n",
            "work_arrangement_cluster3_counts: 0.13157734915203118\n",
            "work_arrangement_cluster4_counts: 0.01701878702549289\n",
            "work_arrangement_cluster5_counts: 0.0\n",
            "work_arrangement_cluster6_counts: -0.10134072714359689\n",
            "work_arrangement_cluster7_counts: -0.014373995950822617\n",
            "work_arrangement_cluster8_counts: -0.01488211162629318\n",
            "work_arrangement_cluster9_counts: 0.019733439313355382\n",
            "AR: 0.0716411924911093\n",
            "AZ: 0.0\n",
            "CA: 0.06894836711193916\n",
            "CO: -0.036138087809051124\n",
            "FL: -0.037439410494178656\n",
            "GA: -0.07473914333578302\n",
            "IA: -0.03833392537318907\n",
            "IL: 0.14351362236871537\n",
            "IN: 0.02161329151382931\n",
            "MA: 0.04272693377484947\n",
            "MD: 0.008936650636904344\n",
            "MI: -0.007500276792804751\n",
            "MO: 0.01871183848148736\n",
            "NC: 0.0\n",
            "ND: 0.0\n",
            "NJ: -0.021834207763830278\n",
            "NY: -0.06790883059396721\n",
            "OR: -0.06743865372059647\n",
            "PA: 0.020398740099710752\n",
            "TX: -0.1080063083041975\n",
            "UT: -0.028838777945548077\n",
            "VA: 0.002416167244832783\n",
            "WA: 0.02735102758711086\n",
            "WI: -0.00016217603942226232\n",
            "USA: -0.023692220103843663\n",
            "United States: 0.022792503728256384\n"
          ]
        }
      ],
      "source": [
        "# Assuming linear_regression_model is your trained linear regression model\n",
        "coefficients = regression_model.coef_\n",
        "\n",
        "# Print coefficients and corresponding feature names\n",
        "for feature, coefficient in zip(X.columns, coefficients):\n",
        "    print(f\"{feature}: {coefficient}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbdUTetsgRlq"
      },
      "source": [
        "Let's print from largest to smallest in terms of magnitude:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6dPQtcsgdiz",
        "outputId": "23ab86c3-d470-4cf5-bcc7-f138e12749a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "common_cluster84_counts: -0.19528603235169736\n",
            "common_cluster496_counts: 0.16319496594053065\n",
            "common_cluster20_counts: 0.1614916896684704\n",
            "common_cluster224_counts: 0.16043499358396066\n",
            "common_cluster145_counts: -0.15056147240398027\n",
            "common_cluster105_counts: -0.14878135930662967\n",
            "common_cluster142_counts: -0.14529016105854844\n",
            "IL: 0.14351362236871537\n",
            "common_cluster57_counts: 0.13616491025323296\n",
            "common_cluster332_counts: -0.13483603180594597\n",
            "common_cluster18_counts: 0.13253736759690016\n",
            "common_cluster122_counts: -0.13200862080208015\n",
            "work_arrangement_cluster3_counts: 0.13157734915203118\n",
            "common_cluster27_counts: 0.12926305201273605\n",
            "common_cluster100_counts: -0.1288097727419905\n",
            "common_cluster177_counts: 0.12662336426446272\n",
            "common_cluster66_counts: -0.12237242013624235\n",
            "city_cluster23_counts: 0.12172765917274267\n",
            "common_cluster97_counts: -0.12119617908237043\n",
            "common_cluster221_counts: 0.11934649601821937\n",
            "common_cluster194_counts: -0.11876432231070823\n",
            "common_cluster247_counts: -0.11677798452198339\n",
            "common_cluster434_counts: -0.11623132443861087\n",
            "common_cluster388_counts: -0.11567181630332107\n",
            "work_arrangement_cluster2_counts: -0.11456496023285165\n",
            "common_cluster23_counts: 0.11363543635409779\n",
            "common_cluster176_counts: 0.11147439192861644\n",
            "common_cluster11_counts: -0.11035313268900035\n",
            "common_cluster197_counts: 0.110302051158503\n",
            "common_cluster347_counts: -0.10983014105108986\n",
            "common_cluster14_counts: 0.10929243197839297\n",
            "TX: -0.1080063083041975\n",
            "common_cluster314_counts: -0.10732124407998934\n",
            "common_cluster346_counts: -0.10556694946035197\n",
            "common_cluster214_counts: -0.10517754967606496\n",
            "common_cluster171_counts: 0.10487978190926707\n",
            "common_cluster284_counts: 0.10436263263384633\n",
            "common_cluster190_counts: 0.10433165400383346\n",
            "common_cluster167_counts: 0.10307193611788021\n",
            "common_cluster463_counts: 0.10260842122772451\n",
            "common_cluster59_counts: 0.10257067694574534\n",
            "work_arrangement_cluster6_counts: -0.10134072714359689\n",
            "common_cluster0_counts: -0.10102475734098516\n",
            "common_cluster160_counts: 0.09572814096064787\n",
            "common_cluster243_counts: 0.09463773600112121\n",
            "common_cluster138_counts: 0.0923439794377326\n",
            "common_cluster144_counts: -0.0907944273347813\n",
            "common_cluster64_counts: -0.08896163679389704\n",
            "common_cluster329_counts: 0.08767445731104927\n",
            "common_cluster153_counts: -0.08731234953656478\n",
            "common_cluster10_counts: 0.0872817123054643\n",
            "city_cluster10_counts: -0.08719274942099833\n",
            "common_cluster471_counts: 0.0867844846933231\n",
            "company_cluster10_counts: 0.08663206476766708\n",
            "common_cluster290_counts: -0.08586196810974817\n",
            "common_cluster168_counts: 0.08546137056867031\n",
            "common_cluster313_counts: 0.08477407826222509\n",
            "common_cluster205_counts: -0.08468668967972884\n",
            "common_cluster96_counts: -0.08332162401840038\n",
            "common_cluster238_counts: 0.08318427122222774\n",
            "common_cluster352_counts: -0.08304086757114273\n",
            "common_cluster175_counts: -0.08259643795366392\n",
            "work_arrangement_cluster0_counts: 0.08158961483000679\n",
            "common_cluster334_counts: -0.08133181410667875\n",
            "common_cluster9_counts: 0.081272470419058\n",
            "common_cluster192_counts: 0.08108428481935218\n",
            "common_cluster206_counts: 0.08073794484924629\n",
            "common_cluster265_counts: -0.07945420480910954\n",
            "common_cluster254_counts: 0.07921132345485705\n",
            "common_cluster146_counts: -0.07905913768094014\n",
            "common_cluster273_counts: -0.07905553862977827\n",
            "common_cluster16_counts: -0.07895611827870287\n",
            "common_cluster376_counts: 0.07884116353387453\n",
            "common_cluster28_counts: 0.07867103583200774\n",
            "common_cluster7_counts: -0.07834933190040484\n",
            "common_cluster357_counts: 0.07729757864312817\n",
            "common_cluster231_counts: 0.07728983666444209\n",
            "common_cluster40_counts: -0.0771028311213622\n",
            "common_cluster108_counts: -0.07687462857945374\n",
            "common_cluster154_counts: 0.07668664693994771\n",
            "common_cluster267_counts: -0.07666785074637814\n",
            "common_cluster209_counts: 0.07654874072992994\n",
            "common_cluster81_counts: -0.07651909517684642\n",
            "common_cluster230_counts: -0.07643242268391598\n",
            "common_cluster25_counts: 0.07619159687909569\n",
            "common_cluster103_counts: 0.07600472591177594\n",
            "common_cluster119_counts: 0.07567092018893222\n",
            "common_cluster429_counts: 0.07495067576613706\n",
            "common_cluster480_counts: 0.07493888456064732\n",
            "common_cluster482_counts: -0.07487882098835731\n",
            "common_cluster336_counts: 0.07487333855438806\n",
            "GA: -0.07473914333578302\n",
            "common_cluster41_counts: -0.0745061898640784\n",
            "common_cluster343_counts: -0.07439067965331483\n",
            "common_cluster382_counts: -0.07439067965331483\n",
            "common_cluster481_counts: -0.07350174789879743\n",
            "common_cluster65_counts: 0.0727225514901839\n",
            "common_cluster72_counts: 0.07264535871864274\n",
            "company_cluster78_counts: -0.07194182779184143\n",
            "company_cluster39_counts: 0.0716411924911093\n",
            "AR: 0.0716411924911093\n",
            "city_cluster4_counts: 0.07143506363584456\n",
            "common_cluster250_counts: 0.06948654490623657\n",
            "common_cluster489_counts: -0.06946492113875424\n",
            "CA: 0.06894836711193916\n",
            "common_cluster184_counts: -0.06860822311571843\n",
            "common_cluster413_counts: 0.06806924970181776\n",
            "NY: -0.06790883059396721\n",
            "common_cluster77_counts: -0.06789906461563186\n",
            "common_cluster323_counts: -0.06771916078958876\n",
            "common_cluster111_counts: 0.0676816408218378\n",
            "common_cluster342_counts: 0.06756793496907913\n",
            "OR: -0.06743865372059647\n",
            "common_cluster476_counts: -0.06735214675685906\n",
            "common_cluster348_counts: 0.06732356785516791\n",
            "common_cluster360_counts: -0.06676083182040093\n",
            "common_cluster241_counts: -0.0666197192306618\n",
            "common_cluster289_counts: -0.0666197192306618\n",
            "common_cluster203_counts: -0.06597628905251816\n",
            "common_cluster276_counts: 0.06554673481144441\n",
            "common_cluster70_counts: 0.0654985413193747\n",
            "common_cluster101_counts: 0.06529083443449536\n",
            "common_cluster33_counts: -0.06416193303711665\n",
            "common_cluster127_counts: -0.0639725907887039\n",
            "common_cluster455_counts: 0.06371055542793952\n",
            "company_cluster32_counts: 0.06371055542793952\n",
            "common_cluster235_counts: -0.06362482348200836\n",
            "common_cluster15_counts: 0.0635951933612277\n",
            "common_cluster51_counts: -0.0631590829504891\n",
            "common_cluster302_counts: -0.06311463606340904\n",
            "common_cluster29_counts: 0.06311027956431176\n",
            "common_cluster118_counts: 0.062696008678203\n",
            "common_cluster90_counts: -0.06254575755080771\n",
            "common_cluster246_counts: -0.06158015731128066\n",
            "common_cluster272_counts: -0.06158015731128066\n",
            "common_cluster325_counts: 0.06150582224599535\n",
            "common_cluster466_counts: 0.06149528025358149\n",
            "common_cluster13_counts: 0.06119439447983172\n",
            "common_cluster107_counts: -0.06092324691105934\n",
            "common_cluster370_counts: 0.06085089600763708\n",
            "common_cluster8_counts: 0.06041962991392335\n",
            "common_cluster208_counts: -0.060405719699092\n",
            "common_cluster327_counts: -0.06022598716801485\n",
            "common_cluster268_counts: 0.060135015855780065\n",
            "common_cluster442_counts: -0.0600826740763894\n",
            "common_cluster183_counts: 0.059931710863187215\n",
            "common_cluster305_counts: 0.059860241225316156\n",
            "common_cluster419_counts: 0.0592625435627092\n",
            "common_cluster308_counts: 0.05924220689483995\n",
            "common_cluster164_counts: 0.059100803731211106\n",
            "common_cluster372_counts: 0.058910481054847516\n",
            "common_cluster462_counts: -0.058388992260991694\n",
            "company_cluster49_counts: -0.058388992260991694\n",
            "city_cluster15_counts: -0.058388992260991694\n",
            "company_cluster23_counts: 0.05830424999701864\n",
            "common_cluster163_counts: -0.05827731800479131\n",
            "common_cluster369_counts: -0.05827731800479131\n",
            "common_cluster330_counts: -0.05821404283991983\n",
            "common_cluster189_counts: 0.05791683449278263\n",
            "common_cluster283_counts: -0.05786584356956609\n",
            "common_cluster493_counts: -0.05783590815166054\n",
            "company_cluster31_counts: -0.05783590815166054\n",
            "city_cluster51_counts: -0.05783590815166054\n",
            "common_cluster310_counts: 0.057677478285732095\n",
            "city_cluster3_counts: 0.05708963295740366\n",
            "common_cluster379_counts: -0.056290979532721344\n",
            "common_cluster156_counts: -0.05626596709557481\n",
            "common_cluster159_counts: 0.05532715680592769\n",
            "common_cluster139_counts: -0.055099986808592044\n",
            "common_cluster212_counts: -0.055056078008184406\n",
            "common_cluster452_counts: 0.05503417963514989\n",
            "common_cluster36_counts: -0.05494408268224821\n",
            "city_cluster33_counts: 0.054429008856638345\n",
            "company_cluster13_counts: 0.05409700463285052\n",
            "common_cluster281_counts: 0.054088869433578976\n",
            "common_cluster104_counts: -0.05408715878045925\n",
            "common_cluster202_counts: 0.053962395440991115\n",
            "common_cluster256_counts: -0.05395584685024492\n",
            "common_cluster1_counts: 0.05388115344764163\n",
            "common_cluster297_counts: 0.05360017435081247\n",
            "city_cluster5_counts: 0.053505111071785225\n",
            "common_cluster93_counts: 0.05336040917258131\n",
            "common_cluster106_counts: -0.05301334750093365\n",
            "common_cluster397_counts: -0.052783474730175986\n",
            "company_cluster52_counts: -0.052783474730175986\n",
            "common_cluster74_counts: -0.052644611896688884\n",
            "common_cluster188_counts: -0.05214760432473771\n",
            "common_cluster200_counts: 0.05202353399418557\n",
            "company_cluster24_counts: -0.05183873381327872\n",
            "common_cluster132_counts: 0.051311806028293286\n",
            "common_cluster444_counts: 0.051304210613862256\n",
            "common_cluster485_counts: 0.051304210613862256\n",
            "common_cluster114_counts: 0.05068446389015252\n",
            "common_cluster371_counts: 0.05057165395533119\n",
            "common_cluster378_counts: 0.050249376178846575\n",
            "common_cluster94_counts: 0.04974178369911726\n",
            "common_cluster498_counts: 0.04967208813047515\n",
            "common_cluster483_counts: -0.04958426459119503\n",
            "common_cluster148_counts: 0.049495320631111686\n",
            "common_cluster213_counts: -0.049236487761342436\n",
            "common_cluster402_counts: 0.048990874462057465\n",
            "common_cluster85_counts: 0.048896936783348034\n",
            "company_cluster19_counts: -0.04880716165976415\n",
            "common_cluster438_counts: -0.048615283568013624\n",
            "common_cluster257_counts: -0.04861399791692159\n",
            "common_cluster340_counts: 0.04854864227515325\n",
            "common_cluster182_counts: -0.04780921338648802\n",
            "common_cluster441_counts: -0.04761158863420786\n",
            "city_cluster8_counts: -0.047305671615532674\n",
            "common_cluster299_counts: -0.04693553498444698\n",
            "common_cluster31_counts: -0.04688543070009464\n",
            "common_cluster277_counts: 0.04687740000427435\n",
            "common_cluster185_counts: 0.04659078897957311\n",
            "common_cluster150_counts: -0.04640162764749362\n",
            "common_cluster147_counts: 0.04631429713236427\n",
            "company_cluster54_counts: 0.046195597086991586\n",
            "common_cluster3_counts: 0.04604276456888401\n",
            "common_cluster169_counts: -0.04537922192796337\n",
            "common_cluster410_counts: 0.04535126021145729\n",
            "common_cluster88_counts: 0.0449956072075476\n",
            "common_cluster240_counts: -0.04490198284179643\n",
            "common_cluster131_counts: 0.044747281719758426\n",
            "common_cluster373_counts: -0.04474397777406649\n",
            "city_cluster22_counts: -0.04474397777406649\n",
            "common_cluster109_counts: 0.04468011531360037\n",
            "common_cluster178_counts: 0.04429885710155587\n",
            "common_cluster102_counts: 0.044250798651874285\n",
            "common_cluster285_counts: -0.04414533461926174\n",
            "name_of_department/team_cluster0_counts: 0.04392527194732304\n",
            "common_cluster22_counts: 0.04364423401811214\n",
            "MA: 0.04272693377484947\n",
            "common_cluster117_counts: 0.04239844897527724\n",
            "common_cluster298_counts: -0.042359771651986115\n",
            "common_cluster296_counts: 0.042341873015361645\n",
            "common_cluster415_counts: 0.042341873015361645\n",
            "company_cluster57_counts: 0.042341873015361645\n",
            "city_cluster52_counts: 0.042341873015361645\n",
            "common_cluster386_counts: -0.04214231816430464\n",
            "common_cluster120_counts: 0.04209567438448426\n",
            "common_cluster63_counts: -0.04200478032588745\n",
            "city_cluster1_counts: 0.04193828204986035\n",
            "common_cluster338_counts: 0.04189049992431174\n",
            "common_cluster141_counts: -0.04180144589626043\n",
            "common_cluster174_counts: 0.04178726438262749\n",
            "common_cluster350_counts: 0.04159213561111387\n",
            "common_cluster422_counts: 0.04159213561111387\n",
            "company_cluster59_counts: 0.04159213561111387\n",
            "common_cluster307_counts: -0.041575407154774605\n",
            "city_cluster7_counts: -0.041345117749555196\n",
            "common_cluster361_counts: -0.04129821897683196\n",
            "common_cluster363_counts: -0.04129821897683196\n",
            "company_cluster22_counts: -0.04129821897683196\n",
            "name_of_department/team_cluster2_counts: -0.04043669568068709\n",
            "common_cluster337_counts: 0.04040701159540302\n",
            "common_cluster469_counts: 0.04031001666098414\n",
            "company_cluster38_counts: -0.03952776931488913\n",
            "city_cluster18_counts: -0.03952776931488913\n",
            "common_cluster395_counts: -0.03927922260012173\n",
            "common_cluster447_counts: -0.039271853491700426\n",
            "common_cluster82_counts: 0.03921968794017089\n",
            "common_cluster24_counts: 0.03904799599464914\n",
            "common_cluster35_counts: 0.038918861267019024\n",
            "common_cluster229_counts: -0.03860807175573858\n",
            "common_cluster260_counts: 0.0385397105456394\n",
            "company_cluster71_counts: -0.03833392537318907\n",
            "city_cluster41_counts: -0.03833392537318907\n",
            "IA: -0.03833392537318907\n",
            "company_cluster29_counts: 0.03787291293575959\n",
            "city_cluster34_counts: 0.03787291293575959\n",
            "common_cluster398_counts: -0.037439410494178656\n",
            "common_cluster474_counts: -0.037439410494178656\n",
            "company_cluster58_counts: -0.037439410494178656\n",
            "city_cluster39_counts: -0.037439410494178656\n",
            "FL: -0.037439410494178656\n",
            "common_cluster326_counts: 0.03734080964733187\n",
            "common_cluster470_counts: -0.03734041432236186\n",
            "common_cluster166_counts: 0.03724216608177353\n",
            "common_cluster69_counts: 0.03716591672838617\n",
            "common_cluster262_counts: 0.037062654698681675\n",
            "common_cluster406_counts: -0.036750873949398716\n",
            "common_cluster435_counts: -0.036750873949398716\n",
            "city_cluster17_counts: -0.036750873949398716\n",
            "common_cluster407_counts: 0.03637039357136405\n",
            "CO: -0.036138087809051124\n",
            "common_cluster126_counts: -0.036089183536289156\n",
            "common_cluster304_counts: 0.03604248320400638\n",
            "common_cluster477_counts: -0.0360047425274355\n",
            "common_cluster134_counts: 0.03586504247879068\n",
            "common_cluster155_counts: -0.03556546633323149\n",
            "common_cluster364_counts: 0.03552910501587195\n",
            "common_cluster414_counts: 0.03547181103341715\n",
            "common_cluster355_counts: 0.035371099449833826\n",
            "common_cluster385_counts: 0.035371099449833826\n",
            "name_of_department/team_cluster4_counts: 0.035371099449833826\n",
            "common_cluster478_counts: -0.03534329871137088\n",
            "common_cluster266_counts: 0.035214270627582846\n",
            "common_cluster6_counts: -0.034905316256727326\n",
            "common_cluster19_counts: -0.03488946836048462\n",
            "common_cluster165_counts: 0.034818559672122176\n",
            "common_cluster125_counts: 0.034743272453118285\n",
            "common_cluster280_counts: 0.034743272453118285\n",
            "common_cluster488_counts: 0.03426765408871468\n",
            "common_cluster195_counts: 0.03412245002317666\n",
            "common_cluster55_counts: 0.034098393209942984\n",
            "common_cluster409_counts: 0.0339349293298704\n",
            "city_cluster25_counts: 0.0339349293298704\n",
            "common_cluster417_counts: -0.033581972004706334\n",
            "common_cluster473_counts: -0.033581972004706334\n",
            "company_cluster45_counts: -0.033581972004706334\n",
            "common_cluster258_counts: 0.03355739581657535\n",
            "common_cluster193_counts: 0.03251646581145266\n",
            "common_cluster133_counts: 0.032352551395381235\n",
            "common_cluster318_counts: 0.032206469577602766\n",
            "common_cluster42_counts: 0.0320805292119415\n",
            "common_cluster253_counts: -0.03205184829993121\n",
            "common_cluster275_counts: -0.03205184829993121\n",
            "common_cluster223_counts: 0.031941878356494334\n",
            "common_cluster78_counts: -0.03188804652890103\n",
            "common_cluster464_counts: 0.0318563925543554\n",
            "common_cluster17_counts: -0.031492607389980845\n",
            "common_cluster136_counts: 0.03140794929376032\n",
            "common_cluster380_counts: -0.03127962063327693\n",
            "city_cluster30_counts: -0.03079007865564033\n",
            "common_cluster306_counts: 0.030728653351650606\n",
            "common_cluster421_counts: 0.030728653351650606\n",
            "company_cluster68_counts: 0.030728653351650606\n",
            "city_cluster31_counts: 0.030728653351650606\n",
            "common_cluster351_counts: 0.03036521979591813\n",
            "common_cluster368_counts: -0.03023219611836838\n",
            "common_cluster287_counts: -0.03013709781861348\n",
            "common_cluster312_counts: 0.029852440654392243\n",
            "common_cluster248_counts: 0.029732030720973628\n",
            "common_cluster362_counts: 0.029455240527423758\n",
            "common_cluster399_counts: 0.029455240527423758\n",
            "common_cluster449_counts: 0.029455240527423758\n",
            "company_cluster56_counts: 0.029455240527423758\n",
            "common_cluster317_counts: 0.029351571489177906\n",
            "common_cluster38_counts: -0.02921534094843967\n",
            "common_cluster99_counts: 0.02915783337492476\n",
            "common_cluster335_counts: 0.029102363199684067\n",
            "company_cluster5_counts: 0.029059297042216978\n",
            "company_cluster62_counts: -0.028838777945548077\n",
            "city_cluster37_counts: -0.028838777945548077\n",
            "UT: -0.028838777945548077\n",
            "common_cluster453_counts: -0.02866076858029014\n",
            "common_cluster242_counts: 0.028587510297197822\n",
            "company_cluster35_counts: -0.028132983547787406\n",
            "common_cluster423_counts: 0.02760380587019235\n",
            "common_cluster367_counts: -0.027423593883354847\n",
            "WA: 0.02735102758711086\n",
            "common_cluster211_counts: 0.027054090042974144\n",
            "common_cluster26_counts: -0.02697421716793033\n",
            "name_of_department/team_cluster1_counts: -0.026949396578893843\n",
            "common_cluster75_counts: 0.02691140653005408\n",
            "common_cluster71_counts: -0.026837594151010863\n",
            "common_cluster374_counts: -0.02647194629386628\n",
            "common_cluster251_counts: 0.02628253060110709\n",
            "company_cluster73_counts: 0.02628253060110709\n",
            "common_cluster286_counts: -0.02614429267794039\n",
            "company_cluster11_counts: -0.02614429267794039\n",
            "common_cluster443_counts: -0.026051295987723697\n",
            "common_cluster436_counts: -0.025952605047752993\n",
            "common_cluster282_counts: 0.02592301846469105\n",
            "common_cluster244_counts: -0.025853858646724445\n",
            "common_cluster181_counts: 0.025634066582845855\n",
            "common_cluster416_counts: -0.02531318183577194\n",
            "common_cluster490_counts: -0.02531318183577194\n",
            "company_cluster20_counts: -0.02531318183577194\n",
            "common_cluster98_counts: 0.025076214766012732\n",
            "common_cluster44_counts: 0.024953162170056747\n",
            "common_cluster322_counts: 0.024839084282486747\n",
            "common_cluster45_counts: 0.024823993183852394\n",
            "common_cluster2_counts: 0.024739920659176656\n",
            "common_cluster492_counts: -0.024182142954791\n",
            "common_cluster162_counts: 0.023747331214470122\n",
            "USA: -0.023692220103843663\n",
            "common_cluster47_counts: 0.023640326333345903\n",
            "common_cluster341_counts: -0.02361050068948927\n",
            "common_cluster270_counts: -0.023300610715885677\n",
            "common_cluster92_counts: -0.023127277308816786\n",
            "common_cluster91_counts: 0.023041071190074654\n",
            "common_cluster5_counts: -0.02295420112312413\n",
            "common_cluster210_counts: -0.02292903176663753\n",
            "common_cluster344_counts: -0.02292903176663753\n",
            "company_cluster14_counts: -0.02292903176663753\n",
            "name_of_department/team_cluster9_counts: -0.02292903176663753\n",
            "name_of_department/team_cluster15_counts: -0.02292903176663753\n",
            "city_cluster27_counts: -0.02292903176663753\n",
            "common_cluster179_counts: 0.022907493813753108\n",
            "United States: 0.022792503728256384\n",
            "common_cluster121_counts: -0.022627080067791214\n",
            "common_cluster383_counts: -0.022627080067791214\n",
            "company_cluster9_counts: -0.022627080067791214\n",
            "name_of_department/team_cluster5_counts: -0.022627080067791214\n",
            "city_cluster47_counts: -0.022627080067791214\n",
            "common_cluster87_counts: 0.022544295177125737\n",
            "common_cluster226_counts: 0.022477247907991826\n",
            "common_cluster218_counts: -0.022461112832186297\n",
            "common_cluster62_counts: -0.0222647652077863\n",
            "common_cluster393_counts: -0.02224498825036491\n",
            "common_cluster170_counts: -0.0221276505348231\n",
            "common_cluster222_counts: -0.0221276505348231\n",
            "common_cluster457_counts: -0.0221276505348231\n",
            "common_cluster459_counts: -0.0221276505348231\n",
            "company_cluster66_counts: -0.0221276505348231\n",
            "common_cluster428_counts: 0.02201193314361479\n",
            "common_cluster234_counts: -0.021938652454553204\n",
            "common_cluster151_counts: 0.02192574056146576\n",
            "common_cluster198_counts: 0.02192574056146576\n",
            "company_cluster33_counts: 0.02192574056146576\n",
            "name_of_department/team_cluster16_counts: 0.02192574056146576\n",
            "city_cluster28_counts: 0.02192574056146576\n",
            "common_cluster375_counts: -0.0218970499547563\n",
            "NJ: -0.021834207763830278\n",
            "city_cluster2_counts: 0.02181239214309855\n",
            "IN: 0.02161329151382931\n",
            "company_cluster44_counts: -0.021179885825993058\n",
            "name_of_department/team_cluster10_counts: -0.021179885825993058\n",
            "name_of_department/team_cluster11_counts: -0.021179885825993058\n",
            "city_cluster46_counts: -0.021179885825993058\n",
            "common_cluster204_counts: -0.020956942997329576\n",
            "common_cluster408_counts: -0.020956942997329576\n",
            "city_cluster45_counts: -0.020956942997329576\n",
            "common_cluster418_counts: -0.020872135750863705\n",
            "company_cluster7_counts: 0.020833470664767866\n",
            "common_cluster259_counts: 0.02074641276306782\n",
            "common_cluster349_counts: 0.02074641276306782\n",
            "company_cluster37_counts: 0.02074641276306782\n",
            "name_of_department/team_cluster14_counts: 0.02074641276306782\n",
            "city_cluster14_counts: 0.02074641276306782\n",
            "common_cluster316_counts: 0.020736154867045515\n",
            "company_cluster2_counts: 0.020736154867045515\n",
            "city_cluster48_counts: 0.020736154867045515\n",
            "common_cluster425_counts: -0.020710180703053027\n",
            "company_cluster15_counts: -0.020683317013422506\n",
            "common_cluster143_counts: 0.020664439245001047\n",
            "PA: 0.020398740099710752\n",
            "common_cluster450_counts: 0.020358533596397287\n",
            "common_cluster61_counts: 0.02033504743919816\n",
            "common_cluster353_counts: -0.020179445671312225\n",
            "common_cluster54_counts: 0.020116296810761297\n",
            "common_cluster115_counts: 0.019964595488261613\n",
            "common_cluster339_counts: 0.01991573740183688\n",
            "company_cluster12_counts: 0.01991573740183688\n",
            "common_cluster446_counts: 0.019733439313355382\n",
            "work_arrangement_cluster9_counts: 0.019733439313355382\n",
            "common_cluster249_counts: -0.019681393832661712\n",
            "common_cluster58_counts: 0.019525590148595527\n",
            "city_cluster12_counts: 0.0193710607357176\n",
            "common_cluster12_counts: -0.019370651676300726\n",
            "common_cluster303_counts: 0.0193133914860849\n",
            "common_cluster130_counts: -0.01925899658449816\n",
            "common_cluster295_counts: -0.019220486440253516\n",
            "company_cluster4_counts: -0.019177997496131093\n",
            "name_of_department/team_cluster8_counts: -0.019177997496131093\n",
            "common_cluster300_counts: -0.01901795544301205\n",
            "company_cluster26_counts: -0.01901795544301205\n",
            "name_of_department/team_cluster7_counts: -0.01901795544301205\n",
            "MO: 0.01871183848148736\n",
            "common_cluster173_counts: -0.01867020716118093\n",
            "city_cluster40_counts: -0.01867020716118093\n",
            "common_cluster274_counts: 0.018626098421307677\n",
            "company_cluster70_counts: 0.018531327349340838\n",
            "city_cluster49_counts: 0.018531327349340838\n",
            "common_cluster365_counts: -0.018416532253291127\n",
            "city_cluster16_counts: 0.01814972096791749\n",
            "common_cluster37_counts: -0.018038948568513485\n",
            "common_cluster319_counts: 0.01791925957681522\n",
            "common_cluster172_counts: -0.017756387011733134\n",
            "common_cluster34_counts: 0.017729825236806333\n",
            "common_cluster89_counts: 0.01751387957118557\n",
            "common_cluster475_counts: 0.017333614582220585\n",
            "company_cluster50_counts: 0.017333614582220585\n",
            "work_arrangement_cluster4_counts: 0.01701878702549289\n",
            "common_cluster392_counts: 0.017014027774459067\n",
            "common_cluster60_counts: 0.016803868901061714\n",
            "common_cluster396_counts: -0.016716026185962178\n",
            "common_cluster135_counts: -0.016632293940510162\n",
            "common_cluster113_counts: 0.016610842700378645\n",
            "common_cluster216_counts: 0.01643711678119495\n",
            "common_cluster479_counts: 0.01643711678119495\n",
            "company_cluster75_counts: 0.01643711678119495\n",
            "common_cluster404_counts: -0.01639819139730172\n",
            "common_cluster411_counts: -0.01639819139730172\n",
            "company_cluster53_counts: -0.01639819139730172\n",
            "company_cluster43_counts: 0.016176275697690617\n",
            "name_of_department/team_cluster20_counts: 0.016176275697690617\n",
            "city_cluster35_counts: -0.016144501617514215\n",
            "common_cluster67_counts: 0.01584289784213817\n",
            "common_cluster199_counts: 0.015278644454230446\n",
            "common_cluster320_counts: -0.015051138911905307\n",
            "work_arrangement_cluster8_counts: -0.01488211162629318\n",
            "common_cluster50_counts: -0.014870736810936574\n",
            "common_cluster358_counts: 0.014830420553376543\n",
            "name_of_department/team_cluster6_counts: 0.014830420553376543\n",
            "common_cluster196_counts: 0.014734606043901916\n",
            "work_arrangement_cluster7_counts: -0.014373995950822617\n",
            "min_salary: 0.014271424173008057\n",
            "common_cluster4_counts: 0.013424107117969986\n",
            "common_cluster445_counts: 0.012944856170133134\n",
            "company_cluster0_counts: 0.012944856170133134\n",
            "name_of_department/team_cluster17_counts: 0.012944856170133134\n",
            "common_cluster129_counts: 0.01286335695437455\n",
            "common_cluster440_counts: 0.01286335695437455\n",
            "name_of_department/team_cluster13_counts: 0.01286335695437455\n",
            "city_cluster44_counts: 0.01286335695437455\n",
            "common_cluster294_counts: 0.012280321864647191\n",
            "common_cluster237_counts: -0.011946775412606412\n",
            "common_cluster461_counts: 0.011940247848784655\n",
            "company_cluster34_counts: -0.01191639547605516\n",
            "common_cluster80_counts: 0.011792393502807665\n",
            "common_cluster112_counts: 0.011719516619230402\n",
            "common_cluster52_counts: -0.011425384046314505\n",
            "common_cluster180_counts: -0.011423231520500347\n",
            "common_cluster427_counts: 0.011364258217570838\n",
            "common_cluster403_counts: -0.011230556416093149\n",
            "common_cluster161_counts: -0.011190297625855546\n",
            "common_cluster426_counts: 0.011178544577039703\n",
            "common_cluster437_counts: 0.011178544577039703\n",
            "common_cluster149_counts: -0.010894911367205294\n",
            "common_cluster324_counts: -0.010894911367205294\n",
            "common_cluster420_counts: 0.010637462016583903\n",
            "city_cluster21_counts: -0.010589664195271492\n",
            "common_cluster83_counts: 0.010556931390590224\n",
            "company_cluster41_counts: 0.010556931390590224\n",
            "common_cluster497_counts: 0.010291414551035015\n",
            "common_cluster301_counts: -0.00981474944060608\n",
            "common_cluster454_counts: -0.009794534881492033\n",
            "common_cluster225_counts: 0.009596833594780632\n",
            "common_cluster233_counts: -0.009479569757486976\n",
            "common_cluster356_counts: -0.009342962695586942\n",
            "common_cluster354_counts: 0.00922621346258791\n",
            "common_cluster187_counts: 0.009040350223933465\n",
            "common_cluster315_counts: 0.009037612474630837\n",
            "common_cluster412_counts: 0.00898273161698726\n",
            "name_of_department/team_cluster19_counts: 0.00898273161698726\n",
            "common_cluster239_counts: 0.00896626061969767\n",
            "common_cluster433_counts: 0.00896626061969767\n",
            "common_cluster467_counts: 0.00896626061969767\n",
            "company_cluster64_counts: 0.00896626061969767\n",
            "MD: 0.008936650636904344\n",
            "common_cluster293_counts: 0.008909559614877351\n",
            "company_cluster8_counts: 0.008853354863302063\n",
            "common_cluster48_counts: -0.008738272671898695\n",
            "common_cluster86_counts: 0.008533748868210005\n",
            "common_cluster359_counts: 0.008399385534022844\n",
            "common_cluster152_counts: -0.008195279629803091\n",
            "common_cluster291_counts: 0.0078778490856306\n",
            "common_cluster32_counts: 0.007831400569617597\n",
            "common_cluster424_counts: -0.00782012830675441\n",
            "common_cluster494_counts: -0.007700658115965989\n",
            "company_cluster28_counts: -0.007700658115965989\n",
            "common_cluster432_counts: -0.007660547398154856\n",
            "city_cluster26_counts: -0.007610917382213353\n",
            "common_cluster39_counts: 0.007599461404372655\n",
            "common_cluster288_counts: 0.007550637639137809\n",
            "city_cluster9_counts: -0.007500276792804751\n",
            "MI: -0.007500276792804751\n",
            "common_cluster128_counts: 0.0073571967917226986\n",
            "common_cluster186_counts: 0.0073302574020250155\n",
            "common_cluster439_counts: 0.0073302574020250155\n",
            "common_cluster321_counts: -0.007196469863263921\n",
            "common_cluster79_counts: -0.006962281420102714\n",
            "common_cluster207_counts: 0.006814658385206559\n",
            "common_cluster381_counts: -0.00664763165269697\n",
            "common_cluster458_counts: -0.00664763165269697\n",
            "company_cluster6_counts: -0.00664763165269697\n",
            "city_cluster6_counts: -0.00664763165269697\n",
            "common_cluster245_counts: -0.006595344280318757\n",
            "name_of_department/team_cluster12_counts: -0.006514825173861788\n",
            "company_cluster16_counts: -0.006367322303624925\n",
            "city_cluster38_counts: -0.006367322303624925\n",
            "common_cluster95_counts: -0.005911121981210691\n",
            "name_of_department/team_cluster3_counts: -0.005882819976962529\n",
            "common_cluster30_counts: 0.005769957708157358\n",
            "company_cluster36_counts: 0.005679575789590684\n",
            "city_cluster43_counts: 0.005679575789590684\n",
            "common_cluster278_counts: -0.005615278208046574\n",
            "company_cluster40_counts: -0.005615278208046574\n",
            "common_cluster269_counts: 0.005458071132915507\n",
            "common_cluster21_counts: -0.005448467511588118\n",
            "company_cluster47_counts: 0.0051457072755175075\n",
            "company_cluster1_counts: -0.005035655392773155\n",
            "common_cluster157_counts: -0.004897267440746016\n",
            "company_cluster74_counts: -0.004897267440746016\n",
            "common_cluster451_counts: -0.004711623534350086\n",
            "common_cluster252_counts: -0.004491893783399124\n",
            "company_cluster42_counts: 0.004199692767011422\n",
            "common_cluster227_counts: 0.004137694959964389\n",
            "common_cluster124_counts: 0.004012015522191818\n",
            "common_cluster261_counts: 0.004012015522191818\n",
            "common_cluster389_counts: 0.004012015522191818\n",
            "common_cluster49_counts: -0.0036394208081406334\n",
            "max_salary: -0.003580867394416598\n",
            "common_cluster191_counts: -0.0035707971835923346\n",
            "common_cluster255_counts: -0.003490261244700636\n",
            "common_cluster116_counts: -0.0034305209129407467\n",
            "common_cluster53_counts: 0.00322379437754846\n",
            "company_cluster48_counts: 0.0030755280603034785\n",
            "common_cluster271_counts: -0.0026810900637003025\n",
            "common_cluster279_counts: -0.002552124132850369\n",
            "common_cluster405_counts: 0.002416167244832783\n",
            "company_cluster72_counts: 0.002416167244832783\n",
            "city_cluster42_counts: 0.002416167244832783\n",
            "VA: 0.002416167244832783\n",
            "common_cluster110_counts: 0.002352263466621046\n",
            "common_cluster487_counts: -0.002179191219379366\n",
            "common_cluster456_counts: 0.002006007761095909\n",
            "city_cluster29_counts: 0.002006007761095909\n",
            "common_cluster43_counts: 0.0019341534826712893\n",
            "company_cluster63_counts: -0.0018971154703405907\n",
            "common_cluster387_counts: -0.00184555814186123\n",
            "common_cluster68_counts: 0.0016090624198920184\n",
            "common_cluster201_counts: 0.0014919082634174304\n",
            "company_cluster18_counts: 0.0014843428140323\n",
            "common_cluster56_counts: -0.0014019898293216974\n",
            "common_cluster309_counts: 0.0013369980516895266\n",
            "common_cluster220_counts: -0.0012143029991578541\n",
            "common_cluster333_counts: 0.001022186934642625\n",
            "company_cluster60_counts: 0.001022186934642625\n",
            "common_cluster46_counts: -0.0009170653070962927\n",
            "common_cluster123_counts: 0.0008888771491879222\n",
            "city_cluster0_counts: -0.0008508891525140019\n",
            "company_cluster3_counts: 0.0007536678778636233\n",
            "common_cluster217_counts: 0.0006514634889230042\n",
            "common_cluster73_counts: 0.0006073140994269505\n",
            "common_cluster331_counts: -0.0005369279927208998\n",
            "work_arrangement_cluster1_counts: 0.0001706507772141555\n",
            "common_cluster76_counts: 0.00016988422289129345\n",
            "WI: -0.00016217603942226232\n",
            "common_cluster328_counts: 0.00011589821260046991\n",
            "common_cluster311_counts: -9.126303139502662e-05\n",
            "city_cluster50_counts: -9.126303139502662e-05\n",
            "common_cluster137_counts: 0.0\n",
            "common_cluster140_counts: 0.0\n",
            "common_cluster158_counts: 0.0\n",
            "common_cluster215_counts: 0.0\n",
            "common_cluster219_counts: 0.0\n",
            "common_cluster228_counts: 0.0\n",
            "common_cluster232_counts: 0.0\n",
            "common_cluster236_counts: 0.0\n",
            "common_cluster263_counts: 0.0\n",
            "common_cluster264_counts: 0.0\n",
            "common_cluster292_counts: 0.0\n",
            "common_cluster345_counts: 0.0\n",
            "common_cluster366_counts: 0.0\n",
            "common_cluster377_counts: 0.0\n",
            "common_cluster384_counts: 0.0\n",
            "common_cluster390_counts: 0.0\n",
            "common_cluster391_counts: 0.0\n",
            "common_cluster394_counts: 0.0\n",
            "common_cluster400_counts: 0.0\n",
            "common_cluster401_counts: 0.0\n",
            "common_cluster430_counts: 0.0\n",
            "common_cluster431_counts: 0.0\n",
            "common_cluster448_counts: 0.0\n",
            "common_cluster460_counts: 0.0\n",
            "common_cluster465_counts: 0.0\n",
            "common_cluster468_counts: 0.0\n",
            "common_cluster472_counts: 0.0\n",
            "common_cluster484_counts: 0.0\n",
            "common_cluster486_counts: 0.0\n",
            "common_cluster491_counts: 0.0\n",
            "common_cluster495_counts: 0.0\n",
            "common_cluster499_counts: 0.0\n",
            "company_cluster17_counts: 0.0\n",
            "company_cluster21_counts: 0.0\n",
            "company_cluster25_counts: 0.0\n",
            "company_cluster27_counts: 0.0\n",
            "company_cluster30_counts: 0.0\n",
            "company_cluster46_counts: 0.0\n",
            "company_cluster51_counts: 0.0\n",
            "company_cluster55_counts: 0.0\n",
            "company_cluster61_counts: 0.0\n",
            "company_cluster65_counts: 0.0\n",
            "company_cluster67_counts: 0.0\n",
            "company_cluster69_counts: 0.0\n",
            "company_cluster76_counts: 0.0\n",
            "company_cluster77_counts: 0.0\n",
            "company_cluster79_counts: 0.0\n",
            "name_of_department/team_cluster18_counts: 0.0\n",
            "city_cluster11_counts: 0.0\n",
            "city_cluster13_counts: 0.0\n",
            "city_cluster19_counts: 0.0\n",
            "city_cluster20_counts: 0.0\n",
            "city_cluster24_counts: 0.0\n",
            "city_cluster32_counts: 0.0\n",
            "city_cluster36_counts: 0.0\n",
            "work_arrangement_cluster5_counts: 0.0\n",
            "AZ: 0.0\n",
            "NC: 0.0\n",
            "ND: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Assuming linear_regression_model is your trained linear regression model\n",
        "coefficients = regression_model.coef_\n",
        "\n",
        "# Create a list of tuples containing feature names and their corresponding coefficients\n",
        "coefficients_with_names = [(feature, coefficient) for feature, coefficient in zip(X.columns, coefficients)]\n",
        "\n",
        "# Sort the list of tuples based on the absolute values of coefficients\n",
        "sorted_coefficients = sorted(coefficients_with_names, key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "# Print sorted coefficients\n",
        "for feature, coefficient in sorted_coefficients:\n",
        "    print(f\"{feature}: {coefficient}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh8RL9f0gk__"
      },
      "source": [
        "The first thing to note is that there are many columns with 0 as their coefficient, meaning the model does not consider them at all. Most of these columns with 0 import are cluster columns. Maybe it'd be useful to look at the distribution of values in those columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wbLapeMhOxk",
        "outputId": "413bd9df-8f1f-4838-8389-f597ba391292"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value counts for 'common_cluster137_counts':\n",
            "0    106\n",
            "5      1\n",
            "Name: common_cluster137_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster140_counts':\n",
            "0    105\n",
            "4      1\n",
            "3      1\n",
            "Name: common_cluster140_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster158_counts':\n",
            "0    106\n",
            "3      1\n",
            "Name: common_cluster158_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster215_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster215_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster219_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster219_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster228_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster228_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster232_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster232_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster236_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: common_cluster236_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster263_counts':\n",
            "0    106\n",
            "3      1\n",
            "Name: common_cluster263_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster264_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster264_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster292_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster292_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster345_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster345_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster366_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster366_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster377_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster377_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster384_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster384_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster390_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster390_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster391_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster391_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster394_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster394_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster400_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster400_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster401_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster401_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster430_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: common_cluster430_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster431_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster431_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster448_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster448_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster460_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster460_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster465_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster465_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster468_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster468_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster472_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster472_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster484_counts':\n",
            "0    105\n",
            "3      1\n",
            "1      1\n",
            "Name: common_cluster484_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster486_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster486_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster491_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster491_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster495_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster495_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster499_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster499_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster17_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: company_cluster17_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster21_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster21_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster25_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster25_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster27_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster27_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster30_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster30_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster46_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster46_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster51_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster51_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster55_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster55_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster61_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster61_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster65_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster65_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster67_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster67_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster69_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster69_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster76_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster76_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster77_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster77_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster79_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster79_counts, dtype: int64\n",
            "\n",
            "Value counts for 'name_of_department/team_cluster18_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: name_of_department/team_cluster18_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster11_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: city_cluster11_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster13_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: city_cluster13_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster19_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: city_cluster19_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster20_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: city_cluster20_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster24_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: city_cluster24_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster32_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: city_cluster32_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster36_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: city_cluster36_counts, dtype: int64\n",
            "\n",
            "Value counts for 'work_arrangement_cluster5_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: work_arrangement_cluster5_counts, dtype: int64\n",
            "\n",
            "Value counts for 'AZ':\n",
            "0    106\n",
            "1      1\n",
            "Name: AZ, dtype: int64\n",
            "\n",
            "Value counts for 'NC':\n",
            "0    106\n",
            "1      1\n",
            "Name: NC, dtype: int64\n",
            "\n",
            "Value counts for 'ND':\n",
            "0    106\n",
            "1      1\n",
            "Name: ND, dtype: int64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Identify features with coefficients equal to 0\n",
        "zero_coefficient_features = [feature for feature, coefficient in zip(X.columns, coefficients) if coefficient == 0]\n",
        "\n",
        "# Print the value counts for columns with zero coefficients\n",
        "for feature in zero_coefficient_features:\n",
        "    print(f\"Value counts for '{feature}':\")\n",
        "    print(df[feature].value_counts())\n",
        "    print()  # Add an empty line for separation between different features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E58vYL4hczA"
      },
      "source": [
        "First of all, note that this about 50 or so columns. Next, note that their distribuition contains all but one or two of their values being 0. So we will probably want to drop columns like this because they are just taking up space. This also means that our clustering algos are sometimes assigning only 1 example phrase to a cluster, which makes sense, given how our choice of n_clusters compares to the number of phrases we chose for the corresponding cluster (they are the same order of magnitude; the number of phrases is not much bigger than the number of cluster). Let's look at our features of highest import.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ttImSqmi0pr"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "common_cluster84_counts: -0.19528603235169736\n",
        "common_cluster496_counts: 0.16319496594053065\n",
        "common_cluster20_counts: 0.1614916896684704\n",
        "common_cluster224_counts: 0.16043499358396066\n",
        "common_cluster145_counts: -0.15056147240398027\n",
        "common_cluster105_counts: -0.14878135930662967\n",
        "common_cluster142_counts: -0.14529016105854844\n",
        "IL: 0.14351362236871537\n",
        "common_cluster57_counts: 0.13616491025323296\n",
        "common_cluster332_counts: -0.13483603180594597\n",
        "common_cluster18_counts: 0.13253736759690016\n",
        "common_cluster122_counts: -0.13200862080208015\n",
        "work_arrangement_cluster3_counts: 0.13157734915203118\n",
        "common_cluster27_counts: 0.12926305201273605\n",
        "common_cluster100_counts: -0.1288097727419905\n",
        "common_cluster177_counts: 0.12662336426446272\n",
        "common_cluster66_counts: -0.12237242013624235\n",
        "city_cluster23_counts: 0.12172765917274267\n",
        "common_cluster97_counts: -0.12119617908237043\n",
        "common_cluster221_counts: 0.11934649601821937\n",
        "common_cluster194_counts: -0.11876432231070823\n",
        "common_cluster247_counts: -0.11677798452198339\n",
        "common_cluster434_counts: -0.11623132443861087\n",
        "common_cluster388_counts: -0.11567181630332107\n",
        "work_arrangement_cluster2_counts: -0.11456496023285165\n",
        "common_cluster23_counts: 0.11363543635409779\n",
        "common_cluster176_counts: 0.11147439192861644\n",
        "common_cluster11_counts: -0.11035313268900035\n",
        "common_cluster197_counts: 0.110302051158503\n",
        "common_cluster347_counts: -0.10983014105108986\n",
        "common_cluster14_counts: 0.10929243197839297\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PefUHJqPjE7u"
      },
      "source": [
        "First of all, I'm just very curious what some of these clusters translate back to. Obviously IL means the job is based out of Illinois, and apparently I have a strong desire to work for a company out of Illinois. That's surprising. Interestingly, min_salary had a small positive correlation with job desirability and max_salary had an even weaker negative correlation with job desirability. Maybe I am subconsciously looking more at the bottom of salary ranges than the top."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxz52kChk2Ob",
        "outputId": "a50ed8fe-cc85-4837-fb1a-a9cd76342a87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "common_cluster84_counts\n",
            "feature common_cluster84_counts\n",
            "coeff -0.19528603235169736\n",
            "phrases_in_cluister 98                                Marketing\n",
            "127                               Marketing\n",
            "295                                Branding\n",
            "296                               Marketing\n",
            "501                      Marketing Services\n",
            "925                 Perform market research\n",
            "1174                      Marketing efforts\n",
            "1732             Email marketing experience\n",
            "1740       BSc in STEM, Marketing, Business\n",
            "1802    Proficiency in marketing principles\n",
            "Name: phrase, dtype: object\n",
            "common_cluster496_counts\n",
            "feature common_cluster496_counts\n",
            "coeff 0.16319496594053065\n",
            "phrases_in_cluister 223     Interdisciplinary Artificial Intelligence Rese...\n",
            "278                                           AI Research\n",
            "280                                           AI research\n",
            "283                                   Data & AI solutions\n",
            "309                                             AI Center\n",
            "319     AI for Autonomy Lab researches applying AI-rel...\n",
            "1274                             Expressing AI dedication\n",
            "1302    Report directly into the Head of Artificial In...\n",
            "1405                                  Solve AI challenges\n",
            "1411                               Shape the future of AI\n",
            "1528                                       AI/ML interest\n",
            "1745    Expertise in AI research topics and methodologies\n",
            "Name: phrase, dtype: object\n",
            "common_cluster20_counts\n",
            "feature common_cluster20_counts\n",
            "coeff 0.1614916896684704\n",
            "phrases_in_cluister 0            Engineering\n",
            "7            Engineering\n",
            "8            Engineering\n",
            "10           Engineering\n",
            "13           Engineering\n",
            "15           Engineering\n",
            "17           Engineering\n",
            "19           Engineering\n",
            "25           Engineering\n",
            "32           Engineering\n",
            "35           Engineering\n",
            "40           Engineering\n",
            "44           Engineering\n",
            "54           Engineering\n",
            "56           Engineering\n",
            "58           Engineering\n",
            "63           Engineering\n",
            "65           Engineering\n",
            "68           Engineering\n",
            "74           Engineering\n",
            "78           Engineering\n",
            "79           Engineering\n",
            "82           Engineering\n",
            "87           Engineering\n",
            "88           Engineering\n",
            "89           Engineering\n",
            "91           Engineering\n",
            "92           Engineering\n",
            "94           Engineering\n",
            "105          Engineering\n",
            "107          Engineering\n",
            "109          Engineering\n",
            "112          Engineering\n",
            "120          Engineering\n",
            "122          Engineering\n",
            "124          Engineering\n",
            "125          Engineering\n",
            "131          Engineering\n",
            "133          Engineering\n",
            "136          Engineering\n",
            "139          Engineering\n",
            "140          Engineering\n",
            "147          Engineering\n",
            "148          Engineering\n",
            "150          Engineering\n",
            "152          Engineering\n",
            "155          Engineering\n",
            "158          Engineering\n",
            "161          Engineering\n",
            "164          Engineering\n",
            "173          Engineering\n",
            "176          Engineering\n",
            "178          Engineering\n",
            "181          Engineering\n",
            "433         Construction\n",
            "450    Civil Engineering\n",
            "733          Engineering\n",
            "735          Engineering\n",
            "770          Engineering\n",
            "Name: phrase, dtype: object\n",
            "common_cluster224_counts\n",
            "feature common_cluster224_counts\n",
            "coeff 0.16043499358396066\n",
            "phrases_in_cluister 799               Collaborate with cross-functional teams\n",
            "860               Collaborate with cross-functional teams\n",
            "898                  Interact with cross-functional teams\n",
            "1005              Collaborate with cross functional teams\n",
            "1059              Collaborate with cross-functional teams\n",
            "1108    Collaborate with cross-functional teams for AI...\n",
            "1251              Collaborate with cross-functional teams\n",
            "1294              Collaborate with cross-functional teams\n",
            "1727    Ability to collaborate with cross-functional t...\n",
            "Name: phrase, dtype: object\n",
            "common_cluster145_counts\n",
            "feature common_cluster145_counts\n",
            "coeff -0.15056147240398027\n",
            "phrases_in_cluister 274              Academic support through tutoring\n",
            "603                                          Tutor\n",
            "624                                     Peer Tutor\n",
            "1073     Provide academic support through tutoring\n",
            "1719    Minimum grade of B in course being tutored\n",
            "2088      Previous tutoring or teaching experience\n",
            "Name: phrase, dtype: object\n",
            "common_cluster105_counts\n",
            "feature common_cluster105_counts\n",
            "coeff -0.14878135930662967\n",
            "phrases_in_cluister 36                 Accounting/Auditing\n",
            "42                 Accounting/Auditing\n",
            "51                 Accounting/Auditing\n",
            "591                         Accountant\n",
            "1608    AA in Accounting or equivalent\n",
            "Name: phrase, dtype: object\n",
            "common_cluster142_counts\n",
            "feature common_cluster142_counts\n",
            "coeff -0.14529016105854844\n",
            "phrases_in_cluister 265     Triage Software Engineer - Initial defect anal...\n",
            "617                              Triage Software Engineer\n",
            "834                 Triage security and compliance issues\n",
            "952                                         issues triage\n",
            "957                                       incident triage\n",
            "1050    Initial defect analysis - Triage defects - Mon...\n",
            "Name: phrase, dtype: object\n",
            "feature IL\n",
            "coefficient 0.14351362236871537\n",
            "common_cluster57_counts\n",
            "feature common_cluster57_counts\n",
            "coeff 0.13616491025323296\n",
            "phrases_in_cluister 577                             Machine Learning Engineer\n",
            "580                      Senior Machine Learning Engineer\n",
            "601                             Machine Learning Engineer\n",
            "607                        Machine Learning SoC Architect\n",
            "619                             Machine Learning Engineer\n",
            "636                           Machine Learning Consultant\n",
            "652                     Machine Learning Systems Engineer\n",
            "660                             Machine Learning Engineer\n",
            "665     Systems Research Engineer, Machine Learning Sy...\n",
            "677                             Machine Learning Engineer\n",
            "682                             Machine Learning Engineer\n",
            "1006                            Deep learning engineering\n",
            "Name: phrase, dtype: object\n",
            "common_cluster332_counts\n",
            "feature common_cluster332_counts\n",
            "coeff -0.13483603180594597\n",
            "phrases_in_cluister 889     Assists in preparing working papers for extern...\n",
            "1223                         Maintains patient data files\n",
            "1224                                Collects patient data\n",
            "1226                  Prepares patient records for audits\n",
            "Name: phrase, dtype: object\n",
            "common_cluster18_counts\n",
            "feature common_cluster18_counts\n",
            "coeff 0.13253736759690016\n",
            "phrases_in_cluister 30     Information Technology - Other - Consulting\n",
            "364                                  IT Consulting\n",
            "371                                  IT Consulting\n",
            "373                                  IT Consulting\n",
            "375                                  IT Consulting\n",
            "383                                  IT Consulting\n",
            "393                  IT Services and IT Consulting\n",
            "414                                  IT Consulting\n",
            "445                                  IT Consulting\n",
            "469                                  IT Consulting\n",
            "492                                  IT Consulting\n",
            "496                                  IT Consulting\n",
            "514                                  IT Consulting\n",
            "524                                  IT Consulting\n",
            "533                                  IT Consulting\n",
            "544                  IT Services and IT Consulting\n",
            "547                                  IT Consulting\n",
            "Name: phrase, dtype: object\n",
            "common_cluster122_counts\n",
            "feature common_cluster122_counts\n",
            "coeff -0.13200862080208015\n",
            "phrases_in_cluister 887    Prepares complex reconciliations\n",
            "927                      Reconciliation\n",
            "931               Reconcile chargebacks\n",
            "Name: phrase, dtype: object\n",
            "work_arrangement_cluster3_counts\n",
            "feature work_arrangement_cluster3_counts\n",
            "coeff 0.13157734915203118\n",
            "phrases_in_cluister 91                     Remote\n",
            "113                    Remote\n",
            "123    Full remote, PST hours\n",
            "141                    Remote\n",
            "156                    Remote\n",
            "170                    Remote\n",
            "173                    remote\n",
            "174                    Remote\n",
            "180                    Remote\n",
            "181                    REMOTE\n",
            "189                    Remote\n",
            "191              Local remote\n",
            "202                    Remote\n",
            "207                    Remote\n",
            "213                    Remote\n",
            "216                    Remote\n",
            "Name: phrase, dtype: object\n",
            "common_cluster27_counts\n",
            "feature common_cluster27_counts\n",
            "coeff 0.12926305201273605\n",
            "phrases_in_cluister 213                           Low Latency Trading Systems\n",
            "355                                 Forex trading systems\n",
            "585             C++ Low Latency Trading Systems Developer\n",
            "865                Developing low latency trading systems\n",
            "1643    3+ years designing and developing trading infr...\n",
            "Name: phrase, dtype: object\n",
            "common_cluster100_counts\n",
            "feature common_cluster100_counts\n",
            "coeff -0.1288097727419905\n",
            "phrases_in_cluister 100    Assistant Manager\n",
            "142           Management\n",
            "627    Assistant Manager\n",
            "703             Director\n",
            "741      Manager On Duty\n",
            "Name: phrase, dtype: object\n",
            "common_cluster177_counts\n",
            "feature common_cluster177_counts\n",
            "coeff 0.12662336426446272\n",
            "phrases_in_cluister 1762     Strong math and algorithm development background\n",
            "1806                          Strong technical background\n",
            "1894    Background in Physical Sciences, Computer Scie...\n",
            "1925                     Strong background in CS and math\n",
            "1988                            Linear algebra background\n",
            "2029     Background in machine learning or related fields\n",
            "Name: phrase, dtype: object\n",
            "common_cluster66_counts\n",
            "feature common_cluster66_counts\n",
            "coeff -0.12237242013624235\n",
            "phrases_in_cluister 49                       Customer Service\n",
            "72                       Customer Service\n",
            "919              Provide customer service\n",
            "1143             Provide customer service\n",
            "1424     Help customer accomplish mission\n",
            "1771              Customer service skills\n",
            "1863    Excellent customer service skills\n",
            "Name: phrase, dtype: object\n",
            "city_cluster23_counts\n",
            "feature city_cluster23_counts\n",
            "coeff 0.12172765917274267\n",
            "phrases_in_cluister 8      Chicago\n",
            "16     Chicago\n",
            "101    Chicago\n",
            "Name: phrase, dtype: object\n",
            "common_cluster97_counts\n",
            "feature common_cluster97_counts\n",
            "coeff -0.12119617908237043\n",
            "phrases_in_cluister 915                            Anticipate customer needs\n",
            "977                          Automate customer scenarios\n",
            "995    Automate order generation and integrate compli...\n",
            "Name: phrase, dtype: object\n",
            "common_cluster221_counts\n",
            "feature common_cluster221_counts\n",
            "coeff 0.11934649601821937\n",
            "phrases_in_cluister 622                                          C++ Engineer\n",
            "946                                         C++ Developer\n",
            "1290                           Guide development with C++\n",
            "1324           Subject matter expert for kernel internals\n",
            "1543                                        C++ expertise\n",
            "1564                                       C++ experience\n",
            "2165    Experience in Fortran, C++, MPI, scientific co...\n",
            "Name: phrase, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Assuming linear_regression_model is your trained linear regression model\n",
        "coefficients = regression_model.coef_\n",
        "\n",
        "# Create a list of tuples containing feature names and their corresponding coefficients\n",
        "coefficients_with_names = [(feature, coefficient) for feature, coefficient in zip(X.columns, coefficients)]\n",
        "\n",
        "# Sort the list of tuples based on the absolute values of coefficients\n",
        "sorted_coefficients = sorted(coefficients_with_names, key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "# Assuming sorted_coefficients is the sorted list of coefficients\n",
        "top_20_coefficients = sorted_coefficients[:20]\n",
        "\n",
        "singular_corpus_columns = ['company', 'name_of_department/team', 'city']\n",
        "\n",
        "# Print sorted coefficients\n",
        "for feature, coefficient in top_20_coefficients:\n",
        "    one_hot_col = True\n",
        "    for col in singular_corpus_columns:\n",
        "      if col in feature:\n",
        "        clusters_df = singular_corpus_clusters_df_dict[col]\n",
        "        one_hot_col = False\n",
        "        keyword = col\n",
        "        break\n",
        "    if 'common' in feature:\n",
        "      clusters_df = common_clusters_df\n",
        "      one_hot_col = False\n",
        "      keyword = 'common'\n",
        "    elif 'work_arrangement' in feature:\n",
        "      clusters_df = work_arrangement_clusters_df\n",
        "      one_hot_col = False\n",
        "      keyword = 'work_arrangement'\n",
        "    if not one_hot_col:\n",
        "      print(feature)\n",
        "      cluster_num_string = feature.split(f\"{keyword}_cluster\")[1]\n",
        "      cluster_num = int(cluster_num_string.split(\"_counts\")[0])\n",
        "      # Filter the DataFrame to get phrases in the specified cluster\n",
        "      phrases_in_cluster = clusters_df[clusters_df['cluster_label'] == cluster_num]['phrase']\n",
        "      print(\"feature\", feature)\n",
        "      print(\"coeff\", coefficient)\n",
        "      print(\"phrases_in_cluister\", phrases_in_cluster)\n",
        "    else:\n",
        "      print(\"feature\", feature)\n",
        "      print(\"coefficient\", coefficient)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boPQBFomyRNV"
      },
      "source": [
        "Interesting! So the model picked up on the fact that I have an aversion to marketing. That cluster was the feature of highest import, with a substantial negative correlation with job desirability of -.195. The feature of second highest import is the cluster containing \"AI Research\"! It has a coefficient of .163. So far the model has picked up on some good information. The feature of next highest import is the cluster that contains the word \"Engineering\", with a coefficient of .161, but that cluster does contain Civil Engineering and Construction as well, which are not in my wheelhouse. What's number 4? The cluster that contains \"collaborate across cross-functional teams\" and has a coeff of .16. #5 is the cluster that contains the word \"tutor\" and has a coeff of -.15. This is quite insightful, as I have had a bad experience attempting to tutor someone. Now I want to visualize a distribution of my feature coefficients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "2fnydMJj0opE",
        "outputId": "018e7959-1831-4be3-a255-fb4ed68970db"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "coefficients = regression_model.coef_\n",
        "\n",
        "# Plot a histogram of coefficients\n",
        "plt.hist(coefficients, bins=10, color='skyblue', edgecolor='black')\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Coefficients')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f71YOhoO1D3l"
      },
      "source": [
        "It is interesting that around 500 of our approximately 700+ features have coefficients with absolute value less than .05. This is about 70% of our features. I will go back to looking at value counts of the least important features, to see if we can make a general assumption about the distribution of their data. I look at the distributions in the 100 least important features. Then I will do the same for the 100 most important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuYaA3QB1q-Z",
        "outputId": "067eccdd-b281-4bd3-805c-73b93ce83b4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value counts for 'common_cluster49_counts':\n",
            "0    104\n",
            "1      3\n",
            "Name: common_cluster49_counts, dtype: int64\n",
            "\n",
            "Value counts for 'max_salary':\n",
            "200.000    80\n",
            "130.000     2\n",
            "220.000     2\n",
            "170.000     2\n",
            "93.600      1\n",
            "140.000     1\n",
            "150.000     1\n",
            "216.646     1\n",
            "122.000     1\n",
            "90.000      1\n",
            "132.000     1\n",
            "385.000     1\n",
            "275.000     1\n",
            "288.000     1\n",
            "289.863     1\n",
            "162.000     1\n",
            "173.000     1\n",
            "223.600     1\n",
            "236.000     1\n",
            "100.000     1\n",
            "189.000     1\n",
            "133.000     1\n",
            "414.000     1\n",
            "175.000     1\n",
            "297.300     1\n",
            "Name: max_salary, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster191_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: common_cluster191_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster255_counts':\n",
            "0    103\n",
            "1      3\n",
            "2      1\n",
            "Name: common_cluster255_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster116_counts':\n",
            "0    102\n",
            "1      5\n",
            "Name: common_cluster116_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster53_counts':\n",
            "0    93\n",
            "1    14\n",
            "Name: common_cluster53_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster48_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster48_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster271_counts':\n",
            "0    104\n",
            "1      3\n",
            "Name: common_cluster271_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster279_counts':\n",
            "0    103\n",
            "1      4\n",
            "Name: common_cluster279_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster405_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster405_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster72_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster72_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster42_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: city_cluster42_counts, dtype: int64\n",
            "\n",
            "Value counts for 'VA':\n",
            "0    105\n",
            "1      2\n",
            "Name: VA, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster110_counts':\n",
            "0    104\n",
            "2      2\n",
            "1      1\n",
            "Name: common_cluster110_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster487_counts':\n",
            "0    103\n",
            "1      4\n",
            "Name: common_cluster487_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster456_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: common_cluster456_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster29_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: city_cluster29_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster43_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: common_cluster43_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster63_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster63_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster387_counts':\n",
            "0    104\n",
            "1      3\n",
            "Name: common_cluster387_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster68_counts':\n",
            "0    100\n",
            "1      6\n",
            "2      1\n",
            "Name: common_cluster68_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster201_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: common_cluster201_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster18_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: company_cluster18_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster56_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster56_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster309_counts':\n",
            "0    104\n",
            "1      3\n",
            "Name: common_cluster309_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster220_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: common_cluster220_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster333_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster333_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster60_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster60_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster46_counts':\n",
            "0    105\n",
            "2      1\n",
            "1      1\n",
            "Name: common_cluster46_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster123_counts':\n",
            "0    103\n",
            "1      3\n",
            "2      1\n",
            "Name: common_cluster123_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster0_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: city_cluster0_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster3_counts':\n",
            "0    100\n",
            "1      7\n",
            "Name: company_cluster3_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster217_counts':\n",
            "0    102\n",
            "1      4\n",
            "2      1\n",
            "Name: common_cluster217_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster73_counts':\n",
            "0    98\n",
            "1     9\n",
            "Name: common_cluster73_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster331_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: common_cluster331_counts, dtype: int64\n",
            "\n",
            "Value counts for 'work_arrangement_cluster1_counts':\n",
            "0    59\n",
            "1    48\n",
            "Name: work_arrangement_cluster1_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster76_counts':\n",
            "0    102\n",
            "1      3\n",
            "2      2\n",
            "Name: common_cluster76_counts, dtype: int64\n",
            "\n",
            "Value counts for 'WI':\n",
            "0    105\n",
            "1      2\n",
            "Name: WI, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster328_counts':\n",
            "0    102\n",
            "1      5\n",
            "Name: common_cluster328_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster311_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster311_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster50_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: city_cluster50_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster137_counts':\n",
            "0    106\n",
            "5      1\n",
            "Name: common_cluster137_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster140_counts':\n",
            "0    105\n",
            "4      1\n",
            "3      1\n",
            "Name: common_cluster140_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster158_counts':\n",
            "0    106\n",
            "3      1\n",
            "Name: common_cluster158_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster215_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster215_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster219_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster219_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster228_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster228_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster232_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster232_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster236_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: common_cluster236_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster263_counts':\n",
            "0    106\n",
            "3      1\n",
            "Name: common_cluster263_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster264_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster264_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster292_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster292_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster345_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster345_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster366_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster366_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster377_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster377_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster384_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster384_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster390_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster390_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster391_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster391_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster394_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster394_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster400_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster400_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster401_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster401_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster430_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: common_cluster430_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster431_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster431_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster448_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster448_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster460_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster460_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster465_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster465_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster468_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster468_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster472_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster472_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster484_counts':\n",
            "0    105\n",
            "3      1\n",
            "1      1\n",
            "Name: common_cluster484_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster486_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster486_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster491_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster491_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster495_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster495_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster499_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: common_cluster499_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster17_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: company_cluster17_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster21_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster21_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster25_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster25_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster27_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster27_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster30_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster30_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster46_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster46_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster51_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster51_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster55_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster55_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster61_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster61_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster65_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster65_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster67_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster67_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster69_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster69_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster76_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster76_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster77_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster77_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster79_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster79_counts, dtype: int64\n",
            "\n",
            "Value counts for 'name_of_department/team_cluster18_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: name_of_department/team_cluster18_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster11_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: city_cluster11_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster13_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: city_cluster13_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster19_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: city_cluster19_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster20_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: city_cluster20_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster24_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: city_cluster24_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster32_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: city_cluster32_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster36_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: city_cluster36_counts, dtype: int64\n",
            "\n",
            "Value counts for 'work_arrangement_cluster5_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: work_arrangement_cluster5_counts, dtype: int64\n",
            "\n",
            "Value counts for 'AZ':\n",
            "0    106\n",
            "1      1\n",
            "Name: AZ, dtype: int64\n",
            "\n",
            "Value counts for 'NC':\n",
            "0    106\n",
            "1      1\n",
            "Name: NC, dtype: int64\n",
            "\n",
            "Value counts for 'ND':\n",
            "0    106\n",
            "1      1\n",
            "Name: ND, dtype: int64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Assuming linear_regression_model is your trained linear regression model\n",
        "coefficients = regression_model.coef_\n",
        "\n",
        "# Create a list of tuples containing feature names and their corresponding coefficients\n",
        "coefficients_with_names = [(feature, coefficient) for feature, coefficient in zip(X.columns, coefficients)]\n",
        "\n",
        "# Sort the list of tuples based on the absolute values of coefficients\n",
        "sorted_coefficients = sorted(coefficients_with_names, key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "# Print sorted coefficients\n",
        "for feature, coefficient in sorted_coefficients[-100:]:\n",
        "    print(f\"Value counts for '{feature}':\")\n",
        "    print(df_copy[feature].value_counts())\n",
        "    print()  # Add an empty line for separation between different features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cljv4bMm2hOr"
      },
      "source": [
        "We see that all but one of these 100 weakest feature columns have extremely uninteresting distributions of having almost only 0s. The only one with an interesting distribution is max_salary, which is a feature that I thought would have a bigger coefficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BZr8VXp23_j",
        "outputId": "466f2ecf-171d-4a59-c7ac-4885c96408d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value counts for 'common_cluster84_counts':\n",
            "0    103\n",
            "1      2\n",
            "2      1\n",
            "6      1\n",
            "Name: common_cluster84_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster496_counts':\n",
            "0    98\n",
            "1     7\n",
            "2     1\n",
            "3     1\n",
            "Name: common_cluster496_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster20_counts':\n",
            "0    52\n",
            "1    51\n",
            "2     4\n",
            "Name: common_cluster20_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster224_counts':\n",
            "0    98\n",
            "1     9\n",
            "Name: common_cluster224_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster145_counts':\n",
            "0    105\n",
            "1      1\n",
            "5      1\n",
            "Name: common_cluster145_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster105_counts':\n",
            "0    104\n",
            "2      2\n",
            "1      1\n",
            "Name: common_cluster105_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster142_counts':\n",
            "0    104\n",
            "1      1\n",
            "2      1\n",
            "3      1\n",
            "Name: common_cluster142_counts, dtype: int64\n",
            "\n",
            "Value counts for 'IL':\n",
            "0    103\n",
            "1      4\n",
            "Name: IL, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster57_counts':\n",
            "0    95\n",
            "1    12\n",
            "Name: common_cluster57_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster332_counts':\n",
            "0    105\n",
            "1      1\n",
            "3      1\n",
            "Name: common_cluster332_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster18_counts':\n",
            "0    91\n",
            "1    15\n",
            "2     1\n",
            "Name: common_cluster18_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster122_counts':\n",
            "0    105\n",
            "1      1\n",
            "2      1\n",
            "Name: common_cluster122_counts, dtype: int64\n",
            "\n",
            "Value counts for 'work_arrangement_cluster3_counts':\n",
            "0    92\n",
            "1    14\n",
            "2     1\n",
            "Name: work_arrangement_cluster3_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster27_counts':\n",
            "0    104\n",
            "1      2\n",
            "3      1\n",
            "Name: common_cluster27_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster100_counts':\n",
            "0    104\n",
            "1      2\n",
            "3      1\n",
            "Name: common_cluster100_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster177_counts':\n",
            "0    101\n",
            "1      6\n",
            "Name: common_cluster177_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster66_counts':\n",
            "0    101\n",
            "1      5\n",
            "2      1\n",
            "Name: common_cluster66_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster23_counts':\n",
            "0    104\n",
            "1      3\n",
            "Name: city_cluster23_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster97_counts':\n",
            "0    104\n",
            "1      3\n",
            "Name: common_cluster97_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster221_counts':\n",
            "0    100\n",
            "1      7\n",
            "Name: common_cluster221_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster194_counts':\n",
            "0    106\n",
            "3      1\n",
            "Name: common_cluster194_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster247_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster247_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster434_counts':\n",
            "0    104\n",
            "1      3\n",
            "Name: common_cluster434_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster388_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster388_counts, dtype: int64\n",
            "\n",
            "Value counts for 'work_arrangement_cluster2_counts':\n",
            "0    86\n",
            "1    21\n",
            "Name: work_arrangement_cluster2_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster23_counts':\n",
            "0    94\n",
            "1     9\n",
            "3     2\n",
            "2     2\n",
            "Name: common_cluster23_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster176_counts':\n",
            "0    104\n",
            "1      2\n",
            "3      1\n",
            "Name: common_cluster176_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster11_counts':\n",
            "0    103\n",
            "1      4\n",
            "Name: common_cluster11_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster197_counts':\n",
            "0    96\n",
            "1    11\n",
            "Name: common_cluster197_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster347_counts':\n",
            "0    106\n",
            "5      1\n",
            "Name: common_cluster347_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster14_counts':\n",
            "0    67\n",
            "1    35\n",
            "2     5\n",
            "Name: common_cluster14_counts, dtype: int64\n",
            "\n",
            "Value counts for 'TX':\n",
            "0    97\n",
            "1    10\n",
            "Name: TX, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster314_counts':\n",
            "0    103\n",
            "1      3\n",
            "2      1\n",
            "Name: common_cluster314_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster346_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster346_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster214_counts':\n",
            "0    104\n",
            "1      3\n",
            "Name: common_cluster214_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster171_counts':\n",
            "0    103\n",
            "1      2\n",
            "3      1\n",
            "2      1\n",
            "Name: common_cluster171_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster284_counts':\n",
            "0    106\n",
            "3      1\n",
            "Name: common_cluster284_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster190_counts':\n",
            "0    100\n",
            "1      6\n",
            "2      1\n",
            "Name: common_cluster190_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster167_counts':\n",
            "0    103\n",
            "1      4\n",
            "Name: common_cluster167_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster463_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster463_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster59_counts':\n",
            "0    101\n",
            "1      4\n",
            "2      2\n",
            "Name: common_cluster59_counts, dtype: int64\n",
            "\n",
            "Value counts for 'work_arrangement_cluster6_counts':\n",
            "0    103\n",
            "1      4\n",
            "Name: work_arrangement_cluster6_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster0_counts':\n",
            "0    101\n",
            "1      5\n",
            "3      1\n",
            "Name: common_cluster0_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster160_counts':\n",
            "0    102\n",
            "1      5\n",
            "Name: common_cluster160_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster243_counts':\n",
            "0    105\n",
            "1      1\n",
            "3      1\n",
            "Name: common_cluster243_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster138_counts':\n",
            "0    105\n",
            "3      1\n",
            "2      1\n",
            "Name: common_cluster138_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster144_counts':\n",
            "0    105\n",
            "2      1\n",
            "1      1\n",
            "Name: common_cluster144_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster64_counts':\n",
            "0    103\n",
            "1      4\n",
            "Name: common_cluster64_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster329_counts':\n",
            "0    102\n",
            "1      5\n",
            "Name: common_cluster329_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster153_counts':\n",
            "0    101\n",
            "1      5\n",
            "2      1\n",
            "Name: common_cluster153_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster10_counts':\n",
            "0    101\n",
            "1      6\n",
            "Name: common_cluster10_counts, dtype: int64\n",
            "\n",
            "Value counts for 'city_cluster10_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: city_cluster10_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster471_counts':\n",
            "0    103\n",
            "1      3\n",
            "2      1\n",
            "Name: common_cluster471_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster10_counts':\n",
            "0    104\n",
            "1      3\n",
            "Name: company_cluster10_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster290_counts':\n",
            "0    100\n",
            "1      7\n",
            "Name: common_cluster290_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster168_counts':\n",
            "0    102\n",
            "1      5\n",
            "Name: common_cluster168_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster313_counts':\n",
            "0    104\n",
            "1      3\n",
            "Name: common_cluster313_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster205_counts':\n",
            "0    102\n",
            "1      5\n",
            "Name: common_cluster205_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster96_counts':\n",
            "0    105\n",
            "1      1\n",
            "2      1\n",
            "Name: common_cluster96_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster238_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster238_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster352_counts':\n",
            "0    101\n",
            "1      6\n",
            "Name: common_cluster352_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster175_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster175_counts, dtype: int64\n",
            "\n",
            "Value counts for 'work_arrangement_cluster0_counts':\n",
            "1    98\n",
            "0     9\n",
            "Name: work_arrangement_cluster0_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster334_counts':\n",
            "0    104\n",
            "1      3\n",
            "Name: common_cluster334_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster9_counts':\n",
            "0    77\n",
            "1    28\n",
            "2     1\n",
            "3     1\n",
            "Name: common_cluster9_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster192_counts':\n",
            "0    102\n",
            "1      4\n",
            "2      1\n",
            "Name: common_cluster192_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster206_counts':\n",
            "0    103\n",
            "1      3\n",
            "2      1\n",
            "Name: common_cluster206_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster265_counts':\n",
            "0    104\n",
            "1      3\n",
            "Name: common_cluster265_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster254_counts':\n",
            "0    101\n",
            "1      6\n",
            "Name: common_cluster254_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster146_counts':\n",
            "0    102\n",
            "1      5\n",
            "Name: common_cluster146_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster273_counts':\n",
            "0    105\n",
            "2      1\n",
            "1      1\n",
            "Name: common_cluster273_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster16_counts':\n",
            "0    98\n",
            "1     8\n",
            "3     1\n",
            "Name: common_cluster16_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster376_counts':\n",
            "0    98\n",
            "1     9\n",
            "Name: common_cluster376_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster28_counts':\n",
            "0    87\n",
            "1    20\n",
            "Name: common_cluster28_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster7_counts':\n",
            "0    99\n",
            "1     7\n",
            "2     1\n",
            "Name: common_cluster7_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster357_counts':\n",
            "0    103\n",
            "1      3\n",
            "2      1\n",
            "Name: common_cluster357_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster231_counts':\n",
            "0    105\n",
            "3      1\n",
            "1      1\n",
            "Name: common_cluster231_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster40_counts':\n",
            "0    103\n",
            "1      4\n",
            "Name: common_cluster40_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster108_counts':\n",
            "0    103\n",
            "1      3\n",
            "2      1\n",
            "Name: common_cluster108_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster154_counts':\n",
            "0    99\n",
            "1     7\n",
            "2     1\n",
            "Name: common_cluster154_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster267_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster267_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster209_counts':\n",
            "0    103\n",
            "1      4\n",
            "Name: common_cluster209_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster81_counts':\n",
            "0    105\n",
            "1      1\n",
            "2      1\n",
            "Name: common_cluster81_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster230_counts':\n",
            "0    104\n",
            "1      3\n",
            "Name: common_cluster230_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster25_counts':\n",
            "0    99\n",
            "1     8\n",
            "Name: common_cluster25_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster103_counts':\n",
            "0    99\n",
            "1     6\n",
            "2     2\n",
            "Name: common_cluster103_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster119_counts':\n",
            "0    103\n",
            "1      4\n",
            "Name: common_cluster119_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster429_counts':\n",
            "0    103\n",
            "1      4\n",
            "Name: common_cluster429_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster480_counts':\n",
            "0    104\n",
            "1      3\n",
            "Name: common_cluster480_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster482_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster482_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster336_counts':\n",
            "0    99\n",
            "1     7\n",
            "2     1\n",
            "Name: common_cluster336_counts, dtype: int64\n",
            "\n",
            "Value counts for 'GA':\n",
            "0    105\n",
            "1      2\n",
            "Name: GA, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster41_counts':\n",
            "0    98\n",
            "1     9\n",
            "Name: common_cluster41_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster343_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: common_cluster343_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster382_counts':\n",
            "0    105\n",
            "1      2\n",
            "Name: common_cluster382_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster481_counts':\n",
            "0    106\n",
            "2      1\n",
            "Name: common_cluster481_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster65_counts':\n",
            "0    98\n",
            "1     9\n",
            "Name: common_cluster65_counts, dtype: int64\n",
            "\n",
            "Value counts for 'common_cluster72_counts':\n",
            "0    99\n",
            "1     8\n",
            "Name: common_cluster72_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster78_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster78_counts, dtype: int64\n",
            "\n",
            "Value counts for 'company_cluster39_counts':\n",
            "0    106\n",
            "1      1\n",
            "Name: company_cluster39_counts, dtype: int64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Assuming linear_regression_model is your trained linear regression model\n",
        "coefficients = regression_model.coef_\n",
        "\n",
        "# Create a list of tuples containing feature names and their corresponding coefficients\n",
        "coefficients_with_names = [(feature, coefficient) for feature, coefficient in zip(X.columns, coefficients)]\n",
        "\n",
        "# Sort the list of tuples based on the absolute values of coefficients\n",
        "sorted_coefficients = sorted(coefficients_with_names, key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "# Print sorted coefficients\n",
        "for feature, coefficient in sorted_coefficients[:100]:\n",
        "    print(f\"Value counts for '{feature}':\")\n",
        "    print(df_copy[feature].value_counts())\n",
        "    print()  # Add an empty line for separation between different features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_Tk0vmL4HhB"
      },
      "source": [
        "In general, we see more interesting distributions for the features of highest import. Meaning that there are more examples of data points having values not equal to the mode of the column for those columns.\n",
        "\n",
        "So for our first modification to our feature engineering process, we may drop the columns that have only 1 example of the non-majority class in them. This could really help us both time-wise and model accuracy-wise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLAaZn0G498L"
      },
      "source": [
        "We will try this now to drop certain columns from the df_copy and then we will retrain the linear regression model to see if accuracy and mae get boosted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqpRG9D75PP9",
        "outputId": "ebd2c644-a2e6-4fd3-e655-69702a8c2977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.7401814227005018\n",
            "accuracy is 0.45454545454545453\n",
            "(107, 464)\n",
            "(107, 693)\n"
          ]
        }
      ],
      "source": [
        "copycat = df_copy.copy()\n",
        "for column in copycat.columns:\n",
        "    if copycat[column].value_counts().max() == copycat.shape[0] - 1:\n",
        "        copycat.drop(column, axis=1, inplace=True)\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "# Assuming df_encoded is your dataframe with one-hot encoded features and target variable\n",
        "# Split the data into features (X) and target variable (y)\n",
        "y = copycat['rating']  # Target variable\n",
        "X = copycat.drop(columns=['rating'])  # Features\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=68)\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing data\n",
        "# Train a regression model instead of SVM classifier\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regression_model.predict(X_test)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "\n",
        "print(\"accuracy is\", accuracy)\n",
        "\n",
        "print(copycat.shape)\n",
        "print(df_copy.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8-L_lta6udC"
      },
      "source": [
        "So as it turns out dropping those columns to make the smaller dataframe copycat with only 464 columns resulted in much worse predictions. Accuracy was an awful .45 and MAE was a quite poor .74. Clearly we should not adopt this method we just tried of dropping columns with extreme imbalance in their data distributions. But what else can we do on the feature engineering side to get increased model accuracy? Before we completely abandon copycat, let's see if any of the tree-based algorithms do better on copycat.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hADjx3IP8TM8",
        "outputId": "37ec3eee-5769-4d61-a6f7-90c11fd03aec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5909090909090909\n",
            "mae: 0.5454545454545454\n",
            "[2 2 2 3 2 2 2 2 2 3 2 2 2 2 2 2 2 3 2 2 2 3]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(max_depth=None, max_features='auto', min_samples_leaf=1, min_samples_split=5, n_estimators=300, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mae:\", mae)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCNWcovK8eku"
      },
      "source": [
        "So off the bat we got the highest accuracy we saw last time from the Random Forest with the larger dataframe, but with the smaller datafram. Let's do a Grid Search and see if we can get better numbers for our best estimator of Random Forest models with this smaller copycat dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksFgCVjE9qjL",
        "outputId": "a5cdfdb0-7b9c-441c-9b6a-8ac286cf538d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "Accuracy: 0.5454545454545454\n",
            "MAE: 0.522665142924398\n"
          ]
        }
      ],
      "source": [
        "#import xgboost as xgb\n",
        "#from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "# Iterate over columns and fill NaN values with the mode of each column\n",
        "'''for col in df_copy.columns:\n",
        "  print(col)\n",
        "  mode_val = df_copy[col].mode()[0]\n",
        "  print(mode_val)  # Get the mode value for the column\n",
        "  df_copy[col].fillna(mode_val, inplace=True)  # Fill NaN values with the mode'''\n",
        "\n",
        "\n",
        "'''# Assuming df_encoded is your dataframe with one-hot encoded features and target variable\n",
        "# Split the data into features (X) and target variable (y)\n",
        "y = df_copy['rating']  # Target variable\n",
        "X = df_copy.drop(columns=['rating'])  # Features\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=68)'''\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 300, 500],        # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20],             # Maximum depth of the trees\n",
        "    'min_samples_split': [2, 5, 10],         # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4],           # Minimum number of samples required to be at a leaf node\n",
        "    'max_features': ['auto', 'sqrt', 'log2'] # Number of features to consider when looking for the best split\n",
        "}\n",
        "\n",
        "rf_classifier = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Define your custom scoring function\n",
        "def custom_accuracy_score(y_true, y_pred):\n",
        "    # Custom calculation of accuracy\n",
        "    # For example, let's consider accuracy for class 1 only\n",
        "    y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "    accuracy = accuracy_score(y_true, y_pred_rounded)\n",
        "    return accuracy\n",
        "\n",
        "# Make a scorer object using your custom scoring function\n",
        "custom_scorer = make_scorer(custom_accuracy_score)\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, scoring=custom_scorer, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Test the classifier on the testing data using the best hyperparameters\n",
        "best_rf_classifier = grid_search.best_estimator_\n",
        "y_pred = best_rf_classifier.predict(X_test)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"MAE:\", mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ2SRBfC_m-x",
        "outputId": "5dba5ded-a906-49fe-d85d-872ae973802e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5454545454545454\n",
            "MAE: 0.48863636363636354\n"
          ]
        }
      ],
      "source": [
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"MAE:\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksLGlqC8BdWi"
      },
      "source": [
        "This experiment yielded the same results as before:\n",
        "Best Hyperparameters: {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
        "Accuracy: 0.5909090909090909"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbWZj0-gBjde",
        "outputId": "faf29ed9-c763-4442-eb75-684bde87f740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mae: 0.45454545454545453\n",
            "[2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ],
      "source": [
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mae:\", mae)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWEIFq_ylpAk"
      },
      "source": [
        "So the unfortunate thing is that when I wrote the code for feature engineering the dataframe, I used the same variable names for the clusters dataframes of the different corpi that I used to store the data on phrases, their rows, and their clusters, so that I cannot access that data for the different corpi. I am going to have to modify my code to use different variable names for the different clusters dataframes. Then I'll rerun the dataframe generation, feature engineering step with modified code, and then the linear regression. Then I will run the above code to understand which phrases were of highest import. The modified feature engineering code is below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmBjVbUJqsQk",
        "outputId": "b549e26a-c917-45fa-ba27-640322a010ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-28-0d5d73abac8b>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-28-0d5d73abac8b>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-28-0d5d73abac8b>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-28-0d5d73abac8b>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-28-0d5d73abac8b>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-28-0d5d73abac8b>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-28-0d5d73abac8b>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-28-0d5d73abac8b>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-28-0d5d73abac8b>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-28-0d5d73abac8b>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:83: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-28-0d5d73abac8b>:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:83: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-28-0d5d73abac8b>:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:83: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-28-0d5d73abac8b>:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:133: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-28-0d5d73abac8b>:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "<ipython-input-28-0d5d73abac8b>:133: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-28-0d5d73abac8b>:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-28-0d5d73abac8b>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-28-0d5d73abac8b>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "common_corpus_columns = ['job_function', 'description_of_product/service', 'industries', 'position_name', 'broader_role_name',\n",
        "                         'responsibilities', 'goals/objectives', 'required_qualifications', 'preferred_qualifications', 'benefits']\n",
        "\n",
        "singular_corpus_columns = ['company', 'name_of_department/team', 'city']\n",
        "\n",
        "work_arrangement_columns = ['employment_type', 'work_arrangement']\n",
        "\n",
        "categorical_label_columns = ['state', 'country']\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-large\")\n",
        "model = AutoModel.from_pretrained(\"thenlper/gte-large\")\n",
        "\n",
        "def average_pool(last_hidden_states: Tensor,\n",
        "                 attention_mask: Tensor) -> Tensor:\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "phrases = []\n",
        "row_labels = []\n",
        "for col in common_corpus_columns:\n",
        "  new_col_data = []\n",
        "  for index, value in df[col].iteritems():\n",
        "    if type(value) == list:\n",
        "      # Tokenize the input texts\n",
        "      for phrase in value:\n",
        "        phrases.append(phrase)\n",
        "        row_labels.append(index)\n",
        "    else:\n",
        "      phrases.append(str(value))\n",
        "      row_labels.append(index)\n",
        "      value = [str(value)]\n",
        "    batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model(**batch_dict)\n",
        "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "    # (Optionally) normalize embeddings\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "  df[f'{col}_vectors'] = new_col_data\n",
        "\n",
        "vector_cols = [f'{col}_vectors' for col in common_corpus_columns]\n",
        "phrase_vecs_list = []\n",
        "for col in vector_cols:\n",
        "  for i in df[col]:\n",
        "    for j in i:\n",
        "      phrase_vecs_list.append(j)\n",
        "kmeans = KMeans(n_clusters=500, random_state=57)\n",
        "kmeans.fit(phrase_vecs_list)\n",
        "\n",
        "for i in range(500):\n",
        "  column_name = f'common_cluster{i}_counts'  # Generate column name\n",
        "  df[column_name] = 0  # Fill the column with zeros\n",
        "\n",
        "cluster_labels = kmeans.labels_\n",
        "# Associate phrases with cluster labels\n",
        "data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "common_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "for i in range(row_labels[-1] + 1):\n",
        "  clusters_in_row = clusters_df.loc[common_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "  # Generate value counts\n",
        "  counts = Counter(clusters_in_row)\n",
        "  for cluster in counts.keys():\n",
        "    df.at[i, f'common_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "n_clusters_scale_factor = {'city': .5, 'company': .75, 'name_of_department/team': .2}\n",
        "singular_corpus_clusters_df_dict = {}\n",
        "for col in singular_corpus_columns:\n",
        "  phrases = []\n",
        "  row_labels = []\n",
        "  new_col_data = []\n",
        "  for index, value in df[col].iteritems():\n",
        "    if type(value) == list:\n",
        "      # Tokenize the input texts\n",
        "      for phrase in value:\n",
        "        phrases.append(phrase)\n",
        "        row_labels.append(index)\n",
        "    else:\n",
        "      phrases.append(str(value))\n",
        "      row_labels.append(index)\n",
        "      value = [str(value)]\n",
        "    batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model(**batch_dict)\n",
        "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "    # (Optionally) normalize embeddings\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "  df[f'{col}_vectors'] = new_col_data\n",
        "  vector_col = f'{col}_vectors'\n",
        "  phrase_vecs_list = []\n",
        "  for i in df[vector_col]:\n",
        "    for j in i:\n",
        "      phrase_vecs_list.append(j)\n",
        "  n_clusters = int(df.shape[0]*n_clusters_scale_factor[col])\n",
        "  kmeans = KMeans(n_clusters=n_clusters, random_state=57)\n",
        "  kmeans.fit(phrase_vecs_list)\n",
        "\n",
        "  for i in range(n_clusters):\n",
        "    column_name = f'{col}_cluster{i}_counts'  # Generate column name\n",
        "    df[column_name] = 0  # Fill the column with zeros\n",
        "\n",
        "  cluster_labels = kmeans.labels_\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "  clusters_df = pd.DataFrame(data)\n",
        "  singular_corpus_clusters_df_dict[col] = clusters_df\n",
        "\n",
        "  for i in range(row_labels[-1] + 1):\n",
        "    clusters_in_row = clusters_df.loc[clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      df.at[i, f'{col}_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "phrases = []\n",
        "row_labels = []\n",
        "for col in work_arrangement_columns:\n",
        "  new_col_data = []\n",
        "  for index, value in df[col].iteritems():\n",
        "    if type(value) == list:\n",
        "      # Tokenize the input texts\n",
        "      for phrase in value:\n",
        "        phrases.append(phrase)\n",
        "        row_labels.append(index)\n",
        "    else:\n",
        "      phrases.append(str(value))\n",
        "      row_labels.append(index)\n",
        "      value = [str(value)]\n",
        "    batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model(**batch_dict)\n",
        "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "    # (Optionally) normalize embeddings\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "  df[f'{col}_vectors'] = new_col_data\n",
        "\n",
        "vector_cols = [f'{col}_vectors' for col in work_arrangement_columns]\n",
        "phrase_vecs_list = []\n",
        "for col in vector_cols:\n",
        "  for i in df[col]:\n",
        "    for j in i:\n",
        "      phrase_vecs_list.append(j)\n",
        "kmeans = KMeans(n_clusters=10, random_state=57)\n",
        "kmeans.fit(phrase_vecs_list)\n",
        "\n",
        "for i in range(10):\n",
        "  column_name = f'work_arrangement_cluster{i}_counts'  # Generate column name\n",
        "  df[column_name] = 0  # Fill the column with zeros\n",
        "\n",
        "cluster_labels = kmeans.labels_\n",
        "# Associate phrases with cluster labels\n",
        "data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "work_arrangement_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "for i in range(row_labels[-1] + 1):\n",
        "  clusters_in_row = clusters_df.loc[clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "  # Generate value counts\n",
        "  counts = Counter(clusters_in_row)\n",
        "  for cluster in counts.keys():\n",
        "    df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "for col in categorical_label_columns:\n",
        "  # Perform one-hot encoding\n",
        "  one_hot_encoded_df = pd.get_dummies(df[col])\n",
        "\n",
        "  # Concatenate the original dataframe with the one-hot encoded dataframe\n",
        "  df = pd.concat([df, one_hot_encoded_df], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iSXXXr3461d"
      },
      "source": [
        "Sticking with the sentence transformer embeddings for now, how can we tweak our process to hopefully get better performance? One idea is to simply reduce our number of clusters. I'm not too optimistic about this though, as we already saw that removing rare phrase types didn't change anything or even made our models worse, in the case of linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUHwQrj2PPM9"
      },
      "source": [
        "We will modify our feature engineering code to only create 300 clusters for the common corpus, not 500."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv2cZmZmPNyD",
        "outputId": "a869c656-bd2a-438b-8e11-bc0263049c3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-b9593d390b75>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-35-b9593d390b75>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-35-b9593d390b75>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-35-b9593d390b75>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-35-b9593d390b75>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-35-b9593d390b75>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-35-b9593d390b75>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-35-b9593d390b75>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-35-b9593d390b75>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-35-b9593d390b75>:31: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:83: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-35-b9593d390b75>:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:83: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-35-b9593d390b75>:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:83: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-35-b9593d390b75>:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:133: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-35-b9593d390b75>:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "<ipython-input-35-b9593d390b75>:133: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in df[col].iteritems():\n",
            "<ipython-input-35-b9593d390b75>:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-35-b9593d390b75>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
            "<ipython-input-35-b9593d390b75>:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "common_corpus_columns = ['job_function', 'description_of_product/service', 'industries', 'position_name', 'broader_role_name',\n",
        "                         'responsibilities', 'goals/objectives', 'required_qualifications', 'preferred_qualifications', 'benefits']\n",
        "\n",
        "singular_corpus_columns = ['company', 'name_of_department/team', 'city']\n",
        "\n",
        "work_arrangement_columns = ['employment_type', 'work_arrangement']\n",
        "\n",
        "categorical_label_columns = ['state', 'country']\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-large\")\n",
        "model = AutoModel.from_pretrained(\"thenlper/gte-large\")\n",
        "\n",
        "def average_pool(last_hidden_states: Tensor,\n",
        "                 attention_mask: Tensor) -> Tensor:\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "phrases = []\n",
        "row_labels = []\n",
        "for col in common_corpus_columns:\n",
        "  new_col_data = []\n",
        "  for index, value in df[col].iteritems():\n",
        "    if type(value) == list:\n",
        "      # Tokenize the input texts\n",
        "      for phrase in value:\n",
        "        phrases.append(phrase)\n",
        "        row_labels.append(index)\n",
        "    else:\n",
        "      phrases.append(str(value))\n",
        "      row_labels.append(index)\n",
        "      value = [str(value)]\n",
        "    batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model(**batch_dict)\n",
        "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "    # (Optionally) normalize embeddings\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "  df[f'{col}_vectors'] = new_col_data\n",
        "\n",
        "vector_cols = [f'{col}_vectors' for col in common_corpus_columns]\n",
        "phrase_vecs_list = []\n",
        "for col in vector_cols:\n",
        "  for i in df[col]:\n",
        "    for j in i:\n",
        "      phrase_vecs_list.append(j)\n",
        "kmeans = KMeans(n_clusters=475, random_state=57)\n",
        "kmeans.fit(phrase_vecs_list)\n",
        "\n",
        "for i in range(475):\n",
        "  column_name = f'common_cluster{i}_counts'  # Generate column name\n",
        "  df[column_name] = 0  # Fill the column with zeros\n",
        "\n",
        "cluster_labels = kmeans.labels_\n",
        "# Associate phrases with cluster labels\n",
        "data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "common_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "for i in range(row_labels[-1] + 1):\n",
        "  clusters_in_row = common_clusters_df.loc[common_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "  # Generate value counts\n",
        "  counts = Counter(clusters_in_row)\n",
        "  for cluster in counts.keys():\n",
        "    df.at[i, f'common_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "n_clusters_scale_factor = {'city': .5, 'company': .75, 'name_of_department/team': .2}\n",
        "singular_corpus_clusters_df_dict = {}\n",
        "for col in singular_corpus_columns:\n",
        "  phrases = []\n",
        "  row_labels = []\n",
        "  new_col_data = []\n",
        "  for index, value in df[col].iteritems():\n",
        "    if type(value) == list:\n",
        "      # Tokenize the input texts\n",
        "      for phrase in value:\n",
        "        phrases.append(phrase)\n",
        "        row_labels.append(index)\n",
        "    else:\n",
        "      phrases.append(str(value))\n",
        "      row_labels.append(index)\n",
        "      value = [str(value)]\n",
        "    batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model(**batch_dict)\n",
        "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "    # (Optionally) normalize embeddings\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "  df[f'{col}_vectors'] = new_col_data\n",
        "  vector_col = f'{col}_vectors'\n",
        "  phrase_vecs_list = []\n",
        "  for i in df[vector_col]:\n",
        "    for j in i:\n",
        "      phrase_vecs_list.append(j)\n",
        "  n_clusters = int(df.shape[0]*n_clusters_scale_factor[col])\n",
        "  kmeans = KMeans(n_clusters=n_clusters, random_state=57)\n",
        "  kmeans.fit(phrase_vecs_list)\n",
        "\n",
        "  for i in range(n_clusters):\n",
        "    column_name = f'{col}_cluster{i}_counts'  # Generate column name\n",
        "    df[column_name] = 0  # Fill the column with zeros\n",
        "\n",
        "  cluster_labels = kmeans.labels_\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "  clusters_df = pd.DataFrame(data)\n",
        "  singular_corpus_clusters_df_dict[col] = clusters_df\n",
        "\n",
        "  for i in range(row_labels[-1] + 1):\n",
        "    clusters_in_row = clusters_df.loc[clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      df.at[i, f'{col}_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "phrases = []\n",
        "row_labels = []\n",
        "for col in work_arrangement_columns:\n",
        "  new_col_data = []\n",
        "  for index, value in df[col].iteritems():\n",
        "    if type(value) == list:\n",
        "      # Tokenize the input texts\n",
        "      for phrase in value:\n",
        "        phrases.append(phrase)\n",
        "        row_labels.append(index)\n",
        "    else:\n",
        "      phrases.append(str(value))\n",
        "      row_labels.append(index)\n",
        "      value = [str(value)]\n",
        "    batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model(**batch_dict)\n",
        "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "    # (Optionally) normalize embeddings\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "  df[f'{col}_vectors'] = new_col_data\n",
        "\n",
        "vector_cols = [f'{col}_vectors' for col in work_arrangement_columns]\n",
        "phrase_vecs_list = []\n",
        "for col in vector_cols:\n",
        "  for i in df[col]:\n",
        "    for j in i:\n",
        "      phrase_vecs_list.append(j)\n",
        "kmeans = KMeans(n_clusters=10, random_state=57)\n",
        "kmeans.fit(phrase_vecs_list)\n",
        "\n",
        "for i in range(10):\n",
        "  column_name = f'work_arrangement_cluster{i}_counts'  # Generate column name\n",
        "  df[column_name] = 0  # Fill the column with zeros\n",
        "\n",
        "cluster_labels = kmeans.labels_\n",
        "# Associate phrases with cluster labels\n",
        "data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "work_arrangement_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "for i in range(row_labels[-1] + 1):\n",
        "  clusters_in_row = clusters_df.loc[clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "  # Generate value counts\n",
        "  counts = Counter(clusters_in_row)\n",
        "  for cluster in counts.keys():\n",
        "    df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "for col in categorical_label_columns:\n",
        "  # Perform one-hot encoding\n",
        "  one_hot_encoded_df = pd.get_dummies(df[col])\n",
        "\n",
        "  # Concatenate the original dataframe with the one-hot encoded dataframe\n",
        "  df = pd.concat([df, one_hot_encoded_df], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYbqsXQdiKBM"
      },
      "source": [
        "Now, we will retrain the algorithms we have already tried with this smaller dataframe.\n",
        "\n",
        "We will start with Linear Regression, since that yielded the highest accuracy before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUVV4_rMimKl",
        "outputId": "6fd364d7-94fe-412e-e090-4d9c5bdc6d61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.5031449901483038\n",
            "accuracy is 0.5909090909090909\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "columns_to_drop = common_corpus_columns + singular_corpus_columns + work_arrangement_columns + categorical_label_columns\n",
        "embedded_data_columns = common_corpus_columns + singular_corpus_columns + work_arrangement_columns\n",
        "embedded_data_columns = [f'{col}_vectors' for col in embedded_data_columns]\n",
        "\n",
        "columns_to_drop = columns_to_drop + embedded_data_columns\n",
        "\n",
        "# Make a copy of the dataframe with specified columns dropped\n",
        "df_copy = df.drop(columns=columns_to_drop).copy()\n",
        "df_copy = df_copy.drop(columns=[''])\n",
        "\n",
        "# Iterate over columns and fill NaN values with the mode of each column\n",
        "for col in df_copy.columns:\n",
        "  mode_val = df_copy[col].mode()[0]\n",
        "  df_copy[col].fillna(mode_val, inplace=True)  # Fill NaN values with the mode\n",
        "\n",
        "\n",
        "# Assuming df_encoded is your dataframe with one-hot encoded features and target variable\n",
        "# Split the data into features (X) and target variable (y)\n",
        "y = df_copy['rating']  # Target variable\n",
        "X = df_copy.drop(columns=['rating'])  # Features\n",
        "\n",
        "# Assuming X and y are your feature matrix and target variable respectively\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing data\n",
        "# Train a regression model instead of SVM classifier\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regression_model.predict(X_test)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "\n",
        "print(\"accuracy is\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU2kS5eHTrMq"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDW1ScAfiRfQ"
      },
      "source": [
        "So our hypothesis that our predictions would get less accurate with having fewer columns in our dataset had merit, at least with linear regression. What about for the Random Forest though?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2TJX67WkR_Q",
        "outputId": "44d15720-eec0-4b67-93ba-e8c0289a9925"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5454545454545454\n",
            "mae: 0.5\n",
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(max_depth=None, max_features='auto', min_samples_leaf=1, min_samples_split=2, n_estimators=300)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mae:\", mae)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZphJ277Y_aC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkyMeeURkoKK"
      },
      "source": [
        "We see that with the Random Forest Classifier our accuracy isn't anything to cheer for at .545 and our MAE is .5 which is not bad but so far we can generalize to say that the modification we made to our feature engineering didn't get us any improvement to our model accuracy. It is interesting that our MAE decreased in the case of the Random Forest Classifier, but the accuracy for the best estimator probably didn't change. What happens if we instead INCREASE the number of common clusters and look at the accuracy of the linear regression model once again? We will choose 650 for our number of common clusters and rerun the feature engineering code. Then we will evaluate the linear regression model again.\n",
        "\n",
        "Well, we have re-feature engineered our data to have 650 common corpus cluster columns and the accuracy and MAE are even worse than the case where the number of common corpus clusters was 300. So it seems like we are at a quite favorable number of 500 when the linear regression model was most accurate. Maybe the model is most accurate at a number between 300 and 500? Let's try 400.\n",
        "\n",
        "Very interesting. 400 is the next best number of common clusters, yielding an accuracy .636 and a MAE of .42, so it's less accurate on average but has a smaller MAE than the model that has 500 common clusters. We should try training the Random Forest Classifier with best hyperparameters on this data. Again we get an accuracy of .545 and a MAE of .5. Let us try doing a grid search to see if we can get a RF Classifier model with better accuracy than .59.\n",
        "\n",
        "Interestingly, with the 400 common clusters, the best RF model gives an accuracy of .59 yet again but this time the MAE is notably lower - .4545. We are also doing a grid search on Random Forest Regressor best hyperparameters.\n",
        "\n",
        "The results:\n",
        "\n",
        "Best Hyperparameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
        "Accuracy: 0.5454545454545454\n",
        "MAE: 0.522665142924398\n",
        "\n",
        "*Note: We took the RF regressor model's predictions and rounded them before calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmdz0H9x-sFQ",
        "outputId": "bed3a1e9-29d5-4e87-fc4d-c571e27664c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2.138 1.668 1.54  2.03  1.874 1.478 1.746 1.632 2.168 2.332 2.16  2.058\n",
            " 1.738 2.002 1.914 1.64  1.662 1.988 1.984 1.856 1.826 1.86 ]\n"
          ]
        }
      ],
      "source": [
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaW0iwihMPbd"
      },
      "source": [
        "I'm curious what results we get with slightly fewer than 500 clusters, say 475. After a first evaluation we get the following results which are quite surprising:\n",
        "\n",
        "Mean Absolute Error: 0.5031449901483038\n",
        "accuracy is 0.5909090909090909\n",
        "\n",
        "I would have thought the numbers would be between those for 400 and 500 common clusters, but at 475 clusters we have more error and are less accurate than with 400 or 500 clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcUJATCxMxjG",
        "outputId": "fa18b3f9-9dd6-4b5d-f659-87c279c83919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n"
          ]
        }
      ],
      "source": [
        "json_files_path = \"drive/MyDrive/LI-Jobs-JSON/\"\n",
        "links_csv_path = \"drive/MyDrive/successfulLinksGDRIVE.csv\"\n",
        "\n",
        "import pandas as pd\n",
        "links_dataframe = pd.read_csv(links_csv_path, header=None, names=['url', 'rating'])\n",
        "#links_dataframe.head()\n",
        "#print(links_dataframe.loc[0, 'rating'])\n",
        "\n",
        "# let's snakecase our column names to avoid having spaces in them\n",
        "# also we add a rating column at the end of the list to store the target variable\n",
        "df_columns = [\"employment_type\", \"job_function\", \"description_of_product/service\", \"industries\",\n",
        "              \"position_name\", \"broader_role_name\", \"company\", #\"location\", \"salary/compensation_range\",\n",
        "              \"responsibilities\", \"goals/objectives\", \"name_of_department/team\", \"required_qualifications\",\n",
        "              \"preferred_qualifications\", \"benefits\", \"work_arrangement\", \"city\", \"state\", \"country\",\n",
        "              \"min_salary\", \"max_salary\", \"rating\"]\n",
        "# Initialize DataFrame with column names\n",
        "df = pd.DataFrame(columns=df_columns)\n",
        "\n",
        "import os\n",
        "import json\n",
        "locale_json_files_path = \"drive/MyDrive/jobLocations/\"\n",
        "salary_json_files_path = \"drive/MyDrive/jobSalaries/\"\n",
        "\n",
        "for i in range(1, 108):\n",
        "  row_num = df.last_valid_index()\n",
        "  print(row_num)\n",
        "  if row_num == None:\n",
        "    row_num = 0\n",
        "  else:\n",
        "    row_num = row_num + 1\n",
        "  assert i == row_num + 1\n",
        "  json_file_path = os.path.join(json_files_path, f'row{i}.json')\n",
        "  # Read JSON file\n",
        "  with open(json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  if 'fields' in json_data.keys():\n",
        "    #print(json_data)\n",
        "    field_names = json_data['fields']\n",
        "    for index, value in enumerate(field_names):\n",
        "      info = json_data['info'][index]\n",
        "      # Check if the value exists as a column name (ignoring case)\n",
        "      column_name = value.replace(\" \", \"_\").lower()\n",
        "      if column_name in df.columns:\n",
        "        # Add the info to the corresponding column and row\n",
        "        df.at[row_num, column_name] = info\n",
        "  else:\n",
        "    for key, value in json_data.items():\n",
        "      # Check if the key exists as a column name (ignoring case)\n",
        "      column_name = key.replace(\" \", \"_\").lower()\n",
        "      if column_name == 'emploment_type':\n",
        "        column_name = 'employment_type'\n",
        "      if column_name in df.columns:\n",
        "        # Add the value to the corresponding column and row\n",
        "        df.at[row_num, column_name] = value\n",
        "\n",
        "  locale_json_file_path = os.path.join(locale_json_files_path, f'row{i}.json')\n",
        "  salary_json_file_path = os.path.join(salary_json_files_path, f'row{i}.json')\n",
        "  # Read locale JSON file\n",
        "  with open(locale_json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  try:\n",
        "    city = json_data[\"city\"]\n",
        "    state = json_data[\"state\"]\n",
        "    country = json_data[\"country\"]\n",
        "    df.at[row_num, 'city'] = city\n",
        "    df.at[row_num, 'state'] = state\n",
        "    df.at[row_num, 'country'] = country\n",
        "  except:\n",
        "    df.at[row_num, 'city'] = \"N/A\"\n",
        "    df.at[row_num, 'state'] = \"N/A\"\n",
        "    df.at[row_num, 'country'] = \"N/A\"\n",
        "  # Read salary JSON file\n",
        "  with open(salary_json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "  min_salary = json_data[\"salary_min\"]\n",
        "  max_salary = json_data[\"salary_max\"]\n",
        "  df.at[row_num, 'min_salary'] = min_salary\n",
        "  df.at[row_num, 'max_salary'] = max_salary\n",
        "  rating = links_dataframe.loc[row_num, 'rating']\n",
        "  df.at[row_num, 'rating'] = rating\n",
        "\n",
        "import numpy as np\n",
        "# Replace 'N/A' with NaN in the whole DataFrame\n",
        "df.replace('N/A', np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV9wDeUJTrpp"
      },
      "source": [
        "One thing we've been doing which is technically not kosher or how it would have to work in the real world is we've been including our training set phrases in our cluster maps, but we should not do so. Instead we would have the same code we've been running only apply to the training dataframe subset, and then we'd have separate code that loops over all phrases in our test dataframe subset rows,assigning them clusters based on the nearest pre-defined cluster centers, and then populating the different cluster_counts columns appropriately. We need to diverge our path to do this, otherwise all the results we get will live in a fairy tale, where our ML model will already have knowledge about the test set. I imagine our results are going to get worse after doing this, but it's the correct way to engineer our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQWL4LfhWg_5",
        "outputId": "d6ffbbc6-1b56-4982-cb94-a3458c9ea97a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-dc9584e212ef>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:85: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in test_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:124: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-10-dc9584e212ef>:151: ConvergenceWarning: Number of distinct clusters (71) found smaller than n_clusters (79). Possibly due to duplicate points in X.\n",
            "  kmeans.fit(phrase_vecs_list)\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:172: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in test_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:124: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:172: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in test_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:124: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:172: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in test_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:213: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:232: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "<ipython-input-10-dc9584e212ef>:213: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-10-dc9584e212ef>:232: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-10-dc9584e212ef>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-10-dc9584e212ef>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-10-dc9584e212ef>:262: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in test_df[col].iteritems():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[76, 10, 4, 99, 70, 66, 30, 45, 94, 11, 78, 47, 0, 79, 18, 105, 55, 77, 65, 42, 12, 36, 76, 10, 4, 99, 70, 66, 30, 30, 45, 94, 11, 78, 47, 0, 79, 18, 105, 55, 77, 65, 42, 12, 36]\n",
            "['Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Other', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Contract', 'Part-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Contract', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Onsite', 'On-site', 'On-site', 'N/A', 'Remote', 'Hybrid', 'Hybrid', 'Telecommuting up to 40%', 'N/A', 'Hybrid, Remote, In-Person', 'N/A', 'N/A', 'Remote', 'N/A', 'Remote', 'N/A', 'Virtual', 'Hybrid', 'N/A', 'Remote', 'On-site', 'N/A', 'N/A']\n",
            "[1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 6, 8, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 2, 2, 2, 0, 3, 4, 4, 6, 0, 6, 0, 0, 3, 0, 3, 0, 6, 4, 0, 3, 2, 0, 0]\n",
            "got through feature engineering step\n",
            "Mean Absolute Error: 0.6135589620950797\n",
            "accuracy is 0.5909090909090909\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "common_corpus_columns = ['job_function', 'description_of_product/service', 'industries', 'position_name', 'broader_role_name',\n",
        "                         'responsibilities', 'goals/objectives', 'required_qualifications', 'preferred_qualifications', 'benefits']\n",
        "\n",
        "singular_corpus_columns = ['company', 'name_of_department/team', 'city']\n",
        "\n",
        "work_arrangement_columns = ['employment_type', 'work_arrangement']\n",
        "\n",
        "categorical_label_columns = ['state', 'country']\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-large\")\n",
        "model = AutoModel.from_pretrained(\"thenlper/gte-large\")\n",
        "\n",
        "def average_pool(last_hidden_states: Tensor,\n",
        "                 attention_mask: Tensor) -> Tensor:\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "def feature_engineering_step(train_df, test_df):\n",
        "  phrases = []\n",
        "  row_labels = []\n",
        "  for col in common_corpus_columns:\n",
        "    new_col_data = []\n",
        "    for index, value in train_df[col].iteritems():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          phrases.append(phrase)\n",
        "          row_labels.append(index)\n",
        "      else:\n",
        "        phrases.append(str(value))\n",
        "        row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "      new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "    train_df[f'{col}_vectors'] = new_col_data\n",
        "\n",
        "  vector_cols = [f'{col}_vectors' for col in common_corpus_columns]\n",
        "  phrase_vecs_list = []\n",
        "  for col in vector_cols:\n",
        "    for i in train_df[col]:\n",
        "      for j in i:\n",
        "        phrase_vecs_list.append(j)\n",
        "  kmeans = KMeans(n_clusters=400, random_state=57)\n",
        "  kmeans.fit(phrase_vecs_list)\n",
        "  centroids = kmeans.cluster_centers_\n",
        "\n",
        "  for i in range(400):\n",
        "    column_name = f'common_cluster{i}_counts'  # Generate column name\n",
        "    train_df[column_name] = 0  # Fill the column with zeros\n",
        "    test_df[column_name] = 0\n",
        "\n",
        "  cluster_labels = kmeans.labels_\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "  common_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "  for i in range(row_labels[-1] + 1):\n",
        "    clusters_in_row = common_clusters_df.loc[common_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      train_df.at[i, f'common_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "  test_phrases = []\n",
        "  test_row_labels = []\n",
        "  test_cluster_labels = []\n",
        "  for col in common_corpus_columns:\n",
        "    for index, value in test_df[col].iteritems():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          test_phrases.append(phrase)\n",
        "          test_row_labels.append(index)\n",
        "      else:\n",
        "        test_phrases.append(str(value))\n",
        "        test_row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "      for emb in embeddings:\n",
        "        distances = np.linalg.norm(centroids - emb.detach().numpy(), axis=1)\n",
        "        # Find the index of the centroid with the minimum distance\n",
        "        closest_centroid_index = np.argmin(distances)\n",
        "        test_cluster_labels.append(closest_centroid_index)\n",
        "\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': test_phrases, 'row_label': test_row_labels, 'cluster_label': test_cluster_labels}\n",
        "  test_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "  for i in range(test_row_labels[-1] + 1):\n",
        "    clusters_in_row = test_clusters_df.loc[test_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      test_df.at[i, f'common_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "  n_clusters_scale_factor = {'city': .625, 'company': .94, 'name_of_department/team': .25}\n",
        "  singular_corpus_clusters_df_dict = {}\n",
        "  for col in singular_corpus_columns:\n",
        "    phrases = []\n",
        "    test_phrases = []\n",
        "    row_labels = []\n",
        "    test_row_labels = []\n",
        "    test_cluster_labels = []\n",
        "    new_col_data = []\n",
        "    for index, value in train_df[col].iteritems():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          phrases.append(phrase)\n",
        "          row_labels.append(index)\n",
        "      else:\n",
        "        phrases.append(str(value))\n",
        "        row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "      new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "    train_df[f'{col}_vectors'] = new_col_data\n",
        "    vector_col = f'{col}_vectors'\n",
        "    phrase_vecs_list = []\n",
        "    for i in train_df[vector_col]:\n",
        "      for j in i:\n",
        "        phrase_vecs_list.append(j)\n",
        "    n_clusters = int(train_df.shape[0]*n_clusters_scale_factor[col])\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=57)\n",
        "    kmeans.fit(phrase_vecs_list)\n",
        "    centroids = kmeans.cluster_centers_\n",
        "\n",
        "    for i in range(n_clusters):\n",
        "      column_name = f'{col}_cluster{i}_counts'  # Generate column name\n",
        "      train_df[column_name] = 0  # Fill the column with zeros\n",
        "      test_df[column_name] = 0\n",
        "\n",
        "    cluster_labels = kmeans.labels_\n",
        "    # Associate phrases with cluster labels\n",
        "    data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "    clusters_df = pd.DataFrame(data)\n",
        "    singular_corpus_clusters_df_dict[col] = clusters_df\n",
        "\n",
        "    for i in range(row_labels[-1] + 1):\n",
        "      clusters_in_row = clusters_df.loc[clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "      # Generate value counts\n",
        "      counts = Counter(clusters_in_row)\n",
        "      for cluster in counts.keys():\n",
        "        train_df.at[i, f'{col}_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "    for index, value in test_df[col].iteritems():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          test_phrases.append(phrase)\n",
        "          test_row_labels.append(index)\n",
        "      else:\n",
        "        test_phrases.append(str(value))\n",
        "        test_row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "      for emb in embeddings:\n",
        "        distances = np.linalg.norm(centroids - emb.detach().numpy(), axis=1)\n",
        "        # Find the index of the centroid with the minimum distance\n",
        "        closest_centroid_index = np.argmin(distances)\n",
        "        test_cluster_labels.append(closest_centroid_index)\n",
        "\n",
        "    # Associate phrases with cluster labels\n",
        "    data = {'phrase': test_phrases, 'row_label': test_row_labels, 'cluster_label': test_cluster_labels}\n",
        "    test_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "    for i in range(test_row_labels[-1] + 1):\n",
        "      clusters_in_row = test_clusters_df.loc[test_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "      # Generate value counts\n",
        "      counts = Counter(clusters_in_row)\n",
        "      for cluster in counts.keys():\n",
        "        test_df.at[i, f'{col}_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "\n",
        "  phrases = []\n",
        "  test_phrases = []\n",
        "  row_labels = []\n",
        "  test_row_labels = []\n",
        "  test_cluster_labels = []\n",
        "  for col in work_arrangement_columns:\n",
        "    new_col_data = []\n",
        "    for index, value in train_df[col].iteritems():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          phrases.append(phrase)\n",
        "          row_labels.append(index)\n",
        "      else:\n",
        "        phrases.append(str(value))\n",
        "        row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "      new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "    train_df[f'{col}_vectors'] = new_col_data\n",
        "\n",
        "  vector_cols = [f'{col}_vectors' for col in work_arrangement_columns]\n",
        "  phrase_vecs_list = []\n",
        "  for col in vector_cols:\n",
        "    for i in train_df[col]:\n",
        "      for j in i:\n",
        "        phrase_vecs_list.append(j)\n",
        "  kmeans = KMeans(n_clusters=10, random_state=57)\n",
        "  kmeans.fit(phrase_vecs_list)\n",
        "  centroids = kmeans.cluster_centers_\n",
        "\n",
        "  for i in range(10):\n",
        "    column_name = f'work_arrangement_cluster{i}_counts'  # Generate column name\n",
        "    train_df[column_name] = 0  # Fill the column with zeros\n",
        "    test_df[column_name] = 0\n",
        "\n",
        "  cluster_labels = kmeans.labels_\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "  work_arrangement_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "  for i in range(row_labels[-1] + 1):\n",
        "    clusters_in_row = work_arrangement_clusters_df.loc[work_arrangement_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      train_df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "  for col in work_arrangement_columns:\n",
        "    for index, value in test_df[col].iteritems():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          test_phrases.append(phrase)\n",
        "          test_row_labels.append(index)\n",
        "      else:\n",
        "        test_phrases.append(str(value))\n",
        "        test_row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "      for emb in embeddings:\n",
        "        distances = np.linalg.norm(centroids - emb.detach().numpy(), axis=1)\n",
        "        # Find the index of the centroid with the minimum distance\n",
        "        closest_centroid_index = np.argmin(distances)\n",
        "        test_cluster_labels.append(closest_centroid_index)\n",
        "\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': test_phrases, 'row_label': test_row_labels, 'cluster_label': test_cluster_labels}\n",
        "  test_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "  print(test_row_labels)\n",
        "  print(test_phrases)\n",
        "  print(test_cluster_labels)\n",
        "  for i in range(test_row_labels[-1] + 1):\n",
        "    clusters_in_row = test_clusters_df.loc[test_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      test_df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "  return train_df, test_df\n",
        "\n",
        "\n",
        "df_copy = df.copy()\n",
        "\n",
        "for col in categorical_label_columns:\n",
        "  # Perform one-hot encoding\n",
        "  one_hot_encoded_df = pd.get_dummies(df_copy[col])\n",
        "  # Concatenate the original dataframe with the one-hot encoded dataframe\n",
        "  df_copy = pd.concat([df_copy, one_hot_encoded_df], axis=1)\n",
        "\n",
        "y = df_copy['rating']  # Target variable\n",
        "X = df_copy.drop(columns=['rating'])  # Features\n",
        "\n",
        "# Assuming X and y are your feature matrix and target variable respectively\n",
        "# Split the data into training and testing sets\n",
        "train_df, test_df, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "train_df, test_df = feature_engineering_step(train_df, test_df)\n",
        "\n",
        "print('got through feature engineering step')\n",
        "\n",
        "columns_to_drop = common_corpus_columns + singular_corpus_columns + work_arrangement_columns + categorical_label_columns\n",
        "embedded_data_columns = common_corpus_columns + singular_corpus_columns + work_arrangement_columns\n",
        "embedded_data_columns = [f'{col}_vectors' for col in embedded_data_columns]\n",
        "\n",
        "train_columns_to_drop = columns_to_drop + embedded_data_columns\n",
        "test_columns_to_drop = columns_to_drop\n",
        "\n",
        "# Make a copy of the dataframe with specified columns dropped\n",
        "train_df = train_df.drop(columns=train_columns_to_drop)\n",
        "test_df = test_df.drop(columns=test_columns_to_drop)\n",
        "train_df = train_df.drop(columns=[''])\n",
        "test_df = test_df.drop(columns=[''])\n",
        "\n",
        "# Iterate over columns and fill NaN values with the mode of each column\n",
        "for col in train_df.columns:\n",
        "  mode_val = train_df[col].mode()[0]\n",
        "  train_df[col].fillna(mode_val, inplace=True)  # Fill NaN values with the mode\n",
        "  if col in test_df.columns:\n",
        "    test_df[col].fillna(mode_val, inplace=True)\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing data\n",
        "# Train a regression model instead of SVM classifier\n",
        "regression_model.fit(train_df, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regression_model.predict(test_df)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "\n",
        "print(\"accuracy is\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UklkdLF-Ybr-"
      },
      "source": [
        "OK, we finally have the new feature engineering code and train-test-split working, and with everything more kosher now, the accuracy of linear regression went down to .59 and the MAE up to .61. Let's check these for Random Forest now.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h_2sn-JZC6Q",
        "outputId": "19c418c2-af58-43e3-8a3e-9152361ca27f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5909090909090909\n",
            "mae: 0.45454545454545453\n",
            "[2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(max_depth=None, max_features='auto', min_samples_leaf=1, min_samples_split=2, n_estimators=300)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(train_df, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(test_df)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mae:\", mae)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlhcI7LUZh2k"
      },
      "source": [
        "Interestingly, the accuracy is the same for the Random Forest at .59 but the MAE is lower."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGP8EaqByKmg"
      },
      "source": [
        "What if we went back to using 500 common clusters just for the training data? Can we get better accuracy? Based on what we've observed previously we would expect it to alter the accuracy of our predictions from the linear regression model, but probably not the the tree-based models. Then again we might have observed different behavior previously because our model included phrases from the test data in it's language corpus.\n",
        "\n",
        "I am hoping to break 60% accuracy with linear regression using 500 common clusters, but we'll see. The 68% number from before seemed promising, but it wasn't legit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tXaRLwr5zQUY",
        "outputId": "a4b4db04-bd42-4a50-db2a-f3d31d3a7160"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-37-0b69da09faaa>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:33: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:85: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in test_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:124: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-37-0b69da09faaa>:151: ConvergenceWarning: Number of distinct clusters (71) found smaller than n_clusters (79). Possibly due to duplicate points in X.\n",
            "  kmeans.fit(phrase_vecs_list)\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:172: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in test_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:124: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:172: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in test_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:124: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:172: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in test_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:213: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:232: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "<ipython-input-37-0b69da09faaa>:213: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in train_df[col].iteritems():\n",
            "<ipython-input-37-0b69da09faaa>:232: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[f'{col}_vectors'] = new_col_data\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-37-0b69da09faaa>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_df[column_name] = 0  # Fill the column with zeros\n",
            "<ipython-input-37-0b69da09faaa>:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_df[column_name] = 0\n",
            "<ipython-input-37-0b69da09faaa>:262: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, value in test_df[col].iteritems():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[76, 10, 4, 99, 70, 66, 30, 45, 94, 11, 78, 47, 0, 79, 18, 105, 55, 77, 65, 42, 12, 36, 76, 10, 4, 99, 70, 66, 30, 30, 45, 94, 11, 78, 47, 0, 79, 18, 105, 55, 77, 65, 42, 12, 36]\n",
            "['Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Other', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Contract', 'Part-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Contract', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Full-time', 'Onsite', 'On-site', 'On-site', 'N/A', 'Remote', 'Hybrid', 'Hybrid', 'Telecommuting up to 40%', 'N/A', 'Hybrid, Remote, In-Person', 'N/A', 'N/A', 'Remote', 'N/A', 'Remote', 'N/A', 'Virtual', 'Hybrid', 'N/A', 'Remote', 'On-site', 'N/A', 'N/A']\n",
            "[1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 6, 8, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 2, 2, 2, 0, 3, 4, 4, 6, 0, 6, 0, 0, 3, 0, 3, 0, 6, 4, 0, 3, 2, 0, 0]\n",
            "got through feature engineering step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'from sklearn.metrics import mean_absolute_error, accuracy_score\\nfrom sklearn.linear_model import LinearRegression\\nregression_model = LinearRegression()\\n\\n# Assuming X_train, X_test, y_train, y_test are your training and testing data\\n# Train a regression model instead of SVM classifier\\nregression_model.fit(train_df, y_train)\\n\\n# Make predictions on the testing data\\ny_pred = regression_model.predict(test_df)\\n\\n# Calculate the mean absolute error\\nmae = mean_absolute_error(y_test, y_pred)\\nprint(\"Mean Absolute Error:\", mae)\\n\\n# Round the predictions\\ny_pred_rounded = [round(pred) for pred in y_pred]\\n\\n# Calculate accuracy using the rounded predictions and actual target values\\naccuracy = accuracy_score(y_test, y_pred_rounded)\\n\\nprint(\"accuracy is\", accuracy)'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "common_corpus_columns = ['job_function', 'description_of_product/service', 'industries', 'position_name', 'broader_role_name',\n",
        "                         'responsibilities', 'goals/objectives', 'required_qualifications', 'preferred_qualifications', 'benefits']\n",
        "\n",
        "singular_corpus_columns = ['company', 'name_of_department/team', 'city']\n",
        "\n",
        "work_arrangement_columns = ['employment_type', 'work_arrangement']\n",
        "\n",
        "categorical_label_columns = ['state', 'country']\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-large\")\n",
        "model = AutoModel.from_pretrained(\"thenlper/gte-large\")\n",
        "\n",
        "def average_pool(last_hidden_states: Tensor,\n",
        "                 attention_mask: Tensor) -> Tensor:\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "def feature_engineering_step(train_df, test_df):\n",
        "  phrases = []\n",
        "  row_labels = []\n",
        "  for col in common_corpus_columns:\n",
        "    new_col_data = []\n",
        "    for index, value in train_df[col].iteritems():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          phrases.append(phrase)\n",
        "          row_labels.append(index)\n",
        "      else:\n",
        "        phrases.append(str(value))\n",
        "        row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "      new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "    train_df[f'{col}_vectors'] = new_col_data\n",
        "\n",
        "  vector_cols = [f'{col}_vectors' for col in common_corpus_columns]\n",
        "  phrase_vecs_list = []\n",
        "  for col in vector_cols:\n",
        "    for i in train_df[col]:\n",
        "      for j in i:\n",
        "        phrase_vecs_list.append(j)\n",
        "  kmeans = KMeans(n_clusters=400, random_state=57)\n",
        "  kmeans.fit(phrase_vecs_list)\n",
        "  centroids = kmeans.cluster_centers_\n",
        "\n",
        "  for i in range(400):\n",
        "    column_name = f'common_cluster{i}_counts'  # Generate column name\n",
        "    train_df[column_name] = 0  # Fill the column with zeros\n",
        "    test_df[column_name] = 0\n",
        "\n",
        "  cluster_labels = kmeans.labels_\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "  common_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "  for i in range(row_labels[-1] + 1):\n",
        "    clusters_in_row = common_clusters_df.loc[common_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      train_df.at[i, f'common_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "  test_phrases = []\n",
        "  test_row_labels = []\n",
        "  test_cluster_labels = []\n",
        "  for col in common_corpus_columns:\n",
        "    for index, value in test_df[col].iteritems():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          test_phrases.append(phrase)\n",
        "          test_row_labels.append(index)\n",
        "      else:\n",
        "        test_phrases.append(str(value))\n",
        "        test_row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "      for emb in embeddings:\n",
        "        distances = np.linalg.norm(centroids - emb.detach().numpy(), axis=1)\n",
        "        # Find the index of the centroid with the minimum distance\n",
        "        closest_centroid_index = np.argmin(distances)\n",
        "        test_cluster_labels.append(closest_centroid_index)\n",
        "\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': test_phrases, 'row_label': test_row_labels, 'cluster_label': test_cluster_labels}\n",
        "  test_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "  for i in range(test_row_labels[-1] + 1):\n",
        "    clusters_in_row = test_clusters_df.loc[test_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      test_df.at[i, f'common_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "  n_clusters_scale_factor = {'city': .625, 'company': .94, 'name_of_department/team': .25}\n",
        "  singular_corpus_clusters_df_dict = {}\n",
        "  for col in singular_corpus_columns:\n",
        "    phrases = []\n",
        "    test_phrases = []\n",
        "    row_labels = []\n",
        "    test_row_labels = []\n",
        "    test_cluster_labels = []\n",
        "    new_col_data = []\n",
        "    for index, value in train_df[col].iteritems():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          phrases.append(phrase)\n",
        "          row_labels.append(index)\n",
        "      else:\n",
        "        phrases.append(str(value))\n",
        "        row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "      new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "    train_df[f'{col}_vectors'] = new_col_data\n",
        "    vector_col = f'{col}_vectors'\n",
        "    phrase_vecs_list = []\n",
        "    for i in train_df[vector_col]:\n",
        "      for j in i:\n",
        "        phrase_vecs_list.append(j)\n",
        "    n_clusters = int(train_df.shape[0]*n_clusters_scale_factor[col])\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=57)\n",
        "    kmeans.fit(phrase_vecs_list)\n",
        "    centroids = kmeans.cluster_centers_\n",
        "\n",
        "    for i in range(n_clusters):\n",
        "      column_name = f'{col}_cluster{i}_counts'  # Generate column name\n",
        "      train_df[column_name] = 0  # Fill the column with zeros\n",
        "      test_df[column_name] = 0\n",
        "\n",
        "    cluster_labels = kmeans.labels_\n",
        "    # Associate phrases with cluster labels\n",
        "    data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "    clusters_df = pd.DataFrame(data)\n",
        "    singular_corpus_clusters_df_dict[col] = clusters_df\n",
        "\n",
        "    for i in range(row_labels[-1] + 1):\n",
        "      clusters_in_row = clusters_df.loc[clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "      # Generate value counts\n",
        "      counts = Counter(clusters_in_row)\n",
        "      for cluster in counts.keys():\n",
        "        train_df.at[i, f'{col}_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "    for index, value in test_df[col].iteritems():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          test_phrases.append(phrase)\n",
        "          test_row_labels.append(index)\n",
        "      else:\n",
        "        test_phrases.append(str(value))\n",
        "        test_row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "      for emb in embeddings:\n",
        "        distances = np.linalg.norm(centroids - emb.detach().numpy(), axis=1)\n",
        "        # Find the index of the centroid with the minimum distance\n",
        "        closest_centroid_index = np.argmin(distances)\n",
        "        test_cluster_labels.append(closest_centroid_index)\n",
        "\n",
        "    # Associate phrases with cluster labels\n",
        "    data = {'phrase': test_phrases, 'row_label': test_row_labels, 'cluster_label': test_cluster_labels}\n",
        "    test_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "    for i in range(test_row_labels[-1] + 1):\n",
        "      clusters_in_row = test_clusters_df.loc[test_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "      # Generate value counts\n",
        "      counts = Counter(clusters_in_row)\n",
        "      for cluster in counts.keys():\n",
        "        test_df.at[i, f'{col}_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "\n",
        "  phrases = []\n",
        "  test_phrases = []\n",
        "  row_labels = []\n",
        "  test_row_labels = []\n",
        "  test_cluster_labels = []\n",
        "  for col in work_arrangement_columns:\n",
        "    new_col_data = []\n",
        "    for index, value in train_df[col].iteritems():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          phrases.append(phrase)\n",
        "          row_labels.append(index)\n",
        "      else:\n",
        "        phrases.append(str(value))\n",
        "        row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "      new_col_data.append(embeddings.detach().numpy())\n",
        "\n",
        "    train_df[f'{col}_vectors'] = new_col_data\n",
        "\n",
        "  vector_cols = [f'{col}_vectors' for col in work_arrangement_columns]\n",
        "  phrase_vecs_list = []\n",
        "  for col in vector_cols:\n",
        "    for i in train_df[col]:\n",
        "      for j in i:\n",
        "        phrase_vecs_list.append(j)\n",
        "  kmeans = KMeans(n_clusters=10, random_state=57)\n",
        "  kmeans.fit(phrase_vecs_list)\n",
        "  centroids = kmeans.cluster_centers_\n",
        "\n",
        "  for i in range(10):\n",
        "    column_name = f'work_arrangement_cluster{i}_counts'  # Generate column name\n",
        "    train_df[column_name] = 0  # Fill the column with zeros\n",
        "    test_df[column_name] = 0\n",
        "\n",
        "  cluster_labels = kmeans.labels_\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': phrases, 'row_label': row_labels, 'cluster_label': cluster_labels}\n",
        "  work_arrangement_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "  for i in range(row_labels[-1] + 1):\n",
        "    clusters_in_row = work_arrangement_clusters_df.loc[work_arrangement_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      train_df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "  for col in work_arrangement_columns:\n",
        "    for index, value in test_df[col].iteritems():\n",
        "      if type(value) == list:\n",
        "        # Tokenize the input texts\n",
        "        for phrase in value:\n",
        "          test_phrases.append(phrase)\n",
        "          test_row_labels.append(index)\n",
        "      else:\n",
        "        test_phrases.append(str(value))\n",
        "        test_row_labels.append(index)\n",
        "        value = [str(value)]\n",
        "      batch_dict = tokenizer(value, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "      outputs = model(**batch_dict)\n",
        "      embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "      # (Optionally) normalize embeddings\n",
        "      embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "      for emb in embeddings:\n",
        "        distances = np.linalg.norm(centroids - emb.detach().numpy(), axis=1)\n",
        "        # Find the index of the centroid with the minimum distance\n",
        "        closest_centroid_index = np.argmin(distances)\n",
        "        test_cluster_labels.append(closest_centroid_index)\n",
        "\n",
        "  # Associate phrases with cluster labels\n",
        "  data = {'phrase': test_phrases, 'row_label': test_row_labels, 'cluster_label': test_cluster_labels}\n",
        "  test_clusters_df = pd.DataFrame(data)\n",
        "\n",
        "  print(test_row_labels)\n",
        "  print(test_phrases)\n",
        "  print(test_cluster_labels)\n",
        "  for i in range(test_row_labels[-1] + 1):\n",
        "    clusters_in_row = test_clusters_df.loc[test_clusters_df['row_label'] == i, 'cluster_label'].tolist()\n",
        "    # Generate value counts\n",
        "    counts = Counter(clusters_in_row)\n",
        "    for cluster in counts.keys():\n",
        "      test_df.at[i, f'work_arrangement_cluster{cluster}_counts'] = counts[cluster]\n",
        "\n",
        "  return train_df, test_df\n",
        "\n",
        "\n",
        "df_copy = df.copy()\n",
        "\n",
        "for col in categorical_label_columns:\n",
        "  # Perform one-hot encoding\n",
        "  one_hot_encoded_df = pd.get_dummies(df_copy[col])\n",
        "  # Concatenate the original dataframe with the one-hot encoded dataframe\n",
        "  df_copy = pd.concat([df_copy, one_hot_encoded_df], axis=1)\n",
        "\n",
        "y = df_copy['rating']  # Target variable\n",
        "X = df_copy.drop(columns=['rating'])  # Features\n",
        "\n",
        "# Assuming X and y are your feature matrix and target variable respectively\n",
        "# Split the data into training and testing sets\n",
        "train_df, test_df, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "train_df, test_df = feature_engineering_step(train_df, test_df)\n",
        "\n",
        "print('got through feature engineering step')\n",
        "\n",
        "columns_to_drop = common_corpus_columns + singular_corpus_columns + work_arrangement_columns + categorical_label_columns\n",
        "embedded_data_columns = common_corpus_columns + singular_corpus_columns + work_arrangement_columns\n",
        "embedded_data_columns = [f'{col}_vectors' for col in embedded_data_columns]\n",
        "\n",
        "train_columns_to_drop = columns_to_drop + embedded_data_columns\n",
        "test_columns_to_drop = columns_to_drop\n",
        "\n",
        "# Make a copy of the dataframe with specified columns dropped\n",
        "train_df = train_df.drop(columns=train_columns_to_drop)\n",
        "test_df = test_df.drop(columns=test_columns_to_drop)\n",
        "train_df = train_df.drop(columns=[''])\n",
        "test_df = test_df.drop(columns=[''])\n",
        "\n",
        "# Iterate over columns and fill NaN values with the mode of each column\n",
        "for col in train_df.columns:\n",
        "  mode_val = train_df[col].mode()[0]\n",
        "  train_df[col].fillna(mode_val, inplace=True)  # Fill NaN values with the mode\n",
        "  if col in test_df.columns:\n",
        "    test_df[col].fillna(mode_val, inplace=True)\n",
        "\n",
        "'''from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing data\n",
        "# Train a regression model instead of SVM classifier\n",
        "regression_model.fit(train_df, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regression_model.predict(test_df)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "\n",
        "print(\"accuracy is\", accuracy)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_g3pBVz6RTv"
      },
      "source": [
        "But as it turns out, our accuracy remains the same and our MAE actually increases for the linear regression model. What about the random forest?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3YQQeOV6qe5",
        "outputId": "714a9aba-97fe-4fa3-b1f3-77b3158f8515"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5909090909090909\n",
            "mae: 0.45454545454545453\n",
            "[2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(max_depth=None, max_features='auto', min_samples_leaf=1, min_samples_split=2, n_estimators=300)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(train_df, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(test_df)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mae:\", mae)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCD85wDS6usU"
      },
      "source": [
        "And we got the same results with the Random Forest Classifier as we did before with 400 clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANhgNNmF8BND"
      },
      "source": [
        "We have beaten the dead horse long enough; we should move onto trying a new approach to our feature engineering. That approach will be as follows:\n",
        "\n",
        "we will try a much more simple approach that does not involve ChatGPT, JSON files, phrase embeddings, or clustering. We will simply do TFIDF vectorization on the text files for the job postings in our training set, and try training the same model types on this different data.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igV1O7gB-REp",
        "outputId": "07bd129b-e11e-486e-8915-2a3cdafcc293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n"
          ]
        }
      ],
      "source": [
        "links_csv_path = \"drive/MyDrive/successfulLinksGDRIVE.csv\"\n",
        "\n",
        "import pandas as pd\n",
        "links_dataframe = pd.read_csv(links_csv_path, header=None, names=['url', 'rating'])\n",
        "#links_dataframe.head()\n",
        "#print(links_dataframe.loc[0, 'rating'])\n",
        "\n",
        "# let's snakecase our column names to avoid having spaces in them\n",
        "# also we add a rating column at the end of the list to store the target variable\n",
        "df_columns = [\"posting_text\", \"rating\"]\n",
        "# Initialize DataFrame with column names\n",
        "df = pd.DataFrame(columns=df_columns)\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "for i in range(1, 108):\n",
        "  row_num = df.last_valid_index()\n",
        "  print(row_num)\n",
        "  if row_num == None:\n",
        "    row_num = 0\n",
        "  else:\n",
        "    row_num = row_num + 1\n",
        "  assert i == row_num + 1\n",
        "  text_file_path = f'drive/MyDrive/text_files2/row{i}.txt'\n",
        "  with open(text_file_path, 'r') as file:\n",
        "    # Read the entire content of the file into a string\n",
        "    file_contents = file.read()\n",
        "  df.at[row_num, 'posting_text'] = file_contents\n",
        "  rating = links_dataframe.loc[row_num, 'rating']\n",
        "  df.at[row_num, 'rating'] = rating\n",
        "\n",
        "import numpy as np\n",
        "# Replace 'N/A' with NaN in the whole DataFrame\n",
        "df.replace('N/A', np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0jhE7mCXAXn8",
        "outputId": "8f6a8ca8-a3e4-45a4-dd14-8cb19464a17f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 107,\n  \"fields\": [\n    {\n      \"column\": \"posting_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 107,\n        \"samples\": [\n          \"position is ML Ops Engineer\\ncompany is Apexon\\nlocation is Berkeley Heights, NJ\\nsalary is $130,000.00/yr - $140,000.00/yr\\n\\nSeniority level is Mid-Senior level\\nEmployment type is Full-time\\nJob function is Engineering, Information Technology, and Analyst\\nIndustries is IT Services and IT Consulting, Financial Services, and Banking\\n\\nJob Title: MLOps EngineerLocation: Berkeley Heights, NJ - 100% onsiteResponsibilities:Build, install, configure, manage, and scale state-of-the-art machine learning platform in the cloud (Azure preferred) and on-premises powering client\\u2019s Data and Analytics products and solutions.Work with data scientists, architects, DevOps engineers, and vendors to implement scalable ML/DL solutions in the cloud and on-premises to solve complex problems.Creating and maintaining ML/DL pipelines and overall ML/DL workflow orchestration including but not limited to data collection, prep, transform, analyze, experiment, train, validate, serve, monitor, etc.Implement ML/DL solutions addressing performance, scalability, and the governance/ traceability of machine learning models.Iterate quickly through the latest technologies, products, frameworks, and R&D on the latest information related to ML/DL frameworks, tools & services.Qualifications:Overall 10+ years\\u2019 experience delivering DevOps and MLOps in a Production/Enterprise setting.Excellent written and oral communication and presentation skills.Experienced in a technical role involving platform and infrastructure operation.System administration experience of Unix or Linux systems.Container-based deployment experience using Docker and Kubernetes.Proficient with the machine learning modeling lifecycle and comfortable addressing both functional and technical aspects of model deliveryExperience managing and deploying large distributed systems like Spark, DASK & H20, and heterogeneous platform components.Experienced with programming languages like Python or R and comfortable in understanding the statistical foundations of most used ML algorithms.Experienced with Machine Learning frameworks: Sci-kit, Keras, Theano, TensorFlow, SparkMlib, etc.Preferred hands-on experience with IBM Watson Machine Learning systems or related preferredPreferred hands-on experience with HPC \\u2013 Nvidia, CUDAPreferred experience with configuration Management tools like Ansible, puppetPreferred experience in monitoring and performance analysis of Machine Learning platforms using tools like Grafana and Zabbix.\",\n          \"position is C++ Quantitative Developer\\ncompany is Jobot\\nlocation is Indianapolis, IN\\nsalary is $100,000.00/yr - $175,000.00/yr\\n\\nSeniority level is Entry level\\nEmployment type is Full-time\\nJob function is Finance and Sales\\nIndustries is Staffing and Recruiting\\n\\n          Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!Job detailsTop Growing Global Markets Prop Trading Shop - Hiring Infrastructure/Systems EngineersThis Jobot Job is hosted by Ryan KilroyAre you a fit? Easy Apply now by clicking the \\\"Easy Apply\\\" button and sending us your resume.Salary $100,000 - $175,000 per yearA Bit About UsFounded over 45 years ago- we are a privately held global markets proprietary trading firm with offices in Chicago, Caribbean, and Europe. We use next generation technology to capture opportunities around the world and manage risk in financial markets. Our mission is to bless others through the services we provide and through generous stewardship of the wealth we create.We are a well-established and profitable business as a respected member of the global financial system for over 40 years, but also is like a startup because the potential of our group is at least one order of magnitude greater than what we are currently producing. We have an entrepreneurial culture and collaboratively develop our business with patience and discipline; we work hard, learn constantly, and relentlessly improve our expertise.Why join us?What Sets Us ApartCultural Excellence Join a team that thrives on collaboration, creativity, and mutual respect. Our inclusive culture fosters an environment where every voice is heard.Growth Opportunities Your career matters to us. With our investment in employee development, you'll have the resources and support to reach new heights in your professional journey.Innovation at Its Core [Company Name] is synonymous with innovation. As a member of our Core Team, you'll be at the forefront of defining and refining the next generation of automated trading technology.Stability and Retention We're more than an employer; we're a community. We offer stability, excellent benefits, and a culture that values long-term commitment, ensuring your career flourishes with us.Job DetailsResponsibilitiesPinnacle Libraries Design and implement network connectivity, specialized containers, market data, and execution libraries that form the backbone of our automated trading platform.Performance Excellence Enhance existing components for improved performance and enhanced stability, elevating our trading capabilities.Strategic Synergy Collaborate closely with our strategy teams, understanding their utilization of your libraries to anticipate and deliver future enhancements.Data Empowerment Develop and support production-quality components that employ your libraries, enabling data collection and back testing of trading strategies.Sustainment & Expansion Maintain existing applications and exchange connectivity, ensuring seamless trading operations.Tools of the Trade C++, Python, Bash, C#, Linux, SQL, network programmingRequirementsMasterful Foundation Master's degree in Computer Science, Computer Engineering, Informatics, Bioinformatics, or Technology, plus 2 years of software engineering experience. Alternatively, a Bachelor's degree with 5 years of experience.Exchange Expertise Prior experience in implementing exchange connectivity with major Exchanges.Algorithmic Acumen Experience with algorithmic trading strategy teams is a plus, including system design for strategy backtesting.Technological Proficiency Expertise in C++, Multithreading, IPC, Automated testing, benchmarking, Low latency containers, Linux, OnLoad network stack.Scripting & Integration Proficiency in Python and/or Bash scripting, SQL, C#, and CI/CD pipelines in Gitlab preferred.Onsite Innovator This role requires physical presence and is onsite (no remote work).Elevate with UsJoin the [Company Name] team to redefine the landscape of automated trading technology within a thriving investment bank. Apply now to steer our low latency systems to new heights. Your expertise will be the driving force in enhancing our trading prowess and maintaining our reputation for excellence. As part of our esteemed culture, you'll experience career growth, stability, and the opportunity to make your mark on the financial world.Interested in hearing more? Easy Apply now by clicking the \\\"Easy Apply\\\" button.Want to learn more about this role and Jobot?Click our Jobot logo and follow our LinkedIn page!\",\n          \"position is Software Engineer in Test\\ncompany is Optomi\\nlocation is Dallas-Fort Worth Metroplex\\nsalary is N/A\\n\\nSeniority level is Mid-Senior level\\nEmployment type is Full-time\\nJob function is Engineering, Quality Assurance, and Information Technology\\nIndustries is IT Services and IT Consulting\\n\\nThe SDET will participate in test plan design, test case development and execution, and test automation development of large-scale, distributed software applications, systems and services.**MUST be local to Plano, TX. MUST need to know how to code in Java and have proven experience in deploying tests to AWS.ResponsibilitiesBuild and maintain an automated test infrastructure for a large-scale microservice-oriented system comprising of many componentsWrite, execute and maintain end-to-end system integration scenarios and user acceptance scenarios for the large-scale platformCollaborate with other business groups and external teams for end-to-end integrationPartner with developers to create, maintain and execute automated unit and integration testsCollaborate with DevOps to integrate the automated tests in the CI/CD pipelinesRequirements:You have 5+ years of hands-on experience creating and maintaining test automation and associated infrastructureYou have proficiency in coding in JavaYou are very fluent and have solved several real-life problems using TestNG or JUnitYou are very fluent at maintaining and utilizing a collection of API testsYou have experience in setting up test pipelines in CI/CD toolsYou have experience with testing complex data pipelines that span over multiple componentsProficiency in testing serverless-based architecture and testing on AWSYou have experience deploying tests in AWS, using AWS services such as dynamoDB, S3, Lambda, etc.You are experienced in using systems like Jira or qTest for tracking purposes and ensuring traceability among test cases, code, and requirements\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"0\",\n        \"max\": \"3\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2\",\n          \"0\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0afbc984-9e87-49f2-b4f2-3d7c63dee885\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posting_text</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>position is Python Software Engineer (Robotics...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>position is Robotics Engineer – Surgical Robot...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>position is SDE - Amazon Robotics, Robotic\\nco...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>position is Senior Software Engineer\\ncompany ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>position is Software Engineer in Test\\ncompany...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0afbc984-9e87-49f2-b4f2-3d7c63dee885')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0afbc984-9e87-49f2-b4f2-3d7c63dee885 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0afbc984-9e87-49f2-b4f2-3d7c63dee885');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0b251f71-e716-43e5-9715-e91b27294359\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b251f71-e716-43e5-9715-e91b27294359')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0b251f71-e716-43e5-9715-e91b27294359 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                        posting_text rating\n",
              "0  position is Python Software Engineer (Robotics...      1\n",
              "1  position is Robotics Engineer – Surgical Robot...      2\n",
              "2  position is SDE - Amazon Robotics, Robotic\\nco...      2\n",
              "3  position is Senior Software Engineer\\ncompany ...      3\n",
              "4  position is Software Engineer in Test\\ncompany...      1"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLsAuG4QAki7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataframe is named 'df' and the text column is named 'job_posting_text'\n",
        "\n",
        "# Step 1: Split your data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['posting_text'], df['rating'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Initialize and fit TF-IDF vectorizer on the training data only\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Step 3: Transform the test data using the fitted vectorizer\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Now you have X_train_tfidf and X_test_tfidf ready to be used with your model for training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYCeM16PBD4q",
        "outputId": "cdf5fd52-6319-4e51-e09d-731e04b77de6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 3939)\t0.0373744056531433\n",
            "  (0, 789)\t0.019974819862403716\n",
            "  (0, 2143)\t0.03407334904495879\n",
            "  (0, 4919)\t0.04202698362959349\n",
            "  (0, 900)\t0.028800367591366886\n",
            "  (0, 4400)\t0.03007664495773516\n",
            "  (0, 4423)\t0.01468711785621911\n",
            "  (0, 2373)\t0.021790387977360177\n",
            "  (0, 2692)\t0.033154885454750205\n",
            "  (0, 1756)\t0.024350886406621863\n",
            "  (0, 3443)\t0.027651943014806373\n",
            "  (0, 2706)\t0.05463319619067838\n",
            "  (0, 3451)\t0.049980618214228195\n",
            "  (0, 2945)\t0.046679561606043675\n",
            "  (0, 2065)\t0.046679561606043675\n",
            "  (0, 3119)\t0.05463319619067838\n",
            "  (0, 499)\t0.05463319619067838\n",
            "  (0, 3160)\t0.02821179400751259\n",
            "  (0, 3732)\t0.05463319619067838\n",
            "  (0, 4263)\t0.05463319619067838\n",
            "  (0, 2671)\t0.049980618214228195\n",
            "  (0, 865)\t0.05463319619067838\n",
            "  (0, 2813)\t0.04025815557589126\n",
            "  (0, 2268)\t0.023182963661950395\n",
            "  (0, 3166)\t0.03872592702140898\n",
            "  :\t:\n",
            "  (84, 4554)\t0.1259849102063429\n",
            "  (84, 4344)\t0.03335015236630473\n",
            "  (84, 2967)\t0.031200334514116027\n",
            "  (84, 3989)\t0.027722212643870023\n",
            "  (84, 2282)\t0.009579109295730632\n",
            "  (84, 1801)\t0.05024099406657479\n",
            "  (84, 405)\t0.4502181368993397\n",
            "  (84, 4460)\t0.03424533735838453\n",
            "  (84, 2288)\t0.024521753973296607\n",
            "  (84, 2076)\t0.009804510502205786\n",
            "  (84, 2370)\t0.02907344081684836\n",
            "  (84, 4544)\t0.009804510502205786\n",
            "  (84, 2073)\t0.009919231745188828\n",
            "  (84, 4661)\t0.009579109295730632\n",
            "  (84, 1760)\t0.009579109295730632\n",
            "  (84, 2477)\t0.009579109295730632\n",
            "  (84, 3964)\t0.009579109295730632\n",
            "  (84, 3831)\t0.019158218591461263\n",
            "  (84, 2543)\t0.019158218591461263\n",
            "  (84, 4452)\t0.017920869312893526\n",
            "  (84, 1074)\t0.019158218591461263\n",
            "  (84, 1793)\t0.027377010176758265\n",
            "  (84, 4373)\t0.05297523463366402\n",
            "  (84, 2359)\t0.10537020225303695\n",
            "  (84, 3170)\t0.009579109295730632\n"
          ]
        }
      ],
      "source": [
        "print(X_train_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmYP4bsgA6wz",
        "outputId": "afee13a2-d1cc-4d30-8f0a-5bd269c4ca6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.48080695505940163\n",
            "accuracy is 0.5454545454545454\n"
          ]
        }
      ],
      "source": [
        "regression_model = LinearRegression()\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing data\n",
        "# Train a regression model instead of SVM classifier\n",
        "regression_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regression_model.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test.tolist(), y_pred_rounded)\n",
        "\n",
        "print(\"accuracy is\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ2h4koPDPcU"
      },
      "source": [
        "Let's try the Random Forest Classifier. The hyperparameters we declare are probably sub-optimal, but let's see what performance we get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "k5UZThHNDhL5",
        "outputId": "592d295f-e051-44e4-fc55-9334834030d4"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Unknown label type: 'unknown'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-7b09ba906ac8>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Train the classifier on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrf_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Test the classifier on the testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     ]:\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'unknown'"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(max_depth=None, max_features='auto', min_samples_leaf=1, min_samples_split=2, n_estimators=300)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mae:\", mae)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r2vQck8EHFZ"
      },
      "source": [
        "We are getting an error, likely because we need to one hot encode the target classes. Maybe RandomForestRegressor will work straight away."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyKNE0_0EUXR",
        "outputId": "c8639bec-1c71-4410-ffb7-aa64fd5bc8e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mae: 0.5218181818181818\n",
            "[2.41       2.06666667 2.06333333 1.53333333 2.04333333 1.17333333\n",
            " 1.85666667 2.04333333 2.09       2.35666667 1.89666667 1.90666667\n",
            " 2.05       2.18666667 2.17       1.66333333 1.19666667 2.25666667\n",
            " 1.34666667 1.96333333 1.40666667 1.76666667]\n",
            "accuracy is 0.5\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestRegressor(max_depth=None, max_features='auto', min_samples_leaf=1, min_samples_split=2, n_estimators=300)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(X_test_tfidf)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mae:\", mae)\n",
        "print(y_pred)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test.tolist(), y_pred_rounded)\n",
        "\n",
        "print(\"accuracy is\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7bbRmRmEr41"
      },
      "source": [
        "We got a worse MAE and worse accuracy with Random Forest compared to Linear Regression. Still, so far Random Forest with our prior feature engineering approach worked better, but interestingly, linear regression had less error with this feature engineering. As far as small tweaks to our feature engineering, what can we do? For the sake of keeping our experiments controlled it only seems fair to compare linear regression between the feature engineering approaches on only the data representing text. Which means we should return to our previous feature engineering to look at performance after dropping the salary related columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytXP7_gIKkWI",
        "outputId": "f4e7a7e0-f3b1-443d-de89-d3cb8158fa97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 4350137205195.5938\n",
            "accuracy is 0.13636363636363635\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "columns_to_drop = ['min_salary', 'max_salary']\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing data\n",
        "# Train a regression model instead of SVM classifier\n",
        "regression_model.fit(train_df.drop(columns_to_drop, axis=1), y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regression_model.predict(test_df.drop(columns_to_drop, axis=1))\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "\n",
        "print(\"accuracy is\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "I-a4UOJiSyPW",
        "outputId": "8ffbb2d8-4e47-42e7-803c-0c761531780b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-78058deb-474f-4db4-8ada-1b26c8c5a765\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min_salary</th>\n",
              "      <th>max_salary</th>\n",
              "      <th>AR</th>\n",
              "      <th>AZ</th>\n",
              "      <th>CA</th>\n",
              "      <th>CO</th>\n",
              "      <th>FL</th>\n",
              "      <th>GA</th>\n",
              "      <th>IA</th>\n",
              "      <th>IL</th>\n",
              "      <th>...</th>\n",
              "      <th>work_arrangement_cluster0_counts</th>\n",
              "      <th>work_arrangement_cluster1_counts</th>\n",
              "      <th>work_arrangement_cluster2_counts</th>\n",
              "      <th>work_arrangement_cluster3_counts</th>\n",
              "      <th>work_arrangement_cluster4_counts</th>\n",
              "      <th>work_arrangement_cluster5_counts</th>\n",
              "      <th>work_arrangement_cluster6_counts</th>\n",
              "      <th>work_arrangement_cluster7_counts</th>\n",
              "      <th>work_arrangement_cluster8_counts</th>\n",
              "      <th>work_arrangement_cluster9_counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>150.000</td>\n",
              "      <td>200.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>100.000</td>\n",
              "      <td>175.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150.000</td>\n",
              "      <td>200.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>98.144</td>\n",
              "      <td>216.646</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>150.000</td>\n",
              "      <td>200.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 591 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78058deb-474f-4db4-8ada-1b26c8c5a765')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78058deb-474f-4db4-8ada-1b26c8c5a765 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78058deb-474f-4db4-8ada-1b26c8c5a765');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-70e44130-db61-4e04-af23-e4cd3a777da3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-70e44130-db61-4e04-af23-e4cd3a777da3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-70e44130-db61-4e04-af23-e4cd3a777da3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    min_salary  max_salary  AR  AZ  CA  CO  FL  GA  IA  IL  ...  \\\n",
              "76     150.000     200.000   0   0   0   0   0   0   0   0  ...   \n",
              "10     100.000     175.000   0   0   0   0   0   0   0   0  ...   \n",
              "4      150.000     200.000   0   0   0   0   0   0   0   0  ...   \n",
              "99      98.144     216.646   0   0   0   0   0   0   0   0  ...   \n",
              "70     150.000     200.000   0   0   0   0   0   0   0   0  ...   \n",
              "\n",
              "    work_arrangement_cluster0_counts  work_arrangement_cluster1_counts  \\\n",
              "76                                 0                                 0   \n",
              "10                                 0                                 1   \n",
              "4                                  0                                 1   \n",
              "99                                 0                                 0   \n",
              "70                                 0                                 0   \n",
              "\n",
              "    work_arrangement_cluster2_counts  work_arrangement_cluster3_counts  \\\n",
              "76                                 0                                 0   \n",
              "10                                 1                                 0   \n",
              "4                                  1                                 0   \n",
              "99                                 0                                 0   \n",
              "70                                 0                                 0   \n",
              "\n",
              "    work_arrangement_cluster4_counts  work_arrangement_cluster5_counts  \\\n",
              "76                                 0                                 0   \n",
              "10                                 0                                 0   \n",
              "4                                  0                                 0   \n",
              "99                                 0                                 0   \n",
              "70                                 0                                 0   \n",
              "\n",
              "    work_arrangement_cluster6_counts  work_arrangement_cluster7_counts  \\\n",
              "76                                 0                                 0   \n",
              "10                                 0                                 0   \n",
              "4                                  0                                 0   \n",
              "99                                 0                                 0   \n",
              "70                                 0                                 0   \n",
              "\n",
              "    work_arrangement_cluster8_counts  work_arrangement_cluster9_counts  \n",
              "76                                 0                                 0  \n",
              "10                                 0                                 0  \n",
              "4                                  0                                 0  \n",
              "99                                 0                                 0  \n",
              "70                                 0                                 0  \n",
              "\n",
              "[5 rows x 591 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg0McbZOSkIZ",
        "outputId": "d2f631dd-b073-46e0-d9e5-6bf69405b40d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "67     1\n",
            "26     0\n",
            "22     0\n",
            "31     2\n",
            "56     0\n",
            "      ..\n",
            "71     3\n",
            "14     3\n",
            "92     3\n",
            "51     2\n",
            "102    2\n",
            "Name: rating, Length: 85, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8uAzcGYR8Qt"
      },
      "source": [
        "For whatever reason, after removing salary columns and retraining with the phrase embeddings approach, our linear regression model does horribly. What gives?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqal5t_1SXF0",
        "outputId": "fe9af4fc-8d6a-4cc7-f5f0-29ab3586ecfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-2638444314662, -11275575189525, -14264255959781, -774336536416, 2, -2684597667757, -5465579651208, -5394191180100, -2684597667757, -2752689022538, -673726584503, -13090419055087, -6164012217811, 2, -6635616896670, -263092574890, 2, 2, 2, -3799614135099, -12194395535416, 4947874325051]\n"
          ]
        }
      ],
      "source": [
        "print(y_pred_rounded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg6oxMh2TUJE"
      },
      "source": [
        "Maybe we need to apply a standard scaler to our data, because not having the salary columns is causing major issues for the linear regression model, which kind of makes sense given that they are the only truly numerical columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwmGWblcTyDT",
        "outputId": "55470448-1a1e-4574-9978-44dff8b0c698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 2298139031768.334\n",
            "accuracy is 0.13636363636363635\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "regression_model = LinearRegression()\n",
        "# Initialize StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "columns_to_drop = ['min_salary', 'max_salary']\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are your training and testing data\n",
        "# Train a regression model instead of SVM classifier\n",
        "\n",
        "X_train = train_df.drop(columns_to_drop, axis=1)\n",
        "X_test = test_df.drop(columns_to_drop, axis=1)\n",
        "\n",
        "# Fit the scaler on the training data and transform both training and test data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "regression_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regression_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Round the predictions\n",
        "y_pred_rounded = [round(pred) for pred in y_pred]\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "\n",
        "print(\"accuracy is\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "752u-peSU12q"
      },
      "source": [
        "This is even worse. Let's try the Random Forest with no salary columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDimwY5VVMVr",
        "outputId": "d3b50527-7ebb-43ce-e5a7-d50cb44cfe89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mae: 0.45454545454545453\n",
            "accuracy is 0.5909090909090909\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(max_depth=None, max_features='auto', min_samples_leaf=1, min_samples_split=2, n_estimators=300)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mae:\", mae)\n",
        "\n",
        "# Calculate accuracy using the rounded predictions and actual target values\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"accuracy is\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTAUfhF2VmOe"
      },
      "source": [
        "So phrase embeddings or TFIDF? We still haven't gotten a definitive answer."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05cea2751e3d48ef8b19a6cd59251cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08838b80e51542c193247c2e964dba12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0edfad61528e4497ba54ddce869cb46b",
            "placeholder": "​",
            "style": "IPY_MODEL_df4a3f1952ac47038ab80a2a69c41d58",
            "value": " 670M/670M [00:07&lt;00:00, 78.5MB/s]"
          }
        },
        "094056fcc97941a0bb7d9523917b5e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e1a8db993844266a9c10f5328debd59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdebfcd1592e40e0b82e06c3fd27dfee",
              "IPY_MODEL_609d5691aabf4b6b9b55888b19b1cbc2",
              "IPY_MODEL_0ef8e78e195741719bc5e7733e9e9eec"
            ],
            "layout": "IPY_MODEL_094056fcc97941a0bb7d9523917b5e9f"
          }
        },
        "0e253b7723114d3babab10c41eb6d494": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0edfad61528e4497ba54ddce869cb46b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ef8e78e195741719bc5e7733e9e9eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6613cf44acff41c4906d397a37212da3",
            "placeholder": "​",
            "style": "IPY_MODEL_8462f524daf84ae9bf61906528f46b53",
            "value": " 232k/232k [00:00&lt;00:00, 2.45MB/s]"
          }
        },
        "14870ebc6f474eb8a758c246aac860b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16c11f8ff03c48cdb841fddeab29da6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6f2d8e6c3404cb986bb68e272d357aa",
              "IPY_MODEL_91d660e6544d4539b3183682c3756da8",
              "IPY_MODEL_930d71535cf640fa81849eeaf06f13f5"
            ],
            "layout": "IPY_MODEL_d0201d9f2f194230b37e8a8eff1a5e23"
          }
        },
        "1e11858eedb74e1d83511f4a8d71a4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebb6876bceca4313a8b02ccf42517dba",
              "IPY_MODEL_250f7bcc862c46808ea3247acf02ec76",
              "IPY_MODEL_c509e26d1ea34267b61bb21e5ad3f0d3"
            ],
            "layout": "IPY_MODEL_e423b33c22aa4ae681edf96326becbb2"
          }
        },
        "248989e5950b41359a0a4db2ddae5e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "250f7bcc862c46808ea3247acf02ec76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94bf1fc22ecf4742a22b5e4341bdbf47",
            "max": 670332568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cfefdc8982e440381417cea4b08a308",
            "value": 670332568
          }
        },
        "26a58318089b47e2924cb56309e328bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2738ef58041347b784638de6bcf63a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e253b7723114d3babab10c41eb6d494",
            "placeholder": "​",
            "style": "IPY_MODEL_14870ebc6f474eb8a758c246aac860b9",
            "value": "config.json: 100%"
          }
        },
        "279189017e5a4910aeed8e1cbbd3f09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fc74b89464748d79edf3daf0a9ae7a0",
            "placeholder": "​",
            "style": "IPY_MODEL_7274e9fda8824c308fa3500479d65f58",
            "value": " 712k/712k [00:00&lt;00:00, 2.72MB/s]"
          }
        },
        "28b8699a575a456c9100474092c922e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b80923582949128a306c78fefde2e9",
            "placeholder": "​",
            "style": "IPY_MODEL_a642ca0966cd44e8bbb69b13e79ba01a",
            "value": " 125/125 [00:00&lt;00:00, 3.83kB/s]"
          }
        },
        "2c86771d6b94401b9648dcb009b4d484": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2db4cd5154a346858bd7025fd54bcb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3074bbc2aa2e49379053d93f5676c05b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3598f566a3424d638eabde520018d76f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37e03d8587c34545b4b45130035ab3c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c995ab9ec9e948519b9dc6a1100e4b32",
              "IPY_MODEL_c86eb8be076a47fca8d6c376dc199d64",
              "IPY_MODEL_a851782de0e74d769643a5f034506602"
            ],
            "layout": "IPY_MODEL_3074bbc2aa2e49379053d93f5676c05b"
          }
        },
        "3ae5834b0f82407fb98d07ea4e52c8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcee6dd17e4840cea7dd90e8eac8112d",
              "IPY_MODEL_f8c66e840ecf49bd86aa0e9ab0a3651a",
              "IPY_MODEL_5ebf77738c3e4cdf8dec22198ad4eb41"
            ],
            "layout": "IPY_MODEL_cd104025953b4359ac283e969a2b579b"
          }
        },
        "3bcde355f8634868bfc227929e3bb42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3da0019237b243b780acef6d0f22f37a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eb10357400346f5875edc353b400c8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42c41d83887e4530a0fa9a778c809a5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45a190c36e4a47cea541fd153880385d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1c9d64614ca4a3397b51f110d9ad2ef",
            "max": 619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8835e39eaa6d4bc8affe7886742eee78",
            "value": 619
          }
        },
        "46518caac64c4a2ba98131fcd66326f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8fc22bdc3f1401f9e68223d5a37de01",
            "placeholder": "​",
            "style": "IPY_MODEL_2db4cd5154a346858bd7025fd54bcb09",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4be6a679bfb44a44b02ac04583fc3a20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cfefdc8982e440381417cea4b08a308": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d5c5e00063a4903a26e3df8bf18c899": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f6b84d076b04e36956e5ef1b75284cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5484f2b27d3a44db8667246d19fcae52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56f485276f6e4818a45033bd0aa35f28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "572f74ebed604fa6bea72afd5e8742c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "585f9b9684b246b69bff4d2625a3f732": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fde057fbd7904c2ba2f3157555e260b6",
            "placeholder": "​",
            "style": "IPY_MODEL_a598316d50114db39532309d9c1f6ceb",
            "value": " 619/619 [00:00&lt;00:00, 31.9kB/s]"
          }
        },
        "5bb882ae35664d14a8aab0ed77e89608": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc0554f42bf43e2aa0bc85da4d6aadb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d4c529834ce4ed78e1f2ca767bfbff8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e86a8753c8649a3b80f31b58fc5d2f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4be6a679bfb44a44b02ac04583fc3a20",
            "max": 711661,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b048daa757e45259595abe80b56849a",
            "value": 711661
          }
        },
        "5ebf77738c3e4cdf8dec22198ad4eb41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a316d2cf0034d14bfeb57acf3bb1479",
            "placeholder": "​",
            "style": "IPY_MODEL_6556f139039c48919b49fe34c22b7e84",
            "value": " 232k/232k [00:00&lt;00:00, 5.49MB/s]"
          }
        },
        "609d5691aabf4b6b9b55888b19b1cbc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc24527bd3f6412189237de127c64b67",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6cc356f3f4443299b5e0b3c9b6dad82",
            "value": 231508
          }
        },
        "64a2f5bb769c4a159e707d22ed8aff15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6556f139039c48919b49fe34c22b7e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6613cf44acff41c4906d397a37212da3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b048daa757e45259595abe80b56849a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c332a3db4d2420c8146055129172319": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dc87f15a0b64eca8bf31234c800f8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e0c2a0459f144c28d426df9064fc4a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "716eca1540a34cad8a86cb75e68fe5ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7274e9fda8824c308fa3500479d65f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77345e0837034d21afd88761bf99cb52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77db1d0d07924f7fa0c649548c2ea20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_785541714ea8480296bd1e7135e0757b",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_572f74ebed604fa6bea72afd5e8742c5",
            "value": 125
          }
        },
        "781e682023664d3b80e42c6ee79f0c47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "785541714ea8480296bd1e7135e0757b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4829cb21704b06b003573e64b5d5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d00ca8b9c67340f2a05442ab16f725e9",
              "IPY_MODEL_77db1d0d07924f7fa0c649548c2ea20b",
              "IPY_MODEL_28b8699a575a456c9100474092c922e3"
            ],
            "layout": "IPY_MODEL_26a58318089b47e2924cb56309e328bc"
          }
        },
        "7dd279ca1a4d430c86b46637ca0cd52e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8189b9da85b248bd92b6bf9c5e3d867c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3da0019237b243b780acef6d0f22f37a",
            "max": 342,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bcde355f8634868bfc227929e3bb42f",
            "value": 342
          }
        },
        "8304a7fce13446dc8c8e84aa810597a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8462f524daf84ae9bf61906528f46b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8700f1089613406085f728586400a43d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87eb7c5ddd464ad7b6e0569fad7c2c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8835e39eaa6d4bc8affe7886742eee78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a1d553fbc8943339c946184a5e740d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6390d0d4ba24243b79094ef1b43cf59",
              "IPY_MODEL_45a190c36e4a47cea541fd153880385d",
              "IPY_MODEL_585f9b9684b246b69bff4d2625a3f732"
            ],
            "layout": "IPY_MODEL_8700f1089613406085f728586400a43d"
          }
        },
        "8c8245fe58cf440d94bd0c357efd7c64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f9f16d94f404bb09e0f276988946ccc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d660e6544d4539b3183682c3756da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dc87f15a0b64eca8bf31234c800f8cb",
            "max": 711661,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05cea2751e3d48ef8b19a6cd59251cfe",
            "value": 711661
          }
        },
        "930d71535cf640fa81849eeaf06f13f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c38173bb67bd422ab510eb77b176c8d4",
            "placeholder": "​",
            "style": "IPY_MODEL_afbc3d2150fc4aa0bf56eb8727efe662",
            "value": " 712k/712k [00:00&lt;00:00, 7.42MB/s]"
          }
        },
        "94bf1fc22ecf4742a22b5e4341bdbf47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9722ab19e772488fa29913b39ca77c9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97d515b654eb4e64a9bd892e7f514a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "981e8d8eb5314445bf25bf6dca552526": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3598f566a3424d638eabde520018d76f",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_248989e5950b41359a0a4db2ddae5e0a",
            "value": 125
          }
        },
        "9a316d2cf0034d14bfeb57acf3bb1479": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fc74b89464748d79edf3daf0a9ae7a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d3661d6cd142119fc3119f1de8b2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eb10357400346f5875edc353b400c8c",
            "placeholder": "​",
            "style": "IPY_MODEL_8304a7fce13446dc8c8e84aa810597a3",
            "value": " 619/619 [00:00&lt;00:00, 6.14kB/s]"
          }
        },
        "a25aa875d53448bcb2fdcfce02fc73e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9722ab19e772488fa29913b39ca77c9d",
            "placeholder": "​",
            "style": "IPY_MODEL_87eb7c5ddd464ad7b6e0569fad7c2c8f",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a598316d50114db39532309d9c1f6ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5a436be21e64472b04566292585772f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a642ca0966cd44e8bbb69b13e79ba01a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a645403deb474f289c34b95c5cac8533": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a25aa875d53448bcb2fdcfce02fc73e9",
              "IPY_MODEL_981e8d8eb5314445bf25bf6dca552526",
              "IPY_MODEL_f8cfaa7e154e4e0ab533a07d18f50079"
            ],
            "layout": "IPY_MODEL_5cc0554f42bf43e2aa0bc85da4d6aadb"
          }
        },
        "a6cc356f3f4443299b5e0b3c9b6dad82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a851782de0e74d769643a5f034506602": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e0c2a0459f144c28d426df9064fc4a2",
            "placeholder": "​",
            "style": "IPY_MODEL_d0c8839910d642afb20382cd2d03fbab",
            "value": " 342/342 [00:00&lt;00:00, 3.95kB/s]"
          }
        },
        "afadb7d47ca5462c88159d04d282a756": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afbc3d2150fc4aa0bf56eb8727efe662": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b21c99b5d76d4f64805a02d0e94188fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2be7f77fced4758afcdc9551e284339": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e0a1423be7463eb7991a336fff0497": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2738ef58041347b784638de6bcf63a9e",
              "IPY_MODEL_d77de8c82136466c9175e45c38521446",
              "IPY_MODEL_a1d3661d6cd142119fc3119f1de8b2e2"
            ],
            "layout": "IPY_MODEL_cba2026e8b1a45ceb63253e79dfd2402"
          }
        },
        "b66be90ca504470ca479c8b1c91f7a20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdebfcd1592e40e0b82e06c3fd27dfee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56f485276f6e4818a45033bd0aa35f28",
            "placeholder": "​",
            "style": "IPY_MODEL_d9d5b446a43d4815b8a44ccfaf749247",
            "value": "vocab.txt: 100%"
          }
        },
        "beab1d51be68467ea2576bd34d4d9c24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c092cd76cf2c4e958163ce0a54a75624": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d4ebc9801b4ddc85628a7a7b00a5c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3491bdef5a64858abe4f3b175619e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca927467b3d041329d4c486e4aebdea1",
              "IPY_MODEL_5e86a8753c8649a3b80f31b58fc5d2f5",
              "IPY_MODEL_279189017e5a4910aeed8e1cbbd3f09a"
            ],
            "layout": "IPY_MODEL_5d4c529834ce4ed78e1f2ca767bfbff8"
          }
        },
        "c38173bb67bd422ab510eb77b176c8d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c38dfeee5e26454a8e309e78f5142ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c509e26d1ea34267b61bb21e5ad3f0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d126b92c8b2b4501af977738030a4a5b",
            "placeholder": "​",
            "style": "IPY_MODEL_c6ea76a53dc64a9ea52c77e004f9a979",
            "value": " 670M/670M [00:16&lt;00:00, 33.6MB/s]"
          }
        },
        "c6ea76a53dc64a9ea52c77e004f9a979": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6fe69a140e446b180d7ad902bf96f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b21c99b5d76d4f64805a02d0e94188fa",
            "max": 670332568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97d515b654eb4e64a9bd892e7f514a23",
            "value": 670332568
          }
        },
        "c86eb8be076a47fca8d6c376dc199d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2be7f77fced4758afcdc9551e284339",
            "max": 342,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64a2f5bb769c4a159e707d22ed8aff15",
            "value": 342
          }
        },
        "c8fc22bdc3f1401f9e68223d5a37de01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c995ab9ec9e948519b9dc6a1100e4b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9d1aef86724446a9090a435a4b58af9",
            "placeholder": "​",
            "style": "IPY_MODEL_afadb7d47ca5462c88159d04d282a756",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ca927467b3d041329d4c486e4aebdea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b66be90ca504470ca479c8b1c91f7a20",
            "placeholder": "​",
            "style": "IPY_MODEL_4f6b84d076b04e36956e5ef1b75284cd",
            "value": "tokenizer.json: 100%"
          }
        },
        "cba2026e8b1a45ceb63253e79dfd2402": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cca6cc2f3f3046d8836aef6d21348dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd104025953b4359ac283e969a2b579b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d00ca8b9c67340f2a05442ab16f725e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42c41d83887e4530a0fa9a778c809a5e",
            "placeholder": "​",
            "style": "IPY_MODEL_c38dfeee5e26454a8e309e78f5142ea5",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d0201d9f2f194230b37e8a8eff1a5e23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0c8839910d642afb20382cd2d03fbab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d126b92c8b2b4501af977738030a4a5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2e0777a877946209a5e445b5800ce15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_716eca1540a34cad8a86cb75e68fe5ca",
            "placeholder": "​",
            "style": "IPY_MODEL_cca6cc2f3f3046d8836aef6d21348dd0",
            "value": "model.safetensors: 100%"
          }
        },
        "d52d2a2f701b486698cdc2eb6bd6c2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46518caac64c4a2ba98131fcd66326f5",
              "IPY_MODEL_8189b9da85b248bd92b6bf9c5e3d867c",
              "IPY_MODEL_e1187541c7d54ebfae8d864f9251c043"
            ],
            "layout": "IPY_MODEL_2c86771d6b94401b9648dcb009b4d484"
          }
        },
        "d6390d0d4ba24243b79094ef1b43cf59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_781e682023664d3b80e42c6ee79f0c47",
            "placeholder": "​",
            "style": "IPY_MODEL_a5a436be21e64472b04566292585772f",
            "value": "config.json: 100%"
          }
        },
        "d6f2d8e6c3404cb986bb68e272d357aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c8245fe58cf440d94bd0c357efd7c64",
            "placeholder": "​",
            "style": "IPY_MODEL_e5a33594ecfb4b0cb5c01df8a461b2b1",
            "value": "tokenizer.json: 100%"
          }
        },
        "d77de8c82136466c9175e45c38521446": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f9f16d94f404bb09e0f276988946ccc",
            "max": 619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dd279ca1a4d430c86b46637ca0cd52e",
            "value": 619
          }
        },
        "d9d1aef86724446a9090a435a4b58af9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d5b446a43d4815b8a44ccfaf749247": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da8d58d0783b4beeabcd6f6ec5987a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df4a3f1952ac47038ab80a2a69c41d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1187541c7d54ebfae8d864f9251c043": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beab1d51be68467ea2576bd34d4d9c24",
            "placeholder": "​",
            "style": "IPY_MODEL_da8d58d0783b4beeabcd6f6ec5987a90",
            "value": " 342/342 [00:00&lt;00:00, 17.5kB/s]"
          }
        },
        "e423b33c22aa4ae681edf96326becbb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a33594ecfb4b0cb5c01df8a461b2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebb6876bceca4313a8b02ccf42517dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77345e0837034d21afd88761bf99cb52",
            "placeholder": "​",
            "style": "IPY_MODEL_4d5c5e00063a4903a26e3df8bf18c899",
            "value": "model.safetensors: 100%"
          }
        },
        "f1c9d64614ca4a3397b51f110d9ad2ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4a7bf080192418993ba6e6f1523a86e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4b80923582949128a306c78fefde2e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ff7a27ad8e4f5d8365946912e022f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8c66e840ecf49bd86aa0e9ab0a3651a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c092cd76cf2c4e958163ce0a54a75624",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4a7bf080192418993ba6e6f1523a86e",
            "value": 231508
          }
        },
        "f8cfaa7e154e4e0ab533a07d18f50079": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ff7a27ad8e4f5d8365946912e022f7",
            "placeholder": "​",
            "style": "IPY_MODEL_6c332a3db4d2420c8146055129172319",
            "value": " 125/125 [00:00&lt;00:00, 4.52kB/s]"
          }
        },
        "fa55045d4fd14deca3e8de8dc0448bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2e0777a877946209a5e445b5800ce15",
              "IPY_MODEL_c6fe69a140e446b180d7ad902bf96f59",
              "IPY_MODEL_08838b80e51542c193247c2e964dba12"
            ],
            "layout": "IPY_MODEL_c1d4ebc9801b4ddc85628a7a7b00a5c1"
          }
        },
        "fc24527bd3f6412189237de127c64b67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcee6dd17e4840cea7dd90e8eac8112d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bb882ae35664d14a8aab0ed77e89608",
            "placeholder": "​",
            "style": "IPY_MODEL_5484f2b27d3a44db8667246d19fcae52",
            "value": "vocab.txt: 100%"
          }
        },
        "fde057fbd7904c2ba2f3157555e260b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
